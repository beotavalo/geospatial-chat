[
    {
        "question": "1. What is a land survey?",
        "area": "surveying",
        "text": "A land survey is a report in the form of a map showing the location of a parcel of real property. The map will also show the location of visible improvements on and adjacent to the property."
    },
    {
        "question": "2. Why are land surveys so important?",
        "area": "surveying",
        "text": "Prior to the closing on your new home purchase, a land survey provides important information to you as the buyer. The survey map will show the limits of the land you are purchasing and identify any conflicts in your deed. It will also allow you to see if improvements such as driveways, fences, wells or even dwellings encroach over the property lines. Any existing property corner markers found by the surveyor will also be shown on the map."
    },
    {
        "question": "3. How is a land survey performed?",
        "area": "surveying",
        "text": "The land surveyor's responsibility is to locate on the ground the boundaries of the land described in the deed. The surveyor also examines and maps various visible and apparent man-made and natural features as required for the purpose of the survey. Recorded deeds and maps are investigated along with the information and documentation supplied to the surveyor by the owner or title company. Additionally, extensive data gathering is preformed at and around the site."
    },
    {
        "question": "4. Why have I been asked if I want property markers set?",
        "area": "surveying",
        "text": "In the course of performing a survey in New Jersey, State law requires that a land surveyor place permanent markers at all property corners where none currently exist. You may sign a written waiver instructing the surveyor to omit this work."
    },
    {
        "question": "5. Why should I not waive the marking of property corners?",
        "area": "surveying",
        "text": "Boundary lines shown on a survey map of the property may be difficult to locate accurately on the ground without markers denoting the corners of the property. Placing markers helps to avoid future disputes and enables you to identify the physical location of your property."
    },
    {
        "question": "6. Who can do a land survey?",
        "area": "surveying",
        "text": "In New Jersey a land survey may only be performed and signed by a licensed Professional Land Surveyor."
    },
    {
        "question": "7. What is required to become a Professional Land Surveyor?",
        "area": "surveying",
        "text": "To meet the qualifications for licensure in New Jersey, an individual must have a four year college degree in Surveying, three years or more of practical experience, and pass a 16 hour written examination administered by the New Jersey Division of Consumer Affairs. Once licensed, the Professional Land Surveyor must obtain 24 hours of continuing education credits every two years to maintain active status."
    },
    {
        "question": "8. How does a land survey help identify title to property?",
        "area": "surveying",
        "text": "Land surveys identify the record title lines of your property. The survey map shows the limits of the land that you are purchasing. A land survey certified to you provides critical information which, when used with title insurance, allows the buyer to make informed decisions and negotiate with the seller to correct any defects prior to the purchase. A land survey prepared for you and certified to you and to your title company affords important protection against claims which may arise after the closing."
    },
    {
        "question": "9. What is title insurance and how does a land survey expand its coverage?",
        "area": "surveying",
        "text": "Title insurance protects the mortgage lender and the property owner (if insured) against claims to the property such as a disputed property boundary line. Most mortgage lenders require the home buyer to purchase a title insurance policy in the lender's name. This is called a Lender's policy.Title insurance policies do not provide coverage for encroachments, easements and boundary line disputes which would be disclosed by a current certified survey. This is known as the Survey Exception. Mortgage lenders routinely require a Survey Endorsement to their loan policies which limits the scope of the Survey Exception to the specific problems disclosed by the survey. In other words, a Survey Endorsement provides coverage against possible undiscovered problems involving encroachments, easements and boundary line disputes."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "To protect yourselves as home buyers you should insist on an Owner's Policy with a Survey Endorsement based on a professionally prepared current land survey."
    },
    {
        "question": "10. What can you do to protect the investment in you home?",
        "area": "surveying",
        "text": "Buying a home is usually the single largest purchase you will ever make! It makes sound financial sense as well as good common sense to protect this important asset. A land survey prepared by a licensed Profession Land Surveyor is a cornerstone of protection and preservation of home ownership. Remember, a lender's Policy protects the bank but not the homeowner. As you make the major investment of purchasing a home you should insist on an Owner's Policy of Title Insurance with the Survey Endorsement and a current land survey certified to you."
    },
    {
        "question": "1) What is a land or property survey?",
        "area": "surveying",
        "text": "In the simplest terms, a land survey is a graphic depiction of a property, much like a map, outlining its"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "legal boundaries and other features. Land surveys are typically required during real estate transactions and are an extremely useful tool to best understand a property and its improvements at the time of the survey. While not always the case, surveys are typically ordered and paid for by the property owner during the property purchase process."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Topography Surveys:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Different from a common land survey and not required at the closing of a real estate transaction, a topographic survey gathers data about the elevation of points on a piece of land and presents them as contour lines on a plot. The purpose of a topographic survey is to collect survey data about the natural and man-made features of the property, as well as its elevations."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Topographic maps are used to show elevations and grading features for architects, engineers,"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "and building contractors in addition to the land survey."
    },
    {
        "question": "2) Who owns the survey?",
        "area": "surveying",
        "text": "Property owners are responsible for purchasing and storing a property survey. It is not a municipal document and therefore the City of Summit neither generates nor is required to keep a current copy of a property survey on file. It is ordered by, paid for, and kept by the property owner."
    },
    {
        "question": "3) How are land surveys created?",
        "area": "surveying",
        "text": "Only a licensed surveyor can produce an official land survey. Professional land surveyors lay out the"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "exact dimensions of a property and its improvements by using a deed for the property and a site visit to properly measure and document it. If you do not have a current survey or order one as a part of a real estate closing, you can retain a licensed professional to conduct one. The city does not recommend surveyors. Seek referrals from neighbors, a realtor, real estate attorney, or from a professional association (www.plsanj.org or www.njspls.com)."
    },
    {
        "question": "4) How much does a land survey cost?",
        "area": "surveying",
        "text": "While the cost of a land survey varies by the size and complexity of the plot, in general the"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "price can range from as low as $200 for a simple one-side boundary marking to over several thousand dollars for a full property survey."
    },
    {
        "question": "5) What does a land survey depict?",
        "area": "surveying",
        "text": "Property boundaries"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Locations of any improvements such as buildings, patios, driveways, sheds, fences, or A/C units"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Any easements, building setbacks, or other restrictions on the property, which will affect use and"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "future development of the site"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Verification of boundary descriptions for all adjacent properties to ensure that property lines are defined exactly the same on all documents. Occasionally with older adjacent parcels, there may be a discrepancy over property lines; in such cases a surveyor can be retained to settle the dispute."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "(Over)"
    },
    {
        "question": "6) What does it mean to have a land survey \u201cto scale\u201d and why is that necessary?",
        "area": "surveying",
        "text": "All exterior improvements made on a property typically require approval from the city\u2019s Zoning Officer."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The city\u2019s zoning ordinances (Chapter 35 of the city ordinances also known as the Development Regulations Ordinance or DRO) and the zone where a property exists dictates certain specific measurements and conditions including:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "How close to a property line improvements can be made (setbacks)"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "How wide or high certain improvements area allowed to be (signs, building heights)"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "How much lot coverage can exist before a maximum is exceeded (e.g. driveways, patios, etc.)"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The Zoning Officer uses a property survey to measure existing conditions related to the improvements to approve a permit or improvement request."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "To be most useful, a land survey must show locations and distances precisely and accurately on a single sheet of paper. The proportion chosen for a particular land survey is its scale. Simply defined, scale is the relationship between the distance on the survey and the distance on the ground (e.g. one inch on the survey equals 10 feet on the actual property). The copy in your possession that is to scale is the survey that is signed and stamped with a raised seal. All other copies may or may not be to scale depending on how they were duplicated."
    },
    {
        "question": "7) How is my survey not \u201cto scale\u201d?",
        "area": "surveying",
        "text": "Unfortunately, when property owners make copies of a survey or print from an electronic file (e.g. PDF), the scale becomes distorted by the setting of the copier or printer and alters the scale in a way that renders the survey invalid for zoning review. Again, the copy in your possession that will always be to scale is the one that is signed with a raised seal. All other copies may or may not be to scale, depending on how they were duplicated."
    },
    {
        "question": "8) What can I do if my survey is \u201cnot to scale?\u201d",
        "area": "surveying",
        "text": "You will need to locate the original \u201cto scale\u201d survey that will need to be copied without maximizing or minimizing its size. Do not fax or print an emailed/electronic version as the printer will distort the"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "survey and render it invalid. If you have an original survey \u201cto scale\u201d, it can be copied without"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "minimizing or maximizing the copy size to ensure it retains the proper scale. If you have a copy that is"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "not to scale, you might also try to contact the company listed on the survey for an original copy. If you cannot locate an original or \u201cto scale\u201d copy of your land survey, you may need to conduct a new survey."
    },
    {
        "question": "What is Remote Sensing?",
        "area": "remote sensing",
        "text": "Remote sensing is a type of geospatial technology that samples emitted and reflected electromagnetic (EM) radiation from the Earth\u2019s terrestrial, atmospheric, and aquatic ecosystems in order to detect and monitor the physical characteristics of an area without making physical contact. This method of data collection typically involves aircraft-based and satellite-based sensor technologies, which are classified as either passive sensors or active sensors."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u200d"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Passive sensors respond to external stimuli, gathering radiation that is reflected or emitted by an object or the surrounding space. The most common source of radiation measured by passive remote sensing is reflected sunlight. Popular examples of passive remote sensors include charge-coupled devices, film photography, radiometers, and infrared."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Active sensors use internal stimuli to collect data, emitting energy in order to scan objects and areas whereupon a sensor measures the energy reflected from the target. RADAR and LiDAR are typical active remote sensing tools that measure the time delay between emission and return in order to establish the location, direction, and speed of an object. The remote sensing data gathered is then processed and analyzed with remote sensing hardware and computer software (for example energy analytics and energy business intelligence), which is available in a variety of proprietary and open source applications."
    },
    {
        "question": "What is Remote Sensing Used For?",
        "area": "surveying",
        "text": "Remote sensing technology is used in a wide variety of disciplines in thousands of different use cases, including most earth sciences, such as meteorology, geology, hydrology, ecology, oceanography, glaciology, geography, and in land surveying, as well as applications in military, intelligence, commercial, economic, planning, and humanitarian fields. Some typical remote sensing examples include:"
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "GIS remote sensing: Geographic Information System (GIS) is a system designed to capture, store, manage, analyze, manipulate, and present geographic or spatial data -- satellite remote sensing provides an important source of spatial data. Remote sensing and GIS work together to gather, store, analyze, and visualize data from virtually any geographic position on Earth."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Irrigation and soil moisture monitoring and management are major components of remote sensing in agriculture."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Doppler radar measures meteorological events such as wind speed and direction within weather systems as well as precipitation intensity and location. Another application is aerial traffic control."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "AVHRR and MODIS satellites use thermal sensing and mid infrared sensing to monitor active volcanoes."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "INSAR (interferometric synthetic aperture radar) uses interferometry remote sensing technique to predict and provide early warnings for potential landslides."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "A primary application of light detection and ranging (LiDAR) is vegetation management and monitoring, however it is also applied in cases of weapon ranging and laser illuminated homing of projectiles. LiDAR may also be used to detect and measure the concentration of various chemicals in the atmosphere."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Stereographic pairs of aerial photographs are used to model terrestrial habitat features and make topographic maps by imagery and terrain analysts in trafficability and highway departments for potential routes."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Spectropolarimetric Imaging is used by researchers at the U.S. Army Research Laboratory for target tracking purposes by identifying man made items by their polarimetric signatures, which are not found in natural objects."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Remote sensing satellites provide before- and after- remote sensing images in order to quantify post-earthquake damage, which provides vital data for rescue workers."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Data from laser and radar altimeters on satellites, sonar, and ultrasound measurements can be used for coastal mapping and erosion prevention, to better understand how to manage ocean resources, to assess the impacts of a natural disaster and create disaster response strategies to be used before and after a hazardous event, and to minimize the damage that urban growth has on the environment and help decide how to best protect natural resources."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Remote sensing for oil and gas is an integral tool for upstream and downstream gas and oil operations through evaluation of infrastructure for well-site planning. Spectral analysis is vital for the evaluation of surface outcrops and surface hydrocarbon seepage."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Importance of Remote Sensing"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Remote sensing makes it possible to collect data from dangerous or inaccessible areas, with growing relevance in modern society. It replaces slower, costly data collection on the ground, providing fast and repetitive coverage of extremely large areas for everyday applications, ranging from weather forecasts to reports on natural disasters or climate change."
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "Remote sensing is also an unobstructive method, allowing users to collect data and perform data processing and GIS analysis offsite without disturbing the target area or object. Monitoring floods and forest fires, deforestation, polar bears, chemical concentrations, and earthquakes are just a few cases in which geospatial remote sensing provides a global perspective and actionable insights that would otherwise be unattainable."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Advantages of Microwave Remote Sensing"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Microwave remote sensing encompasses both passive and active remote sensing, covering wavelengths ranging from one centimeter to one meter -- the microwave\u2019s longer wavelength is an important feature in remote sensing as it can penetrate haze, rainfall, dust, and cloud cover more effectively than visible and infrared."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Remote sensing of the environment using microwave remote sensing is therefore unaffected as the longer wavelengths are not susceptible to atmospheric scattering. Microwave energy can be detected and data can be gathered under most environmental conditions. Applications include sea ice monitoring and global soil moisture mapping."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Application of Remote Sensing to Climate Change"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Application of remote sensing in the studies of climate change has provided major advances in understanding the climate system and its changes, by quantifying spatio-temporal states and processes of the atmosphere, oceans, and lands. Satellite sensors have aided in the detection and measurement of the cooling effects of increased stratospheric aerosols and the spatial pattern of sea-level rise, which otherwise went unobserved by conventional climate models observations."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Global climate change research uses big data from Earth observation platforms, in which remote multi-satellite, multi-sensor, and long-term time series data methods are implemented. This has facilitated the detection of climate sensitivity factors, advanced the study of the spatial variability of terrestrial ecosystems, and aided in the development of global climate change response strategies."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Limitations of Remote Sensing Data"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Remote sensing is ultimately managed by human operators that make crucial decisions regarding which sensors should be used to collect data and when, resolution specifications for the collected data and sensor calibration, and the selection of the platform that will carry the sensor, all of which expose this method to a certain degree of human error."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Inaccuracy may also be introduced by the electromagnetic spectrum radiation emitted from powerful active remote sensing systems, which can be intrusive and affect the target phenomenon being investigated. Remote sensing instruments may contribute inaccurate, un-calibrated data if the hardware system becomes un-calibrated. There may also be cost related limitations. It is an expensive method that requires extensive, special training for image analysis"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "History of Remote Sensing"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "The earliest practices of modern remote sensing consisted of primitive photographs of the earth\u2019s surface taken from tethered balloons for the purpose of topographic mapping in the 1840s. Systematic aerial photography using modified aircrafts was developed for military surveillance and reconnaissance purposes during the first World War and through the Cold War."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "With the emergence of the space program in the 1960s, instrumentation on Earth observing and weather satellites such as the Nimbus and Landsat provided global measurements of various data for military, civil, and research purposes. IKONOS, the first commercial satellite built to collect very high resolution imagery, was commissioned by Lockheed Martin, launched in 1999, and decommissioned in 2015."
    },
    {
        "question": "Does HEAVY.AI Provide Remote Sensing Solutions?",
        "area": "mapping",
        "text": "Remote sensing data is a major source of spatial data used in Geographic Information Systems (GIS). Geospatial-specific processes in GIS tools are becoming too slow for the enormous data volumes provided by modern remote sensing technologies."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "HEAVY.AI bridges this divide, providing an accelerated analytics platform that allows geospatial analysts to cross-filter billions of location data records and polygons alongside other features in milliseconds. The HEAVY.AIDB SQL engine natively stores geographic and geometric data types, enabling users to run geo calculations with the massively parallel processing power of CPUs and GPUs."
    },
    {
        "question": "What type of survey do I need?",
        "area": "other",
        "text": "There are several types of surveys that we offer, ultimately, check with your township zoning officer and construction official to confirm."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "New Construction:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The first step in the process, prior to architect and engineering plans being generated, a boundary and topographic survey will need to be completed. These type of survey show property lines, trees, elevations and any other existing conditions that are on the property. This in which will be submitted to your architect and engineer so that plans may be developed and submitted to the town."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Once the plans are approved by the town, zoning office, a house location survey with need to be completed; this will set the house location with the property and will be used as a guideline for the excavators to dig for the foundation."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Next a foundation location survey will need to be completed, this will need to be submitted to the township for approval so that building of the house can continue."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The last step in the process is an As-Built survey will need to be completed. This survey shows the completed location of the house, driveway and conditions of the property as a completed project. The town will require a copy of this document for final approval."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Existing Home Additions, where you're adding to the footprint of the original house may require similar surveys as listed above. Your local zoning officer, construction and architect will be able to assist you with what information your town requires."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Fences/In-ground Pools:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "These types of property improvements usually require just a boundary survey, which shows existing conditions of the property, property lines, and the location of the household."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Flood Certificates:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "A flood certificate is required when purchasing or selling a home that is located in a potential flood zone, which is dictated by FEMA. This certificate is also required when you request flood insurance with your insurance provider."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Coastal Erosion Monitoring:"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "GeoAI can analyze satellite imagery and coastal topography to monitor and predict erosion patterns, supporting coastal management and protection efforts."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Flood Prediction:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "By analyzing historical precipitation data, river levels, and terrain characteristics, GeoAI can predict areas at high risk of flooding, enabling timely evacuation and disaster response."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Coastal Change Monitoring: GeoAI enables the monitoring of coastal changes, such as beach erosion or shoreline shifts, by analyzing satellite imagery and LiDAR data, aiding in coastal management and adaptation strategies."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Environmental Impact Assessment:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "GeoAI assists in assessing the environmental impact of infrastructure projects, such as roads, dams, and mines, by analyzing spatial data and predicting potential ecological changes."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Disease Outbreak Monitoring:"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "GeoAI can analyze geospatial data, including population density, climate conditions, and travel patterns, to predict and monitor the spread of diseases like COVID-19 or malaria."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Forest Fire Detection:"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "By analyzing satellite imagery and weather data, GeoAI can detect and monitor forest fires in real-time, enabling an early response and minimizing damage."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Natural Resource Management:"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "GeoAI helps manage natural resources like water, minerals, and forests by analyzing geospatial data and predicting optimal extraction or conservation strategies."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Air Quality Monitoring:"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "GeoAI can analyze air quality data collected from sensors and satellite imagery to identify pollution hotspots, assess health risks, and support air quality management initiatives."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Renewable Energy Site Selection:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "GeoAI assists in identifying suitable locations for renewable energy projects, such as solar farms and wind turbines, by analyzing factors like solar radiation, wind patterns, and terrain."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Archaeological Site Mapping:"
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "GeoAI can analyze aerial imagery and geophysical data to identify and map archaeological sites, contributing to cultural heritage preservation and research."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "GeoAI helps in managing water resources by analyzing data on rainfall, groundwater levels, and river flow to optimize irrigation, drought management, and water allocation."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "12. Land Cover Classification: GeoAI can classify land cover types such as forests, agriculture, urban areas, and water bodies by analyzing satellite imagery."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "13. Earthquake Damage Assessment: By analyzing satellite imagery and geographic data, GeoAI can assess the extent of damage caused by earthquakes, aiding in post-disaster recovery and reconstruction."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "14. Wildlife Conservation: GeoAI helps in monitoring and protecting wildlife by analyzing satellite imagery and tracking animal movements, contributing to biodiversity conservation efforts."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "15. Urban Growth Analysis: GeoAI enables the analysis of urban growth patterns by integrating satellite imagery, population data, and land-use information, supporting urban planning and infrastructure development."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "16. Water Pollution Detection: GeoAI can detect water pollution sources by analyzing satellite imagery, water quality data, and hydrological patterns, facilitating pollution mitigation and water resource protection."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "17. Precision Forestry: GeoAI assists in optimizing forestry operations by analyzing geospatial data to determine optimal tree planting locations, forest health monitoring, and timber yield predictions."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "18. Disaster Damage Assessment: GeoAI aids in assessing the damage caused by natural disasters, such as hurricanes or earthquakes, by analyzing satellite imagery and aerial photographs, supporting disaster response and recovery efforts."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "19. Geolocation Services: GeoAI powers location-based services like mapping, navigation, and geocoding, enabling accurate positioning and routing information for various applications."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "20. Agricultural Pest Monitoring: GeoAI can detect and monitor pests and diseases affecting crops by analyzing satellite imagery and field data, assisting farmers in implementing targeted pest control measures."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "21. Coastal Zone Management: GeoAI supports coastal zone management by analyzing data on coastal erosion, sea level rise, and human activities, facilitating sustainable development and protection of coastal areas."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "22. Landslide Prediction: By analyzing terrain characteristics, rainfall data, and historical landslide events, GeoAI can predict areas prone to landslides, aiding in early warning systems and landslide prevention measures."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "23. Infrastructure Monitoring: GeoAI assists in monitoring critical infrastructure, such as bridges and pipelines, by analyzing satellite imagery and geospatial data to detect anomalies, deterioration, or structural damage."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "24. Geospatial Surveying: GeoAI automates the process of surveying and mapping by using machine learning algorithms to extract features and generate accurate maps from aerial or satellite imagery."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "25. Noise Pollution Mapping: GeoAI can analyze data from noise sensors and urban characteristics to create noise pollution maps, supporting urban planning and noise mitigation strategies."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "26. Soil Quality Assessment: GeoAI helps in assessing soil quality and fertility by analyzing geospatial data on soil composition, moisture content, and nutrient levels, supporting precision agriculture practices."
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "27. Wildlife Habitat Mapping: GeoAI can analyze satellite imagery, topographic data, and ecological parameters to map and monitor wildlife habitats, contributing to biodiversity conservation and habitat management."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "28. Public Health Planning: GeoAI assists in public health planning by analyzing geospatial data on population density, healthcare facilities, and disease prevalence, supporting resource allocation, and healthcare service delivery."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "29. Traffic Management: GeoAI can analyze real-time traffic data from sensors, GPS, and social media to optimize traffic flow, detect congestion, and suggest alternate routes."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "30. Geological Hazard Assessment: GeoAI helps in assessing geological hazards, such as earthquakes or landslides, by analyzing geospatial data on fault lines, rock types, and topography, supporting hazard preparedness and response."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "31. Noise Barrier Optimization: GeoAI can analyze noise data, traffic patterns, and urban characteristics to optimize the placement and design of noise barriers, reducing noise pollution in urban areas."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "32. Infrastructure Planning: GeoAI aids in infrastructure planning by analyzing geospatial data to identify optimal locations for roads, bridges, power lines, and other infrastructure elements, optimizing resource allocation and connectivity."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "33. Coastal Water Quality Monitoring: GeoAI can analyze satellite imagery and water quality data to monitor coastal water quality, detect pollution sources, and support coastal ecosystem management."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "34. Green Space Planning: GeoAI helps in identifying suitable locations for parks, green spaces, and urban forests by analyzing geospatial data on population density, land availability, and ecosystem services."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "35. Disaster Risk Assessment: GeoAI enables the assessment of disaster risks by integrating geospatial data on hazards, vulnerability, and exposure, supporting risk reduction strategies and resilience planning."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "36. Air Pollution Source Identification: GeoAI can analyze data from air quality sensors, meteorological data, and emission sources to identify and locate air pollution sources, aiding in pollution control measures."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "37. Agricultural Yield Prediction: GeoAI assists in predicting crop yields by analyzing geospatial data on climate, soil, and vegetation indices, supporting agricultural planning, and making food security assessments."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "38. Water Supply Planning: GeoAI helps in planning water supply systems by analyzing geospatial data on water availability, demand, and infrastructure and optimizing water resource management and distribution."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "39. Noise Impact Assessment: GeoAI can assess the impact of noise on human health and well-being by analyzing noise data, population density, and land-use information, supporting urban planning and noise mitigation strategies."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "40. Geofencing and Location-Based Marketing: GeoAI enables geofencing and Location-Based Marketing by analyzing location data and user behavior, targeting personalized marketing messages to specific geographic areas."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "41. Urban Heat Island Analysis: GeoAI can analyze satellite imagery and temperature data to identify and assess urban heat island effects, supporting urban planning and heat mitigation strategies."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "42. Waterway Management: GeoAI aids in managing rivers, lakes, and coastal areas by analyzing geospatial data on water quality, flow rates, and ecosystems, supporting water resource protection and restoration."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "43. Soil Erosion Monitoring: GeoAI can analyze satellite imagery and topographic data to monitor soil erosion rates and identify erosion-prone areas, supporting soil conservation and sustainable land management."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "44. Spatial Data Quality Assessment: GeoAI assists in assessing the quality of spatial data by analyzing data consistency, accuracy, and completeness, ensuring reliable geospatial information for decision-making."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "45. Marine Biodiversity Monitoring: GeoAI helps in monitoring and mapping marine biodiversity by analyzing satellite imagery, bathymetric data, and species distribution models, supporting marine conservation and management efforts."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "46. Transportation Network Optimization: GeoAI can optimize transportation networks by analyzing geospatial data on traffic patterns, road conditions, and population density, improving efficiency and reducing congestion."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "47. Water Leakage Detection: GeoAI aids in detecting water leakage in water distribution systems by analyzing geospatial data on water pressure, flow rates, and network characteristics, supporting efficient water management."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "48. Coastal Tourism Planning: GeoAI assists in coastal tourism planning by analyzing geospatial data on visitor patterns, infrastructure, and environmental sensitivity, supporting sustainable tourism development and management."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "49. Soil Moisture Monitoring: GeoAI enables the monitoring of soil moisture levels by analyzing satellite imagery and weather data, supporting precision agriculture practices and water management."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "50. Noise Impact on Wildlife: GeoAI can analyze noise data and ecological parameters to assess the impact of noise on wildlife populations, contributing to wildlife conservation and habitat management efforts."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "51. Environmental Justice Analysis: GeoAI aids in analyzing spatial patterns of environmental hazards and social vulnerabilities to assess environmental justice issues, supporting equitable and inclusive decision-making."
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "52. Disease Vector Habitat Mapping: GeoAI can analyze geospatial data on climate, vegetation, and habitat suitability to map disease vector habitats, aiding in disease control and prevention strategies."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "53. Energy Infrastructure Siting: GeoAI assists in the siting of energy infrastructure, such as power plants and transmission lines, by analyzing geospatial data on energy demand, renewable energy potential, and environmental constraints."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "54. Coastal Risk Management: GeoAI helps in managing coastal risks by analyzing geospatial data on sea level rise, storm surge, and vulnerability, supporting adaptation planning and coastal protection measures."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "55. Urban Air Quality Management: GeoAI enables the monitoring and management of urban air quality by analyzing data from air quality sensors, traffic patterns, and emission sources, supporting pollution reduction strategies."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "56. Soil Erosion Control: GeoAI can analyze topographic data, land cover, and erosion models to identify and prioritize areas for soil erosion control measures, supporting sustainable land management practices."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "57. Green Infrastructure Planning: GeoAI aids in planning green infrastructure, such as green roofs, rain gardens, and urban forests, by analyzing geospatial data on land availability, stormwater runoff, and ecosystem services."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "58. Public Transport Demand Analysis: GeoAI can analyze geospatial data on population density, employment centers, and transportation networks to assess public transport demand and optimize service provision."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "59. Geological Resource Exploration: GeoAI assists in geological resource exploration, such as minerals or oil and gas, by analyzing geospatial data on geological structures, remote sensing data, and geophysical surveys."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "60. Noise Impact on Human Health: GeoAI helps in assessing the impact of noise on human health by analyzing noise data, population density, and health indicators, supporting urban planning and noise mitigation strategies."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "61. Carbon Footprint Analysis: GeoAI enables the analysis of carbon footprints by integrating geospatial data on energy consumption, transportation patterns, and land-use change, supporting climate change mitigation strategies."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "62. Habitat Connectivity Analysis: GeoAI aids in analyzing habitat connectivity for wildlife by analyzing landscape features, land cover, and ecological corridors, supporting biodiversity conservation and landscape planning."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "63. Climate Change Vulnerability Assessment: GeoAI can analyze geospatial data on climate projections, socio-economic factors, and ecosystem vulnerability to assess climate change impacts and develop adaptation strategies."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "64. Agriculture Water Management: GeoAI helps in managing agricultural water use by analyzing geospatial data on soil moisture, crop water requirements, and irrigation efficiency, supporting water conservation and productivity."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "65. Noise Planning for Urban Development: GeoAI can analyze noise data, land-use patterns, and urban development plans to optimize noise planning in urban areas, ensuring noise-sensitive activities are appropriately located."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "66. Renewable Energy Potential Mapping: GeoAI assists in mapping the potential for renewable energy generation, such as solar and wind, by analyzing geospatial data on solar radiation, wind speeds, and land suitability."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "67. Greenhouse Gas Emission Monitoring: GeoAI enables the monitoring and mapping of greenhouse gas emissions by analyzing data from satellite sensors, atmospheric models, and emission inventories, supporting climate change mitigation efforts."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "68. Water Pollution Remediation Planning: GeoAI aids in planning water pollution remediation strategies by analyzing geospatial data on pollution sources, hydrological patterns, and water quality, supporting targeted pollution control measures."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "69. Public Safety Planning: GeoAI can analyze geospatial data on crime patterns, emergency response times, and population distribution to optimize public safety planning and resource allocation."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "70. Land Use Planning: GeoAI helps in land use planning by analyzing geospatial data on land suitability, environmental constraints, and socio-economic factors, supporting sustainable land management and development."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "71. Urban Green Infrastructure Assessment: GeoAI enables the assessment of urban green infrastructure, such as parks and green roofs, by analyzing geospatial data on vegetation coverage, ecosystem services, and accessibility."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "72. Geospatial Data Visualization: GeoAI aids in visualizing geospatial data by using AI algorithms to create interactive maps, 3D models, and data visualizations, facilitating data exploration and communication."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "73. Noise Control in Construction: GeoAI can analyze noise data, construction plans, and land-use information to optimize noise control measures during construction projects, minimizing noise disturbance to surrounding areas."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "74. Real Estate Market Analysis: GeoAI assists in analyzing real estate markets by integrating geospatial data on property prices, demographics, and amenities, supporting market research and investment decision-making."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "75. Environmental Impact Monitoring: GeoAI enables the monitoring of environmental impacts caused by human activities, such as deforestation or mining, by analyzing satellite imagery, land cover change, and ecological indicators."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "76. Public Health Surveillance: GeoAI helps in public health surveillance by analyzing geospatial data on disease incidence, healthcare facilities, and population demographics, supporting early detection and response to health threats."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "77. Landslide Risk Assessment: GeoAI can assess landslide risk by analyzing topographic data, rainfall patterns, and soil properties, supporting landslide hazard mapping and risk reduction strategies."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "78. Noise-Reducing Urban Design: GeoAI aids in designing noise-reducing urban environments by analyzing noise data, urban layouts, and building characteristics, supporting noise mitigation strategies and urban livability."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "79. Marine Spatial Planning: GeoAI enables marine spatial planning by analyzing geospatial data on marine ecosystems, human activities, and conservation objectives, supporting sustainable marine resource management."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "80. Transportation Demand Forecasting: GeoAI can forecast transportation demand by analyzing geospatial data on population growth, employment centers, and transportation infrastructure, supporting transport planning and investment decisions."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "81. Forest Carbon Stock Assessment: GeoAI helps in assessing forest carbon stocks by analyzing satellite imagery, forest inventory data, and biomass models, supporting carbon accounting and REDD+ initiatives."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "82. Noise-Reducing Infrastructure Design: GeoAI aids in designing noise-reducing infrastructure, such as highways or railways, by analyzing noise data, traffic patterns, and engineering parameters, supporting noise abatement measures."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "83. Water Conservation Planning: GeoAI enables water conservation planning by analyzing geospatial data on water demand, availability, and efficiency, supporting water resource management and conservation initiatives."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "84. Geospatial Social Media Analysis: GeoAI can analyze geospatial data from social media platforms to extract information on user preferences, behavior, and sentiment, supporting location-based marketing and social analysis."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "85. Precision Livestock Farming: GeoAI assists in optimizing livestock farming practices by analyzing geospatial data on animal behavior, environmental conditions, and feed availability, supporting animal welfare and productivity."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "86. Urban Agriculture Planning: GeoAI helps in planning urban agriculture initiatives by analyzing geospatial data on land availability, sunlight exposure, and water resources, supporting food security and urban sustainability."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "87. Coastal Aquaculture Planning: GeoAI enables the planning of coastal aquaculture activities by analyzing geospatial data on water quality, habitat suitability, and marine resources, supporting sustainable aquaculture practices."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "88. Noise Impact on Education: GeoAI can analyze noise data, school locations, and population density to assess the impact of noise on educational settings, supporting noise management and creating healthier learning environments."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "89. Geospatial Disaster Risk Communication: GeoAI aids in communicating disaster risks by analyzing geospatial data and generating visualizations, maps, and risk communication tools, supporting public awareness and preparedness."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "90. Pest Control Planning: GeoAI helps in planning pest control strategies by analyzing geospatial data on pest populations, habitat suitability, and crop vulnerability, supporting integrated pest management practices."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "91. Agricultural Land Suitability Assessment: GeoAI enables the assessment of agricultural land suitability by analyzing geospatial data on soil properties, climate conditions, and crop requirements, supporting land-use planning and agricultural productivity."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "92. Noise Monitoring in Healthcare Facilities: GeoAI can analyze noise data in healthcare facilities to assess noise levels, identify noise sources, and implement noise control measures, improving patient comfort and well-being."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "93. Smart City Management: GeoAI assists in managing smart cities by integrating geospatial data with data from various sensors and IoT devices, supporting efficient resource management, and enhancing urban services."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "94. Environmental Education and Awareness: GeoAI enables the creation of interactive and immersive educational tools and games using geospatial data, promoting environmental awareness and understanding."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "95. Noise Impact on Wildlife Migration: GeoAI can analyze noise data, migration patterns, and ecological parameters to assess the impact of noise on wildlife migration routes, supporting conservation planning and habitat connectivity."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "96. Soil Contamination Mapping: GeoAI aids in mapping soil contamination by analyzing geospatial data on pollution sources, soil properties, and land use history, supporting remediation efforts and land management strategies."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "97. Urban Resilience Planning: GeoAI helps in planning urban resilience strategies by analyzing geospatial data on hazards, infrastructure vulnerabilities, and social vulnerabilities, supporting adaptive and resilient urban development."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "98. Noise-Reducing Urban Green Design: GeoAI can analyze noise data, vegetation coverage, and urban design parameters to optimize noise-reducing green spaces, supporting noise mitigation and enhancing urban livability."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "99. Fire Risk Assessment: GeoAI enables the assessment of fire risks by analyzing geospatial data on vegetation cover, weather conditions, and fire history, supporting fire prevention and management strategies."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "100. Geospatial Data Integration: GeoAI facilitates the integration of geospatial data from multiple sources, such as satellite imagery, sensors, and social media, enabling comprehensive analysis and decision-making across various domains."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "101. Urban Planning: GeoAI helps in optimizing urban infrastructure, transportation networks, and land use planning,"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "102. Real Estate: GeoAI aids in property valuation, market analysis, and identifying investment opportunities based on geospatial data."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "103. Wildlife Tracking: GeoAI supports wildlife tracking and conservation efforts by analyzing animal movement patterns and habitat suitability."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Remote sensing is the process of acquiring information about objects or areas from a distance."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "In broad terms, as you read this sentence, you are performing a type of remote sensing. Your eyes collect visible light waves reflected by the dark and light shapes in front of you, and your brain analyzes this information, assigning letters, words and meanings to the patterns."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "In a geospatial context, remote sensing is defined as the collection of information about the Earth using satellites, aircraft, or drones."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "As far as remote sensors go, human eyes are quite limited. Of the entire electromagnetic spectrum, which includes radio waves, microwaves, infrared waves, UV rays, X-rays, and gamma rays, our eyes can only detect the portion that corresponds to visible light, or 0.0035% of the spectrum. Our eyes are also limited in how much detail they can perceive from a distance. Thanks to the human ability to innovate, we have technologies to overcome these constraints and dramatically expand our remote sensing capabilities."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Scientists have developed a variety of remote sensors. When mounted onto drones, aircraft and satellites, these sensors can detect, record and analyze different types of electromagnetic energy from the Earth\u2019s surface, such as visible light, infrared, and microwave radiation. These energy waves contain valuable information about land, water, and man-made features of interest, as well as geometric structures and relative scale. The data are digitally transmitted from the satellite down to a ground receiving station on Earth, where they can be processed and used to inform all sorts of commercial, scientific, humanitarian, and military activities."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "There are two main categories of sensors: passive and active."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "A passive sensor detects and records naturally occurring electromagnetic energy as it is reflected or emitted from objects on the Earth\u2019s surface. Your eyes are passive sensors because they collect energy (visible wavelengths) generated by the sun or another external source. Optical cameras, including those mounted on satellites, are another example of passive sensors."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "An active sensor provides its own source of energy. The sensor emits a signal, in the form of electromagnetic energy, toward an area of interest on the Earth\u2019s surface. This signal interacts with physical objects in that area, and is reflected or diffracted back toward the sensor, which then records and measures the signal. The process is similar to how mammals such as bats and whales use echolocation to sense objects in their path."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Because an active sensor functions without the need for an external energy source, it can collect information in the dark or through clouds\u2014something that most passive sensors cannot do. Synthetic aperture radar (SAR) is an example of an active radar sensor."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "As scientists continue to innovate, advances are being made in these four important areas of remote sensing:"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Radiometric resolution: A sensor\u2019s ability to detect differences in the magnitude of electromagnetic energy. The higher the radiometric resolution, the greater the sensitivity to small differences in reflected or emitted energy."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Spectral resolution: A sensor\u2019s ability to distinguish wavelengths of energy within the electromagnetic spectrum (e.g., in the visible, infrared, and/or microwave regions). The finer the spectral resolution, the more narrowly defined the wavelength range is in a particular band."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Spatial resolution: The size of the smallest feature that can be detected or displayed. The higher the spatial resolution, the more detail it contains, and the greater the time and cost to capture and process the image. Depending on the size of the area to be imaged, active sensors can provide adjustable spatial resolution (e.g., images of very large areas will have coarse spatial resolution, while images of more focused areas will have higher resolution)."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Temporal resolution: The time between data collections within an area. This depends on how long it takes for the satellite or other platform carrying the sensor to revisit an observation area."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "While our eyes can\u2019t see with the acuity of a hawk or perceive as much of the electromagnetic spectrum as a butterfly or a mantis shrimp, we more than make up for these shortcomings. Using powerful remote sensors on satellites, people are now able to measure the Earth\u2019s land and sea surface temperature and topography, vegetation patterns, precipitation, wind, soil moisture, and more."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "We can use these data to map agricultural crops, forest fires, flooding, sea ice, oceans, oil spills, or any area of land. Multiple data collections also allow us to monitor changes to the Earth\u2019s Surface over time (weeks, years, decades) and better understand patterns of life within ecosystems."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "We\u2019ve come a long way from the mid-1800s, when the first aerial photos of the Earth\u2019s surface were taken from a hot air balloon. Hundreds of years later, space is the limit!"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "A Complete Guide to Surveying and Mapping"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Surveying and mapping have a rich history dating back thousands of years. In ancient Egypt, surveyors used simple tools such as rope with knots to measure land boundaries and construct the pyramids. As early as the 1500s, Florida surveyors were utilizing primitive tools to map and navigate the region in the development of railroads and roads, which connected growing communities. Fast forward to modern times, surveying and mapping have evolved to become highly technical and sophisticated fields."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Today, surveying and mapping are critical for a wide range of applications, from property ownership and development to infrastructure planning and disaster preparedness. This article delves into the definition and significance of these fields, the various types of surveys, and their relevance in the A/E/C industry. Additionally, we\u2019ll discuss essential factors to consider when selecting a surveying and mapping provider, as well as the future of the industry as technology advances."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "TABLE OF CONTENTS click to show"
    },
    {
        "question": "WHAT IS SURVEYING AND MAPPING?",
        "area": "mapping",
        "text": "Surveying is the science, art, and profession of determining the positions of points on the surface of the earth and measuring the distances, directions, angles, and elevations between them. This can involve using a variety of tools and techniques, such as GPS (Global Positioning System), aerial photography, and ground-based measurements using instruments like total stations and levels. Mapping is the process of creating a visual representation of the data gathered during surveying, which can take many forms, from simple two-dimensional plans to complex three-dimensional models and geographic information systems (GIS) that integrate multiple layers of data."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Surveying and mapping form a critical foundation for many fields, including civil engineering, construction, urban planning, environmental science, and more. Accurate surveying and mapping can help ensure the safe and efficient use of land, resources, and infrastructure, as well as support informed decision-making in a wide range of applications."
    },
    {
        "question": "What is a Surveyor and Mapper?",
        "area": "surveying",
        "text": "A surveyor and mapper is a skilled professional who specializes in measuring and mapping the features of land, water, and air to determine its boundaries, elevations, and topography, which are material to the development of any project."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Surveyors and mappers perform the following roles and responsibilities:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Establish property boundaries and create maps and survey plots of the site"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Measure and record physical characteristics of the land, including elevation, distance, and direction"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Conduct research and analyze existing survey data, maps, deeds, and other relevant documents"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Provide expert advice to clients on land use, zoning, and building regulations"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Prepare legal documents such as land deeds, maps, and boundary descriptions"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Serve as expert witnesses in court cases and provide expertise to engineers, architects, and developers"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Becoming a Licensed Professional Surveyor and Mapper (PLS / PSM)"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "To become a licensed land surveying professional, individuals must meet education and experience requirements and pass an examination. The requirements for licensure may vary by state, but typically include:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A bachelor\u2019s degree in surveying and mapping or a related field such as geomatics or land surveying."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Four to six years of experience as a subordinate to a licensed surveyor."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Successful completion of the Fundamentals of Surveying (FS) exam, the Principles and Practice of Surveying (PS) exam, and a state-specific examination."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Learn more about becoming a Licensed Professional Surveyor and Mapper (PLS / PSM) in Florida"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land surveyors can work in a variety of industries, including the A/E/C industry, government agencies, and private firms:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "In the A/E/C industry, these professionals are typically involved in the planning, design, and construction of buildings, roads, bridges, and other important infrastructure projects. They play a critical role in ensuring that these projects are built according to plan and within regulatory requirements."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "In government agencies, land surveyors may work for departments responsible for land management, zoning, and environmental protection."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Private firms may hire land surveyors to provide services such as boundary surveys, topographic surveys, and construction layout services."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The planning and execution of nearly every successful infrastructure project begins with the daily work of professional surveyors and mappers, survey field crew, and CADD technicians. The wide range of career possibilities requires a high level of technical expertise and a strong understanding of surveying and mapping principles."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Collecting data for a land survey at the University of Florida Katie Seashole Pressly Stadium"
    },
    {
        "question": "What is a land survey?",
        "area": "surveying",
        "text": "A land survey is a report, drawing, or map of a parcel or parcels of land, which provides precise measurements on the shape, size, and boundaries of the property and location of any structures or features found on the property."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land surveys can also provide information on the topography and natural features of the land, such as trees, bodies of water, and slopes, which can be important for environmental assessments and planning. They can also be used to identify any potential hazards or risks, such as flooding or landslides, and inform decisions about land use and development."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Importance of Land Surveys"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land surveys are essential in establishing legal descriptions and providing legal proof of property ownership ensuring property owners are aware of their boundaries and rights. Here are a few of their main benefits:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Legal descriptions in land surveying are used to define the exact boundaries and dimensions of a piece of property.  Map of Gainesville, 1853."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Legal Proof of Property Ownership: Land surveys are the only legally binding documents that define where a property begins and ends. Having a recent survey on file is crucial when purchasing or selling property and helps to prevent legal disputes."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Property Disputes: Land surveys help to resolve disputes between neighbors and ensure that construction projects comply with zoning and building regulations."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Building and Development: Land surveys are necessary before any new construction, renovation, or expansion project. They help to identify any potential issues with the site and ensure compliance with zoning regulations and building codes."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land surveying and mapping are vital to the success of the A/E/C industry, providing critical data for land development, infrastructure planning, property ownership, and legal disputes. Understanding the various types of surveys is essential in selecting the most suitable survey for a specific project and ensuring accurate and reliable data collection."
    },
    {
        "question": "WHAT ARE THE DIFFERENT TYPES OF SURVEYS?",
        "area": "surveying",
        "text": "Surveying and mapping are essential tools for a wide range of industries which rely on accurate measurements and mapping of land and structures to ensure the successful completion of their projects. In this section, we\u2019ll explore the different types of surveys that are commonly used in the A/E/C industry."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "ALTA/NSPS Land Title Surveys:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "An ALTA/NSPS land title survey is a comprehensive survey that meets the standards set by the American Land Title Association (ALTA) and the National Society of Professional Surveyors (NSPS). It provides a detailed report of a property\u2019s boundary lines, improvements, easements, rights-of-way, encroachments, and other features that could affect ownership or the use of the property. ALTA/NSPS surveys are usually required for commercial properties and provide a comprehensive view of a property\u2019s physical and legal characteristics, helping identify potential issues or conflicts that could arise in the future."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Commercial/Residential Boundary Surveys:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A commercial/residential boundary survey accurately identifies the boundaries of a property, including its corners, lines, and angles. These surveys are essential for resolving property disputes, complying with zoning regulations and building codes, and providing evidence of legal property ownership."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Construction Layout Services:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Construction layout services, also known as construction staking or site layout survey, establish and mark the precise location of proposed structures, utilities, and other infrastructure on a construction site. This crucial step ensures buildings are placed correctly according to design plans and minimizes errors and conflicts, reducing the risk of costly rework later in the construction process."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Surveying and mapping are essential tools for a wide range of industries which rely on accurate measurements and mapping of land and structures to ensure the successful completion of their projects."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Lot Splits + Boundary Line Adjustments:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Lot splits and boundary line adjustments are processes related to the division of land into separate parcels or lots. A lot split involves dividing an existing piece of land into two or more separate lots or parcels, while a boundary line adjustment involves changing the boundaries of existing lots or parcels to better fit the needs of the property owner. These complex processes require the services of a licensed surveyor to ensure the new lots or parcels are accurately defined and comply with the local zoning and subdivision regulations for approval from the local planning department or zoning board."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Platting Services and Lot Staking:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Platting services involve mapping and staking an entire property to define the boundaries and dimensions of the property, as well as any legal restrictions. During lot staking, land surveyors place survey monuments or markers at property corners and lines, at predefined intervals, using wooden stakes to clearly mark property boundaries. This type of surveying is used to ensure that the land is properly prepared for development."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A topographic survey is used to gather detailed data about the location of natural and man-made features of the land. These features include elevations, contours, trees, streams, drainage ditches, grading, buildings, and more. A topographic survey is a useful tool for landscape architects and engineers for land planning and development, site design, engineering design, and environmental analysis."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "As-Built or Record Drawings:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "As-built surveys are important for documenting the final horizontal and vertical field location of constructed improvements, such as sewer pipes, buildings, and utilities, in relation to the engineered construction plans, design changes, and contractor\u2019s field changes. These surveys ensure that construction projects are completed according to plan and serve as a record of the final, \u201cas-built\u201d state of the building or structure. Often required by regulatory agencies, these land surveys are useful for property management, maintenance and repair, and future construction or renovation projects."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Wetland + Environmental Surveys:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Wetland and environmental surveys are assessments conducted to identify and evaluate the natural features and resources of a particular area, including wetlands, habitats, and other environmental features. These surveys are used to determine the presence and extent of wetlands, wildlife habitats, endangered species, and other environmentally sensitive areas. The goal of wetland and environmental surveys is to ensure that development projects and other activities do not negatively impact the environment and to identify potential mitigation measures to minimize any impacts. These surveys may be required by local, state, or federal regulations and are typically conducted by environmental consultants or specialists."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Hydrographic + Mean High Water Surveys:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Hydrographic and Mean High Water (MHW) surveys are specialized surveys that measure and map the depths, contours, and features of bodies of water, such as lakes, rivers, and coastal areas. Hydrographic surveys are typically used for navigation, dredging, and engineering purposes, while MHW surveys are used to establish the legal boundary between public and private land along the shoreline. These surveys are conducted using specialized equipment, such as sonar, GPS, and multibeam echosounders, to create accurate maps and 3D models of the water and land features. These surveys are specifically important for peninsulas, such as Florida."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "FEMA Elevation Certificates:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "FEMA Elevation Certificates verify property\u2019s location, flood zone designation, and the structure\u2019s elevation. The certificate is often required by lenders and insurance companies for properties located in flood zones to determine flood insurance rates, building code compliance, and other flood-related issues. Licensed land surveyors or engineers typically prepare these certificates in compliance with the National Flood Insurance Program."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Subsurface Utility Locations:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Subsurface utility locations involve identifying and mapping the location of underground utilities, such as water pipes, gas lines, electrical cables, and telecommunication lines, using methods such as ground-penetrating radar, electromagnetic induction, or vacuum excavation. The Subsurface Utility Engineering process helps prevent accidental damage during construction or excavation work, enables utilities to be relocated or repaired more efficiently, and prevents service interruptions by identifying potential issues before they occur."
    },
    {
        "question": "What is Subsurface Utility Engineering?",
        "area": "other",
        "text": "Subsurface utility locations & designations provide utility conflict avoidance by mapping existing underground utility facilities.  //READ MORE"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Aerial Surveying and Mapping:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Aerial surveying and mapping is a method of collecting geospatial data from the air using various sensors mounted on a survey aircraft or drone. This technique is used to create highly accurate maps, 3D models, and other geospatial data products useful for large-scale mapping projects such as city planning and infrastructure development."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Surveying and Mapping provides critical information about the characteristics of a site, including its boundaries, topography, and existing infrastructure enabling A/E/C professionals to plan and execute projects with a high degree of accuracy, reducing the risk of costly errors, safety hazards, and project delays. In the next section, we will delve deeper into the benefits of surveying and mapping and explore some of the specific ways these tools are used to support successful project outcomes."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "THE IMPORTANCE OF SURVEYING AND MAPPING IN THE A/E/C INDUSTRY"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "The architecture, engineering, and construction (A/E/C) industry is a highly collaborative field that encompasses a wide range of professions involved in the planning, design, construction, and maintenance of buildings, infrastructure, and other structures. From landscape architects and engineers to ecologists and project managers, each profession plays a vital role in ensuring that projects are completed safely, on time, and within budget. This industry encompasses a variety of projects, including residential and commercial buildings, infrastructure, and energy systems, and is an essential part of the economy, providing employment opportunities and contributing to the growth and development of strong communities."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Importance of Surveying and Mapping in A/E/C Projects"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Surveying and mapping play a crucial role in providing accurate and reliable data that is essential for project planning and execution. The following are some of the ways surveying and mapping contribute to the success of A/E/C projects:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Planning and Design: Surveying and mapping provide accurate and reliable data that landscape architects, engineers, and construction professionals use in planning and designing a project. This includes topographic data, elevation data, boundary lines, and legal descriptions of the property. The information is critical for creating the initial design of a project and for determining the feasibility of a proposed project."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Construction: During the construction phase, surveying and mapping are used to ensure that the construction work is following the design plans accurately. Surveyors use precision instruments to locate and mark the position of construction elements such as buildings, roads, bridges, and utility lines. This helps to ensure that the construction work is carried out to the exact specifications of the design plans, minimizing the risk of errors and rework."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Site Evaluation: Surveying and mapping are critical in evaluating the suitability of a site for construction. This includes determining the topography, soil type, drainage patterns, and other factors that can affect the construction process. By evaluating these factors, architects and engineers can design structures that are both safe and environmentally sustainable."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land Use Planning: Surveying and mapping provide information that is essential in land-use planning. This includes identifying zoning regulations, environmental constraints, and other factors that can affect land development. This information is critical for developing comprehensive land-use plans that balance economic, social, and environmental considerations."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Property Ownership: Surveying and mapping are used to determine the boundaries of a property and the legal description of the land. This information is essential in property transactions, including buying and selling, leasing, and easement agreements. Surveyors also provide accurate data on the location and size of improvements, such as buildings, roads, and utilities, which can impact property value and development potential."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Accurate Site Planning: Surveying and mapping provide accurate measurements of the land, including its topography, boundaries, and other features that may affect the design and construction of a project. This information is essential for site planning, ensuring that the project is built on a stable foundation and that it meets all zoning and regulatory requirements. Accurate site planning is crucial for ensuring the long-term success of a project and minimizing the risk of future problems or failures."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Building and Development Compliance: Surveying and mapping also play a critical role in ensuring that buildings and structures are built in compliance with local building codes and regulations. Surveyors provide precise measurements and data to ensure that buildings are constructed within the specified boundaries and that they meet all regulatory requirements. This helps to ensure the safety and structural integrity of buildings and structures."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Infrastructure and Utility Planning: Surveying and mapping also contribute to the planning and construction of infrastructure and utility systems, such as roads, bridges, and pipelines. Surveyors provide accurate data on the land and the surrounding environment, including its topography, soil conditions, and other factors that may affect the design and construction of these systems. This information is critical for designing infrastructure and utility systems that are both safe and environmentally sustainable."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "The Power of Surveying and Mapping: Success Stories in A/E/C Projects"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "You can find examples of A/E/C projects that have utilized surveying and mapping to ensure their success across the globe. These Florida examples demonstrate the importance of surveying and mapping in a wide range of projects, from large-scale infrastructure projects to iconic landmarks. By providing accurate and reliable data, surveying and mapping help ensure the success of these projects, both in terms of safety and efficiency."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "UF Data Science and Information Technology Building (DSIT)"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The University of Florida (UF) is committed to creating a sustainable and well-designed campus that integrates with the existing character of the 2,000+ acre campus. To achieve this, UF has undertaken several campus master planning initiatives, including the use of 3D scanning and modeling technologies to create accurate digital representations of existing buildings, infrastructure, and green spaces. The UF Data Science and Information Technology Building (DSIT) is a testament to the success of this planning approach. The building\u2019s design incorporated surveying and mapping, which enabled the project team to control construction costs by identifying potential conflicts early in the process. With detailed survey information, including utility locations and full 3D models, the project team could accurately visualize proposed developments, assess the impact on the campus environment, and avoid potential conflicts with existing or planned improvements. This comprehensive planning approach has resulted in a more sustainable and well-designed campus that meets the needs of students, faculty, and the surrounding community."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "National Park Service Indefinite Delivery Indefinite Quantity (IDIQ) Contract"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "In Florida, surveying and mapping play a significant role in the state\u2019s environmental conservation efforts. Wetland and environmental surveys are essential for ensuring that development projects comply with state and federal regulations for the protection of natural resources. In comparison to other states, Florida has unique environmental features, such as its extensive coastline and the Everglades, making these projects more complex than similar projects in other states."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "The Everglades Restoration Project aims to restore and preserve this unique ecosystem, with surveying and mapping playing crucial roles in tracking environmental changes and guiding restoration efforts. In 2022, CHW joined the Multi-Disciplinary Architect-Engineering (A-E) Team led by Walker Architects for the Indefinite Delivery Indefinite Quantity (IDIQ) Contract with the National Park Service. Uniting in the care of U.S national parks in Southeast Region, which includes the states, possessions, and territories of Louisiana, Mississippi, Alabama, Georgia, Florida, Tennessee, Kentucky, South Carolina, North Carolina, Puerto Rico, and the Virgin Islands (primary geographic area)."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "KEY CONSIDERATIONS FOR CHOOSING A SURVEYING AND MAPPING PROVIDER"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Understanding the role of surveying and mapping is essential for anyone working in industries that rely on accurate spatial data. Whether you are a property owner looking to establish legal proof of ownership, a developer planning new construction projects, or an engineer designing infrastructure systems, surveying and mapping data is essential for making informed decisions. With the right surveying and mapping provider, you can ensure that your projects are based on accurate data and meet all relevant regulations and standards."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Factors to Consider When Choosing a Surveying and Mapping Provider"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Experience and Reputation: Consider the provider\u2019s experience and reputation in the industry. Look for a provider that has a good track record and extensive experience in surveying and mapping in the specific area or type of project you are working on. Check their references and online reviews to get an idea of their reputation."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Communication and Collaboration: Consider the provider\u2019s communication and collaboration skills. A good provider should be able to provide clear communication about the project timeline, keep you informed about any issues or delays, and actively collaborate with you and stakeholders to ensure project goals are met."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Range of Services: Consider the range of services the provider offers. Some providers specialize in specific types of surveying and mapping services, while others offer a full range of services. It may be more efficient and cost-effective to choose a provider that offers a full range of services, as it can reduce the need for multiple providers."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Technology and Equipment: Check what technology and equipment the provider uses. A provider that uses the latest technology and equipment will likely be more efficient, accurate, and cost-effective. Ask the provider what equipment and technology they will use for your project and how it will benefit the project."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Quality Assurance: Ensure that the provider has a quality assurance program in place to ensure the accuracy and quality of their work. Ask the provider about their quality assurance program, including the procedures they follow and the measures they take to ensure accuracy and quality."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Certifications and Licenses: Ensure that the provider has all the necessary certifications and licenses required by the state or local jurisdiction where the project is taking place. This will ensure that the provider meets the legal requirements and has the necessary knowledge and skills to perform the work."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "CHW is Multi-Disciplinary. We empower progress, concept to construction. CHW offers turn-key solutions through our full-service professional disciplines: general civil engineering, surveying + mapping, land planning, ecological services, urban design, design + permitting, transportation engineering, traffic studies, landscape architecture, construction administration, construction engineering inspection."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Importance of Choosing the Right Provider"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Cost and Time Savings: When looking for a provider, it\u2019s important to keep in mind the potential for cost and time savings. By choosing an experienced provider equipped with the latest technology, you can ensure that your project is completed efficiently and accurately, ultimately reducing the need for costly revisions or delays."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Accurate and Reliable Results: The accuracy and reliability of your surveying and mapping results are crucial to the success of your project. Therefore, it\u2019s important to choose a provider with the necessary experience, equipment, and communication skills to ensure that your results are accurate and reliable. When you choose the right provider, you can feel confident that your project is in good hands."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Expert Guidance and Advice: An experienced provider with knowledge of the industry and a comprehensive understanding of local and federal regulations can help you avoid potential legal issues, delays, and non-compliance issues that could otherwise significantly impact your project\u2019s timeline and budget."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "By keeping these key considerations in mind, you can choose a provider that can meet your project\u2019s needs and ensure its success."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "The A/E/C industry is continually evolving and adopting new technologies that are improving the accuracy and speed of surveying and mapping services. These technologies have led to the development of new techniques, which offer better data quality, quicker turnaround times, and increased accuracy. In this section, we will explore the emerging trends in surveying and mapping and their potential impact on the A/E/C industry."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Emerging Trends in Surveying and Mapping"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Emerging trends in surveying and mapping are shaping the future of the industry, leading to improved efficiency, accuracy, and safety. Here are some of the most notable trends:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Drones and Aerial Surveying"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Drones are becoming increasingly popular in the A/E/C industry, particularly for large-scale projects. Aerial surveying with drones provides high-resolution images, which can be used to create 3D models of terrain and structures. This technology can significantly reduce the time and costs associated with traditional land surveying techniques."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "3D Laser Scanning and 3D Model Creation"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "3D laser scanning is a technique that uses lasers to capture high-resolution, 3D images of objects and structures. This technology is particularly useful in capturing data on existing structures, and the 3D models created from the scan can be used to identify potential design problems or compatibility issues."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "CHW\u2019s team expertly used this technology to scan a 96\u2033 reinforced concrete pipe for a conveyor belt system, identifying any potential skew issues and assisting CEMEX and Lake County in modernizing Schofield Road between U.S. 27 and the Orange County line. The $13 mil project will provide improved, paved access for commuters traveling to and from State Road 429 and the Greater Orlando area and is slated for completion this year."
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "GIS and Mapping Software"
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "Geographic Information System (GIS) technology is used to store, analyze, and manipulate geographic data. GIS mapping software is becoming increasingly popular in the A/E/C industry as it allows for improved data visualization and analysis, making it easier for designers and engineers to plan projects accurately."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "These technological advances in the A/E/C industry have resulted in:"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Improved Efficiency and Accuracy: The integration of new technologies in surveying and mapping has improved the accuracy and efficiency of data collection and analysis. This technology has led to more reliable data and has allowed for faster project turnaround times."
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "Enhanced Visualization and Communication: The 3D models created using laser scanning, drone mapping, and GIS technology can be used to improve project visualization and communication. This visualization can aid stakeholders in better understanding project designs and identifying potential design issues before construction."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Opportunities and Challenges in the Future of Surveying and Mapping: The future of surveying and mapping is exciting, with emerging technologies providing significant opportunities for the A/E/C industry. However, the integration of these technologies also presents several challenges, such as increased costs and the need for specialized knowledge and skills."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "By adopting new technologies, surveying and mapping professionals can streamline their workflows, provide more accurate data, and communicate more effectively with clients and stakeholders."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Aerial surveying with drones provides high-resolution images, which can be used to create 3D models of terrain and structures."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "CONCLUSION"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "In conclusion, surveying and mapping play a vital role in the success of projects across various industries. As technology continues to evolve, they will become even more efficient and accurate, providing enhanced visualization and communication opportunities for the A/E/C industry."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "At CHW Professional Consultants, we are committed to delivering multi-disciplinary high-quality solutions that create effective, long-term partnerships with our clients. Our team of over 100 employees across Florida has a wide range of expertise in civil engineering, surveying and mapping, land development planning, ecological services, landscape architecture, urban design, transportation planning and traffic engineering, and construction engineering inspection services."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "When it comes to surveying and mapping, choosing the right provider is critical to ensuring accuracy, reliability, and cost-effectiveness. At CHW, we take pride in supporting our clients\u2019 goals and our commitment to communication and collaboration ensures that our clients\u2019 needs are always met. If you\u2019re looking for a provider that delivers a diverse portfolio of professional services, look no further than CHW."
    },
    {
        "question": "What is Earth Engine?",
        "area": "geospatial intelligence",
        "text": "Earth Engine is a platform for scientific analysis and visualization of geospatial datasets, for academic, non-profit, business and government users."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Earth Engine hosts satellite imagery and stores it in a public data archive that includes historical earth images going back more than forty years. The images, ingested on a daily basis, are then made available for global-scale data mining."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Earth Engine also provides APIs and other tools to enable the analysis of large datasets."
    },
    {
        "question": "How is Earth Engine different from Google Earth?",
        "area": "remote sensing",
        "text": "Google Earth enables you to travel, explore, and learn about the world by interacting with a virtual globe. You can view satellite imagery, maps, terrain, 3D buildings, and much more."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Earth Engine, on the other hand, is a tool for analyzing geospatial information. You can analyze forest and water coverage, land use change, or assess the health of agricultural fields, among many other possible analyses."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "While the two tools rely on some of the same data, only some of Google Earth's imagery and data is available for analysis in Earth Engine."
    },
    {
        "question": "How does Earth Engine data compare to the Landsat and Sentinel data in Google Cloud?",
        "area": "other",
        "text": "The Earth Engine team has worked in close collaboration with Google Cloud to bring the Landsat and Sentinel-2 collections to Google Cloud Storage as part of the Google Cloud public data program."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "The Google Cloud collections make it much easier and more efficient to access the data directly from Cloud services such as Google Compute Engine or Google Cloud Machine Learning."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Please note that the Earth Engine Code Editor and API do not access these Cloud collections; they use the Earth Engine data catalog directly."
    },
    {
        "question": "Why is Google working on Earth Engine?",
        "area": "geospatial intelligence",
        "text": "Google's mission is to organize the world's information and make it universally accessible and useful. In line with this mission, Earth Engine organizes geospatial information and makes it available for analysis."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "More generally, Google strives to make the world a better place through the use of technology. Earth Engine's technical infrastructure powers humanitarian, scientific, and environmental initiatives which Google is proud to support."
    },
    {
        "question": "What can Earth Engine do for me or my organization?",
        "area": "remote sensing",
        "text": "Earth Engine provides easy, web-based access to an extensive catalog of satellite imagery and other geospatial data in an analysis-ready format. The data catalog is paired with scalable compute power backed by Google data centers and flexible APIs that let you seamlessly implement your existing geospatial workflows. This enables cutting-edge, global scale analysis and visualization."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Tell me what some others have done with Earth Engine"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Earth Engine is used by researchers, nonprofits, educators, and governmental agencies who use the system to analyze large-scale geospatial data. Please refer to our Case Studies for examples of Earth Engine in action."
    },
    {
        "question": "How do I get access?",
        "area": "other",
        "text": "To get access to Earth Engine, register your Google Cloud Project. See the Google Earth Engine Developers Site for more information."
    },
    {
        "question": "Can I access Earth Engine from more than one Google account?",
        "area": "other",
        "text": "An Earth Engine account is associated with a single Google account. Creating multiple Earth Engine accounts to circumvent quota restrictions is a violation of the Earth Engine Terms of Service."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Tell me how Earth Engine works"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "See the Google Earth Engine Developers Site for documentation and examples."
    },
    {
        "question": "Is Earth Engine compatible with my existing tools?",
        "area": "remote sensing",
        "text": "Imagery and data from third-parties may be imported into Earth Engine for analysis. Conversely, any analysis performed in Earth Engine can be downloaded for use by third-party tools."
    },
    {
        "question": "What datasets are available?",
        "area": "other",
        "text": "We have a searchable data catalog, including the entire EROS (USGS/NASA) Landsat catalog, numerous MODIS datasets, Sentinel-1 data, NAIP data, precipitation data, sea surface temperature data, CHIRPS climate data, and elevation data."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Users can also upload their own data for analysis in Earth Engine, with full control over access."
    },
    {
        "question": "How do I request additions to the public data catalog?",
        "area": "other",
        "text": "Please file issues to request new datasets or updates to existing datasets."
    },
    {
        "question": "Can I use my own proprietary imagery and vector data?",
        "area": "geospatial intelligence",
        "text": "Yes. Earth Engine enables you to upload your own raster and vector data (e.g. GeoTIFF or Shape files) for analysis."
    },
    {
        "question": "How can I share/publish/etc. the results of my analysis?",
        "area": "remote sensing",
        "text": "We encourage you to share your results. You can share your results and analysis scripts directly with other Earth Engine users, or you can simply download and share them as you would any other data. However, if your results include use of the Google Maps basemap (such as a Code Editor screenshot), note that Google Maps and its imagery providers do require attribution and any Google citations in the screenshot should not be removed."
    },
    {
        "question": "How do I cite Earth Engine in publications?",
        "area": "remote sensing",
        "text": "Gorelick, N., Hancher, M., Dixon, M., Ilyushchenko, S., Thau, D., & Moore, R. (2017). Google Earth Engine: Planetary-scale geospatial analysis for everyone. Remote Sensing of Environment."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Bibtex:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "@article{gorelick2017google,"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "title={Google Earth Engine: Planetary-scale geospatial analysis for everyone},"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "author={Gorelick, Noel and Hancher, Matt and Dixon, Mike and Ilyushchenko, Simon and Thau, David and Moore, Rebecca},"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "journal={Remote Sensing of Environment},"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "year={2017},"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "publisher={Elsevier},"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "doi={10.1016/j.rse.2017.06.031},"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "url={https://doi.org/10.1016/j.rse.2017.06.031}"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "}"
    },
    {
        "question": "How much does Earth Engine cost?",
        "area": "other",
        "text": "Earth Engine is free for noncommercial use: learn more here. For commercial or operational applications, please click here to learn more about pricing options."
    },
    {
        "question": "Beyond evaluation, is Earth Engine available for commercial use?",
        "area": "other",
        "text": "Yes! Earth Engine is now a Google Cloud product. Get more details here."
    },
    {
        "question": "Who owns the algorithms I write in Earth Engine and the results of my analyses?",
        "area": "other",
        "text": "You do. The results of all analyses you perform are yours. All algorithms that you write with our API are yours. Here's the fine print."
    },
    {
        "question": "Am I required to display my Earth Engine results on a Google Map?",
        "area": "other",
        "text": "You are free to display your Earth Engine results on Google Maps or any other mapping platform."
    },
    {
        "question": "What kind of support do you provide?",
        "area": "other",
        "text": "Technical support: Our Help page provides resources for getting support, including the option for Earth Engine users to join the Developers email list where our staff and other Earth Engine users answer questions."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Training: We hold frequent Earth Engine training sessions, including our annual Earth Engine User Summit and the Geo for Good conference, typically held at the Googleplex in Mountain View, CA. To receive announcements about the sessions, stay subscribed to the Developers email list, and/or the Google Earth Outreach mailing list, which also provides information and training on other Google mapping tools."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Paid Technical Support: For commercial customers using Earth Engine in a commercial context, a range of support options are available to you through Google Cloud. Get more details here."
    },
    {
        "question": "I\u2019m a startup interested in using Earth Engine. Is there any program for Startups?",
        "area": "other",
        "text": "Yes! The Google for Startups Cloud Program provides your funded startup with access to dedicated mentors and industry experts, product and technical support, Cloud cost coverage (up to $100,000) for each of the first two years, and more. Apply here"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "If you\u2019ve applied for this program, and were not eligible for it, please reach out here."
    },
    {
        "question": "I have never heard of a property boundary, so when should I consider having my property surveyed?",
        "area": "surveying",
        "text": "Land, property, and the accessories on it are more than likely the largest investments you will ever make, so protect it."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "When purchasing land or a house."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "When selling land or a house. Verify that you are selling only what you intend by using a legal description written by a Surveyor."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "If you don't know where your property lines are located."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Before improving your property by building a house, garage, accessory building, fence, retaining wall, landscaping, or garden when you are close to a property line."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "If you and your neighbor disagree with the location of a line or corner location."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "You feel like your neighbor may be encroaching onto your property."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "When land is not clearly described by a legal description, subdivision, survey, or plat."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "When subdividing a parcel of land."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A lending agency can require a survey for mortgage purposes if the property is not well described or ambiguous."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "There are many different factors that determine the cost of a survey. There is research that needs to be performed, fieldwork both on your property and the surrounding property, and specialized equipment and software."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Amount of research, drafting, office work, and fieldwork required to perform the survey."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Quality of your current legal description and whether it is ambiguous."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Type of equipment and software required to perform the survey."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Current conditions of the property."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "size of the parcel"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "number of unknown property corners."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "building, fences, landscaping, or other improvements."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Terrain and the accessibility of the site."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Please click here or use the quote request button below for a free quote or contact us with questions."
    },
    {
        "question": "What is the reason you are looking into a survey and what is the end result you are looking for when it is complete?",
        "area": "surveying",
        "text": "Location of the property you are looking to get a survey on:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "legal description"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "document number at the Register of Deeds Office."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "parcel number"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "address if available"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "title examination papers if available"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Current owner's names and history of ownership."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Information regarding disagreements with current or past owners and neighbors over the location of property boundaries."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Information regarding easements for your property (these may be verbal agreements but are important)."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Allow adequate time to research and plan your project by contacting the land surveyor well before the survey is needed."
    },
    {
        "question": "What should you see when the survey is finished?",
        "area": "other",
        "text": "Make sure the services spelled out in your contract were performed."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Make sure they set all corners shown on the survey."
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "A copy of the map that the surveyor drafted."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A legal description of your property."
    },
    {
        "question": "What is an easement?",
        "area": "surveying",
        "text": "Even though the owner maintains the ownership of a property, an easement is a legal document that grants the crossing of your property by a neighbor without penalty.  For example, it might include a driveway to access the main road, or to simply share a driveway. Another easement could be granted to a utility company to run power, telephone, and cable lines."
    },
    {
        "question": "What should I do if I\u2019m in a dispute with my neighbor over possible encroachment onto my property?",
        "area": "surveying",
        "text": "You are strongly advised to talk to your neighbor to ensure that there is not a misunderstanding.  It may be advisable to hire a Land Surveyor to do a survey of your property to resolve any misunderstandings."
    },
    {
        "question": "What is a Corner Record Survey and when is it required? (Previously recorded on a Parcel or Tract Map)",
        "area": "surveying",
        "text": "A Corner Record is a document that determines where the physical placements of property corner monuments (also known as corner staking) are to be placed. The document must be prepared by a licensed land surveyor in accordance with the Professional Land Surveyors\u2019 Act."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A Corner Record is required when it has been determined that your property\u2019s boundary corners have already been defined on an existing recorded Record of Survey Map, a Parcel Map, or a Tract Map. The Corner Record is submitted to the County Surveyor\u2019s office for review and approval. Upon approval, it is then filed with the County Surveyor\u2019s office."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Note: If property corners have not been defined on an existing recorded Record of Survey Map, a Parcel Map, or a Tract Map, then a Record of Survey Map will be required."
    },
    {
        "question": "What is a Record of Survey and when is it required? (Not previously recorded on a Parcel or Tract Map)",
        "area": "surveying",
        "text": "The purpose of a Record of Survey is to document the physical placement of property corner monuments (also known as corner staking). A Record of Survey Map is required when it has been determined that your property\u2019s boundary corners have not been defined on an existing recorded Record of Survey Map, a Parcel Map, or a Tract Map."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A Record of Survey Map must be prepared by a licensed land surveyor in accordance with the requirements of the Professional Land Surveyors\u2019 Act. The Record of Survey Map is submitted to the County Surveyor\u2019s office for review and approval. Upon approval, it is then filed with the County Surveyor\u2019s office."
    },
    {
        "question": "What is a Parcel Map?",
        "area": "surveying",
        "text": "A Parcel Map is the official subdivision map required to subdivide a piece of property into four (4) or less lots. It is prepared in accordance with the Professional Land Surveyors\u2019 Act and is filed with the County Surveyor\u2019s office."
    },
    {
        "question": "How do I locate a property line?",
        "area": "surveying",
        "text": "You can obtain this information through your county\u2019s assessor\u2019s office.  It is public information.  You can also look at your property\u2019s deed.  If you have had a survey on your property, you will find the property lines on that document."
    },
    {
        "question": "How do I subdivide a property?",
        "area": "surveying",
        "text": "If you are a Residential or Commercial property owner and are looking to increase the value of your property by subdividing it, you will need to go through an extensive \u201cLand Subdivision\u201d process.  If you are not familiar with this process, it can be a bit overwhelming!  Even for what appears to be a small project, the Land Subdivision Process can be very complicated.  G&M\u2019s 8-Phase Land Subdivision Process located on our Learn page lists in detail the steps involved in subdividing your land."
    },
    {
        "question": "What is a lot line adjustment?",
        "area": "surveying",
        "text": "A lot line adjustment is a process that occurs when a property owner changes the property lines of parcels of land that already exist."
    },
    {
        "question": "What is a Flood Certificate?",
        "area": "surveying",
        "text": "A Flood Certificate is a document that certifies if your property is located within a flood zone. To determine if your property is in a flood zone, you can check with the Federal Emergency Management Agency (FEMA).  FEMA will compare your address with their flood map. A Flood Certificate is typically required when requesting a bank loan."
    },
    {
        "question": "What is a Topographic survey?",
        "area": "surveying",
        "text": "A Topographic (Topo) land survey shows the height depth, size, and location of man-made or natural features on your property such as peaks, valleys, stream or creek, wooded areas, etc.  For you to understand the lay of your land, a topographic survey is typically required when you want to build on your property or if you are having an erosion problem."
    },
    {
        "question": "What is a boundary survey?",
        "area": "surveying",
        "text": "A boundary survey is a document that defines the exact boundaries of your property. The survey will show the distances from your house to the boundary lines, and to the street, etc. The document includes the legal description, parcel identification, section, township.  Typically, you would need a boundary survey if you were in dispute with your neighbor, if you are buying a property, dividing, or building on your property."
    },
    {
        "question": "Do I need a survey to put up a fence, what type of survey is needed?",
        "area": "surveying",
        "text": "Check with your municipality as some require a survey for fence installation.   It is strongly recommended because you do not want to accidentally put your fence on your neighbor\u2019s land. The ideal location is \u201cjust\u201d inside your property so that you become the sole owner of the fence. A boundary survey would be the type of survey to determine your boundaries."
    },
    {
        "question": "Do I need a survey or a permit to build a retaining wall on property line?",
        "area": "surveying",
        "text": "Not always.  However, if a retaining wall is to be built on a property line (like a fence), most municipalities require a survey for that property line.  A permit may or may not be required.  Typically, if a retaining wall is no higher than 4\u2019, then a permit may not be required.  Always check with your local municipality before building a retaining wall to determine what they require."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land Surveyor FAQ"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A land survey on a property is vital for a property owner. It\u2019s an essential step for any land development. It determines the land\u2019s accurate measurement and boundaries. Knowing where your boundaries lie can prevent any disputes in the future."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Below are some of the most asked questions at Accurate Land Surveyors, Inc. These questions apply to both residential and commercial properties. If you can\u2019t find your concerns on the list, feel free to contact us. Our team will get to you as fast as we can."
    },
    {
        "question": "What is land surveying?",
        "area": "surveying",
        "text": "Land surveying is a process of measuring the boundaries, corners, etc., of a land. It helps owners determine where their property lines lie. A survey helps establish the locations of residential and commercial properties. Moreover, it prevents issues, such as potential boundary disputes."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land surveys also highlight the restrictions that a property may have. A survey could help experts analyze a structure. It shows if a structure is appropriate and within the property\u2019s constraints."
    },
    {
        "question": "Why is surveying important?",
        "area": "surveying",
        "text": "The law requires property owners for a land survey. For example, you plan on having a new structure built on your property. It can be a new fence or a physical monument. Doing this will need you to get planning permission from your local office. But first, you must present a property survey."
    },
    {
        "question": "Do you have plans to sell your home? If so, potential buyers need to know the property\u2019s boundary lines. This way, they can avoid potential disputes with their neighbors. Encroachment is one of the most common causes of disputes in the US.",
        "area": "surveying",
        "text": "Another use of a land survey is applying for insurance from a title insurer. Surveys can reveal unforeseen issues that can affect a property\u2019s title. Once the assessment is complete, the owner will receive the title insurance."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A title company must ensure that buyers receive the land title legitimately. Surveys also help them do the following:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Confirm the following property\u2019s dimensions"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Identify the easements of record"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Check that the property sold or mortgaged is correct"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Detail the encroachments affecting the property"
    },
    {
        "question": "Why do you need a professional?",
        "area": "surveying",
        "text": "You can\u2019t do a land survey by yourself. You need professional land surveyors to check your property for you. It is a surveyor\u2019s job to measure a property and define its boundaries for you."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Only professional land surveyors have the license to do these tasks. They have the appropriate training to conduct surveying work. This job comes with strict guidelines that they must follow, and varies by municipality."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "If you need land surveying services, feel free to contact us here at Accurate Land Surveyors, Inc. We\u2019ll go above and beyond to assist you with any of your land surveying needs."
    },
    {
        "question": "Why would you hire a land surveyor?",
        "area": "surveying",
        "text": "State statutes and regulations mandate that only licensed land surveyors can conduct surveys. The reasons for these surveys include the selling, development, or subdivision of property."
    },
    {
        "question": "What does a land surveyor produce?",
        "area": "surveying",
        "text": "Land surveyors produce a survey map and the property\u2019s legal descriptions. The official, drawn map of the subject property must be accurate and detailed. It shouldn\u2019t miss out on important information, such as the property\u2019s ownership and the rights and limitations."
    },
    {
        "question": "How do surveyors survey land?",
        "area": "surveying",
        "text": "Surveyors use various tools and equipment to assess a property. Paired with years of experience, we can offer the best surveying services to our clients."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "But a surveyor\u2019s process may depend on the type of land survey that they must do. But the general task is identifying property placements and the neighboring buildings. They must also analyze any possible changes in the property, as well as its topographic data. They check the latter using a topographical survey."
    },
    {
        "question": "What type of survey should you conduct?",
        "area": "surveying",
        "text": "The survey you should have on your property depends on what you need. At Accurate Land Surveyors, Inc., here are some of the surveys that we offer:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Boundary Survey. Boundary surveys help determine where the boundaries of your property lie. This survey is for selling, dividing, or building new structures on the land. Once surveyors determine the boundaries, they\u2019ll set property corners."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Location Survey. Location surveys provide more information about the location of interior improvements. This survey is essential for a loan application or zoning permit."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Site Planning Survey. Site planning surveys are necessary for getting a development permit application. This survey helps plan the design improvements and development of a project."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Subdivision Survey.  This survey helps divide a parcel of land into two or smaller lots. A subdivision survey can also aid in designing drainage and streets."
    },
    {
        "question": "How does a land surveyor help in boundary disputes?",
        "area": "surveying",
        "text": "Boundary disputes arise when neighbors disagree about where their property line lies. Encroaching structures such as fences can escalate into a full-blown court hearing. Because of this, homeowners shouldn\u2019t skip getting their properties surveyed."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land surveyors determine your boundary using the legal description on the deed. It will show whether you\u2019ve infringed on your neighbor\u2019s property or vice versa. Moreover, surveyors can testify in court and explain the result of their survey."
    },
    {
        "question": "How much does surveying cost?",
        "area": "surveying",
        "text": "Various factors can affect the cost of a land survey. These include:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Terrain"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Type of survey"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Previous improvements on the property"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Purpose of the survey"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "How recent the last survey was"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land that can be hard to reach or access is often more costly when it\u2019s time for a survey. These include properties that are steep or have a lot of trees in the area."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Moreover, the type of survey will be a significant factor in the costs. Different surveys need different levels of attention to detail and equipment. Hence, surveyors might do intense research before measuring your land. The more labor-intensive a survey is, the higher the fee you might pay."
    },
    {
        "question": "Can a land surveyor trespass?",
        "area": "surveying",
        "text": "Land surveyors can\u2019t enter a property without the owner\u2019s consent. They can only enter the property they\u2019re going to survey. To enter the land\u2019s bordering properties, they must have permission to access it. If a surveyor enters without permission, property owners can sue them for civil or criminal trespass."
    },
    {
        "question": "Can a land surveyor be wrong?",
        "area": "surveying",
        "text": "Of course, surveyors can be wrong. Miscalculations with property boundaries can happen. Most of the time, this stems from a simple mistake. Other times, it can be because of equipment that isn\u2019t working right. Client miscommunication can also be a reason why a surveyor produces wrong results."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Many factors often lead to errors in a property survey. These can range from a surveyor marking the corners wrong or erroneous data. But rest assured! At Accurate Land Surveyors, Inc., we\u2019ll ensure that you get an accurate survey of your property. So please feel free to contact us for any concerns or land surveying needs."
    },
    {
        "question": "Why Do You Need a Land Surveyor?",
        "area": "surveying",
        "text": "Getting your land surveyed isn\u2019t optional. Whether you\u2019re trying to sell your property, construct a building, or add new additions to your home or business, you\u2019ll need to survey your property by a licensed and certified land surveyor."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "When you do a land survey, you can provide peace of mind to the buyer or get approval from the local government to begin your project. Don\u2019t skip on this crucial step. Doing so can end up costing you a lot more in the long run."
    },
    {
        "question": "Can NY Rising Help You?",
        "area": "surveying",
        "text": "The NY Rising program can help Long Islanders recover from several past hurricanes and other natural disasters. In addition, it can also provide Long Island homeowners resiliency for any future natural disasters. To qualify for this initiative, you will need to obtain an elevation certificate and a land survey from a qualified surveyor."
    },
    {
        "question": "Should You Consider Raising Your Home?",
        "area": "other",
        "text": "In areas prone to flooding, hurricanes, and natural disasters, homeowners should consider raising their homes. Doing so can help curb the cost of insurance premiums and prevent any significant damages from taking place."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Raising your home requires a lot of prep work. If you want to raise your home, you\u2019ll need a land survey and various certificates to get authorized to do so. In addition, construction companies and architects will greatly appreciate any reports you provide to make their job easier and of better quality."
    },
    {
        "question": "Do You Need a FEMA Elevation Certificate?",
        "area": "surveying",
        "text": "If you live in a flood-prone area such as Long Island, you should obtain a FEMA elevation certificate. A licensed and qualified land surveyor can only issue these certificates. Home insurance premiums can be crippling, but getting a FEMA elevation certificate may help to lower the costs."
    },
    {
        "question": "When Do I Need a Topographic Survey?",
        "area": "surveying",
        "text": "Topographic surveys measure elevations and other landforms you typically wouldn\u2019t find on a basic land survey. You would need a topographic survey for when you:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Conduct environmental restoration"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Redevelop land"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Build drainage ditches"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Provide additional information to builders or architects about the terrain"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "A licensed professional land surveyor should always do topographic surveys. Knowing the elevation and the terrain of your land will help save time and money for whatever project you\u2019re doing on it."
    },
    {
        "question": "What Type of Land Survey Do I Need?",
        "area": "surveying",
        "text": "The term land survey is a general term. Specific projects need certain types of land surveys. There are various types of land surveys you need as a property owner, depending on your project. These include:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Subdivision surveys"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Boundary surveys"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Topographic surveys"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Each survey has its own specific uses. For example, if you\u2019re trying to resolve a property dispute, you might want to go with a simple boundary survey. On the other hand, if you\u2019re trying to break up a large chunk of land into separate lots, a subdivision survey would be best."
    },
    {
        "question": "How Do I Find My Property Boundaries?",
        "area": "surveying",
        "text": "If you need to find your property boundaries, the best way to do so is to consult with local records about the land you own. If there are none available, you should hire a land surveyor to determine where your property boundaries are accurately. Even though you can technically measure the boundaries yourself, it\u2019s still best to get a professional to help you."
    },
    {
        "question": "What Is the Cost to Survey My Property?",
        "area": "surveying",
        "text": "Getting a land survey done can cost anywhere from a couple hundred to more than a thousand dollars. It all depends on:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The size of your property"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "The scale of your project"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The type of survey you need"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "The terrain of the land"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Any special requests or additional data you need"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "For the most accurate estimate of how much your land survey will cost, it\u2019s best to talk with experienced land surveyors. Most land surveying services will offer you a free estimate to learn more about how much you\u2019ll have to pay."
    },
    {
        "question": "Who Pays for a Boundary Survey?",
        "area": "surveying",
        "text": "More often than not, the person who pays for a boundary survey is the one who requests it. While there are certain exceptions to this rule, on general principle, if you want a land survey done, you have to pay for it yourself. Thus, there\u2019s very little reason to compel another party to pay for a boundary survey unless there\u2019s a good legal reason to do so."
    },
    {
        "question": "What Is the Difference Between a Land Survey and a Boundary Survey?",
        "area": "surveying",
        "text": "In understanding differences between land and boundary surveys, a land survey is an all-encompassing term. Land surveys are broad, and there are many different types available for landowners depending on the project they\u2019re trying to complete. In contrast, a boundary survey is a type of land survey."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Boundary surveys are relatively straightforward to complete. The main goal of a boundary survey is to measure property lines. If you need a survey that measures other things, such as elevation, then you\u2019ll need to request a different type of land survey."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Get Answers to Your Questions About Land Surveying"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "If you need land surveying services, you\u2019ll need a licensed, certified, and professional land surveyor to do it for you. Even if you have the tools and knowledge to survey your property on your own, state law requires that a professional conduct the survey. We provide many different services:"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Land surveys (boundary, topographic, ALTA/NSPS, subdivision)"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Civil engineering"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Site planning"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Staking property lines"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Construction layouts"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "For more specific information regarding surveying your land, you\u2019ll need to get in touch with us by phone or through our online contact form to receive a free estimate."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Boundary Survey FAQs"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Though a land surveyor is frequently associated with construction staking or engineering the main reason that land surveyors exist in the private sector is to find and identify boundary lines. The principle reason that a land surveyor is licensed in a given state is to serve and protect the public in regards to this fact. Boundary surveying is an evidence gathering process that starts in the office and then goes to the field to continue that gathering of evidence. In the end, the surveyor produces a document that shows the results of all this work. A land surveyor\u2019s role is quasi-judicial, this means that we should not be biased or take sides in a given boundary dispute like an attorney would. Nor does a surveyor represent you like a real estate agent would. In both Arizona and Colorado, the State Statutes declare that to land survey, one must be licensed by the state."
    },
    {
        "question": "Q:  What is a boundary survey?",
        "area": "surveying",
        "text": "A:  It is a type of land survey to locate boundary lines or one or more corners of a subject parcel. It is sometimes called a certified boundary survey. The document produced showing the results of this work is called a Record of Survey (ROS) in Arizona or a Land Survey Plat (LSP) in Colorado. This type of survey includes looking for existing boundary monuments on the subject parcel as well as looking for boundary monuments on adjacent parcels. At the end of the survey, we set any boundary monuments that are missing on the subject parcel. We have to do this level of work because no parcel sits independently \u2013 it has to be in harmony with the other parcels that surround it. We need to locate the boundary monuments on adjacent parcels in order to \u201cprove\u201d the boundary monuments on the subject parcel. The final drawing shows the results of this work and the boundary analysis. An ROS/LSP usually excludes showing physical features except along the boundary lines where fence/wall lines, tree lines, or hedge lines serve as boundary line evidence to consider during boundary analysis."
    },
    {
        "question": "Q:  Will you identify the boundary monuments on site so that I can see where my corners are?",
        "area": "surveying",
        "text": "A:  Yes, For each boundary monument found or set on the subject parcel we also set a 4\u2032 lath next to it and tie survey flagging on it so that it can be easily seen."
    },
    {
        "question": "Q:  Is there a chance the boundary monuments are already there?",
        "area": "surveying",
        "text": "A:  Yes, most likely all or some of the boundary monuments marking the corners are there, possibly below grade where you can\u2019t see them. This is part of what we look for when we do the field for a boundary survey and we set the boundary monuments that might be missing."
    },
    {
        "question": "Q:  Would the final price of the survey vary depending on how many boundary monuments are already there?",
        "area": "surveying",
        "text": "A:  No, pricing is not on a per boundary monument basis. For surveying, costs are driven by two factors \u2013 amount of work involved and professional liability. Even if the boundary monuments are there, we still have the time and work involved to find them (this includes office research and calculations time as well as labor time in the field). Furthermore, it\u2019s not just the subject parcel\u2019s boundary monuments we have to look for. Professional surveying requires us also look for the pins on adjacent parcels as well in order to prove the ones on the subject parcel. Drive time to the site is also a factor. If the subject parcel is \u201cout in the middle of nowhere\u201d or at least a long drive from the surveyor\u2019s office, this has to be factored into the price."
    },
    {
        "question": "Q:  Is it possible to skip a full ROS/LSP and just have you come out and flag up my boundary monuments to save money?",
        "area": "surveying",
        "text": "A:  No, if we just come out and flag the boundary monuments where they are, without doing the work of evidence finding/analysis and locating other boundary monuments to check against, we are doing a dis-service to the public. If one or more of those boundary monuments are off, then we have told you that this is where your corner is, when that\u2019s really not where it is. In addition to this, a surveyor just doesn\u2019t magically know where boundary monuments are, there is a lot of pre-field-work research and calculations that have to be completed in the office prior to showing up on site of the subject parcel. This amount of work, combined with the reasons stated above, is why GLS does not engage in \u201cfind and flags\u201d. In Colorado, the State Board that governs land surveyors actually frowns on this practice, this is partly because of the reasons stated above but also Colorado statutes clearly state that if we come out and participate in survey work, we have to deliver a document to you showing the results of that work."
    },
    {
        "question": "Q:  Does the survey have to be filed anywhere?",
        "area": "other",
        "text": "A:  It depends."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "In Arizona, if we have to set any missing boundary monuments on the subject parcel or upgrade a found boundary monument on the subject parcel, then yes, we have to record our survey per State Statutes. This recording is in the County Recorder\u2019s Office so that it is in the public records database."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "In Colorado, if the subdivision the subject parcel is located in is less than 20 years old, then the answer is no. But if it is more than 20 years old, or the subject parcel is not in a platted subdivision (e.g. metes & bounds or aliquot part type of legal description) then the answer is yes. The survey is deposited with the County Recorder so that it is in the public records database."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "GeoAI AI-driven geospatial workflows"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Discover how organizations are building a more resilient future with accelerated spatial problem-solving"
    },
    {
        "question": "What is GeoAI?",
        "area": "geospatial intelligence",
        "text": "Geospatial artificial intelligence (GeoAI) is the application of artificial intelligence (AI) fused with geospatial data, science, and technology to accelerate real-world understanding of business opportunities, environmental impacts, and operational risks. Organizations are modernizing operations to run at scale through automated data generation and approachable spatial tools and algorithms."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Extract rich geospatial data with deep learning"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Save time by automating the extraction, classification, and detection of information from data such as imagery, video, point clouds, and text."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Perform predictive analysis using machine learning"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Build more accurate models. Detect clusters, calculate change, find patterns, and forecast outcomes with spatial algorithms backed by experts."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Model the real world for prediction"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "Aerial imagery is used to extract imagery of buildings and roads in Grenada to identify the population and infrastructure at risk for landslides."
    },
    {
        "question": "Why is GeoAI important?",
        "area": "other",
        "text": "GeoAI is transforming the speed at which we extract meaning from complex datasets, thereby aiding us in addressing the earth\u2019s most pressing challenges. It reveals and helps us perceive intricate patterns and relationships in a variety of data that continues to grow exponentially. Organizations leveraging GeoAI are revolutionizing how they turn data into information, with models that adapt even as data evolves."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Improve data quality, consistency, and accuracy"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Streamline manual data generation workflows by using the power of automation to increase efficiency and reduce costs."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Accelerate the time to situational awareness"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Monitor and analyze events, assets, and entities from sensors and sources such as video to enable quicker response times and proactive decisions."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Bring location intelligence to decision-making"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Make data-driven decisions with real-world awareness. Improve business outcomes with insight from spatial patterns and accurate predictions."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Create a sustainable future"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Optimize resource management and understand the impact of business decisions on the community to reduce waste and better plan and manage sites."
    },
    {
        "question": "How is GeoAI used?",
        "area": "other",
        "text": "GeoAI is used in various industries and applications to tackle challenges and proactively seize opportunities. Explore how GeoAI is used to optimize crop yields, heighten community safety, streamline asset inspection, shorten emergency response times, and more."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2022  State and local government"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "GeoAI is accelerating the speed at which government officials better serve communities using data. By leveraging GeoAI, governments can model the impacts of urban development, understand the availability of resources to the population, forecast road and infrastructure deterioration, and identify land-use change (such as new buildings) to proactively take action."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2022  \u2022  Natural resources"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "GeoAI is revolutionizing the precision agriculture market by aiding the automated detection of invasive species. It helps the oil and gas industry monitor assets through automated extraction of flares, new well pads, or field access roads. Foresters and landowners use GeoAI to give them knowledge about the volumes and species of trees without a time-consuming on-site inspection."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2022  \u2022  National mapping and statistics"
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "GeoAI is enhancing the responsiveness, productivity, and speed of product delivery for national mapping agencies. Through automation, these organizations are scaling their internal capacities and production workflows. A national mapping department can quickly update a nation's geographic information system (GIS) in hours, not months or days."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "\u2022  \u2022  Defense and intelligence"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "GeoAI is speeding up how organizations extract information, identify patterns, and determine changes in big data. An intelligence organization can support its activity-based intelligence efforts by automating how they analyze information related to events, entities, surveillance video, and remotely sensed data."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2022  \u2022  Public safety"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "GeoAI is improving public safety as it relates to traffic accidents, emergency response, and disaster management. Organizations are making communities safer by predicting where accidents are likely to occur and optimizing emergency response times. Damaged infrastructure and navigable roads can be quickly identified to help allocate first responders."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2022  \u2022  Insurance"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "GeoAI is helping insurance organizations understand the impact of an event in hours instead of days to improve claim processing and efficiently help members. Insurance companies can use imagery and GeoAI to detect and classify damage that impacts its members. With this understanding, they can get members back on their feet more quickly."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2022  \u2022  AEC"
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "GeoAI is transforming the architecture, engineering, and construction (AEC) industry with its ability to extract information from imagery, which feeds a digital twin. This data allows decision-makers to improve project management, identify potential risks, and optimize building performance. As a result, architecture firms can design energy-efficient buildings."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2022  Business"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "GeoAI is accelerating smart business decisions, delivering insight and predictions that drive better market planning, site selection, supply chain efficiency, and customer intelligence. With these insights, a business can respond to customer behavior and determine whether a new market area is viable based on pattern and predictive analysis of market characteristics."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Geospatial AI"
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "Geospatial AI, also commonly known as GeoAI, is the combination of geographical information systems (GIS) and artificial intelligence (AI). It's a multidimensional field that applies AI techniques to geographically referenced data. Such data, often denoted as geospatial data or geographic information, refer to data that are associated with a physical location."
    },
    {
        "question": NaN,
        "area": "mapping",
        "text": "The integration of GIS and AI, through machine learning (ML) and deep learning, allows for the capturing, organization, manipulation, and display of geographically-referenced information, providing more efficient and accurate analysis of large and complex geospatial datasets."
    },
    {
        "question": "What is Geospatial AI?",
        "area": "surveying",
        "text": "Geospatial AI is a cutting-edge technology that integrates spatial intelligence and machine knowledge to analyze geospatial data and provide predictions. By merging GIS \u2013 having capabilities like geocoding, distance measurement, map display, and spatial analysis \u2013 with AI\u2019s ability to learn, reason, problem-solve, perceive, and understand language, GeoAI enables smart applications that have a huge impact in various important fields."
    },
    {
        "question": NaN,
        "area": "remote sensing",
        "text": "GeoAI applications can evaluate massive amounts of geospatial data to identify patterns, trends, and predictions that would take humans an enormous amount of time to do manually. It is heavily used in remote sensing technologies, location-based services, transportation, natural resources management, public safety, public health, agriculture, and many more sectors."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Developments in recent years in deep learning techniques, alongside the massive increase in availability of geospatial datasets, have dramatically pushed forward the use and importance of GeoAI in both research and application."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "FAQs"
    },
    {
        "question": "What is the significance of Geospatial AI?",
        "area": "geospatial intelligence",
        "text": "The significance of Geospatial AI lies in its ability to analyze complex and large volumes of geospatial data, enabling a more intelligent understanding of spatial phenomena and relationships. It drives advanced location intelligence, which is crucial in decision-making processes in various sectors."
    },
    {
        "question": "What are the applications of Geospatial AI?",
        "area": "geospatial intelligence",
        "text": "Geospatial AI has a wide range of applications including in disaster management (for instance predicting the path of cyclones), natural resources management (like predicting regions of potential mineral deposits), transportation (for traffic management), public health (like mapping the spread of diseases), agriculture (for crop yield prediction), and many more."
    },
    {
        "question": "How does Geospatial AI benefit businesses?",
        "area": "geospatial intelligence",
        "text": "In the business world, Geospatial AI can be used in location-based services, customer analytics, logistics and supply chain optimization. It can predict patterns and trends, providing businesses with valuable insights that can inform strategic decision-making."
    },
    {
        "question": "What is the future of Geospatial AI?",
        "area": "mapping",
        "text": "With continuous advancements in AI and GIS technologies, along with an increasing amount of geospatial data being generated, the future of Geospatial AI is promising. It is predicted to play an even more integral role in many sectors, contributing to the evolution of smart cities, autonomous vehicles, environmental sustainability, and beyond."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "In the realm of artificial intelligence, computer vision has emerged as a powerful and transformative field. Often referred to as \u201cvisual intelligence,\u201d it represents the ability of machines to interpret, understand, and derive meaning from visual data, much like the human visual system. This article explores the burgeoning Visual Intelligence Revolution, highlighting its significance, applications, and implications for various industries and our daily lives. know more"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "The Essence of Visual Intelligence"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "At its core, visual intelligence in machines is about teaching them to see and comprehend the visual world. It encompasses a range of tasks, including image recognition, object detection, facial analysis, and scene understanding. Computer vision systems leverage deep learning models, neural networks, and advanced algorithms to process and analyze visual data, allowing machines to extract meaningful information."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Applications Across Industries"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Visual intelligence is making profound impacts across various sectors, revolutionizing the way tasks are performed, decisions are made, and information is extracted from the visual realm."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "1. Healthcare: Visual intelligence has been instrumental in medical imaging, enabling the detection and diagnosis of diseases from X-rays, MRIs, and CT scans. AI-powered systems can pinpoint anomalies with high accuracy, aiding healthcare professionals in providing better patient care."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "2. Automotive: In the automotive industry, computer vision plays a pivotal role in autonomous vehicles. These vehicles use visual sensors, cameras, and lidar to perceive their surroundings, interpret traffic signals, and navigate safely, reducing the risk of accidents."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "3. Retail: Visual intelligence enhances the retail experience through cashier-less stores, where cameras track customers and their selected items, allowing for automated checkouts. It is also used for shelf monitoring, ensuring products are stocked correctly."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "4. Agriculture: In agriculture, computer vision helps optimize crop management. Drones equipped with visual sensors can monitor fields for signs of disease, pests, or irrigation needs, allowing for targeted interventions."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "5. Security and Surveillance: Security systems benefit from visual intelligence by identifying suspicious activities, recognizing faces, and enhancing perimeter monitoring. These capabilities enhance public safety and threat detection."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "6. Entertainment: Visual intelligence enhances the entertainment industry through facial recognition for personalized recommendations, content analysis, and visual effects in movies and gaming."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "7. Manufacturing: In manufacturing, computer vision ensures product quality by inspecting items for defects and automating quality control processes. Robots equipped with visual sensors can perform tasks with precision."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Challenges and Considerations"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Despite its transformative potential, visual intelligence faces several challenges. Ensuring data privacy and security in surveillance and facial recognition applications is a major concern. Additionally, addressing bias in algorithms and ensuring transparency and fairness in decision-making are ongoing challenges."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "The computational demands of deep learning models used in computer vision can be resource-intensive, requiring robust hardware infrastructure and efficient algorithms. Overcoming these challenges is essential for the responsible and ethical development of visual intelligence systems."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "The Future of Visual Intelligence"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "The future of visual intelligence is promising, with numerous exciting developments on the horizon. As technology evolves, we can expect even more advanced capabilities in areas such as:"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "1. Augmented Reality (AR) and Virtual Reality (VR): Visual intelligence will play a pivotal role in creating immersive AR and VR experiences, blurring the line between the digital and physical worlds."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "2. Robotics: Robots will become more adept at navigating complex environments and interacting with objects, thanks to enhanced visual perception."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "3. Healthcare Diagnostics: Visual intelligence will continue to improve medical diagnosis and treatment planning by analyzing medical images with unparalleled accuracy."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "4. Environmental Monitoring: Visual intelligence will contribute to environmental preservation by monitoring wildlife, assessing deforestation, and tracking climate-related changes."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Conclusion"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "The Visual Intelligence Revolution is reshaping industries and enhancing our daily lives in ways previously thought impossible. With its ability to teach machines to see and understand the visual world, computer vision is enabling breakthroughs in healthcare, automotive technology, retail, and many other fields. However, as we navigate this revolution, it is crucial to address ethical and privacy considerations, ensuring that visual intelligence benefits society while respecting individual rights and values. As technology continues to advance, the future of visual intelligence holds the promise of even greater innovation, creativity, and improved quality of life."
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Revolutionizing Real Estate: AI\u2019s Dynamic Impact and the Rise of Visual Intelligence"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "We have all observed the transformative power of Artificial Intelligence (AI) in various facets of our lives, reshaping entire industries. What was once perceived as a mere entertainment gimmick has matured into a system boasting remarkable accomplishments. While AI has gained significant acclaim, particularly in the realm of AI art, our focus today is on its less explored impact \u2014 how it is fundamentally revolutionizing real estate property markets."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "AI has significantly impacted the real estate industry, transforming various aspects of property markets, introducing unprecedented efficiency, accuracy, and foresight."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "The Power of Predictive Analytics and Market Trends"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Armed with the ability to meticulously sift through vast datasets, decode intricate market trends, and analyze economic indicators, these smart algorithms make super accurate guesses about what property values will be like in the future and where the market is heading. It changes how people make wiser decisions in the real estate world."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Risk Assessment and Informed Decision-Making"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "AI algorithms play a crucial role in real estate by helping us understand and manage risks. Their capabilities extend to a deep dive assessment of diverse risks associated with property investments, spanning market volatility, legal considerations, and financial intricacies. By minimizing potential challenges, people in real estate get important insights to make better decisions. In essence, AI emerges as an indispensable ally, ensuring that stakeholders are well armed with foresight and precision."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Automated Valuation Models (AVMs): Transforming the Way Specialists Value Properties"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Instead of the expensive and time consuming traditional methods that have been done for years and years, AVMs use smart algorithms and data to give us a fresh perspective on property values. AVMs analyze all important information, such as recent sales, market trends, and property features, to provide a quick estimation of a property\u2019s value. This speeds up the appraisal process that real estate agents may not provide.This shift towards fact driven data ensures a more factual understanding of property values, providing more comfortable transactions."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Anticipating Market Demand with AI: Mirrorball the Future"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "It doesn\u2019t just stop at figuring out property values \u2014 it\u2019s like a fortune-teller when it comes to predicting what people want in specific places. By analyzing past data and understanding the market consumer behavior, AI assists developers and investors in strategically deciding where to build or invest. This foresight not only eases uncertainties and provides confident decisions but also ensures that resources are allocated efficiently minimizing waste, aligning investments with evolving market demands."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Elevating Customer Experience with Virtual Assistants"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Imagine having your own virtual guide when exploring real estate. That\u2019s the magic of AI-driven virtual assistants and chatbots. They\u2019ve transformed customer service in real estate, making it more like a personalized journey. When you\u2019re looking for a property, these virtual assistants give you instant answers, walk you through different listings effortlessly, and even suggest options tailored just for you. This not only enhances the overall user experience; it also revolutionizes how we search for properties and book viewings. It streamlines the property search and the end-to-end buying process, introducing customer-centric real estate interactions."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Transforming Homes into Intelligent Spaces with Technology"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "People consistently invest in cutting-edge technology, embracing the latest updates and enhanced features that contribute to an improved quality of life. A smart home undoubtedly plays a pivotal role in influencing one\u2019s purchasing choices. AI\u2019s influence extends beyond transactional aspects, picture your home becoming more than just a place to live that also makes life so much more easy when powered by AI. Smart home technologies, powered by AI, offer automated climate control, advanced security systems, and optimized energy management. Keeping your feet warm, yourself safe and the world a better place. It\u2019s not just about meeting modern preferences; it\u2019s about homes becoming pioneers in innovation. By integrating AI into daily living, properties become intelligent, efficient, and prepared for the future, making life not just comfortable but cutting-edge."
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Visual AI: Transforming the Landscape of Real Estate Markets"
    },
    {
        "question": NaN,
        "area": "geospatial intelligence",
        "text": "Visual AI \u2014 this innovative solution brings a new dimension to your real estate endeavors, utilizing cutting-edge image recognition and analysis to transform the way you interact with properties. Delving into the realms of AI within your career not only has the potential to elevate your professional standing but also to supercharge your sales."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Virtual Property Tours: Bringing Properties to Life"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Starting first during the Covid-19 pandemic, this trend carries on. Visual AI has elevated property listings to an immersive level. Virtual property tours allow potential buyers to explore properties remotely. These virtual experiences, created through image analysis, bridge geographical gaps, enabling distant or international buyers to virtually step inside a property before making decisions."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Smart Image Tagging and Classification: Streamlining Property Listings"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Property images are essential to listing websites. However, it is also overwhelming to organize hundreds of images of new listings every day. Visual AI simplifies the organization of property listings through automated image tagging and classification. The technology identifies and categorizes features visible in images, such as swimming pools, kitchens, or scenic views. This not only enhances the visual appeal of listings but also improves search functionality for prospective buyers."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "From redefining property valuations to offering immersive virtual tours, Visual AI is a game-changer in the real estate landscape. Saving us the time, manpower and money. As we navigate this transformative era, Visual AI emerges as a silent yet powerful force, bringing a visual dimension to data analysis"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "Embracing a New Era"
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "In wrapping up, the integration of AI into real estate signals a significant shift in how we approach, transact, and engage with properties. AI\u2019s impact is versatile, hinting at a future real estate landscape defined by efficiency, precision, and innovation. As we navigate this transformative era, it\u2019s clear that the collaboration between AI and real estate is more than just a technological evolution \u2014 it\u2019s a meaningful change with implications for professionals and property enthusiasts. The fusion of technology and real estate is reshaping the way we buy and sell homes, offering a fresh perspective on what a home represents in the 21st century."
    },
    {
        "question": "How fast is your AI technology?",
        "area": "surveying",
        "text": "Our cutting-edge technology is the fastest real estate-specific computer vision solution available. Clients can expect image response times of less than 500 ms and property response times of only a few seconds. Multiple APIs calls can be made in parallel to meet any client\u2019s speed requirements."
    },
    {
        "question": "How do I integrate your technology?",
        "area": "other",
        "text": "Clients can quickly and easily integrate our AI solution via our cloud-based API service. It is based on the industry standard web protocol (HTTP) and returns a simple JSON response easily accommodated with any back or front-end interface."
    },
    {
        "question": "Does Restb.ai have an app?",
        "area": "other",
        "text": "We currently do not have an app. However, we do partner with other software providers to offer seamless solutions to enhance their services. Read more about our exciting partnerships here."
    },
    {
        "question": "Which types of Media can Restb.ai process?",
        "area": "other",
        "text": "Restb.ai can process standard image formats (JPEG, PNG, PPM, GIF, TIFF, BMP, etc.), including 360/equirectangular images, as well as videos."
    },
    {
        "question": "How do you respond to our API requests?",
        "area": "surveying",
        "text": "We respond using the JSON format. Once you send a request to our cloud-based RESTful API service, it will send back a JSON response for each image or property. Contact our team and book a demo to see our tech at work."
    },
    {
        "question": "What is JSON?",
        "area": "other",
        "text": "In computing, JavaScript Object Notation or JSON is an open-standard file format that uses human-readable text to transmit data objects consisting of attribute\u2013value pairs and array data types. \u2013 See more in www.json.org"
    },
    {
        "question": "What is ALT-Text and what are the benefits?",
        "area": "other",
        "text": "ALT-Text (Alternative Text) is a textual description of an image that can be read by screen readers for people with visual impairments. ALT-Text should provide a concise description of an image, conveying its content and context to users who cannot see the image."
    },
    {
        "question": "How do I edit an advanced tag (Image Captions and Property Features)?",
        "area": "other",
        "text": "Through our partnerships with various MLS platforms, our advanced tags are pre-populated on listings in two steps:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2013 Image Captions: Each image is provided with a concise and descriptive caption describing what the photo depicts. These are presented to the user during the image upload phase and may be edited however the user likes."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "\u2013 Property Features: The images are analyzed to determine if any of the property fields (i.e. Exterior Features or View Types) from the MLS\u2019s data dictionary are visible. The detected characteristics are then presented to the user to confirm. Any detections the user does not wish to make part of the listing may be deselected/removed (e.g. a photo contains a refrigerator but the seller does not plan to include the refrigerator as part of the sale). All approved fields will appear populated later in the listing upload process in their corresponding fields and may be changed at any time."
    },
    {
        "question": "Which kind of valuation/appraisal reports are you able to validate?",
        "area": "other",
        "text": "Our solutions are designed to analyze a report\u2019s images and return the AI insights using the terminology of the specified report. We support the following standardized reports:"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2013 PDR"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2013 PDC"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2013 1004/Form 70"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2013 1073"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2013 Form 30"
    },
    {
        "question": NaN,
        "area": "other",
        "text": "\u2013 And many more!"
    },
    {
        "question": "Are your condition and quality scores based on any standard?",
        "area": "surveying",
        "text": "We have built standardized condition and quality models to map to the UAD\u2019s property condition (C1C6) and property quality (Q1Q6) ratings. While the UAD\u2019s 6-point scale provides a single score for the entire property, our scores provide a granularity of one decimal and scores for the kitchen, bathroom(s), interior and exterior, as well as the property as a whole."
    },
    {
        "question": NaN,
        "area": "surveying",
        "text": "Our proprietary R1R6 model is not based on a standard, but is meant to provide a single, easy to use score based on a property\u2019s quality, condition, and potential. Similar to our other scoring models it provides a result on a home\u2019s kitchen, bathroom(s), interior and exterior, as well as the property as a whole."
    },
    {
        "question": "Is Restb.ai an AVM?",
        "area": "other",
        "text": "No, Restb.ai is not an Automated Valuation Model, though our solutions are widely used by many leading AVMs."
    },
    {
        "question": "Are you extracting images from PDFs?",
        "area": "other",
        "text": "Yes, Restb.ai can extract images from PDFs."
    },
    {
        "question": "Do you use humans to validate your results or data?",
        "area": "other",
        "text": "No, these are AI generated results. We don\u2019t have access to your data and do not control it. All responses are returned in real time."
    },
    {
        "question": "How long does it take to get results back from an appraisal report?",
        "area": "other",
        "text": "It is a real-time process and the results take between 5 to 15 seconds."
    },
    {
        "question": "How is Restb.ai Data different from any other Property intelligence data supplier?",
        "area": "surveying",
        "text": "Restb.ai extracts unique information from the property\u2019s photos, information that may not exist unless manually input by a person in the past. This provides up to 700 real estate-specific data points on any property\u2019s photos in as little as a few seconds. Many of our data points are exclusive to Restb.ai, such as condition and quality scores, granular kitchen layouts, etc. All responses from Restb.ai are provided consistently, always using the same criteria and the same data structure, on any property processed."
    },
    {
        "question": "The GIS of War - Tracking Conflicts and Their Effects",
        "area": [
            "data"
        ],
        "text": "\nDiego Valle-Jones has done some interesting work analysing and mapping Mexico&#39;s drug war (R code on github). Wikinarco provides webmap interface to some drug related crime statistics in Mexico. \n\n\n\n\nNow interactive map is also available:\n\n\n\n\nThe Economist has also done some mapping of drug related deaths, cartel areas and traffic routes.\n\n\n\n\n\n\n\n\n\nFrench OWNI provides nice web frontend for Wikileak&#39;s diplomatic cables. There seems to be map app, but it didn&#39;t work for me. Telegraph came with a web map as well.\n\n\n\n\n\n\n\nFor Iraq Wikileaks data visualization mentioned already by Kirk there is also interesting visualization from placr. For &#39;nonspatial&#39; browsing check OWNI&#39;s \napp.\nAnd before Iraq, Guardian  and The Atlantic also tried to visualize selection of Afgan Wikileaks data. \n\n\n\n\n\nOWNI provides &#39;nonspatial&#39; browser again. Nai&#39;s MediaWatch team provides spatio-temporal overview of the violence against journalists.\n\n\n\n\n\n\n\nAs for contrast to wars, Vision of Humanity provides interactive map of Global Peace Index.\n\n\n\n\nUpdate 1: Recently stumbled upon Guardian&#39;s visualization of Nato attacks in Libya. \n\n\n\n\n\nUpdate 2: Although not a military conflict per se, London riots start to fit description of this question as well. Slashgeo points to few geovisualizations on the topic. Guardian maps location of suspects, riots against poverty. And GENeSIS analyzes geolocated tweets.\n\n\n\nUpdate 3: Interesting visualization of protected areas &amp; civil conflicts in Democratic Republic of Congo.\n\n\n\nUpdate 4: Somalian Piracy Threat Map 2010 from Wikipedia article.\n\n\n Wikinarco provides <span class=\"highlight\">webmap</span> interface to some drug related crime statistics in Mexico. &hellip; "
    },
    {
        "question": "Seeking developer-friendly web GIS?",
        "area": [
            "web-mapping",
            "software-recommendations",
            "php"
        ],
        "text": "I&#39;m a recent Computer Science graduate who prides himself on his knowledge of software development and problem solving, but has no idea how GIS systems work. (Read: I&#39;m a programmer.)\n\nI&#39;ve been charged with developing (ie. coding) a new webmap from scratch.\n\nI can program in any language that has bindings to COM (Microsoft Component Object Model), so I&#39;ve been writing in PHP.\n I&#39;ve been charged with developing (ie. coding) a new <span class=\"highlight\">webmap</span> from scratch.\n\nI can program in any language that has bindings to COM (Microsoft Component Object Model), so I&#39;ve been writing in PHP. &hellip; "
    },
    {
        "question": "Is GIS industry always ruled by two options only, namely Esri products and OSGeo projects?",
        "area": [
            "open-source-gis",
            "arcgis-platform"
        ],
        "text": "I always wonder, why in GIS industry there are merely two major options available. Although there are many other proprietary software products for GIS, their market share is well below ESRI products (here, here and here although quite back dated). My opinion became stronger after joining GIS SE. Most of the questions, as well as the leading users (with highest reputation), are either for/interested in ESRI line of products or FOSS (of course apart from some questions related to data and theory). \n\nHowever this not the case in other streams of information technology, databases and programming languages in broad sense. I personally feel one reason could be the lack of interest by the software giants like Microsoft, Google or Oracle. While the first two have WebMaps, these are not WebGIS, and the spatial extension of Oracle is not fully GIS too. \n\nWhat are the major reasons for such a trend? There is nice article somewhat related to this, &quot; The Five Major Roadblocks to GIS Gaining Corporate Market Share&quot;. But this is not the answer I am looking for.\n\n\n\nMost of the answers seem to be trying to prove open source tools are better than Esri products! But that was not the question. Because it is difficult to compare a matured but expensive tool with a bunch of comparatively newer open source tools with great usability. My question is why no industry standard product from any established software giants? \n I always wonder, why in GIS industry there are merely two major options available. Although there are many other proprietary software products for GIS, their market share is well below ESRI products ( &hellip; "
    },
    {
        "question": "Configure which bands to display from a 4-band ArcGIS image service?",
        "area": [
            "qgis",
            "configuration",
            "image-service"
        ],
        "text": "The USDA (via the National Map) provides 4-band NAIP ArcGIS &quot;ImageServer&quot; (services) for most states in the US.  I am able to successfully connect to the WMS service in QGIS as described here, which loads the imagery into QGIS using the default RGB (1,2,3) bands.\n\nHowever, I&#39;d like to change the imagery to display the CIR (bands 4,1,2).  On the &quot;Style&quot; tab, the Render Type only offers the &quot;Singleband color data&quot; option, not the &quot;Multiband color&quot; option described in step 3.5 for typical rasters here.  This appears to be a limitation of the WMS Service.\n\nYou can do this from the same service in ArcGIS Desktop using the REST endpoint.  An ArcGIS Online webmap example of changing the bands of a service is available using the REST endpoint.  Just go to the &quot;...&quot; on the layer, choose &quot;Image Display&quot; and then &quot;User Defined Renderer&quot;.  \n\nUPDATE:\n\nI&#39;ve been playing around with the Developer Tools in Chrome and the ArcGIS.com map sample from here, and think I&#39;ve found a small nugget of info.  After I changed the image display settings, I noticed some query parameters set as:\n\n\n\nAfter I changed the band ID&#39;s again, I realized that the bandID&#39;s in this query parameter are zero-based, instead of 1-based.  Therefore &amp;bandIds=3,0,1 are really referring to bands 4,1,2 used to display imagery in CIR format.  So I just need to figure out how to configure the query string for QGIS to accept this parameter.  Any thoughts?\n An ArcGIS Online <span class=\"highlight\">webmap</span> example of changing the bands of a service is available using the REST endpoint. &hellip; "
    },
    {
        "question": "Are there any Hosting companies, that offer Geoserver?",
        "area": [
            "geoserver",
            "hosting"
        ],
        "text": "I am working with a non-profit, and we are planning to have a webmap for them. Most of the hosting providers just offer a simple LAMP setup on their Linux option, and if you want to install any software on your own, you need to go for a dedicated server (either real or virtual) which is very expensive for the organisation I am working with.\n\nI have seen that there is a hosting provider for Mapserver based maps.\n\nIs there any similar provider for Geoserver based maps?\n I am working with a non-profit, and we are planning to have a <span class=\"highlight\">webmap</span> for them. &hellip; "
    },
    {
        "question": "Steps for creating an online webmap with editable features using ArcGIS Server/SDE and SQL Server?",
        "area": [
            "arcgis-server",
            "web-mapping",
            "enterprise-geodatabase"
        ],
        "text": "EDIT/UPDATE: I&#39;m adding a bounty to this in hopes of obtaining a step-by-step guide to creating an online map with feature editing using the ArcGIS Flex API, SQL Server Express and ArcGIS Server 10.1. I&#39;ve run into so many issues (database authentication with Express, errors enabling feature editing) that I think my best bet is to start over and go through each step. A moderately detailed guide would be very much appreciated.\n\n\n\nI&#39;m primarily a desktop GIS programmer and need to develop a web application in which features can be edited by multiple users. I&#39;m looking for a brief summary of the full steps I would need to carry this process out if I were starting from scratch.\n\nSoftware: ArcGIS Flex API and SQL Server Express with ArcGIS Server 10.1.\n\nThe steps as I understand them so far:\n\n1) Install ArcGIS Server on our server (actually a virtual machine on an existing server)\n\n2) Install the ArcGIS Web Adapter\n\n3) Install ArcSDE on the same server\n\n4) Install SQL Server Express on the same server\n\nThis is where I need some clarification. As I understand it I need to create a new geodatabase to store the features I wish to display/edit. I also understand I need to create a Feature Service and Geometry Service. Finally I will need to host the developed application using a web server.\n\nI&#39;m essentially looking for a walk-through for this process as I have never carried it out before. Any information/resources would be much appreciated.\n EDIT/UPDATE: I&#39;m adding a bounty to this in hopes of obtaining a step-by-step guide to creating an online map with feature editing using the ArcGIS Flex API, SQL Server Express and ArcGIS Server 10.1. &hellip; "
    },
    {
        "question": "QGIS 2.18 QuickMapServices basemap labels shrink when exported to PDF from Print Composer",
        "area": [
            "qgis",
            "labeling",
            "basemap"
        ],
        "text": "This issue has been discussed (and lamented) many times on this site before. Have a look at these questions:\n\n\nWhy do quickmapservices basemap labels shrink when printed?\nHow to increase label size of OpenLayers plugin basemap layers?\nSet scale level of background map (QGIS)\nQGIS - changing WMS / ArcGISMapServer Zoom level\nHow to make a map in Qgis with a background of google maps?\nHow can I show the details from the highest zoom of OSM webmaps in QGIS for printing?\n\n\nThis is a limitation of base layers from WMS services. They&#39;re rendered as tiles, which means that the size of the labels is baked into each zoom level. When you increase the resolution, the server provides you a more zoomed-in tile, which has: (1) higher resolution and (2) smaller labels. You can&#39;t get (1) without (2).\n\nOne workaround is to force the tileserver to give you the zoomed-out version of the tiles. The image will be slightly fuzzy/pixelated but the labels will be larger. There are two ways to do this:\n\n\nReduce the dpi of your export. This requires some trial and error to find the highest dpi that will still give you the higher zoom level.\nImport the WMS layer as an XYZ tile layer. The basemap will still have a low resolution, but the other elements in your map can have as high a resolution as you want.\n\nFirst, find and copy the service URL from the layer properties &gt; Information &gt; GetMapURL\n\n\n\nNext, open the Browser panel, right click on &quot;XYZ Tiles&quot; &gt; New Connection. Paste the URL you found before. Set the max zoom level, and give the layer a name like &quot;This Basemap max zoom 16&quot;. Import the layer from the browser.\n\n\n\nIt takes some trial and error to find the right maximum zoom level for the scale at which you&#39;re making maps. \n\n\nAnother workaround is to use a basemap without labels, and add the labels from another source. \n\n\nIf you search around, you may find a WMS basemap which is just label, so you can control the label size independently. For example, through the QuickMapServices plugin you can get a layer called &quot;ESRI Boundaries&amp;Places&quot; which has place names (cities, states, parks, natural features) and political boundaries, but no street names. \nOr you can manually add the labels you want. \n\n\nIt&#39;s a trade-off between the convenience of a pre-made basemap versus having control over every aspect of your map.\n This issue has been discussed (and lamented) many times on this site before. Have a look at these questions:\n\n\nWhy do quickmapservices basemap labels shrink when printed?\nHow to increase label size of &hellip; "
    },
    {
        "question": "MapScript with Python 3",
        "area": [
            "python",
            "mapscript",
            "django-raster",
            "django-wms"
        ],
        "text": "I am trying to build raster summarizing features into a GeoDjango webmap,\nand would like to use the django-raster and django-wms packages to do so. I believe that I have them set up correctly, but am hitting errors when I try to install the MapScript Python bindings for MapServer (necessary for\ndjango-wms).\n\nI believe there is a compatibility error with Python 3 and MapScript, but\nam unsure of how to resolve them. I found this forum-post &amp; GitHub issue , but unfortunately my software development knowledge is not solid enough to make much sense of them.\n\nHas anyone compiled MapServer/MapScript with Python 3 recently, or know of any information per updating the software for compatibility with Python 3+?\n I am trying to build raster summarizing features into a GeoDjango <span class=\"highlight\">webmap</span>,\nand would like to use the django-raster and django-wms packages to do so. &hellip; "
    },
    {
        "question": "What are Pros and Cons to ArcGIS Online Organizational Account?",
        "area": [
            "arcgis-online"
        ],
        "text": "I have been using ArcGIS Online for the past several months for hosting data to be served in a custom JavaScript web application.  Here is a list of some of the pros and cons I have found while working with ArcGIS Online:\n\nCONS:\n\n\nSomewhat less flexible than a traditional ArcGIS Server in terms of hosting services and mapping capabilities\nNo labeling capabilities (that I have found)\nNo Geoprocessing Services (though I&#39;m told that they&#39;re coming)\nLimited Role-Based Security (Security is set on the service so all users have same permissions aside from content authors)\nUser interface seems more suited for sharing data within an organization and is not as presentable for sharing data with clients\nLimited support for developers\n\n\nPROS:\n\n\nSaved us from purchasing ArcGIS Server\nFairly easy to get up and running\nConfiguration of webmaps is very simple and can manage all the data needed for a web application\nService Credit Usage is fairly reasonable (I&#39;ve been going 6 months now and only used 50 credits)\nIntegration with ArcGIS Desktop (v 10.1+)\nBuilt In Security\n\n\nThat&#39;s all I can think of for now.  It can be a great tool for particular purposes.  Although it is saving us money using ArcGIS Online instead of ArcGIS Server, as a developer it is definitely much more limited and we have had to use a fair amount of workarounds.\n I have been using ArcGIS Online for the past several months for hosting data to be served in a custom JavaScript web application.  Here is a list of some of the pros and cons I have found while workin &hellip; "
    },
    {
        "question": "Does ArcGIS Online allow Select By Location?",
        "area": [
            "arcgis-online",
            "select-by-location"
        ],
        "text": "This question refers to the standard ArcGIS Online map, eg http://your-site.maps.arcgis.com/home/webmap/viewer.html\n\nIs it possible to perform a Select By Location, eg to find points from one layer which fall within a polygon layer?\n\nThere are a bunch of operations available under the Analysis menu but I can&#39;t see Select By Location. Is it necessary to build something custom (eg using the ArcGIS JS API, Web AppBuilder, etc) in order to get the Select By Location functionality?\n This question refers to the standard ArcGIS Online map, eg http://your-site.maps.arcgis.com/home/<span class=\"highlight\">webmap</span>/viewer.html\n\nIs it possible to perform a Select By Location, eg to find points from one layer which &hellip; "
    },
    {
        "question": "Overview of GPS tracking system technologies",
        "area": [
            "gps",
            "tracking"
        ],
        "text": "Background: I&#39;ve been asked by a friend to estimate the cost of setting up a GPS tracking system for a small fleet of buses, so we can do real time reporting of bus locations via a webmap.\n\nIn my research, I saw three kinds of active GPS trackers:\n\n\nRadio\nSMS\nSatellite\n\n\nSome major considerations are \n\n\nminimizing long term costs, and \nmaking the system as reliable as reasonably possible.  \n\n\nSecondary concerns are minimizing up front cost, latency, difficulty of installation/setup, level of support required after the initial setup is complete.  \n\nThe buses run within a 5 mile radius, so radio is feasible.\n\nWith an eye towards reducing long term costs, radio seems good: it would be the only way to run the system without a middleman.  \n\nSMS requires cell phone towers, and satellites require a space program.  I am concerned that a DIY solution with radios might prove to be less reliable, though.  \n\nBut if we bought SMS transmitters that provided the data through a third party API, they could go out of business, or have unacceptable down time or latency.\n\n\n\nMy question(s): \n\n\nWhat would each of these three solutions look like?  \nWhat hardware is involved?  \nWhat are the trade-offs between them? \nWhat problems have you encountered?  \nHave you used a system that Just Works?\n\n Background: I&#39;ve been asked by a friend to estimate the cost of setting up a GPS tracking system for a small fleet of buses, so we can do real time reporting of bus locations via a <span class=\"highlight\">webmap</span>. &hellip; "
    },
    {
        "question": "Sentinel 2 imagery as a webservice in a leaflet or openlayers map",
        "area": [
            "wms",
            "sentinel-2"
        ],
        "text": "I&#39;m looking for a simple solution to display the latest available Sentinel 2 imagery (true color) in a webmap, using e.g. Leaflet or OpenLayers, for instance with a WMS or a XYZ layer. I thought this kind of web-service would be provided by some agency/company for free, but I cannot find one. \n\nI found this &quot;sentinel-hub&quot; company that proposes WMS but it is not free. (BTW I don&#39;t like how they mislead users by calling themselves &quot;hub&quot; while they seem to have nothing to do with the official Copernicus Data Hub.) \n\nI know I can download Sentinel data (see this well-documented post) but I don&#39;t want to process and serve the data.\n\nEDIT: \n\nBy the latest imagery, I mean the latest cloud-free imagery. I think there are some flags on the Sentinel 2 imagery for this (clouds/no-clouds). I am looking for a specific location in Africa, but a global product would be fine. \n\nAm I missing something obvious? \n I&#39;m looking for a simple solution to display the latest available Sentinel 2 imagery (true color) in a <span class=\"highlight\">webmap</span>, using e.g. Leaflet or OpenLayers, for instance with a WMS or a XYZ layer. &hellip; "
    },
    {
        "question": "Use of Pictometry images in GIS",
        "area": [
            "imagery",
            "pictometry"
        ],
        "text": "I am wondering if anyone has worked with Pictometry in GIS and their .pmi files.  I recently acquired imagery from them for my area and have discovered that I cannot add the pmi files to the webmap, I presume I would have to export them.  The problem is that there are literally thousands of images and the export would be unrealistic (I&#39;m not very happy with their deliverables, wasn&#39;t involved in the acquisition process).  Has anybody worked much with their imagery and have any insights in how to best use it in GIS?\n I recently acquired imagery from them for my area and have discovered that I cannot add the pmi files to the <span class=\"highlight\">webmap</span>, I presume I would have to export them. &hellip; "
    },
    {
        "question": "&quot;Transferring&quot; ArcGIS Online content from one organization to another",
        "area": [
            "arcgis-online"
        ],
        "text": "ArcGIS Online Assistant (free) and Admin Tools for ArcGIS Online (Pro) (paid) offer solutions for moving items to a different organization.\n\nArcGIS Online Assistant is more limited than Admin Tools for ArcGIS Online (Pro). Most notably, the paid Admin Tools for ArcGIS Online (Pro) clone tool will update references in web apps and web maps to the new versions of the feature services copied to the new org.\n\nIn some cases, especially with a relatively small number of items to move you can use the free ArcGIS Online Assistant to move webmaps and feature services, then use the &quot;Update Web Maps Services URLs&quot; tool in the free version of Admin Tools for ArcGIS Online to update the web maps to use the new feature service URLs. \n\nAnother limitation of the free ArcGIS Online Assistant is that it doesn&#39;t move files such as image files.\n ArcGIS Online Assistant (free) and Admin Tools for ArcGIS Online (Pro) (paid) offer solutions for moving items to a different organization.\n\nArcGIS Online Assistant is more limited than Admin Tools fo &hellip; "
    },
    {
        "question": "How to use the ESRI JS API to map SQL Server Spatial Types without ArcGIS Server",
        "area": [
            "arcgis-maps-sdk-javascript",
            "sql-server"
        ],
        "text": "I have heard of people using the ESRI Javascript API to create webmaps with spatial data from SQL Server or other RDBMS&#39;s.  From what I can tell, they are not using ArcGIS Server as a middleware.  In particular, I recently heard of a company that uses a SQL Server database with spatial types and Entity Framework to link the database to the app, but then they are using the ESRI JS API on the front end to render the data.\n\nThis is something that really interests me as I have worked with SQL Server, Entity Framework, ASP.Net, and the JS API separately and I do not have access to ArcGIS Server.  Does anyone know of a particular architecture or workflow for simply using the JS API as a front end for a non ESRI backend?\n I have heard of people using the ESRI Javascript API to create webmaps with spatial data from SQL Server or other RDBMS&#39;s.  From what I can tell, they are not using ArcGIS Server as a middleware.  In  &hellip; "
    },
    {
        "question": "Creating a small web-mapping/map-tiling service",
        "area": [
            "qgis",
            "openstreetmap",
            "openlayers",
            "web-mapping",
            "tiles"
        ],
        "text": "\nbeing able to show categorized polygons in a thematic map (- if possible, it would be nice to get popups or to be able to retrieve attribute information - but that&#39;s highly optional)\nI would prefer to do most work (styling, etc) in QGIS\nOSM as base map would be perfectly fine\n\nAll this can be done within QGIS and the  plugin.  The workflow is simple:\n\nStyle your data in QGIS.  Use the old symbology as I had issues with the  when using the  plugin.\n\nLaunch the  plugin and define the openlayers settings (such as map size, map controls, basemap, etc).  This will create a directory containing the  and your data layers converted as  files.\n\nUpload the directory into the webserver.\n\n\nNote that this is only for simple webmap.  For creating custom basemaps and other webmapping features, check out iant and Peter&#39;s answers.\n Note that this is only for simple <span class=\"highlight\">webmap</span>.  For creating custom basemaps and other webmapping features, check out iant and Peter&#39;s answers. &hellip; "
    },
    {
        "question": "What is the maximum number of characters for a label in QGIS 3?",
        "area": [
            "qgis",
            "labeling",
            "length",
            "string",
            "limitations"
        ],
        "text": "After experimenting a little bit, I can confirm that QGIS has definitely no limitation of 1000 characters or less (as the initial form of the question suggested). Empirical evidence suggests that the limit of characters for a label is 2^15 - 8 = 32.760 characters - if pasted directly in the label field. If the label is based on an attribute, potential limits in the field length of the data format of the layer&#39;s source (file or database) apply.\nSee my screenshot, where I pasted a blindtext created in Word and counted as 17.016 characters (!). As you can see, the text displays as a label of the point in the bottom left of the map canvas.\nI also tried longer labels. An empirical value where QGIS clipped the text at the end was reached with 32.760 characters (near 32.768 = 2^15). So you could include a shorter term paper inside of a label text. That sayed means that the limitations are definitely more on the side of visualization, as MrXsquared already mentioned in his comment, than technical abilities of QGIS. QGIS is definitely able to display really very, very long labels.\nThe problem in your case has been another one (solved in anotoher answer). In any case, always make sure when using a field name as label if the data provider format has some limitations. I pasted the text directly with simple quotation marks : , thus not using the content of an attribute field. So we really speak here about label length, not lenght of field content - we have to clearly distinguish between them.\nWhat you also have to be aware of is line wrapping. Maybe when lines get too long (or when the labeled geometry feature is not visible on the map canvas) the label does not render. See this answer here: https://gis.stackexchange.com/a/381205/88814\n\nLabels of such a length are definitely not established practice - a label with 30 (!) characters is already characterized as &quot;very long&quot;:\n\nSometimes labels are very long, such as &quot;River of the Big Dry Blue\nReef&quot;\n\nIt would be interesting what you want to use such long labels for. Or is it just curiosity for the technical limitations of the feature?\nFor (dynamic) webmaps, anyway the placement of the labels changes with every zoom level (and panning), so I would use pop-ups, have a look at actions.\nFor print output, in Print Layouts and Reports, you have textfields at your disposal.\n After experimenting a little bit, I can confirm that QGIS has definitely no limitation of 1000 characters or less (as the initial form of the question suggested). Empirical evidence suggests that the  &hellip; "
    },
    {
        "question": "Seeking open source GIS web server",
        "area": [
            "python",
            "web-mapping",
            "software-recommendations",
            "web-service"
        ],
        "text": "If you use QGIS, you have at least two options to publish your maps without dealing with a server: install qgis2web-Plugin and generate web-maps with openlayers or leaflet:  - you can upload the output to a webspace (if you have one) and your web-map is there. However, export tries to &quot;translate&quot; your QGIS-project as good as possible to openlayers/leaflet, but many details (styling etc.) that work in QGIS will not be rendered in the same manner. So if it is just for publishing some basic maps, it&#39;s good enough. If you know how to adapt the output, the export could be a start and the final styling can be done there.\n\nSecond option and probably the fastest and least complicated way: QGIS Cloud - they have their own webspace you can use: just upload all layers as well as your QGIS-Project with the qgiscloud-plugin and your webmap will appear on their site in the exactly same look as your local QGIS-project. You don&#39;t need any understanding of web-technologies - when you have your QGIS-project ready, just press a few buttons, that&#39;s it. Basic use is free, additional use of webspace with costs. \n\nOf course, you could also use QGIS server:  but then, you have to install/configure it on your own.\n option and probably the fastest and least complicated way: QGIS Cloud - they have their own webspace you can use: just upload all layers as well as your QGIS-Project with the qgiscloud-plugin and your <span class=\"highlight\">webmap</span> &hellip; "
    },
    {
        "question": "How to add link in ArcGIS Online web map popup to google or bing driving directions?",
        "area": [
            "google-maps",
            "arcgis-online",
            "popup",
            "bing-maps",
            "driving"
        ],
        "text": "I have an ArcGIS webmap with school boundaries. I would like to provide a link in the pop up that takes a public user to a free routing website like Bing or Google with the directions to their neighborhood school already filled in.\n\nhttp://agtrail.rivcoca.org/ The County of Riverside has what I am talking about on their webmaps.\n\nIs this something I will have to create a url for for each school and add it to each school boundary attribute? Or is there a faster way?\n\nI know ESRI can do routing directions but they use up credits and I want to do this without costing my district any more money.\n\nMy scripting skills are very basic but if coding is the only way to do this I am willing to try my best.\n I have an ArcGIS <span class=\"highlight\">webmap</span> with school boundaries. &hellip; "
    },
    {
        "question": "Using ArcGIS.com map that is not shared with everyone from ArcGIS API for JavaScript?",
        "area": [
            "arcgis-maps-sdk-javascript",
            "arcgis-online"
        ],
        "text": "The identity manager needs to do a POST to login to access your webmap. Since you&#39;re hitting arcgis.com, this is a cross domain request so you need to do this via a proxy. Have you set up a proxy for your app?\n\nLooking at the docs, this isn&#39;t clear. We&#39;ll update our documentation to say you need to use a proxy if you want to use a private webmap in an app you host yourself (if you haven&#39;t guessed, I work on the JS API team).\n The identity manager needs to do a POST to login to access your <span class=\"highlight\">webmap</span>. Since you&#39;re hitting arcgis.com, this is a cross domain request so you need to do this via a proxy. &hellip; We&#39;ll update our documentation to say you need to use a proxy if you want to use a private <span class=\"highlight\">webmap</span> in an app you host yourself (if you haven&#39;t guessed, I work on the JS API team). &hellip; "
    },
    {
        "question": "Automatically download and merge webmap tiles into one big image?",
        "area": [
            "tiles",
            "tilemill",
            "merge",
            "image",
            "web-mapping"
        ],
        "text": "Is there an easy way to download a bunch of web map tiles (in /z/x/y.png format) and stitch them together into a single large image? I could probably script this using ImageMagick, but would prefer not to invent another wheel.\n\n(The tiles in question are made by me in TileMill. I&#39;m having serious problems with TileMill&#39;s export feature, and thought this might be a workaround.)\n\nMac or Linux only.\n Is there an easy way to download a bunch of web map tiles (in /z/x/y.png format) and stitch them together into a single large image? I could probably script this using ImageMagick, but would prefer no &hellip; "
    },
    {
        "question": "Add Item and Publish Service with ArcREST or ArcPy",
        "area": [
            "arcpy",
            "arcgis-online",
            "arcgis-rest-api",
            "arcrest"
        ],
        "text": "I just uploaded a script uploads a CSV and publishes as a github-gist. You may want to change the input as right now its setup to run at command line and enter parameters manually when you execute.\nThe credit goes to a co-worker of mine who shared this with me. I haven&#39;t extensively tested it, but it worked for the case I was trying. Note that it does rely on the requests module. You&#39;ll need to make sure you&#39;ve downloaded and installed that.\nAlso note the script isn&#39;t setup to re-publish or update/overwrite. I haven&#39;t done any work with re-publishing of a CSV file, but my best guess is you&#39;ll need to:\n\ndelete the CSV from the day before (unless you can overwrite it, then this isn&#39;t necessary)\nupload the new CSV (that is in the gist)\nCall publish on the new CSV (that is in the gist)\nSet overwrite:true in publish. (that is NOT in the gist). See the doc on publish params here\nYou should maintain the original ID because of the overwrite (I haven&#39;t tested this to verify)\n\nI should also note, because you asked in your question, there are no true arcpy functions to upload a CSV to Portal. There are functions in ArcGIS Pro to create webmaps or weblayers and the UploadService Defintion tool, but that requires features in a map. Not a stand alone CSV.\n I just uploaded a script uploads a CSV and publishes as a github-gist. You may want to change the input as right now its setup to run at command line and enter parameters manually when you execute.\nTh &hellip; "
    },
    {
        "question": "How to set up WebMap",
        "area": [
            "web-mapping"
        ],
        "text": "I&#39;d like to set up a webmap that clients can drop into their existing website.\nI&#39;m thinking Geoserver, OpenLayers &amp; GeoExt.\nIt would be very simple slippy map kind of thing. Do I need Geoserver at all then?\nJust want to be able to use WMS/pan/zoom/turn layers on and off.\nIf I ditch GeoServer, then do I need Apache?\n\nAnd where would be the best place to host this?\nCould most hosting companies handle it if there was no Geoserver since OL &amp; GeoExt are just JavaScript? I don&#39;t want to host it myself.\n\nAnyone who could point me in the right direction for a checklist or roadmap to offer up simple webmaps is greatly appreciated. I&#39;m looking for info on setting up the web side of it, since I&#39;m fairly good with GIS already.\n I&#39;d like to set up a <span class=\"highlight\">webmap</span> that clients can drop into their existing website.\nI&#39;m thinking Geoserver, OpenLayers &amp; GeoExt.\nIt would be very simple slippy map kind of thing. &hellip; "
    },
    {
        "question": "Maximum number of record returned by the server. Why 1000?",
        "area": [
            "arcgis-server",
            "rest"
        ],
        "text": "It&#39;s a combination of two things really.\n1) How much information can your server handle sending at a given time.\n2) How much information can your client handle displaying.\n\nI can&#39;t answer &quot;why&quot; 1000. A good a guess as any, 1000 individual features drawn on a webmap would really tax the web browser and performance would suffer (a few years back). You can make the argument now that browsers can handle 1000+.\n\nBut to use your example, do the quick math.\nSay you had 100 services. Each service could return 100,000 features. Each feature has 10 attributes. Then make a max request for each service all at the same time. Will the Server/hardware handle that? Will your web server be able to transfer that much data? Is your internet connection fast enough to handle it?\n\nI&#39;d call 1000 a &quot;protective&quot; number. Increase it to what makes sense in your environment as long as you understand the limits of both your Server and Client.\n A good a guess as any, 1000 individual features drawn on a <span class=\"highlight\">webmap</span> would really tax the web browser and performance would suffer (a few years back). &hellip; "
    },
    {
        "question": "qgis2web popup editing",
        "area": [
            "qgis",
            "qgis2web",
            "html-popup"
        ],
        "text": "I have exported a webmap created in qgis2web (QGIS 2.18.13) open layers. There is a list of attributes that I wanted to include in the popup, which are mostly related to a country&#39;s demographic and socioeconomic profile. From the image below however, you will see that the popup is pretty big, out of range and without a scroll.\n\n\n\nI have attempted to edit the qgis2web.css file within resources to try and address some of the points but I am completely new to CSS so am unfamiliar with the syntax... Could any of you please help to:\n\n\nAdjust the width/height of the popup\nAbility to scroll through the popup\n\n\n\n\n\n I have exported a <span class=\"highlight\">webmap</span> created in qgis2web (QGIS 2.18.13) open layers. &hellip; "
    },
    {
        "question": "How to convert from EPSG:4326 to WGS84/UTM 32U?",
        "area": [
            "qgis",
            "wgs84",
            "utm"
        ],
        "text": "I am unable to convert from the project&#39;s coordinate system to a different one using QGIS 1.8.0.\nI have a .shp file with a certain coordinate system information (WGS84 EPSG:4326 according to QGIS ). I wish to convert this to WGS84/UTM 32U.\nNow, WGS84/UTM 32N but not [...] 32U exists in the KBS list if I use [...]32 N it does not change anything.\nIf I compare the coordinates in my project in WGS84 with that from 2 different webmap applications in WGS84/UTM 32U there are these following difference:\n3607000 E / 5738000 N in the .shp and\n607000 E / 5738000 N in the .shp in the web application with an seemingly difference of ~100m west and a ~2000m north shift of the .shp.\nDoes someone have an idea what the problem might be?\nCan I download more Coordinate systems (i.e. WGS84/UTM 32U) for QGIS somewhere?\n If I compare the coordinates in my project in WGS84 with that from 2 different <span class=\"highlight\">webmap</span> applications in WGS84/UTM 32U there are these following difference:\n3607000 E / 5738000 N in the .shp and\n607000 E &hellip; "
    },
    {
        "question": "How to update a hosted feature service on ArcGIS Online using the Python API for ArcGIS Pro?",
        "area": [
            "arcgis-online",
            "arcgis-pro",
            "arcgis-python-api"
        ],
        "text": "I&#39;m trying to follow the steps in the Esri blog post Updating your hosted feature services with ArcGIS Pro and the ArcGIS API for Python but am running into an error.\n\nTo test this I published a simple stand-alone file GDB into an ArcGIS Online web map using ArcGIS Pro&#39;s UI tools. This creates a Service Definition, WebMap and associated Feature Layer on ArcGIS Online.\n\nI then made a simple symbology change in ArcGIS Pro and attempted to push the updates to ArcGIS Online using the script. The script runs correctly as far as these lines:\n\n\n\nI can confirm from the timestamps on ArcGIS Online that the Service Definition has been updated, but the script is falling over when trying to update the associated Feature Layer. The script contains this line:\n\n\n\nThis gives me the error message \n\n\n  RuntimeError: User cant overwrite this service, using this data, as\n  this data is already referring to another service\n\n\nI can confirm that the data doesn&#39;t actually refer to another service since it&#39;s coming from a stand-alone file GDB that isn&#39;t used anywhere else. I&#39;m using the same ArcGIS Online administrator&#39;s login within ArcGIS Pro and the Python script so I&#39;m definitely the owner of the layer.\n\nHow can I overwrite the feature layer using the latest changes in the ArcGIS Pro document?\n This creates a Service Definition, <span class=\"highlight\">WebMap</span> and associated Feature Layer on ArcGIS Online. &hellip; "
    },
    {
        "question": "What does Scale mean in the reference of Desktop GIS or WebGIS?",
        "area": [
            "web-mapping",
            "scale",
            "cartography",
            "desktop-gis"
        ],
        "text": "I&#39;m having trouble understanding the meaning of the concept of scale when it comes to maps on screen, i.e. either in a Desktop GIS or in a WebMap.\n\nWhen it comes to paper maps, the idea is very clear. The Scale is the ratio of a particular distance on the map, to the same distance on the ground.\n\nBut when it comes to maps on screen, the same concept cannot be applied. Firstly different screens do not have the same pixel size. It might be that a 14 inch monitor and a 24 inch monitor could have the same resolution (in terms of pixels). Then comes the issue of dpi. An iOS device with retina display has a dpi several times that of my work-station monitor. So 1 cm on my screen might show a different distance than 1 cm on your screen.\n\nSo what does the scale of a map in digital cartography mean? What does it mean, when I see the scale of a map is 1:180,000 in ArcMap?\n\n\n\nAside\nThis question came about because of several ArcMap Documents I received from a client who publishes paper maps.\nThe paper map is published at 1:180,000, but at that scale the map looks terrible. It&#39;s only when I zoom in, does the map look good. With trial and error, I found that the map looks best on screen at about 3 times the scale, i.e. at 1:60,000\n I&#39;m having trouble understanding the meaning of the concept of scale when it comes to maps on screen, i.e. either in a Desktop GIS or in a <span class=\"highlight\">WebMap</span>. &hellip; "
    },
    {
        "question": "Opening links in same window with ArcGIS Online Popup?",
        "area": [
            "arcgis-online",
            "popup"
        ],
        "text": "I&#39;ve noticed when embedding an ArcGIS Online webmap which has a popup with links on it, that there seems to be no way to have the popup link open in the current window. It will always open in a new window.\n\nThere are no configuration options for link @targets in the ArcGIS Online popup configuration tool and if you try manually setting the target attribute of a popup link to target=&quot;_top&quot; or &quot;_parent&quot; that value will be overwritten as target=&#39;_blank&#39; and thus links will open in a new window.\n\nThis means you can&#39;t really integrate the map with your page, because users are taken outside the original window and you have to figure out a way to get them back in. \n\nI wondered if anyone has a workaround and why ArcGIS Online insists on this behaviour?\n I&#39;ve noticed when embedding an ArcGIS Online <span class=\"highlight\">webmap</span> which has a popup with links on it, that there seems to be no way to have the popup link open in the current window. &hellip; "
    },
    {
        "question": "Web_Map_as_JSON from latest esri jsapi?",
        "area": [
            "arcgis-server",
            "arcgis-maps-sdk-javascript",
            "arcgis-flex-api",
            "printing",
            "arcgis-rest-api"
        ],
        "text": "I&#39;m trying to do a print export using arcgis 10.1 and latest esri jsapi.\n\nIs there any out of the box way that I can extract out  from a given webmap? \n\n generates a  object on its execute method. \n\nI can capture the request parameter while posting but I need much cleaner approach. I have to post this to another application which works as a proxy between my client and server. \n\nPlease help!   \n Is there any out of the box way that I can extract out Web_Map_as_JSON from a given <span class=\"highlight\">webmap</span>? \n\nesri.tasks.PrintTask generates a Web_Map_as_JSON object on its execute method. &hellip; "
    },
    {
        "question": "ArcGIS Portal use server-side obtained authorization in the client / JavaScript",
        "area": [
            "arcgis-maps-sdk-javascript",
            "c#",
            "authentication",
            "arcgis-portal"
        ],
        "text": "I have an ASP.NET MVC web application that is authenticating users server-side against ArcGIS Portal successfully using Owin.Security.Providers.ArcGISPortal.\n\nI would like to use the granted authorization client-side in the browser without requiring the user to login a second time via ArcGIS&#39;s JavaScript API. Does anyone have any pointers regarding how to obtain a relevant token and pass this through client-side to access portal secured web maps, etc.?\n\nThere is a  that I obtain via ArcGISPortalAuthenticationHandler and make available as a claim in order to share the access token.\n\nAny ideas? If you know of a working example for ArcGIS Online then this could also help me as ArcGIS Online and ArcGIS Portal seem to be identical in their mechanics.\n\nFurther investigation...\n\nFollowing the linked example found through the documentation for esri.IdentityManager.registerToken(), I&#39;ve tried the following method to share the access token:\n\n\n\nBut I&#39;m still not getting access to the webmap. I see a html login modal over the empty map div with the title &quot;Please sign in to access the item on https://[HOST]/arcgis (b11824af61df463586dad40d1df7abbd)&quot;.\n\nIn the console log I see the following message logged:\n\n\n\nand for the network request to\n\nhttps://[HOST]/arcgis/sharing/rest/content/items/b11824af61df463586dad40d1df7abbd?f=json&amp;callback=dojo.io.script.jsonp_dojoIoScript1._jsonpCallback\n\nI see the following response:\n\n\n isAdmin: false,\n        ssl: false,\n        creationTime: user.userAccessTokenIssued,\n        scope: &quot;server&quot;\n    }]\n};\nesriId.initialize(credentialsJSON);\n\n\nBut I&#39;m still not getting access to the <span class=\"highlight\">webmap</span> &hellip; "
    },
    {
        "question": "Turn Popups On/Off in ArcGIS Online Webmap via Javascript API Web Application",
        "area": [
            "javascript",
            "arcgis-maps-sdk-javascript",
            "editing",
            "popup",
            "arcgis-online"
        ],
        "text": "I am writing my first ArcGIS Javascript API web map application and consuming a web map authored in ArcGIS Online.  The ArcGIS Online web map apparently does most of the work for me in terms of symbology, editing templates, and even popups.\n\nFor my application, I am trying to allow the user to edit features, but not all the time.  I am able to toggle the editor on and off with the click of a button.  The problem is that I have not been able to toggle the default popups on and off so that the user can edit attributes.  Even when editing is enabled, the default non-editable popup appears when you click on a feature.  The only way to avoid this is to use the  option when calling .  However, this means that when editing is disabled nothing happens when you click on a feature.\n\nHere is my code.  This has all been adapted from several samples provided in the ArcGIS Javascript API documentation.\n\n\n\nI realize that I could recreate a custom  and , but since this is already done automatically by the API, it would be nice if I didn&#39;t have to.\n\nI tried to get the  and  from the response given by  and then  and  when the editor is disabled and enabled, but the default popups remained even after I called .\n\nAny help would be greatly appreciated.\n = new esri.tasks.GeometryService(&quot;http://tasks.arcgisonline.com/ArcGIS/rest/services/Geometry/GeometryServer&quot;);\n\n            var urlObject = esri.urlToObject(document.location.href);\n            var <span class=\"highlight\">webmap</span> &hellip; id=&quot; + <span class=\"highlight\">webmap</span> + &quot;&#39;&gt;View data details&lt;/a&gt;&quot;;\n\n                layers = response.itemInfo.itemData.operationalLayers;\n                // clickHandle = response.clickEventHandle;\n                // clickListener &hellip; "
    },
    {
        "question": "Joining CSV to GeoJSON in Leaflet?",
        "area": [
            "leaflet",
            "geojson",
            "csv",
            "performance"
        ],
        "text": "My goal:\n\nStore the attributes of a geojson in a csv file\nAllow a non-GIS user to edit a cloud-hosted csv file which then updates a webmap\nHave the web map be a static app with no GIS/PostGIS/SQL etc server involved\n\nMy method:\n\nLoad a csv (from say dropbox) and a geojson stored on the webserver\nJoin the csv to the geojson file using javascript\nStyle the polygons using the field added from the csv\n\nThis works, but it is too slow...\nThe loading of the csv happens in about 1 second, and the geojson tiles get created almost instantly. But the join function using  takes between 7 and 10 seconds - on a desktop machine with a fast internet connection. On a phone performance for the join is awful, maybe 30-50 seconds.\nIs there a faster/better way to join the geojson to the csv?\nI could be going about this in the absolute wrong way altogether.\nI am using leaflet 0.7.7. The geojson and csv contain 4500 features/rows.\nUsing  after the Papa.parse, eachLayer and after the tile script gives me this:\n\nAnd without the join:\n\nHere is the code (wellZoneParcelsData is the omnivore variable and wellZoneParcels is the L.geoJson):\n\n My goal:\n\nStore the attributes of a geojson in a csv file\nAllow a non-GIS user to edit a cloud-hosted csv file which then updates a <span class=\"highlight\">webmap</span>\nHave the web map be a static app with no GIS/PostGIS/SQL etc server &hellip; "
    },
    {
        "question": "Creating a small web-mapping/map-tiling service",
        "area": [
            "qgis",
            "openstreetmap",
            "openlayers",
            "web-mapping",
            "tiles"
        ],
        "text": "I decided to provide some information on which way I finally went for my tiled map service. Pure JavaScript and GeoJSONs weren&#39;t a solution, because I have to handle roughly 40k polygons and 33k points. So I went for tiling. Oh, and I still don&#39;t have a access to root server, so I can&#39;t set up GeoServer or something similar (wouldn&#39;t be financially feasible for a single client at the moment)\n\nAfter some researching and reading, I finally settled with OpenLayers (after some showcasing with GMaps). Eric Hazzard&#39;s great book &quot;OpenLayers 2.10&quot; (Packt Publishing, 2011) really, really helped me a lot because it also covers some JavaScript basics and debugging tips.\n\nI did all my vector data work in QGIS, of course, thats definitely the way to go for a small freelancer like me (I also know quite some ArcGIS stuff from university, but QGIS has been offering all I ever needed so far).\n\nStyling the map and creating the tiles was a bigger challenge. First, I went along with &quot;GMapCreator&quot; by CASA, but layering multiple shapefiles proved to be tedious (I have to provide point data over polygons, and then a municipal borderline enclosing everything). It is absolutely possible to do this in GMapsCreator (and I did it for the showcase stage), but it takes 3 full rendering cycles (first you create tiles, then the existing tiles get &quot;overdrawn&quot; with later features - rendering in the right order is important!), and the styling menus are slightly bulky and confusing. Saving your map and editing it later is also a complicated issue.\n\nTileMill seemed very promising, especially their CSS-like styling, so I looked into it. Unfortunately, it&#39;s Mac or Linux only, so that might scare some people off. I really liked what I saw, so I set up a Ubuntu partition on my hard-drive, downloaded it and styled my maps. Documentation on the styling syntax is sometimes a little scarce, but watching their demo video (linked on the main site) answers almost everything. It&#39;s possible to do some interesting stuff with nested and/or conditional styles, and some basic CSS understanding should really get you where you want to go.\n\nIn the end, TileMill renders a nice, single *.mbtiles file. I don&#39;t think there is a way to directly display these in OpenLayers (at least I couldn&#39;t find one?), so it was time to use another tool: mbutil. This tool &quot;unzips&quot; the mbtiles-File in to a regular folder structure containing the tiled pngs of my data on the selected zoom levels.\n\nFinally, I uploaded all these files to my FTP-Server, did some heavy reading on OL to get my webmap up and going (you add the created tiles as a TMS layer, but guessing the right source url and layer name took some time and googling) and then burned some hours fiddling around with basic html/CSS issues. I wanted a 100% width/height map with a floating legend  following my clients &quot;corporate&quot; (it&#39;s a municipality, as mentioned) identity guidelines.\n\nOh, and so far I use Google Maps as base layers, but that might get replaced soon by some custom aerial pictures served via WMS (not provided by me, but the state&#39;s survey and geodata administration).\n\nI hope I didn&#39;t forget anything important, but if I did, please feel free to ask! I&#39;ll check this thread occasionally.\n Finally, I uploaded all these files to my FTP-Server, did some heavy reading on OL to get my <span class=\"highlight\">webmap</span> up and going (you add the created tiles as a TMS layer, but guessing the right source url and layer name &hellip; "
    },
    {
        "question": "Can we use GeoExt Freely?",
        "area": [
            "open-source-gis",
            "geoext"
        ],
        "text": "I want to know, can we use GeoExt freely? is there any need to purchase some license for using GeoExt ?\n\nActually i am already working with free Open source tools (OpenLayers+GeoServer) for my webMap applications. But i need some specific functionality which is possible with GeoExt. so can i use GeoExt freely with Openlayers and GeoServer ?\n Actually i am already working with free Open source tools (OpenLayers+GeoServer) for my <span class=\"highlight\">webMap</span> applications. &hellip; "
    },
    {
        "question": "Retrieve attributes from a GeoJSON feature in openlayers 3",
        "area": [
            "openlayers"
        ],
        "text": "I&#39;m working on a webmap using  and vector layers, . I&#39;ve managed to render the layers and add click interactions:\n\n\n\nThe interaction works fine, it sets a new style to the selected feature (borders of the selected country etc). \n\nWhat I want is to retrieve the selected feature&#39;s id from the geoJSON file and use that to know what country is selected. Depending on what country is selected a network (lines) will be drawn from that country to other countries, retrieved from a DB. \n\nIs there a way of doing this? I&#39;ve tried the following (without proper formatting): \n\n\n\nThis gives me an  that is undefined even though the feature has an  in the geoJSON file. \n\nIs there another way of doing this? I&#39;ve searched around the web and this forum without finding an answer. \n\nThis is a snippet of my geoJSON file, all features have the same properties:\n\n\n I&#39;m working on a <span class=\"highlight\">webmap</span> using OpenLayers 3 and vector layers, geoJSON. &hellip; "
    },
    {
        "question": "Find out ESRI REST URL for web map which is hiding it",
        "area": [
            "geojson",
            "web-mapping",
            "rest"
        ],
        "text": "I would like to extract the pipeline geometries from https://www.arcgis.com/home/webmap/viewer.html?webmap=a00c3b5cee4e4fe0b238b5e05ed80204\n\nIt shows the existing gas &amp; oil pipelines crossing through Pennsylvania and was created by FracTracker for http://www.roverpipelinefacts.com/about/route.html . Despite it&#39;s a NGO they don&#39;t allow you downloading their data.\n\nIf I should know the REST FeatureServer URL I could download it (EXAMPLE):\n\n\n\nHow can I find out this URL for the web map from above?\n I would like to extract the pipeline geometries from https://www.arcgis.com/home/<span class=\"highlight\">webmap</span>/viewer.html? &hellip; <span class=\"highlight\">webmap</span>=a00c3b5cee4e4fe0b238b5e05ed80204\n\nIt shows the existing gas &amp; oil pipelines crossing through Pennsylvania and was created by FracTracker for http://www.roverpipelinefacts.com/about/route.html . &hellip; "
    },
    {
        "question": "Is there a way in the Google Maps API to perform a union?",
        "area": [
            "geoprocessing",
            "google-maps"
        ],
        "text": "There are no extensive Javascript computational geometry implementations: most geometry libraries rely on JTS or its C++ port GEOS, neither of which have yet been ported to native Javascript. Most people handle this by using a spatial database such as PostGIS to manipulate geometries server-side, and then pass back the results with GeoJSON or similar. OpenGeo has an example application which does unions of input geometries from a webmap that might be of help.\n\nIf you&#39;d like to implement the algorithm yourself in Javascript, check this SO post which describes the general process, which involves finding and removing interior points from the joint geometries.\n OpenGeo has an example application which does unions of input geometries from a <span class=\"highlight\">webmap</span> that might be of help. &hellip; "
    },
    {
        "question": "QGIS2WEB Plugin (openLayer3) for QGIS not exporting raster images",
        "area": [
            "qgis",
            "openlayers",
            "qgis2web"
        ],
        "text": "I am using the QGIS2WEB plugin for QGIS. I have added vector features as well as a raster image (.tif or .ecw) format.\n\nWhen I try to export the webmap, all the layers are visible expect the rasters. Why is this?\n When I try to export the <span class=\"highlight\">webmap</span>, all the layers are visible expect the rasters. Why is this? &hellip; "
    },
    {
        "question": "Local GeoServer public access",
        "area": [
            "geoserver",
            "openlayers"
        ],
        "text": "No, it will not be visible to anyone but you. When a user displays your webmap, the code will try to read from his computer (), which doesn&#39;t have a running Geoserver, and will fail.\n When a user displays your <span class=\"highlight\">webmap</span>, the code will try to read from his computer (localhost), which doesn&#39;t have a running Geoserver, and will fail. &hellip; "
    },
    {
        "question": "Displaying Shapefiles in map in browser and not using Google Maps",
        "area": [
            "shapefile",
            "web-mapping",
            "software-recommendations",
            "php",
            "apache"
        ],
        "text": "A quick solution to serve up shapefiles on a basemap in a webapp is through a free arcgis.com account. They allow you upload .shp files, symbolize, and lay them on a base map. The share tool allows provides a html script that can be copied. I served up some symbolized counties to my blogger page in a webmap. Note that ESRI is trying to monetize arcgis.com but this did work recently. \n\nOyvind&#39;s post is valid as well. \n I served up some symbolized counties to my blogger page in a <span class=\"highlight\">webmap</span>. Note that ESRI is trying to monetize arcgis.com but this did work recently. \n\nOyvind&#39;s post is valid as well. &hellip; "
    },
    {
        "question": "Where to download 4 band NAIP imagery?",
        "area": [
            "imagery",
            "remote-sensing",
            "download"
        ],
        "text": "To acquire NAIP for Oregon that includes the NIR band you must contact the OGEO office directly (gisgis.state.or.us or 503-378-2166). The NIR is not available on the download site. \n\nWhen you refer to &quot;historic&quot; NAIP including the NIR band you are going to be somewhat out of luck. Many states still do not include NIR in their contracts and the USDA-APFO option of a NIR band was not officially added to the contract template, as part of NAIP, until 2009. To acquire this data you will have to go state by state. Colorado has an ftp site that you can download the current, quad-level, NAIP that includes the NIR. \n\nI do not believe that Oregon added NIR until the last acquisition of NAIP, but there could be one additional year that includes NIR. For current NAIP (RGB only) for all states, APFO has a webmap service that can be added as a &quot;GIS Server&quot; in ArcGIS (http://gis.apfo.usda.gov/arcgis/services).        \n For current NAIP (RGB only) for all states, APFO has a <span class=\"highlight\">webmap</span> service that can be added as a &quot;GIS Server&quot; in ArcGIS (http://gis.apfo.usda.gov/arcgis/services). &hellip; "
    },
    {
        "question": "Enable Popups for each layer in webmap using ArcGIS API for Python",
        "area": [
            "arcgis-online",
            "popup",
            "arcgis-python-api"
        ],
        "text": "I am looking to use the ArcGIS API for Python to enable popups for each layer in a webmap.\nI found Configure Popup Attributes Programmatically with ArcGIS API for Python on GeoNet which addresses how to disable popups for each layer, but I am looking to do the opposite.\nI have also asked Enable Popups for each layer in a webmap Enable Popups for each layer in a webmap using ArcGIS API for Python on GeoNet.\n I am looking to use the ArcGIS API for Python to enable popups for each layer in a <span class=\"highlight\">webmap</span>. &hellip; I have also asked Enable Popups for each layer in a <span class=\"highlight\">webmap</span> Enable Popups for each layer in a <span class=\"highlight\">webmap</span> using ArcGIS API for Python on GeoNet. &hellip; "
    },
    {
        "question": "Saving Mapzen Global Terrain in QGIS with extent layer (-90 to 90 Lat and -180 to 180 Lon)",
        "area": [
            "qgis",
            "raster",
            "dem",
            "wgs84",
            "mapzen"
        ],
        "text": "No. Mapzen Global Terrain tiles will be designed for use in Web Mercator projection, which only goes to &#177;85.05.. degrees of latitude. From Wikipedia:\n\nBecause the Mercator projects the poles at infinity, a map using the Web Mercator projection cannot show the poles. Services such as Google Maps cut off coverage at 85.051129&#176; north and south. This is not a limitation for street maps, which is the primary purpose for such services. The value 85.051129&#176; is the latitude at which the full projected map becomes a square...\n\nSo it has one useful property: all tiles are square, including the one at zoom 0. But, the point at &#177;90&#176; would be stretched to infinity in order to be rendered as a line along the top or bottom of the map. So the projection just cuts off before that point. That is why Antarctica looks so large, when it&#39;s really about the same size as Australia.\nIf you need estimates of elevation at the poles, you will need to look elsewhere. However if you only ever intend to do stuff on webmaps projected in Web Mercator, there&#39;s no point obtaining the remaining data since you won&#39;t be able to see it.\n No. Mapzen Global Terrain tiles will be designed for use in Web Mercator projection, which only goes to &#177;85.05.. degrees of latitude. From Wikipedia:\n\nBecause the Mercator projects the poles at infini &hellip; "
    },
    {
        "question": "Can you upload maps from QGIS to ArcGIS Online?",
        "area": [
            "qgis",
            "arcgis-online",
            "story-map"
        ],
        "text": "You can use OGIS Cloud to publish the service as WMS or WMTS as per your requirement.\n\nURL: https://qgiscloud.com/\n\nAnd then add OGC services in the Webmap the is being used by your story map in ArcGIS online.\n\nhttps://doc.arcgis.com/en/arcgis-online/reference/ogc.htm\n URL: https://qgiscloud.com/\n\nAnd then add OGC services in the <span class=\"highlight\">Webmap</span> the is being used by your story map in ArcGIS online.\n\nhttps://doc.arcgis.com/en/arcgis-online/reference/ogc.htm &hellip; "
    },
    {
        "question": "US National Grid (USNG) map service?",
        "area": [
            "web-service"
        ],
        "text": "The NGA produced an accessible USNG WMS which should fit the bill. You also might consider downloading USNG shapefiles (webmap) for your area of interest. \n You also might consider downloading USNG shapefiles (<span class=\"highlight\">webmap</span>) for your area of interest. &hellip; "
    },
    {
        "question": "How to display two line traffic road map cartographically?",
        "area": [
            "arcgis-10.1",
            "cartography",
            "symbology",
            "representation"
        ],
        "text": "I have two line traffic maps. I want to display these maps roads as image below. These images show that when I zoom out from map, roads are showing properly.. And two line road never disappear from map. And when I zoom in map, other roads appear properly and two line. How can I do that this trick with ESRI solutions ?\n\nExample - http://www.arcgis.com/home/webmap/viewer.html?webmap=30c24162643b43c291c8151b24674c7f\n\nI follow ESRI&#39;s representation tutorials from this link but I could not get this view. \n\nEDIT 1 - \nAll I want to do is show 2 lines of road every scale. For viewing every scale width of road may be changeable. \n\n\n\n\n\n Example - http://www.arcgis.com/home/<span class=\"highlight\">webmap</span>/viewer.html?<span class=\"highlight\">webmap</span>=30c24162643b43c291c8151b24674c7f\n\nI follow ESRI&#39;s representation tutorials from this link but I could not get this view. &hellip; "
    },
    {
        "question": "Converting Ordnance Survey raster maps to WGS84 webmap tiles",
        "area": [
            "gdal",
            "ordnance-survey",
            "wgs84",
            "gdalwarp"
        ],
        "text": "I would like to generate Google/Bing-like map tiles from Ordnance Survey&#39;s 1:25000 and 1:50000 raster maps, which are provided as 4000x4000 UK national grid tiles (GeoTIFF).\n\nA sample tile can be found at http://www.ordnancesurvey.co.uk/docs/sample-data/25k-raster-sample-data.zip .\n\nThanks to this site and others (this is my first time using proper GIS tools), I have succeeded in using gdalwrap to reproject the tiles, and gdal_retile.py to cut the reprojected tile into smaller pieces.\n\nI still have the following questions:\n\n\nthe source files use a color map, so based on my single-tile sample, I\nconverted that to 24bit color in order to be able to use a better\nresampling algorithm than nearest neighbor, but I don&#39;t know how\nscalable that will be to the whole of the UK. Is there a way to get a quality resampling without first converting to 24bit color?\nhow do I get gdalwrap or gdal_retile.py (or another utility) to align the generated tiles to the webmap grid (the world divided into 2^zoom tiles of equal lat-lon delta)? Right now my tiles are the right pixel size, but most likely not aligned to the lat-lon grid nor the zoom level\nthe tiles generated by gdal_retile.py are named according to each one&#39;s location in the source file, but I need to translate that to the global tile number for my zoom level. Do the tools support doing that on the fly, or do I need to post-process?\nusing gdal_retile.py with the -levels option generates sub-directories but the tiles therein are all black; I was expecting the zoomed out pyramid (and fewer tiles, not more, than the default level), should I be using a different option?\neven for this smallish sample, each command seems to take an inordinately long time, and this is on an octo-core MacPro and SSD. Is there a performance guide for GDAL?\n\n\nHere&#39;s what I have been doing, starting with the sx99.tif sample file:\n\n\n\n\n\nInstead of gdal_retile.py, I&#39;ve tried using gdal2tile.py on the pre-warped raster maps.\n\nHowever, while the X coordinate for each of the generated tiles is correct, the Y coordinate seems to be at least double what I am expecting.\n\nI&#39;ve tried explicitly setting the source SRS and target profile, to no effect.\n\n\n\nI can&#39;t understand what&#39;s going wrong. The warped intermediate image looks OK:\n\n\n\nBut the resulting files are in the range of (for zoom level 11): 1003 &lt;= x &lt;= 1004 and 1359 &lt;= y &lt;= 1360, where I was expecting y around 780...\n how do I get gdalwrap or gdal_retile.py (or another utility) to align the generated tiles to the <span class=\"highlight\">webmap</span> grid (the world divided into 2^zoom tiles of equal lat-lon delta)? &hellip; "
    },
    {
        "question": "OpenTripPlanner (Error: 406) No transit times available",
        "area": [
            "openstreetmap",
            "routing",
            "general-transit-feed-specification",
            "opentripplanner"
        ],
        "text": "I try using OpenTripPlanner to create a webmap with multimodal routing function. \n\nI followed the instruction on: http://opentripplanner.readthedocs.io/en/latest/Basic-Usage/\n\n\nI downloaded  from: https://repo1.maven.org/maven2/org/opentripplanner/otp/\nI grabbed GTFS data from: https://code.google.com/archive/p/googletransitdatafeed/wikis/PublicFeeds.wiki (download for Berlin:  http://www.vbb.de/de/datei/gtfs-daten.zip)\nAlso got latest osm.pbf file from: http://download.geofabrik.de/ (download for Berlin: http://download.geofabrik.de/europe/germany/berlin-latest.osm.pbf)\nStarted the local server with: ,\nwhereas  and  are located in \n\n\nThe server is starting and I can access the map via http://localhost:8080/\nBut when I want to use the routing function for transit, it always gives me the following error: \n\n\n  No transit times available. The date may be past or too far in the\n  future or there may not be transit service for your trip at the time\n  you chose. (Error 406)\n\n\nMy thoughts are that the GTFS data are somehow broken or not useable for OpenTripPlanner. \n\nSo I used the GTFS Feed Validator (https://github.com/google/transitfeed/wiki/FeedValidator) \n\nThe Results of the GTFS FeedValidator: \n\n\nAgencies: Verkehrsverbund Brandenburg-Berlin, ...   \nRoutes: 1363\nStops: 12845 \nTrips: 204915  \nShapes: 0  \nEffective: June 06, 2013 to December 14, 2013\n\n\nFound these problems:\n19528 warnings\n\n\n87 Duplicate IDs \n1 Expiration Date \n1810 Invalid Values   \n5313 Overlapping Trips In Same Blocks \n5 Stops Too Closes \n12310 Too Fast Travels \n2 Unrecognized Columns\n\n I try using OpenTripPlanner to create a <span class=\"highlight\">webmap</span> with multimodal routing function. &hellip; "
    },
    {
        "question": "Leaflet + GeoServer WFST - Inserting Polygons to PostGIS database",
        "area": [
            "postgis",
            "geoserver",
            "leaflet",
            "geojson",
            "wfs-t"
        ],
        "text": "I have a GeoServer installation on top of a PostGIS database. I am trying to set up a leaflet webmap (using Leaflet WFS-T plugin) so that I can insert, update and delete polygon features. I have managed to get this to work fine for Point features but something seems to be going wrong when inserting polygons. \n\nBelow is the request payload to GeoServer:\n\n\n\nAnd this is the response: \n\n\n\nWhen I look at the geometry type in PostGIS it says it is MultiPolygon so I am conscious that the WFST request is only specifying &#39;polygon&#39;. \n\nBelow is my Leaflet code (I am using Leaflet draw to create the polygons): \n\n\n\nFurthermore, when I use the console to look at the original features pulled from GeoServer they are GeoJSON but when I look at the newly created features they don&#39;t seem to be. They just have an array of coordinates.\n\nEDIT: This may have something to do with GML versions. I.E. Geoserver is expecting the XML of the request to be structured differently. \n I am trying to set up a leaflet <span class=\"highlight\">webmap</span> (using Leaflet WFS-T plugin) so that I can insert, update and delete polygon features. &hellip; "
    },
    {
        "question": "WebMap that automatically links to Google Drive Spreadsheet",
        "area": [
            "arcgis-online"
        ],
        "text": "I would like to create a webmap from a contacts spreadsheet stored in Google Drive that will update the map automatically when new data is added to the spreadsheet. I know I can do this with an ArcGIS Online Organisation subscription, but are there any other ways?\n I would like to create a <span class=\"highlight\">webmap</span> from a contacts spreadsheet stored in Google Drive that will update the map automatically when new data is added to the spreadsheet. &hellip; "
    },
    {
        "question": "Overwriting Feature Service to webmap does not update with new data in ArcGIS Online?",
        "area": [
            "arcgis-online",
            "update",
            "feature-service"
        ],
        "text": "This is cross posted to geonet as well: https://geonet.esri.com/thread/196111-updating-feature-service-to-webmap-does-not-update-with-new-data\n\nI have a web feature service on a web map and that map shared through an web app.\nThis service is just a small point layer and I update it every month with updated points. I then upload the layer to agol using the &quot;overwrite&quot; option on my existing point feature service. However my web map does not update with the new points automatically. I have to re-add the service as a new layer and remove the previous one in addition to manually copying my pop-up configs over to the new layer.\nI was under the impression the overwriting the service would in turn have the updates roll out to the web map layer. Am I missing a step here or is this how the overwrite feature works?\n\nRuss lead me to the correct answer to solve this issue. I just needed to set my refresh interval Support docs can be found here: http://doc.arcgis.com/en/arcgis-online/create-maps/set-refresh-interval.htm\n This is cross posted to geonet as well: https://geonet.esri.com/thread/196111-updating-feature-service-to-<span class=\"highlight\">webmap</span>-does-not-update-with-new-data\n\nI have a web feature service on a web map and that map shared &hellip; "
    },
    {
        "question": "Showing Polar coordinate grid?",
        "area": [
            "coordinate-system",
            "openstreetmap",
            "vector-grid",
            "antarctica",
            "openseamap"
        ],
        "text": "I&#39;ve found some maps for Antarctica https://nga.maps.arcgis.com/home/webmap/viewer.html \n\nHow can I show polar coordinate grid for it? \n\nI&#39;ve got the grid source code in grid_wgs.js (I use OpenSeaMap in my software that is based on OpenStreetMap), so I guess I just need to change some mathematical formulas there, but I&#39;ve got no idea how to do that / what to change etc. \n\nHere&#39;s the grid_wgs.js code below.\n\n\n I&#39;ve found some maps for Antarctica https://nga.maps.arcgis.com/home/<span class=\"highlight\">webmap</span>/viewer.html \n\nHow can I show polar coordinate grid for it? &hellip; "
    },
    {
        "question": "Is there a point symbol for ArcMap that looks like the Google Maps Marker Symbol?",
        "area": [
            "arcgis-desktop",
            "arcmap",
            "arcgis-server",
            "symbology",
            "arcgis-10.3"
        ],
        "text": "Is there a symbol available through ArcMap (I&#39;m using 10.3.1) that looks somewhat like the Google Maps marker symbol? We have a webmap that was created using Google Maps Engine and apparently we have a need to do this differently now (cough cough). We will be using ArcGIS Server and the ArcGIS javascript API. We thought it would be best if the map changed as little as possible, so I&#39;m looking for one that looks like the old familiar ...\n\nI know that it is possible to create your own symbols using a graphic but the ones I have attempted look pretty horrible. Using some version of the one I just pasted here could potentially work but I wondered if there was one the looks closer than &quot;Circle 3&quot; from the list below (the green circle with a black dot). I could make it red but it doesn&#39;t have that &quot;tied to the map&quot; look that the Google Marker symbol has (not to mention it&#39;s instant recognition value).\n\nI looked through the symbols available to me and didn&#39;t find anything better. Even something remotely close would be fine with me.\n\nArcMap Symbol Selector:\n\n We have a <span class=\"highlight\">webmap</span> that was created using Google Maps Engine and apparently we have a need to do this differently now (cough cough). We will be using ArcGIS Server and the ArcGIS javascript API. &hellip; "
    },
    {
        "question": "Geoprocessing Service crash while executing",
        "area": [
            "arcgis-desktop",
            "arcpy",
            "arcgis-server",
            "geoprocessing-service",
            "arcgis-10.4"
        ],
        "text": "I have created a geoprocessing service, which can print a webmap(JSON) to a PDF or PNG. The ArcGis for Server and ArcGis for Desktop are running on my workstation. The Website, which host my webmap are also on this workstation. This worked fine until I updated my workstation from windows 7 to windows 10.\n\nThis is the code, which I used to create the geoprocessing service.\n\n\n\nThe main part of the code is from an esri tutorial.\n\nAnd this is my local hosted website.\n\n\n\nNow if I try to print my webmap, this error message comes out:\n\n\n\nIn addition it creates an empty error report and the server log says:\n\n\n  Instance\n  of the service &#39;Printscript2.GPServer&#39; crashed. Please see if an error\n  report was generated in\n  &#39;C:\\arcgisserver\\logs\\BRUNI.ESRI-DE.COM\\errorreports&#39;. To send an\n  error report to Esri, compose an e-mail to ArcGISErrorReport@esri.com\n  and attach the error report file. The containing process\n  for &#39;Printscript2&#39; job &#39;j7a8082331f5842f3b079133bb33e9901&#39; has\n  crashed.\n\n\nWith this logcode from the log, I dont get any helpful informations. The permissions to the ressources should be also okay.\n\nCan anyone help ?\n\nUpdate\n\nIf I run the script before I publish it as a GP, it works fine. But when I run the published GP from Arcmap, it fail too\n\n\n I have created a geoprocessing service, which can print a <span class=\"highlight\">webmap</span>(JSON) to a PDF or PNG. The ArcGis for Server and ArcGis for Desktop are running on my workstation. &hellip; The Website, which host my <span class=\"highlight\">webmap</span> are also on this workstation. This worked fine until I updated my workstation from windows 7 to windows 10. &hellip; "
    },
    {
        "question": "Geoserver SLD text symbology",
        "area": [
            "geoserver",
            "labeling",
            "sld"
        ],
        "text": "I have problem with the Geoserver.\n\nI have a layer (called &quot;cities&quot;) which contains points with attributes.\n(ID, Name, Layer, etc....)\nI&#39;d like to write out all the names (at now it doesn&#39;t matter if overlap eachother).\nIn the geoserver the points showed correctly but the text-s are missing. Under an exact zoom level the all text shown correctly but above that level nothing. Just the marker point.\n\nThis is my SLD:\n\n\n\nIs there any basic restrictions to the labels or any default settings?\nThanks! :)\n\n\n\nUpdate:\nI updated the SLD with the &quot;conflitresolution&quot;.\nIn the attached image you can see, nothing happened.\nOriginaly the basic map created in Arcgis. The cartographer who originaly (a few years ago) created the map placed every single label to the right place (that time they made paper maps not webmaps). Now I&#39;d like to put almost every label back to their place. The original shape has different layer to bigger and smaller cities and exact anchor point, angle, font size ect....\nSo that is why I&#39;d like to show all label at the same time and scale, because the layera are scale dependent.\n\n\nThanks again :)\n\n\n\nUpdate 2:\nI tired Mario&#39;s code but still the same problem :/\n\n I have problem with the Geoserver.\n\nI have a layer (called &quot;cities&quot;) which contains points with attributes.\n(ID, Name, Layer, etc....)\nI&#39;d like to write out all the names (at now it doesn&#39;t matter if  &hellip; "
    },
    {
        "question": "Add WMTS to Leaflet using its GetCapabilities URL",
        "area": [
            "leaflet",
            "wmts"
        ],
        "text": "I am using the Leaflet.TileLayer.WMTS plugin (https://github.com/mylen/leaflet.TileLayer.WMTS). However, I believe that this only works with WMTSes which add parameters to  requests as querystring variables in key=val pairs (eg http://www.provider.net/path?var1=val1&amp;var2=val2 etc). I need to add a WMTS which uses a URL path for its parameters (eg http://www.provider.net/path/val1/val2 etc). The WMTS in question is https://www.basemap.at/wmts/1.0.0/WMTSCapabilities.xml.\n\nThe way other clients handle this is by parsing the  URL, which provides the parameter mapping for  requests. I see that OpenLayers has a method for parsing  to add the WMTS (https://openlayers.org/en/latest/examples/wmts-layer-from-capabilities.html).\n\nI&#39;m aware that at least one other question has this as the underlying issue (https://stackoverflow.com/questions/44300140/wmts-layer-syntax-for-leaflet), but it doesn&#39;t make it clear what the underlying problem is, so I thought it was worth asking a new question.\n\nI know that I can either read the  XML myself (or look at network requests from a working client) and determine the structure to add a plain XYZ tileserver. However, I am trying to code this into qgis2web, which needs to accomplish this programmatically.\n\nSo, is there any way of adding a WMTS to a Leaflet webmap if you only have the URL for its  method?\n So, is there any way of adding a WMTS to a Leaflet <span class=\"highlight\">webmap</span> if you only have the URL for its GetCapabilities method? &hellip; "
    },
    {
        "question": "Modifying straight line segments to follow geodesic / great circle paths using QGIS?",
        "area": [
            "qgis",
            "coordinate-system",
            "google-earth",
            "great-circle",
            "geodesic"
        ],
        "text": "You have to reproject every line into an azimutal equidistant projection based on one of its points, then densify the line.\n\nSince all points of your grid are connected to three lines, you can densify those three with the same projection. The  tool allows to densify only selected elements.\n\nSee my example here on how to create great circles in aeqd:\n\ngreat circles in QGIS and export in 3857 webmap\n\nUsing a gnomonic projection would work too, but that projection shows heavy distortions, and some points can not be reprojected.\n See my example here on how to create great circles in aeqd:\n\ngreat circles in QGIS and export in 3857 <span class=\"highlight\">webmap</span>\n\nUsing a gnomonic projection would work too, but that projection shows heavy distortions, and &hellip; "
    },
    {
        "question": "Exporting QGIS project containing many points with qgis2web: reduce loading time",
        "area": [
            "qgis",
            "point",
            "web-mapping",
            "qgis2web",
            "visibility"
        ],
        "text": "What I have:\n\nQGIS 3.18 on Win 10 containing a project with:\n\nOpenStreetMap basemap\nPoint layer (Geopackage, 5.1 MB), representing centroids of buildings of a city\nPoint layer set to scale based visibility (only visible when zoomed in for more than 1:5000, corresponds to canvas extent of ca. 1km*1km and smaller) - so normally, just a few hundred (at max. ca. 1400) points are visible due to small canvas extent.\n\n\nPoint layer consists of:\n\n54.000 features, extent ca. 12*12 km\nAttributes contain two fields:  and an additional integer field\n\n\n\nWhat I want to do:\nI want to make the project available as WebMap with  plugin, ver. 3.16. This works fine for other projects.\nWhat the problem is:\nThe exported map loads extremely slow and the browser becomes unresponsive. The same is true for the plugin&#39;s preview. I  get the warning:\n\nA large number of features are present in the map. Generating the\npreview may take some time.\n\nI guess this is because it tries to load all 54.000 point features, even if only a small section of the whole extent is inside the current canvas extent. Scale based visibility apparently can&#39;t be converted by qgis2web plugin.\nWhat I tried:\nChanging the  setting in the plugin, but with no success. I also looked to the other settings of the plugin (check the  checkbox for the point layer), but they don&#39;t resolve the problem.\nI also tried splitting up the layer to several small layers, based on a grid. The problem persists. I guess that Leaflet/the Web site still tries to load all layers in the current canvas extent - so the site gets blocked before you even get the chance to zoom in.\nThe question:\nHow can this problem be solved so that I have a WebMap with OSM basemap + the point layer, loading in reasonable time (few seconds at max.)\nScreenshots:\n\n\n\n Point layer consists of:\n\n54.000 features, extent ca. 12*12 km\nAttributes contain two fields: fid and an additional integer field\n\n\n\nWhat I want to do:\nI want to make the project available as <span class=\"highlight\">WebMap</span> with &hellip; The question:\nHow can this problem be solved so that I have a <span class=\"highlight\">WebMap</span> with OSM basemap + the point layer, loading in reasonable time (few seconds at max.)\nScreenshots: &hellip; "
    },
    {
        "question": "What is jimu.js in Web AppBuilder?",
        "area": [
            "arcgis-web-appbuilder",
            "jimu"
        ],
        "text": "The Web AppBuilder is a pure dojo, and Node.js application to build webmap applications by analyst that are not developers. However there is also a developer version where you can extend or build your own custom widgets.\n\nIn the Esri example: https://developers.arcgis.com/web-appbuilder/guide/create-a-feature-action-in-your-widget.htm they provide a code snippet but I&#39;m a bit discombabulated. I can see  in the define module, but the ,\n  , what js library it is?  What is  and where can I find more information on it?\n\n\n The Web AppBuilder is a pure dojo, and Node.js application to build <span class=\"highlight\">webmap</span> applications by analyst that are not developers. &hellip; "
    },
    {
        "question": "How to add item to the ArcGIS Portal with the portal API?",
        "area": [
            "arcgis-maps-sdk-javascript",
            "arcgis-portal"
        ],
        "text": "I think I&#39;ve found the solution to this issue. The code works fine* if security is disabled in chrome (Chrome.exe --disable-web-security), which means my code is ok. The error seems to say that the server will not accept the header X-Requested-With which is added by default by dojo xhrPost. Therefore I set the header value to null (as suggested by ESRI support) and the request went through fine in Chrome/FF\n\nI have submitted a request to ESRI to get the header added to the server as suggested by this exchange\n\nEdit: it works in IE9 using dojo.xhrPost so long as the site and ArcGIS online server are running on the same protocol, most likely https.\n\n*Looking at the way &quot;configure application&quot; works in fiddler on ArcGIS online site they do not use &#39;update item&#39; but instead &#39;add item&#39; with overwrite = true. In order to get the webmap template and its associated data use the code getTemplate code listed below.\n\n\n In order to get the <span class=\"highlight\">webmap</span> template and its associated data use the code getTemplate code listed below.\n\n        addItem: function (item, itemData) {\n            var cont = item;\n            if (! &hellip; "
    },
    {
        "question": "How to iterate through vertices in line segments, and all possible branches in arcpy?",
        "area": [
            "arcpy",
            "geometry"
        ],
        "text": "I have an interesting problem. I am using arcpy with arcGIS desktop 10.2. \n\nI am given a starting point and distance to a fault on electrical lines. My task is to automate the process of plotting these points into a feature class and displaying them on a webmap for other non-GIS users to view. An example: I receive tabular info that has these two relevant pieces of information: \n\nStarting point: Breaker #113  (Which I know the location of, and touches an electric line segment)\nFault Location: 18.3 Miles\n\nIt is important to note that the line features that I must be working on have a commonly shared attribute, called &#39;lineGroup&#39;, but there are many touching line features or segments that may be in that lineGroup. After I select the first line feature that touches my starting point, I iterate recursively through each vertice and measure the distance between them. I keep a running total of the distance, and the code plots a point when it reaches the fault location. \n\nI can get my code to work fine when there is only a single line segment to iterate over, but my dataset contains many different line segments that I may have to iterate over to reach the fault distance. Also, there may be branches off of a line that head in a different direction. So I can potentially have multiple points plotted from one run of this script. \n\nHere is the code I currently have, which works well for a single line segment. What I need help with is how to continue onward with the function when I hit the end of the first line segment, as well as how to branch off and find a possible fault location down a branch. \n\n\n My task is to automate the process of plotting these points into a feature class and displaying them on a <span class=\"highlight\">webmap</span> for other non-GIS users to view. &hellip; "
    },
    {
        "question": "Batch create Leaflet webmaps in QGIS",
        "area": [
            "qgis",
            "leaflet",
            "web-mapping",
            "batch"
        ],
        "text": "During a project on the spider fauna of Greece, we have to face the design of distribution maps of the species. \n\nA good tool to work with is the design of Leaflet webmaps to be used on the website instead of static maps.\n\nAs the number of species is not small (1120 species = 1120 maps) am looking to find a way to create under a batch mode, webmaps with the Leaflet plugin.\n\nAll data are stored in a csv or shapefile with one column contain species name and rest the source (literature code) and coordinates in WGS84\n\nAny idea on how can this work?\n During a project on the spider fauna of Greece, we have to face the design of distribution maps of the species. \n\nA good tool to work with is the design of Leaflet webmaps to be used on the website in &hellip; "
    },
    {
        "question": "Serving content from MXDs to ArcGIS for Server by publishing from ArcGIS Pro?",
        "area": [
            "arcgis-server",
            "map-service",
            "arcgis-pro"
        ],
        "text": "You can import your existing ArcMap MXDs into ArcGIS Pro. See this help link for more information on the process. With that done, you can save your project. Essentially you&#39;ve now migrated from MXDs to APRX (projects).\n\nYou cannot publish from ArcGIS Pro to ArcGIS Server. From ArcGIS Pro you can share webmaps or web layers to ArcGIS Portal (that means a local portal or arcgis.com). In the scenario you propose, if you&#39;re sharing a webmap to arcigs.com, then you&#39;re correct; the data becomes static as it&#39;s pushed up to that server. If you&#39;re making a webmap in your local portal you can setup and reference the data from your enterprise geodatabase, thus the webmap will continue to use data that you make updates too. Its almost the same as publishing a map service to ArcGIS Server, except you&#39;re publishing a webmap to Portal. All the same concepts, just slightly different technologies.\n In the scenario you propose, if you&#39;re sharing a <span class=\"highlight\">webmap</span> to arcigs.com, then you&#39;re correct; the data becomes static as it&#39;s pushed up to that server. &hellip; If you&#39;re making a <span class=\"highlight\">webmap</span> in your local portal you can setup and reference the data from your enterprise geodatabase, thus the <span class=\"highlight\">webmap</span> will continue to use data that you make updates too. &hellip; "
    },
    {
        "question": "Changing size of popup on ArcGIS Online?",
        "area": [
            "arcgis-online",
            "popup"
        ],
        "text": "According to an ESRI source, there is still no way to resize a popup window in ArcGIS Online.\n\nhttps://geonet.esri.com/thread/138840\n\nHopefully (with the newest line of releases and ESRI&#39;s emphasis on &quot;webmaps can do everything that Desktop can do&quot;), we will see an update.\n According to an ESRI source, there is still no way to resize a popup window in ArcGIS Online.\n\nhttps://geonet.esri.com/thread/138840\n\nHopefully (with the newest line of releases and ESRI&#39;s emphasis on &hellip; "
    },
    {
        "question": "Use of Pictometry images in GIS",
        "area": [
            "imagery",
            "pictometry"
        ],
        "text": "We use pictometry, and in terms of web mapping they provide no good solutions (that I have seen at least).  I ended up writing a very simple tool in javascript that finds the coordinates of a clicked point on the webmap.  Once you have the coordinates I pop a new browser window and go to the Bing Maps api with the coordinates in the query string.  Using the birds eye view methods it is easy to get your oblique imagery.\n\nAs you have found, working with Pictometry&#39;s pmi files will not help you with webmapping.  To me, by far the quickest way to a solution was using bing:\nhttp://msdn.microsoft.com/en-us/library/bb429561.aspx\n\nLet me know if you need some help with the actual code.  Its short and both employees and citizens like the feature.  The page is live, you can check out how it works if you like\n I ended up writing a very simple tool in javascript that finds the coordinates of a clicked point on the <span class=\"highlight\">webmap</span>. &hellip; "
    },
    {
        "question": "Embed Esri map in MS Access Report or Form",
        "area": [
            "software-recommendations",
            "ms-access",
            "arcgis-platform",
            "hyperlink",
            "integration"
        ],
        "text": "The thing to do these days would probably be to link to a map on ArcGIS Online. You could do this by providing a hyperlink to the Webmap viewer, https://www.arcgis.com/home/webmap/viewer.html?... It should be possible to pass parameters to set the center and scale of the map in the URL, see the documentation for more details.\n\nA variation could be to embed a Web Control on your Access form, and open the same ArcGIS Online page in that control.\n\nIf you prefer a more traditional approach, or if you do not want to share your data on AGOL, you could use the map control provided with ArcGIS Engine. This is very similar to the map used in ArcMap. \n\nAlternatively, use the SharpMap control to do the same thing. EDIT: I&#39;m not quite sure if this can work, because it&#39;s a .NET control.\n\nIf you want to add a map to a report, you will problably have to export the map as an image, and embed it.\n You could do this by providing a hyperlink to the <span class=\"highlight\">Webmap</span> viewer, https://www.arcgis.com/home/<span class=\"highlight\">webmap</span>/viewer.html?... &hellip; "
    },
    {
        "question": "Is clip and ship possible with ArcGIS Server map service?",
        "area": [
            "arcgis-server",
            "map-service",
            "geoprocessing-service",
            "feature-service"
        ],
        "text": "As Vince pointed out in a comment - you could theoretically write code to clip a map/feature service. But that would probably be a lot of custom work. You wouldnt as much be extending the Clip and Ship tool as you&#39;d be writing a custom extraction of JSON from map services.\n\nGenerally the clip and ship work flow is comprised of 2 services: GP + Map. They both reference the same data. The map service (which you build a webmap off of) is so the user knows what data they&#39;re working with and in what area (visualized) and the GP service is there to provide the extraction.\n\nThe tutorial talked about is this one: http://resources.arcgis.com/en/help/main/10.2/#/Clip_and_ship/005700000073000000/\n The map service (which you build a <span class=\"highlight\">webmap</span> off of) is so the user knows what data they&#39;re working with and in what area (visualized) and the GP service is there to provide the extraction. &hellip; "
    },
    {
        "question": "Takes Two Clicks to Select New Feature",
        "area": [
            "arcgis-maps-sdk-javascript",
            "dojo"
        ],
        "text": "I&#39;m writing a web app using ESRI&#39;s Javascript API and a map I created in ArcMap 10.1 hosted on ArcGIS online (Feature Service, not WebMap).\n\nI have written the code necessary to print attributes in a stationary DIV instead of creating a popup. The only problem is, I now have to click twice every time I want to select a new feature.\n\nSo, I select a feature, the DIV updates with the new attributes. I click on a different feature, nothing happens. I click on the same feature again and the attributes update in the DIV.\n\nWhat is going on here? I&#39;m using map.infoWindow.on() to listen for &quot;selection-change&quot;. My code is below and the website is live here.\n\n\n I&#39;m writing a web app using ESRI&#39;s Javascript API and a map I created in ArcMap 10.1 hosted on ArcGIS online (Feature Service, not <span class=\"highlight\">WebMap</span>). &hellip; "
    },
    {
        "question": "How to push newly added or updated domain values to ArcGIS rest service?",
        "area": [
            "arcmap",
            "arcgis-server",
            "enterprise-geodatabase",
            "rest",
            "feature-service"
        ],
        "text": "I&#39;m currently using ArcGIS Server 10.4 for my REST service and ArcGIS Online. I have created a domain list and assigned it to a field. All of it works fine. I&#39;m currently using Oracle for my geodatabase. When i added the the rest service to a webmap, i can see the domains as a select list.\n\nHowever, from time to time, additional values must be added to the domain or need to be updated. I tried updating it in ArcMap and it reflects nicely. In editing mode you can see it straightaway in the select list. This is not the same for the REST service. After adding in the value, it is still not available when i try to check it via webmap.\n\nI then proceed to restart the REST service and now it starts to show the new entries. Is this the standard way? in order for it to reflect the new entries, i would constantly need to restart the service?\n\nIs there a way to refresh the connection to the geodatabase maybe without the need of fully restarting a rest service. I can see that if you add/or edit data in ArcMap and save editing, it can straightaway reflect. But this is not the case for domain.\n\nIs there a way around restarting the service?\n When i added the the rest service to a <span class=\"highlight\">webmap</span>, i can see the domains as a select list.\n\nHowever, from time to time, additional values must be added to the domain or need to be updated. &hellip; After adding in the value, it is still not available when i try to check it via <span class=\"highlight\">webmap</span>.\n\nI then proceed to restart the REST service and now it starts to show the new entries. &hellip; "
    },
    {
        "question": "Creating drop down box / combo box of bookmarks from ArcGIS Online webmap?",
        "area": [
            "arcgis-maps-sdk-javascript",
            "arcgis-online",
            "bookmarks"
        ],
        "text": "Without using the clunky ArcGIS bookmark dijit, how do I create a drop down box of bookmarks from an ArcGIS Online webmap (or JSON) that zoom to the extents when clicked?\n\n\n Without using the clunky ArcGIS bookmark dijit, how do I create a drop down box of bookmarks from an ArcGIS Online <span class=\"highlight\">webmap</span> (or JSON) that zoom to the extents when clicked? &hellip; "
    },
    {
        "question": "Can I use SELECTION mode on FeatureLayer from ArcGIS.com Webmap in ESRI JS API",
        "area": [
            "arcgis-maps-sdk-javascript",
            "arcgis-online",
            "popup",
            "feature-service"
        ],
        "text": "I am using an  in an ESRI Javascript API application I am developing.  One of the layers in my  is rather large and cannot be rendered all at once when zoomed out, however I would like to avoid showing holes in the data on screen when data does actually exist there.\n\nI have seen samples and demos before where it is possible to use a tiled map service to cover the entire large area without rendering all the individual features, but still be able to show an  when the map is clicked.  I am assuming this would be done using a  with its  set to  and the  handler for the  would query the  based on where the  was clicked, then the selected features would appear on the  and the  could be visible.\n\nI have not seen where it is possible to set the  of a  that is provided via an .  If I simply create a new  in my application that points to the  on , then I lose all of the configuration (symbology, popup, etc.) that I have done when publishing the .\n\nIs what I have described above possible?  If not, is there another way to render a large number of features on the map and still have access to attribute information?\n I am using an ArcGIS.com <span class=\"highlight\">Webmap</span> in an ESRI Javascript API application I am developing. &hellip; I have not seen where it is possible to set the mode of a FeatureLayer that is provided via an ArcGIS.com <span class=\"highlight\">Webmap</span>. &hellip; "
    },
    {
        "question": "Grouping layers in Portal for ArcGIS?",
        "area": [
            "arcgis-desktop",
            "arcgis-10.2",
            "arcgis-portal",
            "group-layer"
        ],
        "text": "I agree with Zara. Unfortunately, Portal doesn&#39;t support group layer as of 10.6. \nA workaround that  I have been using is to group the layers in .mxd and publish them as one service. Then I would add these service in the Portal&#39;s WebMap. \nOne caveat to this process is, any time you make non-trivial changes in one of the layer, you will have to republish the whole service and add the new REST URL in Webmap again. Then you might have to reconfigure all of your formattings in the service (like pop-ups).\n Then I would add these service in the Portal&#39;s <span class=\"highlight\">WebMap</span>. &hellip; One caveat to this process is, any time you make non-trivial changes in one of the layer, you will have to republish the whole service and add the new REST URL in <span class=\"highlight\">Webmap</span> again. &hellip; "
    },
    {
        "question": "Read (GEO)JSON file from web service using FME Desktop",
        "area": [
            "geojson",
            "fme-form"
        ],
        "text": "I have a webmap of bike stations and there is a json service for these stations behind the map. \n\nIs it possible to provide this URL as the source dataset, using FME Desktop? \n\nDoes FME Desktop support real-time data applications?\n\nI need to be able to access the URL and write a workbench that would capture the bike station status in 5 minutes increments and put the results in a .csv ot .txt file.\n\nAny ideas? \n I have a <span class=\"highlight\">webmap</span> of bike stations and there is a json service for these stations behind the map. \n\nIs it possible to provide this URL as the source dataset, using FME Desktop? &hellip; "
    },
    {
        "question": "XYZ tiles generated with QGIS not visible when uploading on web server",
        "area": [
            "qgis",
            "leaflet",
            "web-mapping",
            "xyz-tiles"
        ],
        "text": "Short answer\nYou need an index file that refers to your tiles. This can be created automatically when creating an  in the dialog window.\nSee this example here, a quick and dirty topographic map I created for this purpose in QGIS: https://daniel-ursprung.ch/tiles/\nDetailed answer\n\nIn the  dialog window, apart from the  you also have the option . Define a path and filename here - advice: use . I would recommend to save it in the same directory as the tiles itself (the output directory). If you than open this html file in a webbrowser, the tiles map shows up correctly. If this works locally, you&#39;re ready to load it to a server.\n\nYou have to make a little change in the index.html file as this links to the local folder path where you saved the tiles. On the server, you must refer to the path (URL) where the tiles are saved. So in the output index.html, search for this line where  stands for the path where you saved the tiles locally:\n\nYou can use relative paths: in case you saved the index-file and the output to the same directory, change the above line to this one here:\n\nAdapt the path to your needs. You could also use absolute path (URL to the folder) like e.g. for the webmap I created:\n\n\nWhen you now load your output directory with the folder structure and content unchanged to a html server with FTP (e.g. using FileZilla), you can open the URL refering to the folder or the  file. The map then appears as you know it from other web maps.\n\n\n You could also use absolute path (URL to the folder) like e.g. for the <span class=\"highlight\">webmap</span> I created:\nL.tileLayer(&#39;https://daniel-ursprung.ch/tiles/{z}/{x}/{y}.png&#39;, {\n\nWhen you now load your output directory with &hellip; "
    },
    {
        "question": "Adding custom web tile layer to ArcMap?",
        "area": [
            "arcgis-desktop",
            "arcmap",
            "tiles",
            "mapbox",
            "tile-layer"
        ],
        "text": "Update for September 2017:\n\nThis is pretty straighforward at this point (finally). You don&#39;t need to &quot;own&quot; the tiles to do this, only add the tile service to an ArcGIS online webmap (Add --&gt; Layer From Web) like so:\n\n\n\nAfter that, save the webmap (not the tiles themselves) to your &quot;Content&quot;. Then go to Content, and click on the map:\n\n\n\nThis will bring up the page for your particular webmap:\n\n\n\nFrom here, you can click . This will download a mysterious  file, which when clicked will open ArcMap with the tile service displayed.\n You don&#39;t need to &quot;own&quot; the tiles to do this, only add the tile service to an ArcGIS online <span class=\"highlight\">webmap</span> (Add --&gt; Layer From Web) like so:\n\n\n\nAfter that, save the <span class=\"highlight\">webmap</span> (not the tiles themselves) to your &quot;Content &hellip; Then go to Content, and click on the map:\n\n\n\nThis will bring up the page for your particular <span class=\"highlight\">webmap</span>:\n\n\n\nFrom here, you can click Open in ArcGIS Desktop. &hellip; "
    },
    {
        "question": "How was this map made by qgis2web",
        "area": [
            "qgis-3",
            "legend",
            "filter",
            "qgis2web"
        ],
        "text": "I have a layer with some points and I want to publish it using qgis2web. I have seen some exampes where the legend can be filtered such as in this webmap: https://ukerc.rl.ac.uk/TOOLS/EnergyDemonstrators/map.html#5/55.674/-2.490\n\nWhat setting was used to make this filtered legend? The closest I can make is this where I can only filter the layers themselves.:\n\n I have seen some exampes where the legend can be filtered such as in this <span class=\"highlight\">webmap</span>: https://ukerc.rl.ac.uk/TOOLS/EnergyDemonstrators/map.html#5/55.674/-2.490\n\nWhat setting was used to make this filtered &hellip; "
    },
    {
        "question": "Scraping the vectorlayer/shp/SVG/GeoJSON from this webmap?",
        "area": [
            "geojson",
            "web-mapping"
        ],
        "text": "Webmap layers cannot be exported out unless the provider gives the user some sort of export data tool within the map or if they provide a WFS url.  I would recommend contacting the map provider to see if they can provide the raw data via another means.\n <span class=\"highlight\">Webmap</span> layers cannot be exported out unless the provider gives the user some sort of export data tool within the map or if they provide a WFS url. &hellip; "
    },
    {
        "question": "Toggle ArcGIS Online WebMap Layers using Javascript?",
        "area": [
            "javascript",
            "arcgis-maps-sdk-javascript"
        ],
        "text": "Your modules are mapped incorrectly. You have  going to  and  going to . Reverse them in this line so that they match the order of your module paths.\n\n\n\nshould be\n\n\n\n*Edit: Actually, looking at your code more you don&#39;t even need the  module, as you are not instantiating a new one. You also had a minor syntax error, missing one final  to close out your  function. Here is a working fiddle of your code.\n\nAs for why only one layer is showing up in your legend, it&#39;s because you explicitly tell it to when you use the  option. Removing that shows all visible layers in your legend.\n function(\n    MapView, Legend, <span class=\"highlight\">WebMap</span>, Locate, Search, ScaleBar, FeatureLayer, LayerList\n  ) {\n\nshould be\n\nfunction(\n    MapView, Legend, <span class=\"highlight\">WebMap</span>, Locate, Search, ScaleBar, LayerList, FeatureLayer\n  ) { &hellip; "
    },
    {
        "question": "Migrating GIS Stack",
        "area": [
            "postgis",
            "geoserver",
            "software-recommendations",
            "hosting",
            "geomoose"
        ],
        "text": "I&#39;m currently running the following GIS stack with a private hosting firm.\n\nGeoServer v2.5.2\nPostgreSQL v9.3.5 / PostGIS v2.1\nGeoMoose v2.6\n\nI would like to find a less expensive option for hosting.  I&#39;m researching options like Amazon EC2, linode, and a2hosting.\nI would like to learn how to do this for myself and  need some input from anyone who has experience with this.  Ideally I&#39;d like to just migrate my current stack, db, and webmaps to another host.\n\nI should add that I am an experienced desktop GIS guy and have understand the functionality of GeoServer and how GeoMoose uses mapbooks.  I just have questions about the server side of things and installing software.  My current host said he would be able to provide me with a server footprint If I wanted to host elsewhere.\n\nThe maps I&#39;m building are state wide maps and contain between 25-35 layers.  So far I have 9 maps and will probably increase that to 15 in the next year.\n I&#39;m currently running the following GIS stack with a private hosting firm.\n\nGeoServer v2.5.2\nPostgreSQL v9.3.5 / PostGIS v2.1\nGeoMoose v2.6\n\nI would like to find a less expensive option for hosting.   &hellip; "
    },
    {
        "question": "Global shipping network datasets for download?",
        "area": [
            "shapefile",
            "data",
            "network",
            "download",
            "maritime-map"
        ],
        "text": "Does anyone know if global shipping routes for free download (preferably ESRI shapefile) exist? I would need them for my research only as a background presentation on the world image. They can be rough presentation, I would need something like this: http://www.arcgis.com/home/webmap/viewer.html?layers=12c0789207e64714b9545ad30fca1633&amp;useExisting=1 \n\nI have already tried the link of Global Shipping Lane Network from Oak Ridge National Labs (mentioned in this post What are the existing datasets of world maritime routes?), but the link does not function anymore.\n They can be rough presentation, I would need something like this: http://www.arcgis.com/home/<span class=\"highlight\">webmap</span>/viewer.html? &hellip; "
    },
    {
        "question": "Creating editable Map with OpenLayers",
        "area": [
            "geoserver",
            "wfs",
            "openlayers-2"
        ],
        "text": "My girlfriend is trying to create a webmap using OpenLayers that is similar to this one, which was done in ArcGIS Server. I thought I&#39;d be able to help her as I have GIS and some coding experience but this is over my head.\n\nShe&#39;s wanting to use a WFS-capable template and already has a very basic page set up. She&#39;d like users to be able to edit the data. \n\nDo you have any advice, know of any tutorials, or of any published maps that are similar to the Gender Map that we could take a look at? \n\nNeither of us have any real experience with webmaps. \n\nHer current code is as follows:\n\n\n\n\n My girlfriend is trying to create a <span class=\"highlight\">webmap</span> using OpenLayers that is similar to this one, which was done in ArcGIS Server. &hellip; "
    },
    {
        "question": "how to save drawable entities with leaflet.draw/draw polygons into my Postgis database with getting also the coordinates",
        "area": [
            "postgis",
            "leaflet",
            "leaflet-draw",
            "save"
        ],
        "text": "I am very new to creating webmaps with Leaflet and I am trying to save my shapes I draw into my postgis db. I would prefer to be saved as .shp or any default format (i.e. json) with its geometry field. I seek a step-by-step code like a small demo.\n\nthe script till now:\n\n\n I am very new to creating webmaps with Leaflet and I am trying to save my shapes I draw into my postgis db. I would prefer to be saved as .shp or any default format (i.e. json) with its geometry field &hellip; "
    },
    {
        "question": "How do I show feature attributes in a Leaflet popup?",
        "area": [
            "leaflet",
            "geojson",
            "popup",
            "json"
        ],
        "text": "\nSo I have a JSON file displayed on my leaflet webmap. I would like to have it so a popup will appear when a feature is clicked. Right now it is a polygon feature. How do I call up information from the JSON file (Syriashape.json) so it can be displayed? The fields I would like to display are called &quot;Sheet_Num&quot; and &quot;Date&quot;\n\nCurrently, this is what I have:\n\n\n So I have a JSON file displayed on my leaflet <span class=\"highlight\">webmap</span>. I would like to have it so a popup will appear when a feature is clicked. Right now it is a polygon feature. &hellip; "
    },
    {
        "question": "Linking pdf which is stored on local server to web map made with qgis2web",
        "area": [
            "qgis",
            "qgis2web"
        ],
        "text": "This happens because qgis2web interprets QGIS &quot;Attachment&quot; fields as images. If you make the fields text, rather than attachments, it will try to recognize hyperlinks and make them clickable.\n\nOne thing I&#39;ve run into, though, is that links to  addresses often fail in browsers these days, so even if the above works - in other words, it produces the link correctly - the links still might not work in a browser. Depending on which browser you need this to work in, there might be registry hacks to allow file:// links, but that may or may not be a solution for you (ie do you have access to the registry on every machine which will view the webmap?).\n you need this to work in, there might be registry hacks to allow file:// links, but that may or may not be a solution for you (ie do you have access to the registry on every machine which will view the <span class=\"highlight\">webmap</span> &hellip; "
    },
    {
        "question": "Leaflet/HTML/GeoJSON: How to put a pop-up on a geoJSON point?",
        "area": [
            "leaflet",
            "geojson",
            "html"
        ],
        "text": "I don&#39;t have much knowledge of HTML/JS/GeoJSON, and have made a webmap from trial and error with many different tutorials. I have tried leaflet&#39;s tutorials but cannot get the desired results.\n\nI have a functioning Leaflet webmap that shows GeoJSON points. I need to symbolize the points based on GeoJSON properties, and provide a pop-up when the point is clicked. I can use &quot;pointToLayer&quot; to turn the default blue markers into a custom point, \n\n\n\nbut when I try to incorporate a pop-up, the blue points turn back into default markers \n\n\n\nHow can I get a custom-symbolized point with a pop-up? What am I doing wrong?\n\nHere is the HTML code I am using:\n\n\n I don&#39;t have much knowledge of HTML/JS/GeoJSON, and have made a <span class=\"highlight\">webmap</span> from trial and error with many different tutorials. I have tried leaflet&#39;s tutorials but cannot get the desired results. &hellip; I have a functioning Leaflet <span class=\"highlight\">webmap</span> that shows GeoJSON points. I need to symbolize the points based on GeoJSON properties, and provide a pop-up when the point is clicked. &hellip; "
    },
    {
        "question": "PopUp with Images with QGIS2web",
        "area": [
            "qgis",
            "qgis2leaf",
            "qgis2web"
        ],
        "text": "\nyes it is possible, like what @TomChadwin said with\n\n\nwith a huge help from excel (using CSV file), i will explain in step:\n\n1.Load your data with the image hyperlink Column inside\n \n\n2.Make a new column where your url picture inside img tag with this formula    okok\n\n\n\n\n\nThen Copy those cells and Paste with Paste Special Values.\n\n\nIf you missing something, here is example for much clearer explanation, download it and open in spreadsheet like excel to see how it works. It supposed now you have Picture hyperlink that will pop up with Qgis2web.\n\nhere is the webmap : Endemic Animal of Indonesia Map\n\nand here is the screen capture\n\n\nand \n here is the <span class=\"highlight\">webmap</span> : Endemic Animal of Indonesia Map\n\nand here is the screen capture\n\n\nand &hellip; "
    },
    {
        "question": "Use MapBox Satellite basemap in ArcGIS Online web map",
        "area": [
            "arcgis-online",
            "mapbox",
            "arcgis-online-basemaps"
        ],
        "text": "This link demonstrates how MapBox can be added as a basemap in a webmap. As cbunn mentioned, save the webmap with just the basemap. Share the webmap with a group that will be used for basemaps. Then change the organisational basemaps to use that group as below (any groups that you have in your organisation will appear):\n\n\n\nWhen you select a group that is not default, an option appears to add the Esri basemaps to the group. Note that all basemaps in the group must have the same spatial reference. And don&#39;t ask me about licencing!\n This link demonstrates how MapBox can be added as a basemap in a <span class=\"highlight\">webmap</span>. As cbunn mentioned, save the <span class=\"highlight\">webmap</span> with just the basemap. Share the <span class=\"highlight\">webmap</span> with a group that will be used for basemaps. &hellip; "
    },
    {
        "question": "How does oversampling work in WMTS layers?",
        "area": [
            "qgis",
            "raster",
            "tiles",
            "resampling"
        ],
        "text": "The quirky behaviours described by the questioner can be explained from the QGIS source codes. Here they are in simplified pseudocodes, with details omitted for clarity.\n\n\n\nWe will refer to the above in subsequent descriptions.\n\n(Nominal) Scale and Magnifier\n\nThe relationship between the Scale value and Magnifier value is\n\n\n\nIn the question, when Scale=1:125K and Magnifier=200%, the actual or effective scale used by QGIS was 1:62.5K. (Hence, the User was not looking at 1:125K.)\n\nQGIS&#39;s map view, at 1:125K loads Level 13 of the webmap service. But at 1:62.5K, QGIS loads Level 14. \n\nOversampling and Raster Layer\n\nAs explained in another answer, Oversampling is a limiter (pseudocode Line 2). It limits toUseRatio, which is a coefficient for amount of pixels to be read from the raster layer (i.e., resWdith and resHeight in pseudocode Line 4 and 5.) \n\nIf User specifies 0.0, then resWdith and resHeight will be zeroes, and nothing will be read from the raster layer. This explains the blank visual output described by the questioner.\n\nA raster layer backed by a file usually has only one &quot;layer&quot;, with a fixed native pixel resolution. (Note: Overlays omitted to simplify explanation.) QGIS loads the same layer for every map view, and scales up or down to produce the desired visual output. (Pseudocode Line 6 and 7.)\n\nNow, for a raster layer backed by a multi-layer webmap service, something interesting happened in Line 6. Based on the inputs (i.e., current map view extent, resWidth and resHeight), QGIS computes and loads the layer that supposedly gives the best pixel resolution. And this &quot;best&quot; layer is not necessarily the same layer computed by the effective (nominal) Scale.\n\nHence, at Scale=1:62,500 and Oversampling=2.0 (remember that OverSampling is not the actual coefficient but a limiter), QGIS loads Level 14. At Scale=1:62,500 and Oversampling=3.0, QGIS loads Level 15 (which happens to be the last layer, i.e. the layer with supposedly highest pixel resolution).\n\nAdditional Info\n\nThe ArcGIS Online USA Topo Maps webmap service actually has 16 layers and not three. Each layer has its own native pixel resolutions (i.e., &quot;scales&quot;). Hence, all GIS apps will look at it as having 16 layers - not three. The layer compositions are as below:\n\n\n\n(I suspected that Layer 12 to 15 may contain Topo! 1:100K content for areas not covered by Topo! 1:24K. Clarification on this is welcomed.) \n\nThe nominal scale of the map (i.e., 1:100K, 1:24K, and etc is true only on printed paper) and it is not to be confused with the pixel resolution of a digital map layer.\n\nIn the questioner&#39;s description, he observed that when Scale=1:125K and Magnifier=200% and Oversampling=2.0, QGIS shows GTopo 1:100K and not GTopo 1:24K. This may be due to (1) some tiles not successfully loaded during testing,\nor (2) User was looking at an extent where Topo! 1:24K does not cover and it was filled by content from Topo! 1:100K, or (3) QGIS on Mac uses a slightly different set of screen metric constants. (My apology as I had not gotten that far in the QGIS source codes.)\n QGIS&#39;s map view, at 1:125K loads Level 13 of the <span class=\"highlight\">webmap</span> service. But at 1:62.5K, QGIS loads Level 14. &hellip; Now, for a raster layer backed by a multi-layer <span class=\"highlight\">webmap</span> service, something interesting happened in Line 6. &hellip; "
    },
    {
        "question": "What is meant with EPSG:4326 projection",
        "area": [
            "coordinate-system",
            "openlayers",
            "wgs84"
        ],
        "text": "This openlayers example is a bit confusing.\nMost webmaps display in &quot;Web Mercator&quot; ie. &#39;Google Maps-style&#39; projections - EPSG / SRID: 3857\nOpenStreetMap data is collected, stored, and distributed in &#39;unprojected lat/lon&#39; aka WGS84 - EPSG / SRID: 4326.\nHowever, local data for administrative organizations are projected to State Plane zones or UTM zones (traditionally by &quot;GIS&quot; practices, though we store our data in WGS84 and project using PostGIS st_transform() when we need units in feet).\nOpenlayers has the ability to project your webmap to any coordinate system, and I believe this example is showing how to do that given any of the data storage coordinate system issues noted above.\n Openlayers has the ability to project your <span class=\"highlight\">webmap</span> to any coordinate system, and I believe this example is showing how to do that given any of the data storage coordinate system issues noted above. &hellip; "
    },
    {
        "question": "Failure to connect QGIS with GeoServer WMS?",
        "area": [
            "qgis",
            "geoserver",
            "wms"
        ],
        "text": "I&#39;m trying to add a WMS to QGIS from GeoServer from localhost but after I paste in the URL and go to connect I get the following error:\n\n\n\nI&#39;m pretty sure I typed in the right parameters but I&#39;m a total webmap nube so I could be off:\n\n\n\n\n SERVICE=WMS&amp;REQUEST=GetCapabilities - server replied: Not Found\n\n\nI&#39;m pretty sure I typed in the right parameters but I&#39;m a total <span class=\"highlight\">webmap</span> nube so I could be off: &hellip; "
    },
    {
        "question": "Why do you use ArcGIS for Desktop?",
        "area": [
            "arcgis-desktop"
        ],
        "text": "In response to the &quot;ESRI is slow ...so I am surprised to see you find it quick to develop on&quot; idea:  it&#39;s important to separate web-map/services development from &quot;desktop&quot; development from &quot;real&quot; development.\n\nwebmaps - It&#39;s been a few years since I seriously looked at serving webmaps with an ESRI (ArcIMS) or Open Source (Mapserver) platform, so things might be different now. At that time mapserver was faster/better both in performance and dev time. Reading various conversations here and there on the web indicate things are much improved with ArcGIS Server. The open source side has seen even more activity; from a distance the relative balance looks much the same. In any case web facing maps and services have never been ESRI&#39;s strong suite, as much as one can do with arcgis server now, it pales in comparison to the desktop tools. They&#39;re pumping boatloads of energy into arcgis server though so this may change eventually.\n\nDesktop development - this is modeller and the command line interface, followed by cleaning up and extending the saved scripts from that (but many never find the need to go that far). With modeller the initial design &amp; protoyping phase is a snap as one drags and drops compponents and defines relationships and dependencies between the processes. The model is not just conceptual, not just a picture. It&#39;s a tool that can be saved and re-used on real data at will. \n\nTurn on the CLI and run the canned toolboxes at will. As the tools run the actual commands executed and their parameters are reported. These reports can be copied to a text editor or spreadsheet, tweaked as desired, and pasted back into the CLI for execution. The CLI is also interactive, showing possible commands to choose from as one types, with tooltips for possible parameters, and accepts drag-n-drop from the various arcmap/catalog panels.\n\nDesktop development in ArcGIS is fast, largely intuitive, and well integrated. (I do have a looong list of desired improvements and gripes mind you!)\n\nReal development - this is firing up Visual Studio or [insert-favourite-IDE] and building something direct from ArcObjects in C#, C++, Java, Python, etc. I can&#39;t speak to how developing in this environment compares to other GIS platforms as I&#39;ve not done it. My hunch is that it has the perception of being more difficult because the number of possible objects to choose from is damnably large. I&#39;ve been told the ESRI COM library is the largest in the world, bigger than anything even Microsoft has built. That&#39;s going to take some time to get the gist of.\n In response to the &quot;ESRI is slow ...so I am surprised to see you find it quick to develop on&quot; idea:  it&#39;s important to separate web-map/services development from &quot;desktop&quot; development from &quot;real&quot; deve &hellip; "
    },
    {
        "question": "Webmapping with pgRouting and Mapserver for Beginners",
        "area": [
            "web-mapping",
            "mapserver",
            "pgrouting"
        ],
        "text": "First you&#39;ll need to get pgRouting running. For a tutorial check: A Beginner\u2019s Guide to pgRouting.\n\nThe simplest approach is to do node-to-node routing using shortest_path().\n\nYou&#39;ll need to enable the user to pick start and end node for their routings. For example code check: Picking a Feature\u2019s Attribute Value From a WMS Layer With OpenLayers\n\nIn Mapscript, you can then tie a &quot;Get Routing&quot; button to a function that loads a new layer based on the shortest_path() query.\n\n\n\nUpdate:\n\nThis is a great tutorial for creating a webmap with routing functionality: http://workshop.pgrouting.org/chapters/geoext_client.html\nIt is based on OpenLayers with GeoExt and pgRouting, but it&#39;s easy to adjust it to any other routing webservice.\n Update:\n\nThis is a great tutorial for creating a <span class=\"highlight\">webmap</span> with routing functionality: http://workshop.pgrouting.org/chapters/geoext_client.html\nIt is based on OpenLayers with GeoExt and pgRouting, but it&#39;s &hellip; "
    },
    {
        "question": "How to create a webmap showing point density?",
        "area": [
            "web-mapping",
            "heat-map"
        ],
        "text": "I am trying to develop hotspot map showing point density in our GIS based web application. \n\nAfter searching for an option I have decided to use v.kernel command. I have a table containing some point data i.e. crime data. I need to display the hotspot of crime for a particular area. \n\nIn v.kernel vector file containing points and polygon are used for displaying hotspots/heatmaps. In QGIS there is an option for selecting some rows and exporting it to shapefile. Is there any option for running this command from a Python file or is there any better option for displaying hotspot/heatmaps? \n\nI have tried OpenLayers heatmap, Python&#39;s heatmap and django-heat app but nothing seems to work for me. I am using OpenLayers TMS (Openlayers-2.12) for displaying maps generated through Mapnik and TileCache.\n I am trying to develop hotspot map showing point density in our GIS based web application. \n\nAfter searching for an option I have decided to use v.kernel command. I have a table containing some point  &hellip; "
    },
    {
        "question": "Looking for local data sets for 6th graders?",
        "area": [
            "data",
            "united-states",
            "education"
        ],
        "text": "I recommend reaching out to local Government agencies to request data. You may be able to find someone willing to supply data for teaching purposes.\n\nAs a GIS Specialist for a County Government, I know that we typically sell data to local contractors and consultants (for a low cost) but will share data with teaching institutions for free. We always require a signed license agreement protecting us from misuse of our data but will not typically charge for non-commercial use.\n\nI found some links that may be helpful to you.\nOakland County Michigan Enterprise GIS\nThere is a contact listed at this site.\n\nWebmaps:\nWebmaps Link\n\nOften statewide data repositories will have information that will be useful as well.\nStatewide GIS Data repository for Michigan\n I recommend reaching out to local Government agencies to request data. You may be able to find someone willing to supply data for teaching purposes.\n\nAs a GIS Specialist for a County Government, I kno &hellip; "
    },
    {
        "question": "create buffer around locator-derived point",
        "area": [
            "arcgis-10.0",
            "arcgis-maps-sdk-javascript",
            "point",
            "buffer",
            "dojo"
        ],
        "text": "Here&#39;s a working example that geocodes and address/place and then buffers the first result:\n\n\n\nNote that no proxy is used. If you&#39;re buffering a single point, a proxy isn&#39;t necessary as the URL that&#39;s generated isn&#39;t likely to be &gt; 2k characters. If you&#39;re buffering many points, or large line or polygon geometries then you&#39;d need a proxy.\n\nAnother point to stress is that you should ask for results from the locator in the spatial reference of your map. This is done with the following line of code:\n\n\n dojo.require(&quot;esri.map&quot;);\n      dojo.require(&quot;esri.tasks.locator&quot;);\n\n      var map, locator;\n      function init() {\n        // why write a lot of javascript code when you can use arcgis.com to author your <span class=\"highlight\">webmap</span> &hellip; "
    },
    {
        "question": "&quot;undefined&quot; attributes in webmap",
        "area": [
            "qgis2web"
        ],
        "text": "I am trying to make a basic web map for my employer showing all past projects completed in the state. The map (via qgis2web plugin version 2.33.1, leaflet option) itself is created fine, but the data within the attribute table is not carrying over to the webmap, giving all of my attributes the value of &quot;undefined&quot;. Dataset is not huge; I tried hiding all but one to see if that would work, but no luck.\n\nThe reason I am using leaflet is because my map would not show up at all in OpenLayers, so if anyone has advice there too I&#39;m all ears!\n\nAny ideas how I can fix this?\n The map (via qgis2web plugin version 2.33.1, leaflet option) itself is created fine, but the data within the attribute table is not carrying over to the <span class=\"highlight\">webmap</span>, giving all of my attributes the value of &hellip; "
    },
    {
        "question": "Adding ArcGIS Server services or ArcSDE datasets to Tilemill?",
        "area": [
            "arcgis-server",
            "enterprise-geodatabase",
            "tilemill"
        ],
        "text": "Our web design department wants to use mapbox/tilemill to create webmaps for our public websites, but all our data is made available through ArcGIS-server or ArcSDE. Is there some way to use these directly in tilemill, maybe through OGR, or serverside script thats converts ArcGIS-services into geojson? \nI would prefer not set up a parallel storage in shapefile if I don&#39;t have to.\n\nExtra caveat: our designers are hardcore Mac-users.\n Our web design department wants to use mapbox/tilemill to create webmaps for our public websites, but all our data is made available through ArcGIS-server or ArcSDE. Is there some way to use these dir &hellip; "
    },
    {
        "question": "Why do you use ArcGIS for Desktop?",
        "area": [
            "arcgis-desktop"
        ],
        "text": "Since Esri make applications for desktop, mobile, server and the new-ish ArcGIS.com, it&#39;s relatively easy to migrate the same application across all environments.\n\nFor example, you can create a map document in ArcGIS Desktop and push it to the cloud-hosted ArcGIS.com with a few clicks (and pay later for online storage and access). You can use that same hosted version in your mobile or desktop applications, webmaps, etc.\n\nOther organisations produce similar &quot;seamless&quot; packages, such as Boundless Geo&#39;s excellent OpenGeo Suite or MapBox&#39;s suite, and perhaps they&#39;ll soon remove the advantages of ArcGIS. But for me, for the meanwhile, ArcGIS provides enough benefits to justify the cost.\n Since Esri make applications for desktop, mobile, server and the new-ish ArcGIS.com, it&#39;s relatively easy to migrate the same application across all environments.\n\nFor example, you can create a map do &hellip; "
    },
    {
        "question": "Performing TIFF to MBTILES conversion on Mac?",
        "area": [
            "qgis",
            "mac",
            "ios",
            "geotiff-tiff",
            "mbtiles"
        ],
        "text": "I agree with mapbarker and say TileMill would be the best route. However the problem you have is that the original raster files are in British National grid (epsg:27700) and need to be warped to the google sperical mercator projection (epsg:3857)\n\nThe MapBox team have a good tutorial on this - https://www.mapbox.com/tilemill/docs/guides/reprojecting-geotiff/\n\nSo all you will have to do is warp your virtual raster, load into TileMill then export out.\n\nThe alternative is to use the gdal2tiles.py and then mbutil to load the directory of tiles into the mbtile. This is a painful and very time consuming route.\n\n--EDIT--\n\nOk to explain further.\n\nYou said you had already created your VRT for the rasters using QGIS. So you need to warp the VRT from its current projection to the one required to created MBTiles - as explained in the link above.\n\nDo you have GDAL installed? If not you could install it and then using the link above use the gdal_warp command to convert to the EPSG 3875.\n\nIf you dont want to install GDAL then you can use QGIS&gt;Raster(from the top toolbar)&gt;Projections&gt;Warp\n\nThen select your VRT file, then specificy an output to save to\n\nThen select EPSG:27700 as the source SRS and then EPSG:3875 as the target SRS, \n\nThen I would loolk at this previous question - Converting Ordnance Survey raster maps to WGS84 webmap tiles and determine which resampling method you want.\n\nThen let QGIS do it works\n\nOnce the warp has finished you will have a new raster file\n\nLoad this into TileMill and then export out as an MBTile\n specificy an output to save to\n\nThen select EPSG:27700 as the source SRS and then EPSG:3875 as the target SRS, \n\nThen I would loolk at this previous question - Converting Ordnance Survey raster maps to WGS84 <span class=\"highlight\">webmap</span> &hellip; "
    },
    {
        "question": "EPSG 3857 or 4326 for Web Mapping",
        "area": [
            "coordinate-system",
            "leaflet",
            "openstreetmap",
            "google-maps",
            "web-mapping"
        ],
        "text": "The discussion at What is the difference between WGS84 and EPSG4326? shows that 4326 is just the EPSG identifier of WGS84..\n\nWikipedia entries for Google Maps and OpenStreetMap shows that they both use  WGS 84.\n\nhttp://wiki.openstreetmap.org/wiki/EPSG:3857 states that \n\nEPSG:3857 is a Spherical Mercator projection coordinate system popularized by web services such as Google and later OpenStreetMap. \n\nLeaflet&#39;s help states:\n\nEPSG3857 The most common CRS for online maps, used by almost all free and commercial tile providers. Uses Spherical Mercator projection. Set in by default in Map&#39;s crs option.|\n\nEPSG4326 A common CRS among GIS enthusiasts. Uses simple Equirectangular projection.\n\nThis is confusing - it seems that Google Maps and OpenStreetMap use EPSG3857 but they use WGS84 which &#39;is&#39; EPSG4326. Something can&#39;t be right here, most likely my understanding. \n\nCould someone help me understand?\n .|\n\nEPSG4326 A common CRS among <span class=\"highlight\">GIS</span> enthusiasts. Uses simple Equirectangular projection. &hellip; "
    },
    {
        "question": "Installing File Geodatabase (*.gdb) support in QGIS",
        "area": [
            "qgis",
            "installation",
            "file-geodatabase",
            "osgeo4w"
        ],
        "text": "Update December 2017\n\nNow you can simply drag&amp;drop .gdb file (directory) into QGIS. This is read access to File Geodatabases only. If you require write access please read further.\n\nUpdate July 2015 \n\nIt is time to bring this answer a bit more current as some elements of FileGDB support in QGIS have changed.  I am now running QGIS 2.10.0 - Pisa.  It was installed using the OSGeo4W installer.  \n\nWhat has changed is that upon the basic install of QGIS, File GDB read-only access is enabled by default, using the Open FileGDB driver.  Credit for first noting this must be given to @SaultDon.\nRead/Write access may be enabled using the FileGDB driver install through the OGR_FileGDB library.  The library needs to be enabled using the process below, either when you install QGIS, or individually.  More detail about the drivers is below:  \n\n\nFileGDB driver:  Uses the FileDB API SDK from ESRI - Read/Write to FGDB&#39;s of ArcGIS 10 and above  \nOpenFleGDB driver:  Available in GDAL &gt;= 1.11 - Read Only access to FGDB&#39;s of ArcGIS 9 and above\n\n\nWhen you add a Vector Layer, you simply choose the  based on the driver you want to use.\nESRI FileGDB Driver\n\n\nOpen FileGDB Driver\n\n\nThe process below shows in more detail the steps to install QGIS from the OSGeo4W installer, ensure the OGR_FileGDB library is installed, then load layers from a File Geodatabase.\n\n\nDownload and run  for 32bit or  for 64bit from OSGeo4W.\nChoose Advanced Install, then Install from Internet.  Choose your root and local package directories, and then your connection type, in my case, &quot;Direct Connection&quot;.  Once you click next, it will bring up a screen with a number of collapsed menus.\n\nExpand the &quot;Desktop&quot; menu.  Find the entry for &quot;qgis: Quantum GIS (desktop)&quot;.  In the &quot;New&quot; column, change entry from &quot;Skip&quot;, to show version 2.10.0-1.\n\nExpand the &quot;Libs&quot; menu.  Find the entry for &quot;gdal-filegdb: OGR FileGDB Driver&quot;.  In the &quot;New&quot; column, change the entry from &quot;Skip&quot;, to show version 1.11.2-1.\n\nOnce you click Next, it will install QGIS and all of the associated libraries.  Once this is completed, open Quantum GIS, and Choose &quot;Add Vector Data&quot;.  Change the option to &quot;Directory&quot;.  This is where you choose the driver as shown above.\n\nBrowse to the File Geodatabase and select the directory.  Click &quot;Open&quot;\n\nSelect a Vector Layer and press &quot;Ok&quot;.  Please note that the FileGDB API Does not support Raster Images.\n\nAs you can see, the selected layer loads in.  Using the Esri driver, editing is possible.  If you use the Open FileGDB driver, the data is read only.\n\nFor your reference, here is the &quot;About&quot; window from my install of QGIS, showing the versions of the software, and the GDAL/OGR library being used.\n\n\n\nThis install was performed on a Windows 7 64bit computer.  With previous installers, there were some inconsistent results.  This may have changed with the switch to the 32 or 64bit installers.  This thread at OSGeo discusses some old issues people were experiencing: Thread\n Find the entry for &quot;qgis: Quantum <span class=\"highlight\">GIS</span> (desktop)&quot;.  In the &quot;New&quot; column, change entry from &quot;Skip&quot;, to show version 2.10.0-1.\n\nExpand the &quot;Libs&quot; menu. &hellip; Once this is completed, open Quantum <span class=\"highlight\">GIS</span>, and Choose &quot;Add Vector Data&quot;.  Change the option to &quot;Directory&quot;.  This is where you choose the driver as shown above. &hellip; "
    },
    {
        "question": "Seeking examples of beautiful maps?",
        "area": [
            "cartography"
        ],
        "text": "Oftentimes when we make maps it is based on our subjective interpretation of what is aesthetically pleasing. I would like it if people posted examples of beautiful maps, displaying any phenomena in any manner.\n\nBelow I have posted one of my favorite maps. This is an example of a value-by-alpha map recently asked about as How to implement value-by-alpha map in GIS?, and the picture is taken from the GeoVista website.\n\n\n\nCitation for the map&#39;s makers:\n\n\n  Geovisual analytics to enhance spatial scan statistic interpretation:\n  an analysis of U.S. cervical cancer mortality Jin Chen , Robert E Roth\n  , Adam T Naito , Eugene J Lengerich and Alan M MacEachren\n  International Journal of Health Geographics 2008, 7:57\n\n\nIt would be best for the cultivation of knowledge if people would elaborate on why the particular maps they cite are beautiful. \n\nThe reason I believe I think the cited value-by-alpha map is beautiful is that it creates a very simple, but obvious and striking visual hierarchy with which to interpret the standardized mortality ratio&#39;s. This is in particular useful combined with the very &quot;noisy&quot; standardized mortality ratio&#39;s, and the typically very noisy clusters of abnormally high rates produced by the SatScan clustering technique. One can even clearly see very small clusters around Chicago and Philadelphia. \n\nThere are other supplemental elements of the map that make it easy on the eyes. For example, the black background, the heavier white outline for around the states and the white outline for the states (that is blended the same as the attribute values). Maps with many polygons can particularly be distracting if one does not take care when plotting the polygon outlines. \n\nAlso the legend is particularly well created, and effectively demonstrates the concept (although it certainly isn&#39;t a typical legend, so took some original creative thought).\n This is an example of a value-by-alpha map recently asked about as How to implement value-by-alpha map in <span class=\"highlight\">GIS</span>?, and the picture is taken from the GeoVista website. &hellip; "
    },
    {
        "question": "What free programs should every GIS user have installed?",
        "area": [
            "open-source-gis",
            "software-recommendations",
            "free-software"
        ],
        "text": "Note: This question is specifically about installed, desktop software. There is another question specifically about free cloud-based software and services.\n\nWhat free programs should every GIS user have installed?\n\nI&#39;m not necessarily referring to ESRI extensions or open-source products, but others that increase your productivity and ability to handle GIS tasks.\n\nFor example:\n\n\nNotepad++ for writing code snippets or editing XMLs. Paint.NET or GIMP for quick graphic editing.\nI use Google Tasks daily and I think it&#39;s worth mentioning. It&#39;s not GIS-specific, but it&#39;s a great tool, especially if used independently and on multiple projects where purchasing time-management software isn&#39;t reasonable.\nWhile it&#39;s not focused on GIS development, Rainmeter has proven to be very useful in terms of increasing productivity and monitoring system resources. I have created a GIS &quot;sidebar&quot; on my desktop that holds all of my development tools, as well as links to the online resources I used the most. It&#39;s nice to be able to use one location, rather than many (e.g. taskbar, bookmarks in browser, search engine).\n\n What free programs should every <span class=\"highlight\">GIS</span> user have installed? &hellip; I have created a <span class=\"highlight\">GIS</span> &quot;sidebar&quot; on my desktop that holds all of my development tools, as well as links to the online resources I used the most. &hellip; "
    },
    {
        "question": "How much math does a GIS Analyst need to know?",
        "area": [
            "education"
        ],
        "text": "I make my living applying mathematics and statistics to solving the kinds of problems a GIS is designed to address.  One can learn to use a GIS effectively without knowing much math at all: millions of people have done it.  But over the years I have read (and responded to) many thousands of questions about GIS and in many of these situations some basic mathematical knowledge, beyond what&#39;s usually taught (and remembered) in high school, would have been a distinct advantage.\n\nThe material that keeps coming up includes the following:\n\n\nTrigonometry and spherical trigonometry.  Let me surprise you: this stuff is overused.  In many cases trig can be avoided altogether by using simpler, but slightly more advanced, techniques, especially basic vector arithmetic.\nElementary differential geometry.  This is the investigation of smooth curves and surfaces.  It was invented by C. F. Gauss in the early 1800&#39;s specifically to support wide-area land surveys, so its applicability to GIS is obvious.  Studying the basics of this field prepares the mind well to understand geodesy, curvature, topographic shapes, and so on.\nTopology.  No, this does not mean what you think it means: the word is consistently abused in GIS.  This field emerged in the early 1900&#39;s as a way to unify otherwise difficult concepts with which people had been grappling for centuries.  These include concepts of infinity, of space, of nearness, of connectedness.  Among the accomplishments of 20th century topology was the ability to describe spaces and calculate with them.  These techniques have trickled down into GIS in the form of vector representations of lines, curves, and polygons, but that merely scratches the surface of what can be done and of the beautiful ideas lurking there.  (For an accessible account of part of this history, read Imre Lakatos&#39; Proofs and Refutations.  This book is a series of dialogs within a hypothetical classroom that is pondering questions that we would recognize as characterizing the elements of a 3D GIS.  It requires no math beyond grade school but eventually introduces the reader to homology theory.)\n\nDifferential geometry and topology also deal with &quot;fields&quot; of geometric objects, including the vector and tensor fields Waldo Tobler has been talking about for the latter part of his career.  These describe extensive phenomena within space, such as temperatures, winds, and crustal movements.\nCalculus. Many people in GIS are asked to optimize something: find the best route, find the best corridor, the best view, the best configuration of service areas, etc.  Calculus underlies all thinking about optimizing functions that depend smoothly on their parameters.  It also offers ways to think about and calculate lengths, areas, and volumes.  You don&#39;t need to know much Calculus, but a little will go a long way.\nNumerical analysis. We often have difficulties solving problems with the computer because we run into limits of precision and accuracy.  This can cause our procedures to take a long time to execute (or be impossible to run) and can result in wrong answers.  It helps to know the basic principles of this field so that you can understand where the pitfalls are and work around them.\nComputer science. Specifically, some discrete mathematics and methods of optimization contained therein.  This includes some basic graph theory, design of data structures, algorithms, and recursion, as well as a study of complexity theory.\nGeometry. Of course.  But not Euclidean geometry: a tiny bit of spherical geometry, naturally; but more important is the modern view (dating to Felix Klein in the late 1800&#39;s) of geometry as the study of groups of transformations of objects.  This is the unifying concept to moving objects around on the earth or on the map, to congruence, to similarity.\nStatistics. Not all GIS professionals need to know statistics, but it is becoming clear that a basic statistical way of thinking is essential.  All our data are ultimately derived from measurements and heavily processed afterwards.  The measurements and the processing introduce errors that can only be treated as random.  We need to understand randomness, how to model it, how to control it when possible, and how to measure it and respond to it in any case.  That does not mean studying t-tests, F-tests, etc; it means studying the foundations of statistics so that we can become effective problem solvers and decision makers in the face of chance.  It also means learning some modern ideas of statistics, including exploratory data analysis and robust estimation as well as principles of constructing statistical models.\n\n\n\n\nPlease note that I am not advocating that all GIS practitioners need to learn all this stuff!  Also, I am not suggesting that the different topics should be learned in isolation by taking separate courses.  This is merely an (incomplete) compendium of some of the most powerful and beautiful ideas that many GIS people would deeply appreciate (and be able to apply) were they to know them.  What I suspect we need is to learn enough about these subjects to know when they might be applicable, to know where to go for help, and to know how to learn more if it should be needed for a project or a job.  From that perspective, taking a lot of courses would be overkill and would likely tax the patience of the most dedicated student.  But for anyone who has an opportunity to learn some mathematics and has a choice of what to learn and how to learn it, this list might provide some guidance.\n One can learn to use a <span class=\"highlight\">GIS</span> effectively without knowing much math at all: millions of people have done it. &hellip; No, this does not mean what you think it means: the word is consistently abused in <span class=\"highlight\">GIS</span>. &hellip; "
    },
    {
        "question": "Does Y mean latitude and X mean longitude in every GIS software?",
        "area": [
            "coordinate-system",
            "mapinfo",
            "latitude-longitude"
        ],
        "text": "I am using Mapinfo and it has Y as latitude and X as longitude. Is that the same case for all mapping software? As for any country their respective value is multiple of 1 or -1. So for Nepal can I say it is on positive side +1 for both latitude and longitude? And for USA to be +1 Y and -1 X.\n I am using Mapinfo and it has Y as latitude and X as longitude. Is that the same case for all mapping software? As for any country their respective value is multiple of 1 or -1. So for Nepal can I say &hellip; "
    },
    {
        "question": "Choosing OpenLayers or Leaflet?",
        "area": [
            "openlayers-2",
            "leaflet",
            "software-recommendations",
            "api"
        ],
        "text": "I have used both OpenLayers and Leaflet in my apps. There has been so much discussion on this topic in this forum and others on planet-internet. They usually fall into 2 camps - features and flexibility of OpenLayers versus simplicity of Leaflet. I would not be surprised if someone spawns an &quot;OpenLeaf&quot; initiative soon marrying the best of both worlds!\n\nI found Leaflet very simple to use, a petite 64K size, compared to over 700K Openlayers, and in very few steps you can create apps that have the freshness and eye-candy of today&#39;s web and mobile GIS apps. Your stack - GeoServer, PostGIS etc., is a standard stack, so OpenLayers or Leaflet could easily be incorporated.\n\nHaving said that, I would still go with OpenLayers for the following reasons\n\n\nThere is just a TON of material around OpenLayers. It is a lot more mature than Leaflet.\nCheck out the comparison on commits and users.\nOpenLayers, GeoServer, PostGIS stack is so proven in the FOSS world that you are going on a path that is solid.\nOpenLayers has tad bit more features on Map Controls.\nWhile its a bit more work to create transitions and visual-effects, it can be done in OpenLayers.\n\n I found Leaflet very simple to use, a petite 64K size, compared to over 700K Openlayers, and in very few steps you can create apps that have the freshness and eye-candy of today&#39;s web and mobile <span class=\"highlight\">GIS</span> apps &hellip; "
    },
    {
        "question": "What is the purpose of PostGIS on PostgreSQL?",
        "area": [
            "postgis",
            "postgresql",
            "geography-data-type",
            "indexing",
            "operator"
        ],
        "text": "If you re-wound the universe to early 2001, and not only let the inventors of PostGIS see the future, but also let the PSC of PgSQL see the future, perhaps PostGIS would be a series of patches on PgSQL. But at a minimum, if we had started as patches to core, the first thing we would have run up against is:\n\n\ncore PgSQL areas don&#39;t support holes, but the GIS model really wants holes, can we change that?\n\n\nAnd core PgSQL would have said: &quot;no, of course not, areas have an existing well-understood semantic and we can&#39;t go making backwards incompatible changes like that&quot;.\n\nAs non-core developers, PostGIS was able to knock out monthly and 6-monthly releases for a number of years while PgSQL core plodded along with annual and longer releases. We were also able to add whatever features we wanted, whenever, since we had commit rights in our project, but gaining commit rights in PgSQL takes a Very Long Time.\n\nBy the time PostGIS was demonstrating enough external value that PgSQL core looked over and said to themselves &quot;huh, that would have been nice to have in core as an extra feature&quot;, there was already so much code of such a different standard and style from PgSQL (not to mention under an incompatible license) that the idea of merging was not really possible. \n\nInstead, PostGIS has become the canonical example of a Really Large Complex Extension that helps PgSQL remain modular and extensible. &quot;How will this effect something like PostGIS&quot; is a question often asked as core PgSQL evaluates some change. This is also a good thing, not perhaps quite as nice as PostGIS being part of core, but good enough.\n\nThere&#39;s other reasons, like the long list of dependencies PgSQL core would have hated to see, the generally lower code consistency and API cleanliness which they would have despaired of improving, and on and on. Even at conception, PostGIS was too big a hairball for PgSQL to swallow in one bite. \n But at a minimum, if we had started as patches to core, the first thing we would have run up against is:\n\n\ncore PgSQL areas don&#39;t support holes, but the <span class=\"highlight\">GIS</span> model really wants holes, can we change that &hellip; "
    },
    {
        "question": "Comparing various JavaScript mapping libraries?",
        "area": [
            "javascript",
            "web-mapping"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\nFor non-GIS background devs creating single-function mapping apps - I&#39;d probably recommend Leaflet (now supported by MapBox). Easy to use and small. More functionality relies on plugins of varying quality and support. \n\nGIS online type application - use OpenLayers3 - has the full suite of data sources, controls etc. in a single library. It can also be used for simple mapping apps, so if you have a mix then I&#39;d use this for everything. \n\nGoogle still has the library/data combination (e.g. StreetView is not available anywhere else). \n\nEsri has GUI web app builders, and as noted below, why complicate things if you already use their stack. \n\nCommercial APIs (Google, Bing, Yahoo)\n\nUsing any commercial API leaves you at the mercy of whatever changes the provider makes to the API or Terms of Service. What happens for example if suddenly your local government portal that uses Google Maps suddenly has adverts popping up all over it? Want to reuse your JavaScript Google Maps code for an Intranet site? You&#39;ll find yourself having to pay the $10,000 licencing fee. \n\nMicrosoft often have more defined and fixed terms for their services (if paying) so there may be less of a risk here. \n\nThe recent backlash against Twitter is a good example of developers having an API that changed beneath them. If you aren&#39;t paying for a service then you (or your system) are the one being sold. \n\nGoogle started charging for use of their maps from October 2011. \n\nEsri\n\nAs others have mentioned if you are using an Esri stack then the ArcGIS API for JavaScript will no doubt work well on top of it. Coming from a GIS background Esri have probably thought more about traditional GIS tasks and features than the &quot;neo-geography&quot; web-giants (though this is just an opinion/feeling). \n\nOpenLayers has built in support for ArcGIS REST layers, and if you are looking to reuse your code for non-ESRI based websites then again an open API serves you best. \n\nUse OpenLayers...\n\nI can&#39;t really think why developers would use an API other than OpenLayers. Open Source projects lead to related Open Source projects so there are a wealth of reusable components out there such as the GeoExt library, MapQuery,  and GeoPrisma. \n\nI&#39;ll just add that just because a project is Open Source does not automatically make it better than commercial equivalents - but the OpenLayers API matches the commercial competition in this case, and the ability to see how the source works, the unit tests, the build scripts etc. mean that you can easily build new features on top of it. \n\nThere has been some recent criticism of OpenLayers, mainly related to complexity, styling, and size. There have been counter-arguments made to these here and here by Christopher Schmidt one of the lead developers of OpenLayers. \n\nIt is worth noting that if you need a simple Open Source mapping API then take a look at Cloudmade&#39;s Leaflet. \n\nThe comment smaller, faster, newer, and more straightforward can also be read as less features and less tested.\n\nScan the API documentation for Leaflet and OpenLayers. The latter includes items such as WFS layers, editing tools, and SLD support. It has also been tested in many different environments, and works in IE6 (allowing government and local authority users). \n\nFor simpler display of spatial data Leaflet looks ideal, and easier to get started. However I&#39;ll be sticking with OpenLayers for more feature-rich GIS applications. \n\nCaveats\n\nOne possible downside is often new innovations are seen first in commercial providers&#39; systems - however these nearly always filter through to OpenLayers in time. \n\nFinally I&#39;m sure there are certain scenarios where other APIs are more suitable - on custom hardware, to fit in with an organisations other IT systems, or if you already know an API inside-out and can get a system developed in half the time. \n\nAll the APIs you mentioned are capable of producing great online mapping systems, but your choice should also fit in with you or your company&#39;s future development needs. \n Coming from a <span class=\"highlight\">GIS</span> background Esri have probably thought more about traditional <span class=\"highlight\">GIS</span> tasks and features than the &quot;neo-geography&quot; web-giants (though this is just an opinion/feeling). &hellip; However I&#39;ll be sticking with OpenLayers for more feature-rich <span class=\"highlight\">GIS</span> applications. &hellip; "
    },
    {
        "question": "What is Lanczos resampling useful for in a spatial context?",
        "area": [
            "raster",
            "gdal",
            "resampling"
        ],
        "text": "What is Lanczos resampling?\nAlthough the theory is described in an early paper and the Wikipedia article, a &quot;feel&quot; for resampling methods is best obtained by computing them on simple or standard images.  This can be a vast topic, requiring extensive experimentation, but some simplifications are available:\n\nThese operators work separately in each color channel.  Therefore it suffices to study how they work on a monochromatic (&quot;black and white&quot;) image.\n\nMost convolution operators used in image processing work the same way in the x and y directions and independently in both directions.  In effect, they are really one dimensional operators applied first to the rows and then to the columns.  This means we can study them by studying &quot;1D&quot; images, which can be plotted in detail.\n\nEverything we need to know about a linear operator (which includes all convolution operators) can be inferred from how an operator works on the simplest non-constant image of all: this is a sudden jump from one value to another.\n\n\nLet&#39;s look at an illustration of several popular resampling methods.  Actually, we need two illustrations: one to show what happens in &quot;downsampling,&quot; where the new image is coarser than the old, and another to look at &quot;upsampling,&quot; where the new images is  refinement of the old.  Let&#39;s start with the latter, because it shows more detail.\nUpsampling\n\nThe original 7 by 7 image on the left is really one-dimensional because each row is the same.  The resampling occurs across the columns.  The dimension of the other five images is 80 by 80, showing in detail how each method interpolates between the original coarse pixels.  Nearest-neighbor sampling retains the sharp division between dark and light while the other four methods blur the intervening region to some extent.  Notably, the Lanczos resampler creates some regions that are darker than any in the original and others that are lighter than any in the original.  (This can have implications for GIS work, because such an extrapolation of the original values can potentially cause the new values to be invalid.  They can also extend beyond the range of the original color map, sometimes causing the extreme values in the resampling image to be rendered incorrectly.  This is a problem with bicubic convolution resampling in ArcGIS, for example.)\n(NB: The &quot;bicubic&quot; method shown here is a bicubic spline, not the &quot;bicubic convolution&quot; of ArcGIS.)\nUsing lightness to depict image values, although natural, is not very precise.  The next illustration rectifies this by graphing the cell values (vertical axis) by column (horizontal axis).\n\nLower values on the graphs correspond to darker parts of the images.  A thoughtful examination of the original uncovers a hidden assumption: although the original image looks like a sharp jump from dark to light, the jump actually occurs over one-seventh (1/7) of the extent of the columns.  Who is to say what really happens in that interval in the original scene the image is depicting?  We therefore should not be too critical of differences among the resampling methods that occur within this short interval: each one is giving a different but potentially equally valid rendering of what might be occurring in the original scene.  In this sense, it is no longer apparent that nearest neighbor sampling is the most faithful interpolation method.\nOne conclusion we should draw is that the accuracy of any upsampling method depends on the nature of the underlying scene.  If the scene consists of values that should smoothly vary from one point to the next, then the nearest neighbor method is likely to be the least faithful way of resampling among those shown.\nDownsampling\n\nHere we see the result of downsampling a 16 by 16 image to 8 by 8 images (a 2 by 2 aggregation).  Nearest neighbor accurately retains the sharp boundary.  Lanczos differs from the others by enhancing the apparent sharpness.  A close look shows that it darkens the dark area on one side of the boundary and lightens the light area on the other side.  The graphs clarify this:\n\nThe bilinear, bicubic, and Gaussian resamplers show characteristics of convolution operators that have all positive weights (or very small negative weights): they average, or &quot;smear,&quot; neighboring values.  In downsampling this causes sharp features to be blurred.  The extent of the blur depends on the width of the kernel.  Like these others, the Lanczos resampler also blurs the jump, but it &quot;overshoots&quot; it on both sides.  That&#39;s the contrast enhancement seen just above in the images themselves.  Because of this tendency to increase contrast (the local differences between the highs and lows in the image), the Lanczos resampler is often called a &quot;sharpening filter.&quot;  These graphs show that this characterization requires a nuanced understanding, because evidently it does not actually reduce the averaging of values on both sides of the jump.  At pixel 4, its value of 0.56 is comparable to the values computed by the other convolution filters.\nHow does using it affect the output?\nLet&#39;s take a look at what happens in a more complex image.\n\nThe original, which is a 13 by 13 image now includes a pattern with the highest possible spatial frequency (alternating between light and dark with every column at the right).  We cannot hope to reproduce such features when downsampling: the smaller amount of pixels simply cannot hold all this information.  Let&#39;s focus, then, on what happens when such an image is upsampled.  If we care about faithful reproduction of the scene, we will want this high-frequency pattern to be reproduced accurately.\nThe smaller images are resampled to 25 by 25 pixels: almost, but not quite, a 2:1 refinement.  To my eye, the Lanczos and bilinear methods reproduce the stripes most sharply among the four convolution resamplers.  Nearest neighbor is, of course, the most faithful (because it cannot average values at all).\n\nThese graphs of the same results show that the Lanczos resampler was able to maintain the contrast in the stripes (as seen by the size of the vertical swings from lows to highs) at the expense of introducing a variation of intensity within the constant-value light area in the middle of the image (pixels 5, 6, 7 of the original).  This variation shows up as stripe-like artifacts within the light part of the image (the middle).  Of the resamplers shown here, it is alone in introducing such spurious detail.\nWhat is it useful for in a spatial application?\nEvidently, Lanczos resampling is not a panacea or omnibus solution to resampling.  It is superior to many other convolution resamplers in maintaining (or even enhancing) local contrast.  This can be useful when the resampled image is intended for viewing identification of detailed features or boundaries.  When the resampled image will subsequently be analyzed or processed, Lanczos resampling may increase the ability to detect edges and linear features.\nWhen the resampled image will be analyzed in other ways, though, the benefits of Lanczos resampling are doubtful.  It typically will (artificially) increase local measures of spatial variability, such as focal ranges and focal standard deviations.  It will not affect spatial means on the whole--like the other convolution resamplers, it is usually normalized (which means it&#39;s a local weighted average, with no bias introduced)--but it may increase some local averages and decrease others compared to the other resamplers.\nThe (necessarily brief) evaluation here suggests the Lanczos resampler generally should not be used for downsampling: for that application, it appears to offer nothing that simpler (and more commonly available) methods have, which retaining the potential disadvantage of extrapolating beyond the original range of data values.\nAfterword: a general comment\nThe investigation described here is an example of what anybody can do when they have a question about how a GIS operation works.  It uses the GIS itself as the subject of the investigation: to know what some operation or analytical method does, simply apply it under controlled experimental conditions.  In this case that amounts to constructing simple test images, resampling them according to available methods, and examining the results.\nThere are three critical aspects of this approach to learning about how GIS works:\n\nTheory.  The experimentation usually cannot be done &quot;blind&quot;: it helps to know some theory.  We don&#39;t usually need to know much, but we need the basics.  In this case, the theory of convolutions greatly reduced the number and types of images that we need to experiment with.  We didn&#39;t need to know anything about Fourier analysis, etc.  (Make no mistake, such knowledge is beneficial.  But lack of specialized knowledge of this sort shouldn&#39;t stop us.)\nPractice.  By using our GIS itself to perform the experiment, we are able to see what it actually does.  This avoids disconnects between theory (which tells us what the software should do) and practice (which is what it really does).\nQuantification.  Unless the question concerns visual perception, for evaluating the results we should not rely solely on looking at maps (or, in this case, images). To get the best information, we need to quantify the output (done here with graphs) and, often, describe and summarize it with statistical methods.\n\n (This can have implications for <span class=\"highlight\">GIS</span> work, because such an extrapolation of the original values can potentially cause the new values to be invalid. &hellip; By using our <span class=\"highlight\">GIS</span> itself to perform the experiment, we are able to see what it actually does. &hellip; "
    },
    {
        "question": "What free programs should every GIS user have installed?",
        "area": [
            "open-source-gis",
            "software-recommendations",
            "free-software"
        ],
        "text": "QGIS. Although I do most of my analysis using ESRI based tools, QGIS is extremely fast for quickly examining a shapefile, and zooming/panning/reading the attributes. \n\nI don&#39;t mean this in a derogatory way, as QGIS is also a wonderful open-source desktop GIS; but for quick file opening/closing it&#39;s wonderful and the quickest I&#39;ve found.\n I don&#39;t mean this in a derogatory way, as QGIS is also a wonderful open-source desktop <span class=\"highlight\">GIS</span>; but for quick file opening/closing it&#39;s wonderful and the quickest I&#39;ve found. &hellip; "
    },
    {
        "question": "How much math does a GIS Analyst need to know?",
        "area": [
            "education"
        ],
        "text": "For someone studying to pursue a career as a GIS Analyst, what math courses should he/she take?\n\nHere&#39;s a long list of free Math courses from MIT to serve as a frame of reference.\n\nWhich are essential, useful, useless?\n For someone studying to pursue a career as a <span class=\"highlight\">GIS</span> Analyst, what math courses should he/she take?\n\nHere&#39;s a long list of free Math courses from MIT to serve as a frame of reference. &hellip; "
    },
    {
        "question": "What books, journals, and electronic resources are most valuable for expanding knowledge of GIS?",
        "area": [
            "references"
        ],
        "text": "What books, journals, and/or electronic resources have you found most valuable for expanding your knowledge in the GIS field, and why?\n What books, journals, and/or electronic resources have you found most valuable for expanding your knowledge in the <span class=\"highlight\">GIS</span> field, and why? &hellip; "
    },
    {
        "question": "Explaining what GIS is to 11 year old kid?",
        "area": [
            "references"
        ],
        "text": "Well, since it was one of the highest rated proposed questions, hasn&#39;t been asked yet, and I would love to know the answer, I thought I&#39;d ask it.\n\nHow do I explain what GIS is for the 11 year old kid?\n How do I explain what <span class=\"highlight\">GIS</span> is for the 11 year old kid? &hellip; "
    },
    {
        "question": "When to use ModelBuilder over Python scripting and vice versa?",
        "area": [
            "arcgis-desktop",
            "arcpy",
            "modelbuilder"
        ],
        "text": "I am new to Python scripting in ArcGIS but not new to ModelBuilder. \n\nI would like to know the benefits of Python vs ModelBuilder. \n\nWhen should we write Python script for GIS automation rather than use ModelBuilder? \n\nWhat are the automation capabilities of Python that we cannot find in ModelBuilder? \n When should we write Python script for <span class=\"highlight\">GIS</span> automation rather than use ModelBuilder? \n\nWhat are the automation capabilities of Python that we cannot find in ModelBuilder? &hellip; "
    },
    {
        "question": "Learning ArcPy?",
        "area": [
            "arcpy",
            "references"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nLook at posts here and on other websites that use Python scripts and try to deconstruct them and see what techniques the authors are using to accomplish their task.  Our self-assembling FAQ on ArcPy is well worth reviewing for this purpose.\nYou will find it educational to try to solve other people&#39;s problems.  We have a self-assembling list of unanswered questions on ArcPy to help you find them.\nDo not forget that you can right-click any geoprocessing result and click &quot;Copy as Python Snippet&quot; if you just want to get the syntax of a function call, which is especially useful for things like field mappings and code blocks.  It is also possible to export ModelBuilder models to Python code, but there is no guarantee that the code exported from a working model will also work in Python, and for all but the simplest models the code that results is often difficult for beginners to debug.\nArcGIS Documentation:\nRead the help files!!  90% of ArcPy is just the same as using the GUI tools, only you are starting them using Python.  The help files all have example Python code at the bottom.\n\nWhat is ArcPy? is the front page to Help on using ArcPy with ArcMap from versions 10.3 - 10.8\n\n\n\nArcGIS Desktop Help (9.3)\nArcGIS Desktop Help (10)\nArcGIS Desktop Help (10.1)\nArcGIS Desktop Help (10.2)\nArcGIS Desktop Help (10.3)\nArcGIS Desktop Help (10.4)\nArcGIS Desktop Help (10.5)\nArcGIS Desktop Help (10.6)\nArcGIS Pro Help\nPython migration from 10.x to ArcGIS Pro\nArcGIS for Python API (not ArcPy)\n\nOnline Books:\n\nHow to Think Like a Computer Scientist\nDive into Python\nA Byte of Python (2.x)\nLearn Python the Hard Way\n\nOnline Courses:\n\nCodecademy Python Track offers free online coding lessons, including Python.  Use this to get the feel of how Python works before working on ArcPy.\nGoogle\u2019s Python Class\nPenn State \u2013 GEOG 485 \u2013 GIS Programming and Automation\nArcPy for Python Developers using ArcGIS Pro\n\nTutorials:\n\nNon-Programmer\u2019s Tutorial for Python 2.6\nOfficial Python Tutorial (2.5.4)\nOfficial Python Tutorial (2.6.5)\nOfficial Python Tutorial (2.7)\nDoug Hellmann&#39;s Python Module of the Week (PyMOTW) site\nCode Like a Pythonista: Idiomatic Python\nProgression path - using Python for GIS: from apprentice to guru\n\nPython Documentation:\n\nPython.org\nPython 2.5.4 Documentation (for ArcGIS 9.3)\nPython 2.6.5 Documentation (for ArcGIS 10)\nPython 2.7 Documentation (for ArcGIS 10.1-10.6)\nPython 3.6 Documentation (for ArcGIS Pro)\n\nPresentations:\n\nGetting Started with Python in ArcGIS 10 (from 2010)\nArcGIS Geoprocessing: Python Scripting \u2013 Advanced Techniques (from 2009)\nPython Scripting for Map Automation in ArcGIS 10 (from 2010)\n\nPaper Books:\n\nPython in a Nutshell, 2nd Ed\nLearning Python, 3rd Ed\nProgramming Python, 3rd Ed\nPython Cookbook, 2nd Ed\nA Python Primer for ArcGIS\nPython Scripting for ArcGIS\nGIS Tutorial for Python Scripting (coming June 2014)\n\nUser Communities:\n\nStack Overflow\nGIS Stack Exchange\nESRI Python Forum\nESRI Geoprocessing Forum\n\nBlogs:\n\nESRI Geoprocessing Blog\nESRI ArcGIS Desktop Blog\nArcGIS Team Python blog\n\nSample Code:\n\nArcScripts\nGeoprocessing Model and Script Tool Gallery\n\nTools/Integrated Development Environments (IDEs) - Non-commercial:\n\nPythonWin\nPyScripter\nPyDev (plug-in for the Eclipse software development environment)\nPython Tools for Visual Studio\nWinpdb (debugger)\n\nModules/Frameworks:\n\nDjango (web application framework)\ncomtypes (for using ArcObjects in Python)\nscipy/numpy\nPyPI - the Python Package Index\nSeeking Python tools/modules/add-ins for GIS?\n\nAlso see these general tips for new Python programmers in this answer to Exporting mxds into pdfs using ArcPy?.\n Google\u2019s Python Class\nPenn State \u2013 GEOG 485 \u2013 <span class=\"highlight\">GIS</span> Programming and Automation\nArcPy for Python Developers using ArcGIS Pro\n\nTutorials:\n\nNon-Programmer\u2019s Tutorial for Python 2.6\nOfficial Python Tutorial &hellip; in ArcGIS 10 (from 2010)\n\nPaper Books:\n\nPython in a Nutshell, 2nd Ed\nLearning Python, 3rd Ed\nProgramming Python, 3rd Ed\nPython Cookbook, 2nd Ed\nA Python Primer for ArcGIS\nPython Scripting for ArcGIS\n<span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "Choosing SRID and what is its meaning?",
        "area": [
            "postgis",
            "coordinate-system",
            "srid",
            "geography-data-type",
            "geometry-data-type"
        ],
        "text": "I&#39;m new to GIS, in PostGIS, and I&#39;m struggling with the SRID concept.\n\nHow do you choose a SRID for a database column? This is making me crazy. Why do I need to choose a SRID? What&#39;s its meaning?\n\nPicking a SRID is it the same for  and ? Setting a SRID for a  field seems senseless, because it should be just on a 2D plane.\n\nWhen I find lat/lon on the internet or geocoding services, which is the SRID?\n\nDoesn&#39;t a lat/lon coordinate make sense without a SRID?\n I&#39;m new to <span class=\"highlight\">GIS</span>, in PostGIS, and I&#39;m struggling with the SRID concept.\n\nHow do you choose a SRID for a database column? This is making me crazy. Why do I need to choose a SRID? What&#39;s its meaning? &hellip; "
    },
    {
        "question": "What Makes a Map be classed as Badly Designed?",
        "area": [
            "cartography"
        ],
        "text": "A poorly designed map can not only look visually unappealing, but can convey the wrong message, which could lead to bad decisions being made.\n\nI would like to ask people to post examples (that are in the public realm) of poorly designed maps, WITH justification on why it is bad design.   \n\nAlthough this &#39;question&#39; does not have a clear answer, I think it will prove a useful resource to see what merits bad design, so others can learn what NOT to do.  I will let the votes choose the &#39;right&#39; answer.\n\nI would also like to see examples of bad design around web-mapping.\n\nI would argue that although GIS Professionals generally know how to create a good looking map, I would say that they also have a tendency to over-complicate web-maps, by trying to re-create a GIS desktop application on the web:\n\nAlso slow to use, and hard to even get to the map.\n\nI think now that normal people are more used to Google Maps style/simplicity, web-maps should follow a similar approach.\n\nWith the explosion of &#39;NeoGeography&#39; particularly in the web realm, we now have a lot of non-GIS professionals creating maps for the web.  A lot of these developers are often very good at user-interface design, but not trained in cartographic principles.\n\nI think, with web maps, its all about combining the skills of both cartography and user interface design.\n I would argue that although <span class=\"highlight\">GIS</span> Professionals generally know how to create a good looking map, I would say that they also have a tendency to over-complicate web-maps, by trying to re-create a <span class=\"highlight\">GIS</span> desktop &hellip; With the explosion of &#39;NeoGeography&#39; particularly in the web realm, we now have a lot of non-<span class=\"highlight\">GIS</span> professionals creating maps for the web. &hellip; "
    },
    {
        "question": "Are there any attempts to replace the shapefile?",
        "area": [
            "shapefile",
            "vector"
        ],
        "text": "Recently I&#39;ve been spending a lot of time converting perfectly good field names like &quot;Percent of citizens age 25 and over with a bachelor&#39;s degree or higher&quot; into things like &quot;edbchogtr&quot; to meet the DBF&#39;s 10 character field name limit.\n\nIn another thread (\u201cOddities\u201d in the Shapefile technical specification), geospatialpython commented that &quot;Despite the shapefile format&#39;s flaws, oddities, and limitations it persists stubbornly in and around the field of GIS. Every other attempt to replace it has been too bloated for simple vector storage or too proprietary.&quot;\n\nThis activity coupled with Mr. Lawhead&#39;s comment has me wondering: \n\n\nhave any explicit attempts ever been made to replace the shapefile as GIS&#39;s ubiquitous data storage and interchange format? \nAre there any contenders? \nIf there have been competing formats, why have they failed? \nHas Esri refused to support them, or is the story simply one of technological inertia? \nIf there haven&#39;t been attempts... why not?  \n\n\nIt seems like we could do a little better for ourselves, both as GIS developers and users.\n Oddities\u201d in the Shapefile technical specification), geospatialpython commented that &quot;Despite the shapefile format&#39;s flaws, oddities, and limitations it persists stubbornly in and around the field of <span class=\"highlight\">GIS</span> &hellip; It seems like we could do a little better for ourselves, both as <span class=\"highlight\">GIS</span> developers and users. &hellip; "
    },
    {
        "question": "Should GDAL be set to produce GeoTIFF files with compression? Which algorithm should be used?",
        "area": [
            "gdal",
            "geotiff-tiff",
            "compression"
        ],
        "text": "I have a folder of GIS data that consists mainly of GeoTIFF files.  The whole set weighs in at about . I noticed that if I pack the contents into a tarball, it smashes down to about .  I would like to check the set into a revision control system sot it can be worked on by other people and it looks like there is some space that can be squeezed out.\n\nThe GDAL GeoTIFF driver page lists plenty of options that may be used to create compressed GeoTIFF files.  There are also plenty of options that affect the way each algorithm works.\n\nThe help page does a good job at describing the options but doesn&#39;t elaborate on how to select an algorithm or the tradeoffs that are associated with the varying level of compression.  This leads to the following questions:\n\n\nThe pros of using compression are a dramatic savings in space.  What are the cons?  Is information lost when the image is compressed?\nHow should one go about choosing an algorithm and compression level.  Do some types of images lend themselves to a certain algorithm?\n\n I have a folder of <span class=\"highlight\">GIS</span> data that consists mainly of GeoTIFF files.  The whole set weighs in at about 1.2 GB. I noticed that if I pack the contents into a tarball, it smashes down to about 82 MB. &hellip; "
    },
    {
        "question": "Choosing SRID and what is its meaning?",
        "area": [
            "postgis",
            "coordinate-system",
            "srid",
            "geography-data-type",
            "geometry-data-type"
        ],
        "text": "An SRID is a coordinate system. We&#39;re taught in (traditional / Arc) &quot;GIS&quot; to always store your data in a projected coordinate system, because we&#39;re going to eventually use some calculation like &#39;area&#39;, so we&#39;d better store our data in a coordinate system that gives us that measurement.\n\nHowever, PostGIS throws that concept out the window.\n\nHere&#39;s a good Q&amp;A started by @tmcw: Why are Data Projections relevant?\n\nBasically, PostGIS opens up the ability to store your data in a single coordinate system such as WGS84 (SRID 4326), and when you need something like Area, Distance, or Length, you use a function to create that column from your data in a projected coordinate system that will give you a local interpretation of your data in units that you want. \n\nSo for example, I could store students and schools in PostGIS both in WGS84/SRID:4326.  When I want to calculate the distance between students and the schools they attend, I call a distance function on my geometry column, but also wrap a ST_Transform function around the geometry column first to &#39;project&#39; the data into State Plane CO Central (SRID: 2877). This gives me a column for the distance of each student to their closest school in feet because SRID:2877 is a projected coordinate system that stores data in Feet.\n\nSo my recommendation for you would be to store your data in a Geometry (data type) column in SRID 4326 (as oppose to a geography data type which does not support projections / transformations).\n We&#39;re taught in (traditional / Arc) &quot;<span class=\"highlight\">GIS</span>&quot; to always store your data in a projected coordinate system, because we&#39;re going to eventually use some calculation like &#39;area&#39;, so we&#39;d better store our data in &hellip; "
    },
    {
        "question": "Writing Shapely geometries to shapefiles",
        "area": [
            "python",
            "shapefile",
            "shapely"
        ],
        "text": "Well-known binary is a good binary exchange format that can be exchanged with plenty of GIS software, including Shapely and  GDAL/OGR.\nThis is a tiny example of the workflow with :\n\n\nAlthough the poster has accepted the GDAL/OGR answer, here is a Fiona equivalent:\n\n Well-known binary is a good binary exchange format that can be exchanged with plenty of <span class=\"highlight\">GIS</span> software, including Shapely and  GDAL/OGR. &hellip; "
    },
    {
        "question": "Simple thematic mapping of shapefile using Python?",
        "area": [
            "python",
            "shapefile",
            "visualisation",
            "matplotlib"
        ],
        "text": "I do not know ArcPy, but I work with shapefiles and raster in Python for years\n\n\nFor processing shapefiles in Python, there are many modules like osgeo/ogr, Fiona, Pysal or Pyshp (shpUtils is one of them and\nnot the most used), and others, see Pypi: GIS and examples on gis.stackexchange and many examples on the Web (not only in English). Most of them are much older than ArcPy (or arcgisscripting)...\nfor processing raster you can use osgeo/gdal, the standard\nFor processing geospatial geometries, there is shapely\nFor plotting the geometries you can use matplotlib and possibly descartes, &quot;extension&quot; of matplotlib for areas, but also many, many other modules, see  Pypi: Plotting and modules like mayavi for 3D representation (matplotlib also)\nThere are also modules like  mapnik which give you directly the possibilities of 1) read a shapefile and 4) plotting with the module Pycairo.\n\n\nAfter that, it&#39;s like a GIS:\n\n\nyou use the modules 1) to open, save the shapefiles and carry out the treatments with other modules like numpy or scipy, if you want.\nyou can use shapely for manipulation and analysis of the geometric objects (buffer, etc.).\nyou can use matplotlib to plot the geometries, but matplotlib do not know what you want to plot. It is your work with modules 1) or 3) to specify what to plot (attributes, etc,.) and how.\n\n\n\n  If I want to visualise one certain column of my shapefile, how can I implement this in the code?\n\n\nSo, you must learn matplotib and the other modules. You have to learn ArcPy, it&#39;s the same...(there are lots of excellent tutorials on the web, especially for matplolib, and it&#39;s easier that ArcPy because it is pure Python).\n\nSome examples with Python only\n\n\n\nGeological map (polygon shapefile) with colors based on an attribute\n\n\n\n3D Points (PointZ shapefile) with color based on an attribute \n\n\n\n3D points (Point shapefile with z as attribute) and 3D line (PolyLineZ shapefile) on a DEM, and on a raster draped onto the DEM surface.\n\n\n\nTopographic profile  with z values and colors based on attributes (geological formations = Cross section) of the original shapefile (Polyline shapefile)\n\n\n\nDEM (GeoTIFF) with the module Mayavi2\n\n\n\nDEM (ESRI ascii grid, .asc) and Point shapefiles (with z as attribute) with the module visvis\n\n\n\nBoreholes (3D buffer of a polylineZ with colors based on an attribute (geological formations), with a grid surface calculated with the modules numpy and matplotlib from a points shapefile (with z as an attribute), visualized with the module visvis\n and raster in Python for years\n\n\nFor processing shapefiles in Python, there are many modules like osgeo/ogr, Fiona, Pysal or Pyshp (shpUtils is one of them and\nnot the most used), and others, see Pypi: <span class=\"highlight\">GIS</span> &hellip; After that, it&#39;s like a <span class=\"highlight\">GIS</span>:\n\n\nyou use the modules 1) to open, save the shapefiles and carry out the treatments with other modules like numpy or scipy, if you want.\nyou can use shapely for manipulation &hellip; "
    },
    {
        "question": "What strategies, criteria, or rules to use for selecting coordinate systems?",
        "area": [
            "coordinate-system",
            "datum",
            "gis-principle"
        ],
        "text": "What strategies, criteria, or rules do you use for selecting coordinate systems for \n\n\n(a) storing, \n(b) analyzing, and \n(c) displaying GIS data?  \n\n\n(I humbly offer my reply to a related question about watershed analysis as an example of the considerations involved in (b).)\n\nWhat are the pitfalls to watch out for?\n\nLinks to Web sites you find particularly helpful in this regard are welcome.\n What strategies, criteria, or rules do you use for selecting coordinate systems for \n\n\n(a) storing, \n(b) analyzing, and \n(c) displaying <span class=\"highlight\">GIS</span> data? &hellip; "
    },
    {
        "question": "Seeking Mobile GIS applications for Android Tablets?",
        "area": [
            "software-recommendations",
            "android",
            "mobile-gis"
        ],
        "text": "I know that ArcGIS is available for Android, but does anyone know of any other GIS apps that are available for Android tablets?\n I know that ArcGIS is available for Android, but does anyone know of any other <span class=\"highlight\">GIS</span> apps that are available for Android tablets? &hellip; "
    },
    {
        "question": "Seeking QGIS user interface tutorials and web resources",
        "area": [
            "qgis",
            "qgis-3",
            "references"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\nFor QGIS 3.x users:\n\n\nQGIS User Manual - includes both 2.x and 3.x documentation and links to many of the resources listed here\nGIS SE&#39;s self-assembling FAQ on QGIS 3.0\nQGIS Planet blog for more technical and development stuff.\n\n\nFor QGIS 3.x developers:\n\n\nGIS SE&#39;s self-assembling FAQ on PyQGIS in QGIS 3.0\n\n\n\n\nFor QGIS 2.x users:\n\n\nQGIS Training Manual ... covers a wide range of topics\nQGIS User Manual\nQGIS Tutorials and Tips\nLearning QGIS ... if you already know GIS concepts and you are looking for a resource to quickly get started using QGIS\nQGIS Map Design ... for tutorials on making maps\nA Gentle Introduction to GIS Brought to you with Quantum GIS, a Free and Open Source Software GIS Application for everyone; by T. Sutton, O. Dassau, M. Sutton - 115 page manual for beginners with video lectures [here][49]\nDesktop GIS: Mapping the Planet with Open Source Tools by Gary E. Sherman\nQGIS Workshop from Harvard University\nTutorial: QGIS basics for Journalists from UC Berkeley\nIntroducing GIS worksheets\n\n\nFor QGIS 2.x developers:\n\n\nGeneral API documentation\nPyQGIS Cookbook ... on developing python plugins\nMy own notes on developing Python plugins\n\n QGIS ... if you already know <span class=\"highlight\">GIS</span> concepts and you are looking for a resource to quickly get started using QGIS\nQGIS Map Design ... for tutorials on making maps\nA Gentle Introduction to <span class=\"highlight\">GIS</span> Brought to &hellip; you with Quantum <span class=\"highlight\">GIS</span>, a Free and Open Source Software <span class=\"highlight\">GIS</span> Application for everyone; by T. &hellip; "
    },
    {
        "question": "Seeking Free and Open Source GIS Desktop packages?",
        "area": [
            "software-recommendations",
            "open-source-gis",
            "desktop-gis"
        ],
        "text": "Can someone give me a list of free and open source GIS desktop packages?\n Can someone give me a list of free and open source <span class=\"highlight\">GIS</span> desktop packages? &hellip; "
    },
    {
        "question": "Understanding &quot;Join Attributes by Location&quot; in QGIS",
        "area": [
            "qgis",
            "fields-attributes",
            "spatial-join",
            "documentation",
            "spatial-predicates"
        ],
        "text": " concatenates the following set of methods to compare geometries:\n\nintersects if the intersection of both geometries is not empty\n\n\ncontains if the second geometry is completely contained into the first one\n\n\ndisjoint if the intersection of both geometries is the empty set\n\n\nequals if they are spatially identical\n\n\ntouches if the only points in common between both geometries lie in the union of their boundaries\n\n\noverlaps if the intersection of both geometries results in a value of the same dimension of both geometries and is different from both the first and the second geometry\n\n\nwithin if the first geometry is completely contained into the second one\n\n\ncrosses if the intersection of both geometries results in a value whose dimension is less than the maximum dimension of both geometries and the intersection value includes points interior to both geometries, and the intersection value is not equal to either the first or the second geometry\n\n\n\n\nReferences:\n\nA quick tutorial to SpatiaLite | 4.2 Evaluating relationships between geometries\nboundlessgeo/workshops/postgis/source/en/spatial_relationships\nGIS Geography | How Spatial Join Works in GIS\n\n either the first or the second geometry\n\n\n\n\nReferences:\n\nA quick tutorial to SpatiaLite | 4.2 Evaluating relationships between geometries\nboundlessgeo/workshops/postgis/source/en/spatial_relationships\n<span class=\"highlight\">GIS</span> &hellip; Geography | How Spatial Join Works in <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "Python Script examples for geoprocessing shapefiles without using arcpy",
        "area": [
            "python",
            "geoprocessing"
        ],
        "text": "That&#39;s strange, as if people suddenly discovered the power of Python (without ArcPy which is just one Python module among others), see for example the question Visualize shapefile in Python:\n\ngeospatial processing in Python  has a very long history, much older than Arcpy (or arcgisscripting) -&gt; no &quot;mimic&quot; the capabilities of ArcPy here, as Paul says, most were already there  before ArcPy.\nthe reference for the Python modules is the Python Package Index (Pypi) and there is a dedicated section: Topic :: Scientific/Engineering :: GIS\nyou can do anything with these modules and it is often easier and faster than ArcPy because it is pure Python (no cursors...).\nShapely is one of these modules for processing geospatial geometries -&gt;  calculate areas of a polygon and convert polygons to points..\nif you want to process vector layers, there is osgeo/ogr, Fiona or Pyshp (and others, less used) -&gt;  query a shapefile by attributes, create new layer from selection, calculate areas of a polygon, convert polygons to points\nfor processing rasters, the standard is osgeo/gdal\nfor spatial analysis, there is Pysal\nfor 3D, you can use other Scientific modules like numpy or scipy (3D algorithms, grids, but also statistics, geostatistics, 2D or 3D)\nAnd I don&#39;t talk about mapnik, matplotlib/basemap,Geodjango and ...\n\nYou can combine all (Pysal with shapely, ...) and mix them with the other Scientific modules.\nThus for Python Script examples, search for Pyshp Fiona, ogr, gdal or shapely in gis.stackexchange or the internet (many examples, not only in English).)\nOne of them in French (the scripts and the figures are universal !):\n\nPython: Using vector and raster layers in a geological perspective, without GIS software\nan other in English:\nGIS with Python, Shapely, and Fiona\nand in Spanish\nDetermination of areas of irregular polygons using the coordinates of the vertices \nin gis.stackexchange\nElevation profile 10 km each side of a line\nUpdating Attributes using Pyshp\nHow to create a 3D shapefile from a raster?\nPython Script for getting elevation difference between two points\netc\n\nThe script presented by Aaron can be written more simply with Fiona that uses only Python dictionaries:\n\nand if you use shapely in addition:\n\nThere are also two books:\nPython Geospatial Development of Eric Westra.\n\nLearning Geospatial Analysis with Python of Joel Lawhead\n\n(source: cloudfront.net)\nPython is also used as a scripting language in other GIS applications like QGIS (Quantum GIS), GRASS GIS, gvSIG or OpenJump or 3D modelers like Paraview (and Blender also !). And you can use the majority of the geospatial modules in all these application (see Visualising QGIS data with Blender)\n :\n\nPython: Using vector and raster layers in a geological perspective, without <span class=\"highlight\">GIS</span> software\nan other in English:\n<span class=\"highlight\">GIS</span> with Python, Shapely, and Fiona\nand in Spanish\nDetermination of areas of irregular polygons &hellip; Learning Geospatial Analysis with Python of Joel Lawhead\n\n(source: cloudfront.net)\nPython is also used as a scripting language in other <span class=\"highlight\">GIS</span> applications like QGIS (Quantum <span class=\"highlight\">GIS</span>), GRASS <span class=\"highlight\">GIS</span>, gvSIG or OpenJump &hellip; "
    },
    {
        "question": "Seeking administrative boundaries for various countries?",
        "area": [
            "data",
            "global"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nGlobal\n\nFor non-commercial use, try GADM.\nFor small scale global dataset try Natural Earth: Natural Earth is a public domain map dataset available at 1:10m, 1:50m, and 1:110 million scales\nDIVA-GIS is free data. Just click on &#39;Global level&#39; and a zip file will download of all country boundaries.  Under &#39;Country level&#39; you&#39;ll find administrative areas and a few other things that may interest you but you have to pick the country you want so it could take a little time if you want every country\nOpenStreetMap has a lot of data. It isn&#39;t necessarily authoritative, but if you are just trying to get data it may be suitable.\nhttp://wiki.openstreetmap.org/wiki/Potential_Datasources: This wiki has the most comprehensive (reviewed by data quality) list of freely available data sources\nhttp://wiki.openstreetmap.org/wiki/Shapefiles\nhttp://osmdata.thinkgeo.com/openstreetmap-data/\nThe UN has a dataset for many (but not all) countries, known as the Second Administrative Level Boundaries data set project (SALB).   The dataset is standardized in terms of the international border, metadata profile, spelling, coding scheme, editing protocols used and can be downloaded at no cost. However, as it is licensed under the creative commons by-nc-nd license it cannot be used for commercial purposes.\nyou can find world boundaries shapefile on http://thematicmapping.org/downloads/world_borders.php\n\nAustralia\nThe Bureau of Statistics provides most of the information:\n\nCountry boundaries should be produced by merging all the state boundaries (below) into a single polygon feature.\nState level boundaries are available.\nThe states can be geographically disaggregated in a number of ways - perhaps the most similar to county boundaries are Local Government Areas (LGAs).\nTo find the area of cities, the standard dataset to use is the urban centres and localities digital boundaries.\nZipcodes (or postcodes as they are known here) are more difficult to model.  Because they are based on the rules by which Australia Post deliver the post, they are rather fuzzily defined.  The free option approximates postcodes as the census collection district level, and is available for 2006 from the ABS.\nthe updated 2011 datasets and census results are available via the Data Packs section of the ABS site, which requires free registration.\n\nNew Zealand\n\nKoordinates - This site has free and pay data for New Zealand and various international areas (like Florida!). A range of free layers, boundaries, urban areas, land use, digital elevation, coastline, rivers etc... and topo maps, contours, aerials for some areas - pay for these. Excellent interface and system for ordering downloads.\n\nhttp://www.stats.govt.nz/browse_for_stats/people_and_communities/Geographic-areas/digital-boundary-files.aspx is the Statistics Department&#39;s set of administrative boundaries. They&#39;ve got regions and territorial authorities (the rough equivalent of counties), urban areas (roughly city boundaries) and much more, including meshblocks, which most statistical data is tied to.\n\n\nCanada\n\nAdministrative Boundaries are available at GeoBase.  Note that these boundaries are actually Administrative Boundaries and not coastlines (particularly relevant for the north coast).\nThe Political Boundaries layer in the GeoGratis North American Atlas has nice physical boundaries for North America and surroundings, as well as U.S. States and Canadian Provinces.\n\nGreat Britain\nFor a wide range of free data for Great Britain, visit the Ordnance Survey website:\nhttps://www.ordnancesurvey.co.uk/opendatadownload/products.html\nThere&#39;s a product description page too (but I can&#39;t provide another hyperlink sigh)\nThe Boundary-Line dataset has a number of administrative boundary layers (though why they couldn&#39;t provide a simple, continuous, GB county boundary dataset in it is beyond me). However, there&#39;s a lot of good stuff on this site, including a GB post code gazetteer.\nEuropean Union\nEurostat provides several geo-datasets for EU and a few more countries for free for non-commercial use: Countries, NUTS, Communes, LAUs (municipalities) and coastlines: https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units\n For small scale global dataset try Natural Earth: Natural Earth is a public domain map dataset available at 1:10m, 1:50m, and 1:110 million scales\nDIVA-<span class=\"highlight\">GIS</span> is free data. &hellip; "
    },
    {
        "question": "Alternatives to ArcGIS Online?",
        "area": [
            "web-mapping",
            "software-recommendations"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nThere are quite a few alternatives and I&#39;ve actually written a short book on the subject entitled &quot;Online GIS - Meet the Cloud Publication Platforms that Will Revolutionize our Industry&quot; but that&#39;s a little outdated now.\nHere&#39;s an updated summary:\nMangoMap: Very easy to use, no coding required. Lots of tools and functionality available to make really polished map applications. Much more competitive pricing than ArcGIS Online organisational accounts.\nGISCloud: Online alternative to traditional client/server GIS setup. Many features but hampered by a frustrating user interface.\nMapBox: Making maps sexy again. Programmer focused. Great for maps that need to fit a brand and be able to scale for high traffic. Good fit for consumer internet sites.\nCartoDB: Attractive UX and scales very well. Also lets you preserve the Google Maps experience for end users. Postgres + postgis database on the cloud with a set of API&#39;s on top of it to fetch/save and render data.\nDisclosure: Original answer posted by Founder of MangoMaps and includes  an edit by the CTO of CartoDB - these two products are described in this answer.\n\nI&#39;ve had good luck using GeoCommons for more lightweight mapping.\nThe upside is that the service is free within a certain limit, and includes some fairly powerful analysis tools. I believe any mapping is free if using or creating open data, and while my organization did not end up paying for the service, the prices seemed reasonable.\nI didn&#39;t realize until I visited today, though, that this service is now a part of esri, so their terms may have changed.\n There are quite a few alternatives and I&#39;ve actually written a short book on the subject entitled &quot;Online <span class=\"highlight\">GIS</span> - Meet the Cloud Publication Platforms that Will Revolutionize our Industry&quot; but that&#39;s a little &hellip; GISCloud: Online alternative to traditional client/server <span class=\"highlight\">GIS</span> setup. Many features but hampered by a frustrating user interface.\nMapBox: Making maps sexy again. Programmer focused. &hellip; "
    },
    {
        "question": "Generating random locations nearby?",
        "area": [
            "distance",
            "android",
            "coordinates",
            "geolocation"
        ],
        "text": "This is tricky for two reasons: first, limiting the points to a circle instead of a square; second, accounting for distortions in the distance calculations.\n\nMany GISes include capabilities that automatically and transparently handle both complications.  However, the tags here suggest that a GIS-independent description of an algorithm may be desirable.\n\n\nTo generate points uniformly, randomly, and independently within a circle of radius r around a location (x0, y0), start by generating two independent uniform random values u and v in the interval [0, 1).  (This is what almost every random number generator provides you.)  Compute\n\n\n\nThe desired random point is at location (x+x0, y+y0).\nWhen using geographic (lat,lon) coordinates, then x0 (longitude) and y0 (latitude) will be in degrees but r will most likely be in meters (or feet or miles or some other linear measurement).  First, convert the radius r into degrees as if you were located near the equator.  Here, there are about 111,300 meters in a degree.\n\nSecond, after generating x and y as in step (1), adjust the x-coordinate for the shrinking of the east-west distances:\n\n\n\nThe desired random point is at location (x&#39;+x0, y+y0).  This is an approximate procedure.  For small radii (less than a few hundred kilometers) that do not extend over either pole of the earth, it will usually be so accurate you cannot detect any error even when generating tens of thousands of random points around each center (x0,y0).\n\n However, the tags here suggest that a <span class=\"highlight\">GIS</span>-independent description of an algorithm may be desirable. &hellip; "
    },
    {
        "question": "The GIS of War - Tracking Conflicts and Their Effects",
        "area": [
            "data"
        ],
        "text": "I was idly speculating on the many sorts of things people are keeping track of these days with GIS - natural/human catastrophes, demographic and economic patterns, climate change, etc. In that vein, I started to look around for GIS&#39; applications in war and international conflicts.  There are many obvious uses for it in the military, but is there any database or publicly accessible application that organizes war-related information in a spatial and/or cartographic context? Time would undoubtedly play an integral role in any robust methodology. The most I was able to find was an in-progress database for tracking war crimes. What else is out there for public consumption, if anything?\n I was idly speculating on the many sorts of things people are keeping track of these days with <span class=\"highlight\">GIS</span> - natural/human catastrophes, demographic and economic patterns, climate change, etc. &hellip; In that vein, I started to look around for <span class=\"highlight\">GIS</span>&#39; applications in war and international conflicts. &hellip; "
    },
    {
        "question": "PostGIS nearest points with ST_Distance, kNN",
        "area": [
            "postgis",
            "distance",
            "nearest-neighbor"
        ],
        "text": "You are nearly there. There is a little trick which is to use PostgreSQL&#39;s distinct operator, which will return the first match of each combination -- as you are ordering by ST_Distance, effectively it will return the closest point from each senal to each port.\n\nIf you know that the minimum distance in each case is no more than some amount x, (and you have a spatial index on your tables), you can speed this up by putting a , eg, if all the minumum distances are known to be no more than 10km, then:\n\nObviously, this needs to be used with caution, as if the minimum distance is greater, you will simply get no row for that combination of senal and port.\nThe order by order must match the distinct on order, which makes sense, as distinct is taking the first distinct group based on some ordering.\nIt is assumed that you have a spatial index on both tables.\nThere is another option, which is to use PostgreSQL&#39;s &lt;-&gt; and &lt;#&gt; operators, (center point and bounding box distance calculations, respectively) which make more efficient use of the spatial index and don&#39;t require the ST_DWithin hack to avoid n^2 comparisons. There is a good blog article explaining how they work. The general thing to note is that these two operators work in the ORDER BY clause.\n\n\nAs this question has received a lot of attention and k-nearest neighbours (kNN) is generally a hard problem (in terms of algorithmic run-time) in GIS, it seems worthwhile to expand somewhat on the original scope of this question.\nThe standard way for find the x nearest neighbours of one object is to use a LATERAL JOIN (conceptually similar to a for each loop). Borrowing shamelessly from @dbaston&#39;s answer, you would do something like:\n\nSo, if you want to find the nearest 10 ports, ordered by distance, you simply have to change the LIMIT clause in the lateral sub-query. This is much harder to do without LATERAL JOINS and involves using ARRAY type logic.\nWhile this approach works well, it can be sped up enormously if you know you only have to search out to a given distance. In this instance, you can use ST_DWithin(signs.geom, ports.geom, 1000) in the subquery, which because of the way indexing works with the &lt;-&gt; operator -- one of the geometries should be a constant, rather than a column reference -- may be much faster. So, for example, to get the 3 nearest ports, within 10km, you could write something like the following.\n\nAs always, usage will vary depending on your data distribution and queries, so EXPLAIN is your best friend.\nFinally, there is a minor gotcha, if using LEFT instead of CROSS JOIN LATERAL in that you have to add ON TRUE after the lateral queries alias, eg,\n\n #&gt; port.geom LIMIT 1)\nFROM  traffic_signs as senal;\n\n\nAs this question has received a lot of attention and k-nearest neighbours (kNN) is generally a hard problem (in terms of algorithmic run-time) in <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "What free programs should every GIS user have installed?",
        "area": [
            "open-source-gis",
            "software-recommendations",
            "free-software"
        ],
        "text": "Benjamin already mentioned SAGA GIS, but just the name so I would like to add more info about this excellent SW:\n\nSAGA (System for Automated Geoscientific Analyses)\n\n\n\nSAGA is also free and opensource like QGIS, but it is focused on raster data analysis and processing.\n\nThe standard modules are:\n\n\nFile access: interfaces to various table, vector, image and grid file formats, including shapefiles, Esri grids (ASCII and binary), and numerous grid file formats that are supported by the GDAL library, in addition to the native SGRD format of SAGA GIS.\nFilter for grids: Gaussian, Laplacian, multi-directional Lee filter.\nGridding: interpolation from vector data using triangulation, nearest neighbour, inverse distance. (my favourite is Multilevel B-Spline interpolation)\nGeostatistics: residual analysis, ordinary and universal kriging, single and multiple regression analysis, variance analysis.\nGrid calculator: combine grids through user defined functions.\nGrid discretisation: skeletonisation, segmentation.\nGrid tools: merging, resampling, gap filling.\nImage classification: cluster analysis, box classification, maximum likelihood, pattern recognition, region growing.\nProjections: various coordinate transformations for vector and grid data (using Proj4 and GeoTrans libraries), georeferencing of grids.\nSimulation of dynamic processes: TOPMODEL, nitrogen distributions, erosion, landscape development.\nTerrain analysis: geomorphometrical calculations such as slope, aspect, curvatures, curvature classification, analytical hillshading, sink eliminition, flow path analysis, catchment delineation, solar radiation, channel lines, relative altitudes.\nVector tools: polygon intersection, contour lines from grid.\n\n\nAccording to the users it can partially replace commercial tools like Spatial analyst in ArcGIS and some people say, that the hydrological tools are even better than ArcHydroTools.\n\nIn my opinion it is good choice for people who are not familiar with GRASS and who need user friendly and free solution which can share data with other GIS tools.\n\nI use it together with QGIS and it works really nice - SAGA for raster data, QGIS for vectors and final map finishing and for quick mapping.\n Benjamin already mentioned SAGA <span class=\"highlight\">GIS</span>, but just the name so I would like to add more info about this excellent SW:\n\nSAGA (System for Automated Geoscientific Analyses)\n\n\n\nSAGA is also free and opensource &hellip; In my opinion it is good choice for people who are not familiar with GRASS and who need user friendly and free solution which can share data with other <span class=\"highlight\">GIS</span> tools. &hellip; "
    },
    {
        "question": "What are the pros and cons of PostGIS geography and geometry types?",
        "area": [
            "postgis",
            "geometry-data-type",
            "geography-data-type"
        ],
        "text": "I use my intuitive &quot;rules of thumb&quot;... It is useful for a rapid decision,\n\nAbout your DATABASE: if features and/or spatial analysis are of continental-scale, and need precision (serious applications) use geography. Else use geometry: when all database is about same (city-scale) region, or you not need precision, etc. you need only geometry. See similar rule at the suggest lecture of  @underdark.\n\nAbout your needs in terms of PERFORMANCE/PRECISION  BALANCE: geometry is faster; if you need performance and think to use geography, do your benchmarks first.\n\n\n\nKey-concepts\nOn this page, we see some key-words and the focus on some concepts: precision, performance, and something like flexibility/commodity of use.\nAs remembered by others, the difference, for store and calculations, is the use of sphere in geography and plane in geometry:\n\nthe sphere (geography) is better, more precise. See the Los Angeles/Paris example.\nevolution of geography: as @DavidF say, &quot;geography type was more recently added, so fewer functions are supported/implemented&quot;.\n\nPerhaps on the year 2020 all GIS databases will be set to the same standard SRID/EPSG (equivalent to the nowadays 4326 code, for WGS84).\nToday geography is not a default choice because of performance and functional limitations.\nDiscussion\nIn my opinion it is a question of &quot;best practices&quot;, not a deep technical/theoretical problem.\nPrecision\nAfter estimate the error on your data, do your tests and compare results: the precision gains with geography are higher than error of data? The ST_Distance function (with MAX and AVG aggregators) is the main reference in this kind of experiment.\nPerformance\nExamples of benchmarks in an urban area of ~100km2 (diameter ~11km), all stored as geometry, in a planar UTM coordinate system. NOTE: starting with the frequently used geometry/geography conversion \u2014 frequently because some functions not exist and some others, like ST_Buffer and ST_Intersection, do conversion internally.\nBench#1: a table with ~87000 polygons representing urban lots, each with poly with (avg) ~13 points,\n\nso, geography_time=6*geometry_time.\nBench#2: a table with ~3500 polygons representing urban blocks, each with poly with (avg) ~50 points:  0.6s vs 2.7s, geography_time=4.5*geometry_time.\nBench#3: ~10000 lines representing urban streets, each with ~5 points. ~0.87s vs ~0.36s, geography_time=2.4*geometry_time.\nBack to Bench#2, creating the tables and doing queries,\n\nConclusion: for little tasks and good hardaware, the times converge to the &quot;acceptable-same time&quot;, but for big tasks, there are performance ratings to consider.\nFlexibility/Commodity\nOn the benchmarks I do a day-by-day task, checking the number of points (by )... It is an example of operation that not exists for geography, needs cast. The &quot;geography/geometry cast&quot; is an annoying task for programmers, masters, etc.\nWhen reusing libraries of SQL and PL/pgSQL functions, geography need adaptations. And, if you want to optimize code, or avoid precision problems with a lot of intermediary conversions, the absence of a complete set of build-in functions, with geography, is another problem. Program for geography, is not a easy task.\nProcess-only, data interchange, etc.\nFor non-usual demand, with no intensive user like Mapserver, when your only (PostGIS) work is to process input data and return at any time (like hours or days) the processed data, the rule of thumb is &quot;use geography if you are comfortable!&quot; (see &quot;Flexibility/Commodity&quot; above).  If not, check usual rules.\nNOTE: of course, if your (non-usual) task is only  show data from PostGIS to Mapserver, with no process need,  to preserve the same (geometry or geography) of your input data, is better decision.\nI believe the data centralization is another task where geography is better: in context where the diversity of input formats and reference systems are usual, the use of a standard, such as that enforced by the geography, is beneficial... Convention over configuration is a good principle when centralization and data interchange are the business focus (see Google Maps!).\n Perhaps on the year 2020 all <span class=\"highlight\">GIS</span> databases will be set to the same standard SRID/EPSG (equivalent to the nowadays 4326 code, for WGS84). &hellip; "
    },
    {
        "question": "Finding minimum-area-rectangle for given points?",
        "area": [
            "geometry",
            "3d",
            "algorithm",
            "extents",
            "convex-hull"
        ],
        "text": "To supplement @julien&#39;s great solution, here is a working implementation in , which could serve as pseudocode to guide any GIS-specific implementation (or be applied directly in , of course).  Input is an array of point coordinates.  Output (the value of ) is an array of the vertices of the minimum bounding rectangle (with the first one repeated to close it).  Note the complete absence of any trigonometric calculations.\n\n\n\nHere is an example of its use:\n\n\n\n\n\nTiming is limited by the speed of the convex hull algorithm, because the number of vertices in the hull is almost always much less than the total.  Most convex hull algorithms are asymptotically O(n*log(n)) for n points: you can compute almost as fast as you can read the coordinates.\n To supplement @julien&#39;s great solution, here is a working implementation in R, which could serve as pseudocode to guide any <span class=\"highlight\">GIS</span>-specific implementation (or be applied directly in R, of course). &hellip; "
    },
    {
        "question": "Seeking sources for US Zip Code Boundaries",
        "area": [
            "data",
            "united-states",
            "zip-codes"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nZip Codes are not polygons, and therefore do not have boundaries. Zip Codes are lines (delivery routes) or points (Post Offices). See the FAQ on the old Census Bureau website and the paper Zip Codes are Not Polygons for details.\nThat being said, when I need to use Zip Codes the first place I look is at the ESRI data that used to come on CDs with ArcView/GIS, but is now available online at Esri Data &amp; Maps.\n That being said, when I need to use Zip Codes the first place I look is at the ESRI data that used to come on CDs with ArcView/<span class=\"highlight\">GIS</span>, but is now available online at Esri Data &amp; Maps. &hellip; "
    },
    {
        "question": "Online WKT and GeoJSON viewer",
        "area": [
            "geojson",
            "well-known-text",
            "validation",
            "viewer"
        ],
        "text": "I once found a great but simple webpage that has a drop-down with several text-based GIS formats such as GeoJSON and WKT, and a text box to copy/paste your data. The feature is then drawn on a world map. You can continue to add shapes on the same map.\nDoes anyone know the page, or any page where I can paste WKT and GeoJSON to see them displayed on a map?\n I once found a great but simple webpage that has a drop-down with several text-based <span class=\"highlight\">GIS</span> formats such as GeoJSON and WKT, and a text box to copy/paste your data. &hellip; "
    },
    {
        "question": "How to calculate most efficient route passing through all the houses in the world?",
        "area": [
            "open-source-gis",
            "routing"
        ],
        "text": "I&#39;m new to GIS.\n\nI need some help in determining the best or most efficient route, using a flying sleigh, through all the houses in the world. One of my coworkers told me that this site would be the best place to ask, because I would find lots of helpful GIS experts. \n\nI will need some guidance about what software to use, where to get the data, and how to process it. Since I had some extra expenses this month, I would prefer some Open Source solutions.\n\nThank you all!\n\nPS: I&#39;m in a bit of a hurry, as I need this for tomorrow!\n I&#39;m new to <span class=\"highlight\">GIS</span>.\n\nI need some help in determining the best or most efficient route, using a flying sleigh, through all the houses in the world. &hellip; One of my coworkers told me that this site would be the best place to ask, because I would find lots of helpful <span class=\"highlight\">GIS</span> experts. &hellip; "
    },
    {
        "question": "Choosing between QGIS and GRASS for simple thematic maps with different layers",
        "area": [
            "qgis",
            "grass-gis"
        ],
        "text": "I was working with GIS and remote sensing in a university and professional environment some ten years ago (ArcInfo etc), so I have some experience even though somewhat outdated. \n\nNow I am looking for an GIS application for a small farming project and I found GRASS and QGIS projects which both sound very interesting.\nHowever, I do not really get the difference between the two programs. \n\nWhich one do I use best for simple thematic maps with different layers?\n I was working with <span class=\"highlight\">GIS</span> and remote sensing in a university and professional environment some ten years ago (ArcInfo etc), so I have some experience even though somewhat outdated. &hellip; Now I am looking for an <span class=\"highlight\">GIS</span> application for a small farming project and I found GRASS and QGIS projects which both sound very interesting. &hellip; "
    },
    {
        "question": "Are there any attempts to replace the shapefile?",
        "area": [
            "shapefile",
            "vector"
        ],
        "text": "This is a topic that always comes up. I may not have the right answer, but I can give you my personal opinion.\n\nThe reason that they are supported, can be attributed to several characteristics about them, so let me mention a few.\n\n\nFirst, there is a spec. I mean, I am in my early thirties and this thing existed since I was a teenager. So it is safe to say that this spec has been around for some time. Of course, there are several other formats that are also published, but the difference about this one is that...\nIt is relatively simple! It is built on top of the DBF Format, which at the time already existed and was widely supported in several platforms/OSs. There were already parsers that could read half of this format (the DBF part), so it made supporting the extra addition easier. You have a geometry? Sure just serialize it and write it. You are done. Contrast this with a coverage! Try to explain to somebody in simple terms what a topology clean does. It is not trivial to write a topologically clean coverage.\nMost importantly, I think the #1 reason for shapefiles to still be popular is that they are supported in both Open Source and Proprietary systems alike. What GIS do you know that doesn&#39;t support shapefiles?!? Unheard of. \n\n\nAs a replacement, we hear of File GeoDatabases and Spatialite. Both formats, are vastly superior in terms of functionality, flexibility, speed, etc. when compared to Shapefiles. In their own way, they have certain things that make them better than each other in different areas, but a comparison of spatialite and FileGDB is certainly out of the scope of this question. \n\nDo I think that either of this formats will replace Shapefiles? Not in their current incarnations. \n\nWhy?\n\nNot because of a technological argument (I did say they were superior in that aspect after all), but because of something else: licensing.\n\nSo what are their problems?\n\nFileGDB:\n\nFileGDB provides interoperability through the new FileGDB API. Nevertheless, this API is provided in binary format by ESRI. This is not a specification. Having worked in the GeoDatabase team in the past, I can tell you, contrary to all the tin-foil-hat-wearing conspiracy theorists, this is not malicious at all. It is because the internals of the GeoDatabase change on every release. Publishing a full spec would entail basically giving all the details of how everything is supposed to be maintained and then carefully documenting the changes to the format with every yearly release. It doesn&#39;t make sense. So the FileGDB API, even though it is not a spec, it abstracts out all those little changes. And now it can be used cross-platform! Mind you, this is a huge step forward! Considering the conservative nature of ESRI, this is definitely a reaction in the right direction.\n\nAnd yet, binary-only support doesn&#39;t make anybody in the Open Source world too happy. How do you then take advantage of porting some code to say to some other flavor of Linux if ESRI doesn&#39;t support it. You can&#39;t. This is what makes Open Source powerful, and now, you cannot take advantage of this. If ESRI decides to stop supporting Debian, that&#39;s it. You are done. And there is nothing you can do to change it. \n\nSpatialite:\n\nSpatialite is awesome because it gets all the free functionality from SQLite. SQLite is used everywhere. It is on your Android Phone, on your iPhone/iPad, on Firefox, on Google Chrome, on several commercial embedded devices - can go on forever. To truly make it into a Geoformat (and not just do dumb bounding box operations), it needs to leverage the same geometry library that PostGIS uses: GEOS. Sadly, GEOS is based on another even more awesome geometry library known as JTS. All the algorithms in JTS are extremely powerful, so what is the problem?\n\nWell, JTS is licensed as Open Source LGPL, and LGPL is a viral license. JTS is LGPL, means GEOS is LGPL, means spatialite linked statically with GEOS is LGPL. This sucks. Why? Without explaining open source licenses too much, I can tell you that, for example, I cannot use spatialite on, say, an iPhone app because that would make my entire app automatically open source (iOS only allows static linking). Any type of GPL license (reasonably) scares the crap out of ESRI, and so they will not touch it with a 10 foot pole. Hence, ArcGIS, the most popular GIS system in the world does not (and will probably never) support spatialite natively. This automatically kills it as a viable format.\n\nAnd thus we go back to crappy shapefiles that are supported everywhere.\n\nUpdate: \n\nApparently my answer was controversial enough that someone decided it was OK to freely edit and change the entire meaning of my answer to put their point of view. Please don&#39;t do that. If you disagree with me, that is completely fine, just post your opinion in a different answer and let the community decide. I rolled backed the edits to my answer to show the original meaning. I am adding this update in case you read the edited answer that claimed that sqlite was a viable format.\n What <span class=\"highlight\">GIS</span> do you know that doesn&#39;t support shapefiles?!? Unheard of. \n\n\nAs a replacement, we hear of File GeoDatabases and Spatialite. &hellip; Hence, ArcGIS, the most popular <span class=\"highlight\">GIS</span> system in the world does not (and will probably never) support spatialite natively. This automatically kills it as a viable format. &hellip; "
    },
    {
        "question": "What is the going rate for GIS freelancers?",
        "area": [
            "career",
            "freelancing"
        ],
        "text": "There appears to be very little information available about competitive hourly rates for GIS freelancers.  Additionally, GIS freelancers never post rates on their websites.  Upwork has some information on what people are asking, although I believe the rates are well below  the industry standard due to the structure of their bidding system (example).  The US Bureau of Labor Statistics states the median pay for Cartographers and Photogrammetrists is $27.62 USD, although this is presumably low because it does not taking into account fringe benefits. What is the going rate for GIS freelancers in the USA?  I am interested in hearing from both freelancers and businesses who contract out work. \n There appears to be very little information available about competitive hourly rates for <span class=\"highlight\">GIS</span> freelancers.  Additionally, <span class=\"highlight\">GIS</span> freelancers never post rates on their websites. &hellip; What is the going rate for <span class=\"highlight\">GIS</span> freelancers in the USA?  I am interested in hearing from both freelancers and businesses who contract out work. &hellip; "
    },
    {
        "question": "Joining lots of small polygons to form larger polygon using PostGIS?",
        "area": [
            "postgis",
            "sql",
            "dissolve"
        ],
        "text": "I have the following layer using SRID 27700 in postgis:\n\n\n\nIt&#39;s every administrative region in the UK, and (as you can see from the colour grouping) each of them has a text field specifying the county they lie in.\n\nWhat I&#39;d like to do is to make larger county polygons from the smaller ones in a given county, so EG in the picture above all the teal colour polygons would form one large polygon from the single outer ring that contains all the polys in that colour, like wise all purple, brown, pink, grey etc should all form one polygon.\n\nI&#39;ve already tried the following:\n\n\n\nBut it keeps generating broken geometries which I then have big problems processing further.\n\nI&#39;m trying to make a simpler county level map with the major output areas in.\n\nAny solutions don&#39;t have to be in Postgis either, I have the full OS4Geo stack installed, the latest version of QGis and more utils than I can shake a stick at.\n\nThe only things I don&#39;t have are the big boys like ArcGis (Although I may have an Old Mapinfo lying around somewhere)\n\n\n\nFor the record, the dataset I&#39;m trying to create is to accompany a GIS book I&#39;m on writing aimed at .NET programmers wishing to write GIS applications using .NET\n\n\n\nAfter trying the suggestions below, the one that worked the best was &#39;Paul Ramseys&#39; solution.  \n\nI now have a nice simplified counties &amp; boroughs file that&#39;s just simple enough for my book, but complex enough to allow me to demonstrate some interesting geo-spatial SQL.\n\nEven though Paul&#39;s solution ultimately was the one that worked for me, I also drew on the other answers for things like simplifying the polygon map and reducing the complexity further.\n\nOn thing I did observe while doing this however, while ST_Collect is indeed faster than ST_Union, run for run it was also the one mostly responsible for broken geometries.  My guess is the speed increase is obtained at the expense of less accuracy in the core function.\n The only things I don&#39;t have are the big boys like ArcGis (Although I may have an Old Mapinfo lying around somewhere)\n\n\n\nFor the record, the dataset I&#39;m trying to create is to accompany a <span class=\"highlight\">GIS</span> book I&#39;m &hellip; on writing aimed at .NET programmers wishing to write <span class=\"highlight\">GIS</span> applications using .NET\n\n\n\nAfter trying the suggestions below, the one that worked the best was &#39;Paul Ramseys&#39; solution. &hellip; "
    },
    {
        "question": "Seeking Free and Open Source GIS Desktop packages?",
        "area": [
            "software-recommendations",
            "open-source-gis",
            "desktop-gis"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\nhttp://freegis.org/ - the oldest and perhaps most comprehensive directory of free GIS software and projects.\n\nWikipedia has most of them listed\n\n\n\n\nQGIS\nuDig\nOpenJump\ngvSIG\nTerraView\nKosmos\nWhiteBox\nMapWindow\nGeoDa\nIf you consider Google Earth as a GIS application, Nasa&#39;s WorldWind is an open source alternative.\nEpi-map, part of CDC&#39;s Epi-info epidemiology package, may be worth a look if you&#39;re in that line of work.\nOpenMap&#39;s free too. UI&#39;s pretty old school though. I prefer qGIS or uDig. \nQGIS supports native SAGA grid format so it is very easy to work with these two programs together and use advantages of both\n\n http://freegis.org/ - the oldest and perhaps most comprehensive directory of free <span class=\"highlight\">GIS</span> software and projects. &hellip; Wikipedia has most of them listed\n\n\n\n\nQGIS\nuDig\nOpenJump\ngvSIG\nTerraView\nKosmos\nWhiteBox\nMapWindow\nGeoDa\nIf you consider Google Earth as a <span class=\"highlight\">GIS</span> application, Nasa&#39;s WorldWind is an open source alternative &hellip; "
    },
    {
        "question": "What are Esri&#39;s new ArcGIS for Professionals and ArcGIS Pro?",
        "area": [
            "arcgis-pro"
        ],
        "text": "This Q&amp;A was pointed out to me and I thought I could assist by providing a little transparency about ArcGIS Professional.   I look after the teams responsible for ArcMap, ArcGlobe, ArcScene, ArcGIS Engine,  and the new ArcGIS Professional application.   Firstly,  it\u2019s an active development project and many important decisions both technical and business related are yet to be made.   And,  you can help make them,  our team spoke with many folks at the Esri 2013 User Conference who got hands on with ArcGIS Pro,  and gave us great feedback \u2013 if you were one of them,  thanks!   But providing your ideas, thoughts / feedback through ideas.arcgis.com,  your Esri account reps,  by participating in our Early Adaptor or beta programs and forums like this all are good ways to give us guidance as we progress.\n\nIs ArcGIS Professional a replacement for ArcMap, ArcGlobe and ArcScene?  No.    ArcGIS Pro is a brand new application,  with brand new opportunity to help users solve real problems, that can benefit from multiple 2D and 3D views allowing visualization and editing in both environments, for example.   Apparently my choice of words in my demo of the software during the plenary was unclear about it \u201crunning with Desktop,\u201d sorry for that confusion,  I should have been more clear about the side by side capability of existing Desktop applications and ArcGIS Pro.    They simply can run side by side on the same machine,  not sharing registry keys...etc.\n\nOur vision was to take the most commonly used functionality from these three separate Desktop applications (ArcMap/Globe/Scene) and merge it into one application \u2013 support for both 2D and 3D views is the obvious benefit and example here.    But ArcMap/Globe/Scene will stay current and maintained, with new functionality to be delivered through these applications for the long term.  I think ArcGIS 10.2 was a good example of this,  read the what\u2019s new document carefully,  a lot of great new capability went into 10.2.   When ArcGIS Professional is released,  the current Desktop applications will be updated and ship too.   Will there be a day when someone will only use ArcGIS Professional,  and not ArcMap \u2013 maybe \u2013 but it\u2019s up to that person, and their workflows to make that decision based on the capability of ArcGIS Professional.   It won\u2019t be because our team stops shipping ArcMap/ArcGlobe/ArcScene in the foreseeable future.    We are hard at work with the 10.2.1 release now for these applications.\n\nArcGIS Pro is a completely new WPF based application, it\u2019s not java anything,  it\u2019s not based on ArcGIS Runtime either.    The important thing is has great performance, and the application remains responsive all the time, it does not block the UI as can happen in single threaded applications.  This of course is achieved through a multi-threaded (64 bit) application framework that can take advance of large memory address space and GPU\u2019s for display performance.    The 2D parts of the graphics engine have been shipping in several releases of ArcGIS,  the 3D capability has not been released previously, and is new and very fast.  Our Graphics team has many years invested in this engine,  and we\u2019re excited to be getting close to shipping it soon.  This 3D graphics engine is not based on CityEngine,  but the CityEngine runtime is utilized in the application for 3D representations, for example, and will continue to be used for 3D innovation going forward,  a good example of this is our Solution for 3D Cities and Campuses. \nLicensing levels is another topic that questions are being asked about.   \n\nAs I said in the road ahead sessions at the 2013 UC,  we have not made all final (business) decisions here.   But our goal is to simplify licensing where we can,  and make sure it\u2019s in alignment with ArcGIS.com and new simpler subscription models we are releasing now for the ArcGIS Platform.   Also simplifying the access and update of software, through web downloads is what we are working on.   We will provide status as we make progress on these important decisions. \nI hope this helps you understand not just some higher level motivation and vision, but also a bit of the technical architecture of ArcGIS Professional we have implemented so far.\n\nArcGIS Professional Extensibility.   Here are our current thoughts about extensibility for ArcGIS Pro.  You can write and run Python scripts in ArcGIS that call geoprocessing tools and use an exhaustive suite of scripting functions available in the ArcGIS Python API, ArcPy, to automate your GIS tasks. Your scripts can also use a diverse array of functions provided through Python\u2019s standard and 3rd party libraries.\n\nYou can leverage the considerable capabilities of the .NET framework and WPF to extend the application with functionality involving interactive scenarios and rich user interface aspects.  Both of these types of customizations are accomplished using the well-known Add-In model.\n\n.NET Developers can code against a simplified object model that\u2019s easier to understand and use than the COM based interfaces in the ArcObjects API.  The .NET API is modern, language specific.\n\nArcGIS Professional will run \u201cstand alone\u201d like current Desktop applications and ArcGIS Runtime Apps.   But we are also really trying to invite the Desktop users to leverage the ArcGIS Platform as a whole if it makes sense for them.   We created this Professional GIS site with this in mind http://pro.arcgis.com/\n\nWe see this site as a consolidated wealth of information for GIS Professionals,  but also an opportunity to be exposed to brand new capability in the ArcGIS Platform in an integrated way, with the goal of helping you leverage the Platform better to solve the real problems. \n You can write and run Python scripts in ArcGIS that call geoprocessing tools and use an exhaustive suite of scripting functions available in the ArcGIS Python API, ArcPy, to automate your <span class=\"highlight\">GIS</span> tasks. &hellip; We created this Professional <span class=\"highlight\">GIS</span> site with this in mind http://pro.arcgis.com/\n\nWe see this site as a consolidated wealth of information for <span class=\"highlight\">GIS</span> Professionals,  but also an opportunity to be exposed to &hellip; "
    },
    {
        "question": "Learning Python programming with generic GIS goals in mind?",
        "area": [
            "python",
            "references"
        ],
        "text": "In your opinion, what is the best book/site to learn Python with GIS goals in mind?\n\nBy &quot;best&quot;, I mean:\n\n\nnot very long (book)\neasy to understand (book/site)\ngood practical examples (book/site)\n\n\nFor answers specific to learning how to use the ArcPy site-package for Python to customize ArcGIS for Desktop there is a separate Q&amp;A: What are some resources for learning ArcPy?\n In your opinion, what is the best book/site to learn Python with <span class=\"highlight\">GIS</span> goals in mind? &hellip; "
    },
    {
        "question": "What is OSGeo4W?",
        "area": [
            "open-source-gis",
            "osgeo4w",
            "osgeo",
            "shell"
        ],
        "text": "OSGeo:\n\nOSGeo is an umbrella organisation (Foundation) that supports many Open Source GIS Projects. Some of the more well known ones are: QGIS, GeoServer, and OpenLayers.\n\nBeing part of OSGeo gives a project some support, through assistance with governance, and potentially funding. But it also gives a project some legitimacy and assurance. Being part of OSGeo means the project has a team of core developers, a roadmap on where the project is going, and some form of governance.\n\nYou can be confident using Open Source GIS software because it has this support network through OSGeo.\n\nOSGeo4W:\n\nOSGeo4W is a windows installer for Open Source GIS projects. The nature of Open Source means that many project/programs rely on eachother for features. A great example of this is GDAL. GDAL is used to some extent by practically all Open Source GIS projects to read and write data. But because Windows, being a closed platform, it has not developed a package manager like Unix based operating systems. So if you install GRASS and QGIS using their stand-alone installers, you end up with 2 installs of GDAL. Add 3 or 4 more Open Source installs and you can end up with a dozen installs of GDAL, in addition an install just for GDAL.\n\nThis is where OSGeo4W comes in. It can keep track of the shared requirements of Open Source GIS packages, so QGIS and GRASS can share a single install of GDAL. It also keeps track of versions so you can simply upgrade programs.\n You can be confident using Open Source <span class=\"highlight\">GIS</span> software because it has this support network through OSGeo.\n\nOSGeo4W:\n\nOSGeo4W is a windows installer for Open Source <span class=\"highlight\">GIS</span> projects. &hellip; GDAL is used to some extent by practically all Open Source <span class=\"highlight\">GIS</span> projects to read and write data. &hellip; "
    },
    {
        "question": "Comparing QGIS and gvSIG?",
        "area": [
            "qgis",
            "gvsig"
        ],
        "text": "Many debutant GIS users are asking me which one is better QGIS or gvSIG. Since I use Qgis and I don&#39;t have any experience in gvSIG, I aways say that both are very nice softwares and the chose is a matter of liking vanilla or chocolate.\nBut I want to have a better answer for that question, so I would like to hear from people with experience on both of them, what drove you to choose one or the other as your favorite opensource desktop GIS.\n Many debutant <span class=\"highlight\">GIS</span> users are asking me which one is better QGIS or gvSIG. &hellip; But I want to have a better answer for that question, so I would like to hear from people with experience on both of them, what drove you to choose one or the other as your favorite opensource desktop <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "Learning Python programming with generic GIS goals in mind?",
        "area": [
            "python",
            "references"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\n\nGIS Lounge&#39;s GIS + Python page\nPython Geo-Spatial Development\n\n\nFor straight python, his has been discussed thoroughly on Stack Overflow:\n\n\nHow to learn Python?\nNewbie teaching self python, what else should I be learning?\nFastest way to learn Python?\nHow should I go about learning Python?\n\n\nThe second link has a link to the latest edition of a book I loved when learning python How to Think Like A Computer Scientist: Learning With Python\n\n\nZed Shaw&#39;s learn python book:  Learn Python the Hard Way.\nGeoprocessing with Python using Open Source GIS.\n\n <span class=\"highlight\">GIS</span> Lounge&#39;s <span class=\"highlight\">GIS</span> + Python page\nPython Geo-Spatial Development\n\n\nFor straight python, his has been discussed thoroughly on Stack Overflow:\n\n\nHow to learn Python? &hellip; Geoprocessing with Python using Open Source <span class=\"highlight\">GIS</span>. &hellip; "
    },
    {
        "question": "Fastest way to count the number of features in a feature class?",
        "area": [
            "arcgis-desktop",
            "arcpy",
            "arcgis-10.1",
            "performance"
        ],
        "text": "I am using an example with 1 million randomly generated points inside of a filegeodatabase. Attached here.\n\nHere is some code to get us started:\n\n\n\nAnd some initial results:\n\n\n\nImagine larger, more complex datasets. The SearchCursor will indefinitely crawl. \n\nI am not at all dissatisfied with the results, however, the DataAccess module is being used extensively in our GIS development circle. I am looking to rebuild some of our function definitions with this module as it is more flexible than a MakeTableView + GetCount methodology.\n I am not at all dissatisfied with the results, however, the DataAccess module is being used extensively in our <span class=\"highlight\">GIS</span> development circle. &hellip; "
    },
    {
        "question": "How can I convert data in the form of lat, lon, value into a raster file using R?",
        "area": [
            "raster",
            "convert",
            "r"
        ],
        "text": "Several steps required:\n\n\nYou say it&#39;s a regular 1km grid, but that means the lat-long aren&#39;t regular. First you need to transform it to a regular grid coordinate system so the X and Y values are regularly spaced.\n\na. Read it into R as a data frame, with columns x, y, yield.\n\n\n\nb. Convert the data frame to a SpatialPointsDataFrame using the sp package and something like:\n\n\n\nc. Convert to your regular km system by first telling it what CRS it is, and then spTransform to the destination.\n\n\n\nd. Tell R that this is gridded:\n\n\n\nAt this point you&#39;ll get an error if your coordinates don&#39;t lie on a nice regular grid.\nNow use the raster package to convert to a raster and set its CRS:\n\n\nNow have a look:\n\n\nNow write it as a geoTIFF file using the raster package:\n\n\n\n\nThis geoTIFF should be readable in all major GIS packages. The obvious missing piece here is the proj4 string to convert to: this will probably be some kind of UTM reference system. Hard to tell without some more data...\n ) = CRS(&quot;insert your proj4 string here&quot;)\n\nNow have a look:\n\nplot(r)\n\nNow write it as a geoTIFF file using the raster package:\n\nwriteRaster(r,&quot;pts.tif&quot;)\n\n\n\nThis geoTIFF should be readable in all major <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "Why is ArcGIS called that?",
        "area": [
            "arcgis-platform"
        ],
        "text": "In the beginning, there was INFO (a standalone relational file manager,\navailable on minicomputers like Prime, VAX, and DG) made by Henco.\nThen ESRI (now Esri) added geometry processing from its initial PIOS (Polygon Information Overlay  System) product , paired with attributes\nwithin INFO, and called the result ARC/INFO (&quot;arc&quot; files supported line\ntypes, both linear features and the edges of polygons).  The name mutated\nto Arc/Info sometime after ArcView was released, and eventually became\nthe legacy ArcInfo Workstation product.\nThe &quot;Arc&quot; part has been retained across time, and the current Esri product\nline ups the ante to &quot;ArcGIS&quot; in most of the core products.\nThere had been a more complete timeline on the Esri web site, but it&#39;s now 404.  This is as close as I can get to what was present when originally answered. There&#39;s also a history of GIS that mentions ArcInfo&#39;s origin on the esri.com site currently.\n There&#39;s also a history of <span class=\"highlight\">GIS</span> that mentions ArcInfo&#39;s origin on the esri.com site currently. &hellip; "
    },
    {
        "question": "What are Raster and Vector data in GIS and when to use?",
        "area": [
            "raster",
            "vector"
        ],
        "text": "What are raster and vector data in the GIS context? \n\nIn general terms what applications, processes, or analysis are each suited for? (and not suited for!)\n\nDoes anyone have some small, concise, effective pictures which convey and contrast these two fundamental data representations?\n What are raster and vector data in the <span class=\"highlight\">GIS</span> context? \n\nIn general terms what applications, processes, or analysis are each suited for? (and not suited for!) &hellip; "
    },
    {
        "question": "Free GIS workshops, tutorials, and applied learning material",
        "area": [
            "references",
            "education"
        ],
        "text": "This Q&amp;A lists free as in $0 workshops in GIS and related fields that have their material available to view or download online. The list is not limited to FOSS GIS, as GISers usually use a combination of open and closed source tools to accomplish their tasks. Some of these tools are easier than others and some are better documented. This list will be a great benefit to the community especially for new comers to the field.\nGeneral GIS\n\nGIS Project Video Tutorial on Acquiring, Analyzing, and Mapping US Census Data in QGIS from @A.S\nGIS Tutor: Beginner / Intermediate Level GIS from @radek\nBostonGIS from @simo\nLectures on GIS for the Social Sciences from @ubernatural\n\nOpen-source GIS\n\nOpenGEO Education Center from @radek\nQGIS Videos (faunitalia) from @simo\nGIS SE Question: Geoserver Tutorials from @com\nGIS SE Question: Open Source Training Materials from @MarkIreland\nQGIS for Newbies from @IanAllan\n\nESRI Products\n\nGIS SE Question: Best place for (structured) ArcGIS tutorials from @robintw\nArcGIS Automation and Programming from @Bethany\n\nTransportation\nThese links include either theoretical or applied transportation knowledge in transportation planning\n\nGIS primer for Transportation\nTransit Capacity and Quality of Service Manual\nUrbanSim: FOSS Urban development, socio economic, and land use planning package\nMOVES(Motor Vehicle Emission Simulator) Workshop and technical background\nTransit GIS tutorials\nRemote sensing in transportation workshop\nFlorida&#39;s CBT planning model explained\n\nDisaster Management\n\nGeo-information Technology for Crisis Management \n\nDatabases\n\nSpatial Database Course Material from @radek\n\nGeo Statistics\n\nLearn R Lectures and Classes\nGeodatabase Mining Course from @radek\nA Practical Guide to Geostatistical Mapping\n\n General <span class=\"highlight\">GIS</span>\n\n<span class=\"highlight\">GIS</span> Project Video Tutorial on Acquiring, Analyzing, and Mapping US Census Data in QGIS from @A.S\n<span class=\"highlight\">GIS</span> Tutor: Beginner / Intermediate Level <span class=\"highlight\">GIS</span> from @radek\nBostonGIS from @simo\nLectures on <span class=\"highlight\">GIS</span> &hellip; for the Social Sciences from @ubernatural\n\nOpen-source <span class=\"highlight\">GIS</span>\n\nOpenGEO Education Center from @radek\nQGIS Videos (faunitalia) from @simo\n<span class=\"highlight\">GIS</span> SE Question: Geoserver Tutorials from @com\n<span class=\"highlight\">GIS</span> SE Question: Open &hellip; "
    },
    {
        "question": "Are there newer routing algorithms (than Dijkstra, A*) in GIS databases?",
        "area": [
            "algorithm",
            "routing",
            "spatial-database",
            "optimization"
        ],
        "text": "There are works like Reach for A* from Microsoft researchers and Highway Hierarchies by Sanders and Schtolz (if I spell the name correctly) from Karlsruhe Uni. Both of them reduce the calculations order a lot, and speed up thousand times on large graphs (see the results in the linked documents). The latter work led to Open Source Routing Machine, which unfortunatly isn&#39;t popular enough and not adapted (I couldn&#39;t compile it although tried hard).\n\nAt the same time, the dbs that I tried, Spatialite and PgRouting, according to their docs, offer just Dijkstra and A* algorithms. I&#39;ve not even seen bi-directional search mentioned, which saves calculation time twice in my experience.\n\nAre there better algorithms for databases or other applications?\n There are works like Reach for A* from Microsoft researchers and Highway Hierarchies by Sanders and Schtolz (if I spell the name correctly) from Karlsruhe Uni. Both of them reduce the calculations ord &hellip; "
    },
    {
        "question": "How can I convert data in the form of lat, lon, value into a raster file using R?",
        "area": [
            "raster",
            "convert",
            "r"
        ],
        "text": "I have a data set of values over a km grid in the continental U.S. The columns are &quot;latitude&quot;, &quot;longitude&quot;, and &quot;observation&quot;, e.g.:\n\n\n\nor, as an R data frame:\n\n\n\n(the full data set can be downloaded as csv here)\n\nThe data are output from a crop model (intended to be on) a 30km x 30km grid (from Miguez et al 2012). \n\n\n\nHow can I convert these to a raster file with GIS - related metadata such as map projection?\n\nIdeally the file would be a text (ASCII?) file because I would like for it to be platform and software independent.\n How can I convert these to a raster file with <span class=\"highlight\">GIS</span> - related metadata such as map projection?\n\nIdeally the file would be a text (ASCII?) &hellip; "
    },
    {
        "question": "Finding center of geometry of object?",
        "area": [
            "geometry",
            "3d",
            "algorithm",
            "centroids"
        ],
        "text": "Every polygon has, at a minimum, four distinct &quot;centers&quot;:\n\n\nThe barycenter of its vertices.\nThe barycenter of its edges.\nIts barycenter as a polygon.\nA GIS-specific &quot;center&quot; useful for labeling (usually calculated with undocumented proprietary methods).\n\n\n(They may accidentally coincide in special cases, but for &quot;generic&quot; polygons they are distinct points.)\n\nA &quot;barycenter&quot; in general is a &quot;center of mass.&quot;  The three types differ on where the mass is presumed located: it either is entirely on the vertices, spread uniformly on the edges, or spread uniformly throughout the polygon itself.\n\nSimple methods exist to compute all three barycenters.  One approach relies on the basic fact that the barycenter of the disjoint union of two masses is the total-mass-weighted average of the barycenters.  From this we easily obtain the following:\n\n\nThe barycenter of two (equally weighted) vertices is their average.  This is obtained by averaging their coordinates separately.  Geometrically, it is the midpoint of the line segment joining the two vertices.\nInductively, the barycenter of n (equally weighted) vertices is obtained by averaging their coordinates separately.\nThe barycenter of a line segment is its midpoint.  (This is clear by symmetry.)\nThe barycenter of a polyline is obtained by finding the midpoints of each line segment and then forming their weighted average using the segment lengths as weights.\n\nFor example, consider the &quot;L&quot; shape delineated by the points (0,0), (6,0), (6,12).  There are two segments: one of length 6 with midpoint at ( (0+0)/2, (0+6)/2 ) = (3,0) and another of length 12 with midpoint at ( (6+6)/2, (0+12)/2 ) = (6,6).  Their length-weighted average coordinates are therefore (x,y) with\n\n\n\nThis differs from the barycenter of the three vertices, which is ( (0+6+6)/3, (0+0+12)/3 ) = (4,4).\n\n(Edit As another example, consider the figure in the question, which although square in shape, is represented as a pentagon determined by the sequence of points (0,0), (1/2,0), (1,0), (1,1), (0,1).  The five sides have lengths 1/2, 1/2, 1, 1, 1 and midpoints (1/4,0), (3/4,0), (1,1/2), (1/2,1), and (0,1/2), respectively.  Their weighted average therefore equals\n\n\n\nas one would hope, even though the barycenter of the vertices alone (computed as in #2 above) is (0.5, 0.4).)\nThe barycenter of a polygon can be obtained by triangulation to decompose it into triangles.  The barycenter of a triangle-qua-polygon coincides with the barycenter of its vertices.  The area-weighted average of these barycenters is the polygon&#39;s barycenter.  Triangle areas are readily computed in terms of their vertex coordinates (e.g., in terms of the wedge product of two of the sides).  For an illustration of such area calculations, including how to exploit signed (positive or negative) areas, see the section on &quot;Area&quot; at my (old) course notes page.\n\n(Edit Consider the polygon depicted in the question for example.  We could triangulate it with triangles ((0,0), (1/2,0), (0,1)) on the left, ((0,1), (1/2,0), (1,1)) in the middle, and ((1,1), (1,0), (1/2,0)) on the right.  Their areas are 1/4, 1/2, 1/4 respectively and their barycenters--obtained by averaging their vertices--are (1/6,1/3), (1/2,2/3), and (5/6,1/3), respectively.  The area-weighted average of these barycenters equals\n\n\n\nas it should, despite the presence of that fifth vertex along the bottom edge.)\n\n\nIt is evident that each of these methods is efficient: it requires just a single pass over the &quot;spaghetti&quot; representation of the polygon, using (fairly little) constant time at each step.  Note that in all cases except the first (of pure vertices), more information than just a list of vertex coordinates is needed: you need to know the topology of the figure as well.  In the &quot;L&quot; example, we needed to know that (0,0) was connected to (6,0) and not to (6,12), for instance.\n\nThese are all Euclidean concepts.  They can be extended to the sphere (or ellipsoid) in several ways.  A straightforward one views the features as a simplicial complex in three (Euclidean) dimensions, computes the appropriate barycenter, and then projects it outward from the center of the ellipsoid back to the surface.  This requires no new concepts or formulas; you only have to work with a third (z) coordinate in addition to the first two coordinates.  (Areas are still found using lengths of wedge products.)\n\nAnother generalization recognizes that the Euclidean metric--the square root of a sum of squares, according to Pythagoras--can be changed to other Lp metrics for p &gt;= 1: you take the pth root of the sum of pth powers.  Finding appropriate &quot;barycenters&quot; is no longer so simple, because the beautiful additive properties exploited above (barycenters are weighted averages of barycenters of simpler parts of a figure) no longer hold in general.  Often, iterative approximate numerical solutions have to be obtained.  They might not even be unique.\n\nAdditional centers can be defined for various purposes.  Triangles have many different centers that can generalize (somewhat) to polygons: the center of the circumcircle, the center of (some) maximal incircle, the center of a minimum-area bounding ellipse, and others.  Any set can be enclosed in various &quot;hulls,&quot; such as the convex hull, and the centers of those hulls obtained.\n\nNote that many of these &quot;centers&quot; are not necessarily located within the interior of a polygon.  (Any reasonable center of a convex polygon will lie within its interior, though.)\n\nThis variety of approaches and solutions indicates one should be wary of a generic term like &quot;center of geometry&quot; or merely &quot;center&quot;: it could be just about anything.\n A <span class=\"highlight\">GIS</span>-specific &quot;center&quot; useful for labeling (usually calculated with undocumented proprietary methods). &hellip; "
    },
    {
        "question": "Switching career from GIS Technician/Analyst to GIS Web Map Developer/Programmer?",
        "area": [
            "web-mapping",
            "development",
            "career"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\n\nPick a programming language (or maybe 2) and write a lot of code. I would recommend Python and JavaScript given your current skills\nStop using the ESRI examples to learn how to program Python and look at pure python for a while. Do some spatial operations using PostGIS/SpatiaLite and Shapely\nStart thinking of yourself as a programmer who does spatial work and not a GIS analyst who does some programming\nBite the bullet and write code for things that might be quicker through the GUI - without writing code you will never get better\nFollow and start to work on an open source project\nVolunteer to write code for somebody - without a deadline and a concrete project it is hard to get going\nMaybe take some programming classes - not a complete requirement but it might help\nRead programming blogs and the normal stackoverflow to learn and see how programmers think\nGet the book &quot;Coders at work&quot; and &quot;Pragmatic Programmer, from apprentice to Craftsman&quot; [That title is pretty close to the actual title]\nWrite and read a lot of code\nRemember that it takes about 10,000 hours to become and expert at something - so start writing code and reading code\nBe prepared to suck for a while - it is part of moving up the learning curve\nStop using desktop GUIs - Especially for some of your more basic GIS tasks like intersections and such\n\n Do some spatial operations using PostGIS/SpatiaLite and Shapely\nStart thinking of yourself as a programmer who does spatial work and not a <span class=\"highlight\">GIS</span> analyst who does some programming\nBite the bullet and write &hellip; expert at something - so start writing code and reading code\nBe prepared to suck for a while - it is part of moving up the learning curve\nStop using desktop GUIs - Especially for some of your more basic <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "Deciding what interpolation method to use for resampling raster data?",
        "area": [
            "raster",
            "interpolation",
            "gis-principle",
            "resampling"
        ],
        "text": "A clarification to the question indicates that methods of resampling a raster are sought.  Many are in use in imaging and photographic communities.  For GIS work, though, several straightforward methods are in common use:\n\n\nNearest-neighbor resampling.  Each cell in the new raster is assigned the value of the nearest cell (center to center) in the original raster.  Use this for categorical data like land use and other classifications.\nBilinear interpolation.  Each cell in the new raster is assigned an average based on the four nearest original cells.  The averaging is linear in the horizontal and vertical directions.  (The resulting formula, though, is not linear; it&#39;s actually quadratic.)  This is good for general-purpose smoothing but the averaging that goes on typically clips local peaks and valleys a bit.\nCubic convolution.  This is similar in spirit to bilinear interpolation but can slightly extrapolate values from nearby cells.  It does so in a way intended to reproduce local averages and variability in the new grid; in particular, the clipping of local extrema should not be as severe.  (One untoward consequence, evident as a bug in ESRI&#39;s ArcGIS, is that the values in the new grid may extend beyond the range of the old one, causing some of the new extremes not to be rendered correctly.  But this is a matter of data display only.)  The tradeoff is that cubic convolution takes a little more time to compute than bilinear interpolation.\n\n\nI discuss the latter two methods in some detail at http://www.quantdec.com/SYSEN597/GTKAV/section9/map_algebra.htm\n\nFor quick one-off calculations I am usually content to perform bilinear interpolation (for continuous data) or nearest-neighbor interpolation (for categorical data).  For all others, especially when preparing master datasets or when anticipating extensive manipulations, I recommend using cubic convolution (as well as giving some thought to ordering the operations to minimize propagation of floating point error).\n For <span class=\"highlight\">GIS</span> work, though, several straightforward methods are in common use:\n\n\nNearest-neighbor resampling. &hellip; "
    },
    {
        "question": "Seeking top tier conference in GIScience?",
        "area": [
            "research"
        ],
        "text": "In many fields, such as computer sciences, it seems to be quite clear which conferences are top tier and how a paper accepted to those conferences compares to journal publications in the same field.\n\nIs there a general agreement in GIScience about which conferences are considered top tier? And how do publications at those conferences compare to papers in, e.g. Transactions in GIS or the International Journal of Geographical Information Science?\n Transactions in <span class=\"highlight\">GIS</span> or the International Journal of Geographical Information Science? &hellip; "
    },
    {
        "question": "Interview questions for hiring GIS Analyst?",
        "area": [
            "career"
        ],
        "text": "What are some suitable interview questions to ask candidates for a GIS Analyst position?\n\nI am looking for techniques for interviewing analysts at varied experience levels (we are currently looking at hiring for entry and senior-level positions).  \n\nIn the past, I&#39;ve asked questions about their most recent projects and what sites/newsletters they use to keep up with the industry.\n What are some suitable interview questions to ask candidates for a <span class=\"highlight\">GIS</span> Analyst position? &hellip; "
    },
    {
        "question": "What free programs should every GIS user have installed?",
        "area": [
            "open-source-gis",
            "software-recommendations",
            "free-software"
        ],
        "text": "ColorBrewer is a great freebie for anyone who is publishing maps. Even though it&#39;s not an installed program, it&#39;s a powerful tool for picking effective color schemes, and downloads are available for various GIS software (see links below). There is even a new JavaScript version for those who can&#39;t or don&#39;t want to use Flash.\n\nColorBrewer allows you to pick effective, attractive color schemes based on number of classes, data types (e.g. sequential or qualitative), and many optional parameters. It also allows you to preview the color scheme with common features such as roads and city names, and export the scheme for (relatively) easy use in your software or code.\n\nColorBrewer&#39;s ramps can be installed to QGIS and ArcMap through symbol packages and add-ins.\n Even though it&#39;s not an installed program, it&#39;s a powerful tool for picking effective color schemes, and downloads are available for various <span class=\"highlight\">GIS</span> software (see links below). &hellip; "
    },
    {
        "question": "What books, journals, and electronic resources are most valuable for expanding knowledge of GIS?",
        "area": [
            "references"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nNot entirely a GIS Book but very helpful in many map design problems is Tufte&#39;s The Visual Display of Quantitative Information\n\n\nPostGIS In Action by Regina Obe and Leo Hsu   http://www.manning.com/obe/\n\nAn excellent tutorial and resource on spatial databases in general and PostGIS in particular.  The book is currently available through Manning&#39;s Early Access Program in .pdf format, the paper version will be out relatively soon.\n\nGeospatial Analysis: A Comprehensive Guide to Principles, Techniques, and Software Tools\nSmith, Goodchild, Longley 2007\nEntire text is online: http://www.spatialanalysisonline.com/\n\nA solid guide to how geospatial analysis work, particularly with respect to GIS. The book emphasizes conceptual workflows, but still provides the basic math. I found the math quite helpful for creating my own code and also getting an understanding of what&#39;s happening under the hood in contemporary GIS.\n\nComputational Geometry: Algorithms and Applications\n\nThe best computational geometry book. Very good at explaining (with illustrations) the various algorithms and concepts often used in GIS, such as triangulation, indexing, calculating intersection, shortest paths etc.\n\nMap Projections: A Working Manual\n(PDF, 380pages) by John P. Snyder\n\n I found the math quite helpful for creating my own code and also getting an understanding of what&#39;s happening under the hood in contemporary <span class=\"highlight\">GIS</span>. &hellip; Very good at explaining (with illustrations) the various algorithms and concepts often used in <span class=\"highlight\">GIS</span>, such as triangulation, indexing, calculating intersection, shortest paths etc. &hellip; "
    },
    {
        "question": "Why do you use ArcGIS for Desktop?",
        "area": [
            "arcgis-desktop"
        ],
        "text": "I&#39;m new to GIS, having only dabbled with ArcGIS for Desktop for about 4 weeks in 2007. The business I am at wants to target writing complete solutions that involve GIS as it would benefit their hardware sales. They do not know which market they want to target but want me to pick the GIS software to use, yet I am very green to GIS markets. All i know if target platforms are windows, windows mobile, android and web applications. The idea of mobile applications means data connection is not 100% so internet based services may need to be ruled out, i.e. GoogleMaps.\n\nI was struggling to work out how to phrase this as a question, given the huge range of GIS products available, Esri&#39;s ArcGIS for Desktop, CadCorp, MapInfo, GoogleMap/Earth, qGIS, Manifold, openJump, openstreetmap etc.\n\nTo avoid the what do I buy question, I instead ask the question why do you use Esri ArcGIS. From my experience its slow to navigate around maps and quite verbose to program in causing quite a lead time in development. Esri is also the most expensive product on the market, and i believe also the most popular. But why do people continue to use it, when other systems like CadCorp have the same functionality if not more, seem to be more responsive, can import Esri data and cost less.\n\nI feel that I must be overlooking something here. I know client demands in some industries like defense, want Esri but why is it still so popular, given I often hear how other products are betters (Is this a Windows vs. Mac example on market share vs. quality)\n\nP.s. This question has been spawned from this one on StackOverflow. \n I&#39;m new to <span class=\"highlight\">GIS</span>, having only dabbled with ArcGIS for Desktop for about 4 weeks in 2007. &hellip; They do not know which market they want to target but want me to pick the <span class=\"highlight\">GIS</span> software to use, yet I am very green to <span class=\"highlight\">GIS</span> markets. &hellip; "
    },
    {
        "question": "What are the benefits of hexagonal sampling polygons?",
        "area": [
            "polygon",
            "analysis",
            "sampling"
        ],
        "text": "The idea with hexagons is to reduce sampling bias from edge effects of the grid shape, which is related to high perimeter:area ratios.  A circle is the lowest ratio, but cannot form a continuous grid, and hexagons are the closest shape to a circle that can still form a grid.\nAlso, if you are working over a larger area, a square grid will suffer more from distortion due to curvature than shapes like hexagons.\n\nThere are a number of tools and extensions for creating and using hex grids for ecological/landscape analysis, Patch analyst (Rempel et al., 2003) being a good example, that also provides a large volume of landscape metric measurement capacity. The former Hawth&#39;s Tools, now redesigned as the Geospatial Modeling Environment has a wide array of tools that were developed to fill in gaps in arcgis functionality, including repeating grids.\nA number of third-party extensions have been made for this sort of thing, usually by the researchers who need them, so they frequently don&#39;t have the resources to rebuild their products after every new GIS version is released, so it often seems like there is nothing available\n\nThis paper (Birch, 2007) also presents a thorough comparison of rectangular and hexagonal grids for ecological applications, showing how hexagonal grids are preferable when issues of connectivity, nearest neighbourhood or movement paths are crucial aspects to be considered in the analysis.\n number of third-party extensions have been made for this sort of thing, usually by the researchers who need them, so they frequently don&#39;t have the resources to rebuild their products after every new <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "Writing numpy array to raster file",
        "area": [
            "python",
            "raster",
            "gdal",
            "numpy"
        ],
        "text": "I&#39;m new to GIS.\n\nI have some code that converts infrared images of Mars into thermal inertia maps, which are then stored as 2D numpy arrays. I&#39;ve been saving these maps as hdf5 files but I&#39;d really like to save them as raster images so that I can process them in QGIS. I&#39;ve gone through multiple searches to find how to do this but with no luck. I&#39;ve tried following the instructions in the tutorial at http://www.gis.usu.edu/~chrisg/python/ but the files I produce using his example code open as plain grey boxes when I import them to QGIS. I feel like if someone could suggest the simplest possible procedure to a simplified example of what I&#39;d like to do then I might be able to make some progress. I have QGIS and GDAL, I&#39;d be very happy to install other frameworks that anyone could recommend. I use Mac OS 10.7.\n\nSo if for example I have a numpy array of thermal inertia that looks like:\n\n\n\nAnd for each pixel I have the latitude and longitude:\n\n\n\nWhich procedure would people recommend to convert this data into a raster file that I can open in QGIS?\n I&#39;m new to <span class=\"highlight\">GIS</span>.\n\nI have some code that converts infrared images of Mars into thermal inertia maps, which are then stored as 2D numpy arrays. &hellip; "
    },
    {
        "question": "Interview questions for hiring GIS Analyst?",
        "area": [
            "career"
        ],
        "text": "How do you handle boring repetitive tasks?\n\nIf the answer doesn&#39;t mention scripting or automating then you should be wary. Candidates should have come across a scripting language or macros at some point in a GIS course. \n\nWhat database experience do you have?\n\nMany GIS analysts become responsible for geodatabases - whether or not they wish to or are suitable. Any experience with creating databases, primary keys, SQL, foreign keys etc. is going to be a big plus point. \n\nWhat are the differences between raster and vector data?\n\nI&#39;d consider this the fizzbuzz test of GIS. \n Many <span class=\"highlight\">GIS</span> analysts become responsible for geodatabases - whether or not they wish to or are suitable. &hellip; I&#39;d consider this the fizzbuzz test of <span class=\"highlight\">GIS</span>. &hellip; "
    },
    {
        "question": "Using Computer Games to display GIS data?",
        "area": [
            "cartography",
            "visualisation"
        ],
        "text": "Besides being a GIS user I&#39;m a big computer game fan.  \n\nGames like Civilization, Minecraft, World at War and many others have a very powerful engine to display huge maps in a beautiful way. \n\nIs it possible to use a game engine to display GIS data for a better comprehension or visualization of the environment? \n Besides being a <span class=\"highlight\">GIS</span> user I&#39;m a big computer game fan.  \n\nGames like Civilization, Minecraft, World at War and many others have a very powerful engine to display huge maps in a beautiful way. &hellip; Is it possible to use a game engine to display <span class=\"highlight\">GIS</span> data for a better comprehension or visualization of the environment? &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "There are so many options out there and many great answers already. Two of my favorite choices that haven&#39;t already been listed here are CartoDB and MapBox. Both of these provide web based hosting and visualization of data and some very fancy tools with prices starting at FREE. \n\nYou&#39;ll benefit from having desktop software to get your data setup. ArcMap and Quantum GIS are both great choices for the desktop part. \n\nI&#39;d say the strength of MapBox is making beautiful web maps with really great, easy to use templates and ready to go user interface elements. MapBox requires a desktop program called TileMill (also free) which makes use of a styling interface very similar to CSS. \n\nThe strength of CartoDB is that it exposes its PostGIS roots through an SQL API. \n\nBoth of these can be used on their own or in combination with other javascript mapping libraries (e.g. Leaflet, Google Maps, OpenLayers).\n\nNo matter which platforms you decide to start using to get into web mapping, you will most certainly benefit from learning some javascript.  Codecademy is a great place to start (also FREE!!).\n ArcMap and Quantum <span class=\"highlight\">GIS</span> are both great choices for the desktop part. &hellip; "
    },
    {
        "question": "Should GDAL be set to produce GeoTIFF files with compression? Which algorithm should be used?",
        "area": [
            "gdal",
            "geotiff-tiff",
            "compression"
        ],
        "text": "With  and  compression using  can help with imagery that is smoothly varying as it compresses the differences from pixel to pixel instead of the absolute values, and these will tend to be small and have more patterns (ref). Predictor is only useful with  and  compression, the option has no effect with other methods. \n\n\n\nThe predictor savings can be dramatic. I just re-compressed a directory of 16bit geotiff elevation models using up 17GB with the default LZW settings into just 5GB with predictor=2.\n\nThere is conflicting info on the differences between predictors 2 &amp; 3 and when each is best applied (ref1, ref2). Perhaps fuel for another question. \n\nAnother easy option for savings is . There are some software which can&#39;t read tiled images, but those are becoming rarer and mostly outside of GIS (I don&#39;t know of any main stream GIS software now that doesn&#39;t read them).\n\nTo build on @alfonx&#39;s answer of using compressed overviews: This allows the base image to be stored lossless, for data integrity, and the pyramids to be lossy, for speed and some space savings. It&#39;s almost the best of both worlds. For the smallest possible overviews with  on RGB images: use jpeg compression, averaged or gaussian resampling instead of the default nearest neighbour (makes the overviews smoother), and YCBCR photometric overview. See the gdaladdo reference page for more info on these options (though it doesn&#39;t say much about what photometric is all about).\n\nThis is part of a windows batch file I use to apply external jpeg overviews to all tiffs in a directory:\n\n\n\nNotes \n\nGDAL 1.6.0 introduced  resampling which can lead to better results  in case of sharp edges with high contrast or noisy patterns. Powers of 2 levels (2 4 8 ...) should be used so a 3x3 resampling Gaussian kernel is selected.\n\n - if not specified the default of 75% is used, which does yield smaller file, but I find 85% a better compromise in the size vs quality trade off.\n\nUpdate, 2015: GDAL 1.8 and 2.0 have introduced a lot of new options not covered here and which I haven&#39;t had time to digest. Read the official gtiff format page, I&#39;m sure there are additional useful settings detailed.\n There are some software which can&#39;t read tiled images, but those are becoming rarer and mostly outside of <span class=\"highlight\">GIS</span> (I don&#39;t know of any main stream <span class=\"highlight\">GIS</span> software now that doesn&#39;t read them). &hellip; "
    },
    {
        "question": "How would I draw and visualize custom maps based on OSM data?",
        "area": [
            "openstreetmap",
            "visualisation",
            "rendering",
            "map-drawing"
        ],
        "text": "I would like to be able to use openstreetmap data for a specific region as a source and &quot;draw&quot; from that the map of infrastructure improvements - mostly roads. \n\nI want it to be self-hosted (not spoiling any data on the real OSM servers), want to have quite big flexibility and detail level in the editing process and it would be nice to render it in a pretty way.\n\nI&#39;m not familiar with lots of GIS software. Actually it&#39;s not that important to have OSM data as the source, it could be a satellite image as well. The important things - flexible drawing bound to real coordinates and visualization of the map. \n\nWhere could I start?\n\nHope this question makes sense here :)\n I&#39;m not familiar with lots of <span class=\"highlight\">GIS</span> software. Actually it&#39;s not that important to have OSM data as the source, it could be a satellite image as well. &hellip; "
    },
    {
        "question": "Seeking Python tools/modules/add-ins for GIS?",
        "area": [
            "python",
            "software-recommendations"
        ],
        "text": "\nNumPy: NumPy is the fundamental package for scientific computing with Python. It contains among other things:\n\na powerful N-dimensional array object\nsophisticated (broadcasting) functions\ntools for integrating C/C++ and Fortran code\nuseful linear algebra, Fourier transform, and random number capabilities\n\nBesides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases.\n\nSciPy: SciPy (pronounced &quot;Sigh Pie&quot;) is open-source software for mathematics, science, and engineering. It is also the name of a very popular conference on scientific programming with Python. The SciPy library depends on NumPy, which provides convenient and fast N-dimensional array manipulation. The SciPy library is built to work with NumPy arrays, and provides many user-friendly and efficient numerical routines such as routines for numerical integration and optimization. Together, they run on all popular operating systems, are quick to install, and are free of charge. NumPy and SciPy are easy to use, but powerful enough to be depended upon by some of the world&#39;s leading scientists and engineers. If you need to manipulate numbers on a computer and display or publish the results, give SciPy a try!\n\nShapely: Shapely is a BSD-licensed Python package for manipulation and analysis of planar geometric objects. It is based on the widely deployed GEOS (the engine of PostGIS) and JTS (from which GEOS is ported) libraries. This C dependency is traded for the ability to execute with blazing speed. Shapely is not concerned with data formats or coordinate systems, but can be readily integrated with packages that are.\n\nGDAL Python bindings: This Python package and extensions are a number of tools for programming and manipulating the GDAL Geospatial Data Abstraction Library.\n\nGeoDjango: GeoDjango intends to be a world-class geographic Web framework. Its goal is to make it as easy as possible to build GIS Web applications and harness the power of spatially enabled data.\n\nPyProj\n\nSpatialPython: Nicely documented github repository.\n\n\n Its goal is to make it as easy as possible to build <span class=\"highlight\">GIS</span> Web applications and harness the power of spatially enabled data.\n\nPyProj\n\nSpatialPython: Nicely documented github repository. &hellip; "
    },
    {
        "question": "Benefits of Multipart Features?",
        "area": [
            "topology",
            "gis-principle",
            "multipart",
            "datastructure",
            "data-storage"
        ],
        "text": "If your software doesn&#39;t support multi-part features you may have to go to extraordinary and complicated lengths to execute spatial operations.  For example, the intersection of two polygons can, in general, have more than one connected component.  It is convenient, both algorithmically and conceptually, to suppose that such an intersection returns a single object (a multipart polygon) rather than an arbitrary number of polygons.  (For the same reasons it is helpful to support various forms of null and degenerate features--for example, polygons having an extent but zero area or even polygons with locations but neither extent nor area.  These things can arise from geometric operations; supporting them eliminates a lot of fussy case-by-case post-processing and can prevent useful information from disappearing.)\n\nFrom a relational database point of view, multipart features make normalization possible: when an attribute is inseparable from a collection of polygons, you want to represent that collection as a single object.  A good example would be a feature representing almost any country in the world having a coastline, because the country probably includes some islands.  Do you really want to force your RDBMS to make one copy of the country&#39;s attributes for every little island?  Most likely not.  You don&#39;t even want (or need) to maintain multiple copies of a pointer to the attributes, either.\n\nHow would you represent a network or a branching tree if not as a coordinated multi-polyline?\n\nFrom the point of view of mathematics or algorithmic data structures, allowing a multipart feature is a simplification, not a complication.  In order to support multiply connected polygons (rings and polygons with &quot;holes&quot;) you already need the apparatus for representing multi-part polygons.\n\nFinally, &quot;vector&quot; objects and their typical &quot;spaghetti representation&quot; have their origin in the theory of simplicial complexes.  (It is only through this somewhat tenuous connection to the theory of topology that the term &quot;topology&quot; made it into GIS, which otherwise uses essentially nothing from that theory.)  That theory requires, and benefits from, multi-part features.  In fact, having just a single component is not part of the definition of a simplicial complex, but rather turns out to be a special property enjoyed by some of them (as detected by the rank of their zeroth homology group).  As such, &quot;single part&quot; is not a defining property, but is just a topological quality in the same sense that having a ring or a &quot;hole&quot; in a polygon is a topological quality (related to the rank of the first homology group).\n (It is only through this somewhat tenuous connection to the theory of topology that the term &quot;topology&quot; made it into <span class=\"highlight\">GIS</span>, which otherwise uses essentially nothing from that theory.) &hellip; "
    },
    {
        "question": "What is the going rate for GIS freelancers?",
        "area": [
            "career",
            "freelancing"
        ],
        "text": "Firstly - this is an excellent question (+1).  As a freelancer, I wish I had had this information when I started out!\n\nSecondly - YIKES! Translating that rate into sterling is frightening.  GIS professionals must be ten a penny in the US is all I can say if that it the limit of your earning expectations.\n\nThird (and a more serious commentary expanding on Conor&#39;s answer) - The answer to your question depends a lot on the sector in which you are applying your GIS skills.  This is first and foremost the deciding factor.  If I was working in the oil industry I would be charging double what I am at the moment (but GIS for the oil industry is a little bit specialized and some of the skills very niche e.g. bespoke geological software skills required rather than just ArcGIS or what have you).  \n\nI set my rate initially by taking my (then) annual salary (gross of tax to allow for some corporate tax and sundries as very roughly equivalent to my income tax and UK National Insurnce) and divided by 200 to give me a day rate.  I used 200 because I used to work in a commercial GIS group where there was a concept of &#39;200 chargeable days&#39; - the remaining 165 days being taken up by weekends, sick leave, holidays, personal development, business development (including website maintenance), computer maintenance etc.  This was a formula which worked well in my experience.  For an hourly rate I divided the day rate by 7 because:\n\n\nI am a highly qualified and experienced professional and well worth it\nDuring a normal working day you take time out for lunch, making coffee, going to the toilet, answering the phone and so on - as a freelancer you must allow for this.\n\n\nUsing this simple calculation you can work out what you personally must charge to maintain your current standard of living.  Anything less would represent an unacceptable drop in salary and mean it is not worth going freelance.\n\nThe aim of going freelance is to get flexibility, self determination, personal satisfaction and because you have noticed how your current employer is benefiting from your skills and you would like a cut of that money.  The above calculation is just a baseline and to improve on it, you can put your prices up and you work harder once you get a feel for the market.  However, this method of calculating your hourly rate will reflect the market you personally work in and the level at which you are working (as Conor says, it depends on whether you are a junior technician or doing advanced spatial analysis for instance).\n\nADDITIONAL COMMENT:\nI should add that, after all the talk about a minimum acceptable rate, it isn&#39;t just about the money.  As a freelancer I personally have gained a lot more job satisfaction and can meet my clients&#39; needs without all the bureaucracy of a large organisation getting in the way.  I am also a lot more hands-on, which I enjoy and which I was losing with increasing seniority in a traditional employed role.  This sense of satisfaction and achievement are worth a lot and can&#39;t be expressed in a simple monetary rate.  This is the hidden bonus (though I grant you, you can&#39;t eat it and it doesn&#39;t pay the mortgage).\n <span class=\"highlight\">GIS</span> professionals must be ten a penny in the US is all I can say if that it the limit of your earning expectations. &hellip; Third (and a more serious commentary expanding on Conor&#39;s answer) - The answer to your question depends a lot on the sector in which you are applying your <span class=\"highlight\">GIS</span> skills. &hellip; "
    },
    {
        "question": "Creating transparent hillshade?",
        "area": [
            "gdal",
            "dem",
            "gdal-translate",
            "hillshade",
            "gdal-calc"
        ],
        "text": "I get elegant transparent hillshades via a combination  and . Compare to grey-based hillshade commonly used, such transparent hillshades are very cool because they can be placed between the map background and other upper layers (roads, buiding) to provide a 3D feels whatever the background&#39;s type and color. \n\n\nHow it works\n\nThe trick: Starting with a grey scale hillshade produced by , the trick is to take the grey channel&#39;s values, invert each value, and flow this result into a new opacity channel. Black pixel [0,0,0] become [0,0,0,255] (opacity=255), grey pixel [120,120,120] get lower becoming  [120,120,120,135] (opacity=135, aka 255-120), white pixel [255,255,255] become transparent [255,255,255,0] (opacity=0, aka 255-255) and so on. Hills&#39; shades are opaque and black, plains progressively become (white) transparent. Conceptually, the pixel&#39;s band equation is something such :\n\n\n\nFor a laid back video on this approach, explained by a Photoshop designer, see Adding Shaded Relief in Photoshop (16mins).\n\nQuestion\n\nTaking an ETOPO or SRTM derived grey-based hillshade (, file available to download here) as input...\n\n...How to do the trick cited upper via gdal or an other non GIS-destructive way on such .tif files ?\n\nNote that I wish to keep GIS properties (geolocalisation).\n\n\n\n hillshade crop_xl.tmp.tif shadedrelief.tmp.tif -s 111120 -z 5 -az 315 -alt 60 -compute_edges, file available to download here) as input...\n\n...How to do the trick cited upper via gdal or an other non <span class=\"highlight\">GIS</span>-destructive &hellip; Note that I wish to keep <span class=\"highlight\">GIS</span> properties (geolocalisation). &hellip; "
    },
    {
        "question": "Overlaying spatial polygon with grid and checking in which grid element specific coordinates are located using R",
        "area": [
            "r",
            "vector-grid",
            "point-in-polygon"
        ],
        "text": "How can one use R to \n\n\nsplit a shapefile in 200 meter squares/sub-polygons, \nplot this grid (incl. ID numbers for each square) over the original map below, and \nevaluate in which square specific geographic coordinates are located.\n\n\nI am a beginner in GIS and this is perhaps a basic question, but I haven&#39;t found a tutorial on how to do this in R. \n\nWhat I have done so far is loading a shapefile of NYC and plotting some exemplary geographic coordinates.\n\nI am looking for an example (R code) how to this with the data below. \n\n\n\n\n I am a beginner in <span class=\"highlight\">GIS</span> and this is perhaps a basic question, but I haven&#39;t found a tutorial on how to do this in R. &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "I also just attended a conference where they presented the OpenGeo Suite, which is a stack of OpenLayers, GeoServer, GeoExt &amp; PostGIS.  They offer both the &quot;Enterprise Edition&quot; (paid for version with support) or the &quot;Community Edition&quot; (free) versions.\n(Update) OpenGeo Suite is now Boundless Suite.\n\nAnother package that was demonstrated at the conference was GeoMoose, which is a stack of MapServer and OpenLayers.\n\nYou might consider downloading the OSGEO Live DVD, which you can run in a virtual machine environment in case you don&#39;t want to install a bunch of stuff on your machine while testing it out.  It comes pre-packaged with a bunch of different open source GIS software packages, including web mapping tools.\n It comes pre-packaged with a bunch of different open source <span class=\"highlight\">GIS</span> software packages, including web mapping tools. &hellip; "
    },
    {
        "question": "Donating and volunteering geographical knowledge?",
        "area": [
            "openstreetmap",
            "google-maps",
            "crowdsourcing"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\nOf course it is ultimately up to you, but i would hesitate to call working with OpenStreetMap a waste of time.\n\nWhile it is true that the OSM user base is small right now, there are factors that affect both Google and OSM. The primary issue is that now that Google has started to charge for levels of use of their API, a number of companies and organizations are switching to OSM. The list includes Apple, Foursquare, and Wikipedia mobile apps. It looks like more may switch as well, which could increase the user base significantly.\nThis is one aspect.\n\nThe other, and that which seems more important to me is the idea of open access to data. As a Geographer and GIS professional, having access to high quality datasets is critical for me to do my job. Having access that can not be compromised is even more important. The OSM dataset is licensed as Open Data Commons Open Database License, so anyone may use it. Google data is privately owned and while this likely won&#39;t happen, they could close it off tomorrow and charge everyone for access, whether you helped improve the dataset or not.\n\nI know that here in the United States access to data is a big issue.  A lot of time and money is spent collecting and building the datasets, and a big question is who should pick up this cost.  There are arguments either way.  I am sure this is an issue in other parts of the world as well, especially in places where there are not as many sources of data like streets available for people to use.\n\nThis is a pretty hot topic you picked here, with strong, valid feelings on both sides.  Google has every right to charge for their data, and make a profit.  People have the same right to build their own dataset and make it available to everyone. There is nothing to say you can&#39;t support both, just don&#39;t sell one short over the other without researching on your own, and drawing your own conclusions.\n As a Geographer and <span class=\"highlight\">GIS</span> professional, having access to high quality datasets is critical for me to do my job. Having access that can not be compromised is even more important. &hellip; "
    },
    {
        "question": "How to tell which QGIS plugins are slow to load?",
        "area": [
            "qgis",
            "qgis-plugins"
        ],
        "text": "Hidden feature that I never made a UI for\n\n\n\nRun it in the Python console\n\nAlso see the plugin called Plugin Load Times: (https://gitlab.com/GIS-projects/Plugin-Load-Times)\n Hidden feature that I never made a UI for\n\nimport pprint\npprint.pprint(qgis.utils.plugin_times)\n\n\nRun it in the Python console\n\nAlso see the plugin called Plugin Load Times: (https://gitlab.com/<span class=\"highlight\">GIS</span>-projects &hellip; "
    },
    {
        "question": "Choosing coordinate system to store geography data for celestial coordinates",
        "area": [
            "postgis",
            "coordinate-system",
            "spatial-database"
        ],
        "text": "I am doing an astronomy project. I want to have the information about our images stored in a spatially enabled database. This, I would think, should be a very easy special case for GIS functions because the sky can be treated as perfectly spherical, and does not require an elliptical treatment like the surface of the earth. Unfortunately, I have not found a way to do this yet and I have been dodging mines with spatial functions that use an elliptical earth. (Pretty much any function that returns meters instead of degrees may be using an elliptical calculation. Luckily, many of the PostGIS functions I&#39;ve needed appear to have incomplete implementations where the documentation explicitly states that the returned results are for a sphere and not for the ellipsoid. But that may change with future versions, which is a cause for concern.)\nBackground: I am presently using PostgreSQL with PostGIS and WGS 84 coordinates (SRID=4326). This works fairly well. I am creating a closed POLYGON from the right ascension and declination of the four corners of the image. I have a lot of images (10k or more), covering a large area of the sky. Each images is about 1 degree square. From the set of these images, I am making mosaics from small subsets of 15 to 30 images. Each mosaic is about 1.5 degree square.\nPresently, I am storing the geography of the mosaics as a MULTIPOLYGON that consists of all the POLYGONS corresponding to each image that went into the mosaic. [A better solution would be to create a single POLYGON that describes the perimeter of the union of all the individual polygons. I don&#39;t know if this can be done in spherical coordinates (i.e., that the geography type). This would also be an interesting answer for me too.] The date line and celestial poles may be included in an image in the dataset so I have been avoiding projecting to planar coordinates to the extent possible.\nWhat coordinate system ought I use for celestial coordinates with PostGIS functions?\nI have looked at  http://spatialreference.org/ but have not found anything so far. Google has turned up little. I am stumped. Basically, I want to ensure that if a function returns meters as a distance, it is meters along a great circle on a sphere.\n\nI am using PostGIS 1.5.2. I have not yet tried PostGIS 2.0. I am curious if the ST_CoveredBy function works with a POLYGON and a MULTIPOLYGON of type geography. If anybody is running 2.0, could you tell me if you get the same error as this:\n\n\nI have tried PostGIS 2.0. This function still only works on points and polygons, not more general shapes.\n This, I would think, should be a very easy special case for <span class=\"highlight\">GIS</span> functions because the sky can be treated as perfectly spherical, and does not require an elliptical treatment like the surface of the earth &hellip; "
    },
    {
        "question": "Converting .shp into .gpx using QGIS",
        "area": [
            "qgis",
            "shapefile",
            "convert",
            "gpx"
        ],
        "text": "I would like to convert .shp into .gpx. \n\nUsing GIS, I open my shapefile and I tried to &quot;save as&quot; gpx but it gives an OGR error: \n\n\n  creation of field ObjectId failed (OGR error: Field of name &#39;ObjectId&#39;\n  is not supported in GPX schema. Use GPX_USE_EXTENSIONS creation option\n  to allow use of the  element).\n\n\nHow can I fix this error?\n Using <span class=\"highlight\">GIS</span>, I open my shapefile and I tried to &quot;save as&quot; gpx but it gives an OGR error: \n\n\n  creation of field ObjectId failed (OGR error: Field of name &#39;ObjectId&#39;\n  is not supported in GPX schema. &hellip; "
    },
    {
        "question": "Converting ArcGIS (*.mxd) file to QGIS (*.qgs) file",
        "area": [
            "qgis",
            "convert",
            "mxd",
            "qgs"
        ],
        "text": "This looks like the sort of thing you want:\nhttps://underdark.wordpress.com/2011/05/27/converting-mxd-to-qgis-project-file/\n\n\n  On Wednesday, Allan Maungu announced MXD2QGS, a converter that exports layers from an Arcmap 10 document into a Quantum GIS project file. The tool is built as an ArcToolbox and can be downloaded from the blog.\n\n\nThe only working download link seems to be https://sites.google.com/site/lumtegis/files/Mxd2Qgs.zip\n\nAs of August 2017 this tool also appears to be available at https://github.com/fitnr/mxd2qgs\n\nThere&#39;s also one for doing ArcView 3.x files apparently: http://gix.sourceforge.net/\n https://underdark.wordpress.com/2011/05/27/converting-mxd-to-qgis-project-file/\n\n\n  On Wednesday, Allan Maungu announced MXD2QGS, a converter that exports layers from an Arcmap 10 document into a Quantum <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "Creating point features with exact coordinates in QGIS",
        "area": [
            "qgis",
            "point",
            "coordinates",
            "point-creation"
        ],
        "text": "Use plugin Numerical Vertex Edit (https://plugins.qgis.org/plugins/numericalVertexEdit/). Or create table with Lat/Lon/Name and save in csv, then load csv table in QGIS (Add Delimited text layer) (info gis-lab.info)\n Or create table with Lat/Lon/Name and save in csv, then load csv table in QGIS (Add Delimited text layer) (info <span class=\"highlight\">gis</span>-lab.info) &hellip; "
    },
    {
        "question": "Instantiating spatial polygon without using a shapefile in R",
        "area": [
            "shapefile",
            "polygon",
            "r"
        ],
        "text": "First get the coordinates into a 2-column matrix:\n\n\n\nThen create a Polygon, wrap that into a Polygons object, then wrap that into a SpatialPolygons object:\n\n\n\nThe reason for this level of complexity is that a Polygon is a simple ring, a Polygons object can be several rings with an ID (here set to 1) (so is like a single feature in a GIS) and a SpatialPolygons can have a CRS. Ooh, I should probably set it:\n\n\n\nIf you want to turn it into a SpatialPolygonsDataFrame (which is what comes our of readShapeSpatial when the shapefile is polygons) then do:\n\n\n\ngiving this:\n\n\n SpatialPolygons(list(ps))\n\n\nThe reason for this level of complexity is that a Polygon is a simple ring, a Polygons object can be several rings with an ID (here set to 1) (so is like a single feature in a <span class=\"highlight\">GIS</span> &hellip; "
    },
    {
        "question": "GIS professionals working from home",
        "area": [
            "career"
        ],
        "text": "How many of you out there work from home?\nWhat kind of company / organization do you work for (private, government, municipal, institution..)?\nHow did you convince your employer it was a good idea?\nWhat are the major drawbacks to working in a GIS position at home?\n What are the major drawbacks to working in a <span class=\"highlight\">GIS</span> position at home? &hellip; "
    },
    {
        "question": "Advantages of using spatialite over shapefile?",
        "area": [
            "shapefile",
            "spatialite",
            "file-formats",
            "portable-gis"
        ],
        "text": "I found spatialite more useful than shapefiles as it does not have the limitations of shapefile and it is also portable. Many people here use shapefiles to exchange data and even the experts do not know about this new format.\n\nWhat are the advantages of using spatialite over shapefiles? \n\nCan it be used instead of shapefile? \n\nPlease focus only on those formats which are portable, i.e. can be exchanged using USB sticks. GML, GeoJSON, KML, CSV are not an option and they are not directly editable in GIS.\n\nUPDATE:\nIt has been more than 5 years and the new development is directed towards geopackage which is related to spatialite.\n\nSo now question is more like Advantages of using GEOPACKAGE over GEODATABASE?\n GML, GeoJSON, KML, CSV are not an option and they are not directly editable in <span class=\"highlight\">GIS</span>. &hellip; "
    },
    {
        "question": "Best GIS system for high performance web application - PostGIS vs MongoDB",
        "area": [
            "postgis",
            "mobile",
            "geolocation",
            "mongodb",
            "nosql"
        ],
        "text": "I am working on a web/mobile application based on location data. Since i am already familiar with MongoDB, i found the geospatial indexing of mongo is quite suitable for my needs. As i am mainly dealing with simple/short location points, Mongo 2d indexing is good for me.\n\nAlong the way i picked PostGIS, because of its stable/mature way. And its awesome feature set. But my main concern is performance since my data is heavily dependent on location(mostly 70 - 80% of the db calls deal with the location).\n\nI like mongo because its used by high performance web apps like foursquare already. But i have seen PostGIS is mainly used in government/enterprise projects (mostly non web/mobile apps). So i am little confused right now to choose the right GIS db for my web/mobile app? Got any suggestions?\n So i am little confused right now to choose the right <span class=\"highlight\">GIS</span> db for my web/mobile app? Got any suggestions? &hellip; "
    },
    {
        "question": "Dividing polygon into specific sizes using ArcGIS Desktop?",
        "area": [
            "arcgis-desktop",
            "algorithm",
            "polygon-creation"
        ],
        "text": "This problem has many valid solutions.  One of them works a little like your description, but instead of slicing the polygons at &quot;random&quot; locations you can do it purposefully in a way designed to minimize the amount of computation.\n\nHere is the basic algorithm.  Its input consists of any plane sweep direction, a polygon P of nonzero area, a target area a between zero and the polygon&#39;s area, and a nonnegative threshold t (in units of area).  Its purpose is to split P with a line perpendicular to the sweep direction into two parts, one to the right of the line and the other to the left of the line, such that the difference between the righthand area and the target area a is no greater than t.\n\nLet L be any oriented line perpendicular to the sweep direction.  Define f(L) to be the area of P found at the right of L, minus a.  In these terms the task is to find a zero of f.  Because f is unlikely to be differentiable, but is continuous, use either a bisection method, the secant method, or--my favorite--Brent&#39;s method.  All are simple and guaranteed to converge.  Use t for the convergence tolerance for the argument.\n\nThat&#39;s it.  Let&#39;s consider what goes into coding this.  The root finding is routine--you can use a generic chunk of code for it--so the GIS work comes down to coding f.  Doing so requires\n\n\n\nBoth operations are implemented in almost any vector-based GIS.  If not, you can replace the line by a very large rectangle representing the half-plane to the right of the line.  Step 1 becomes\n\n\n\nThat is a really basic operation.\n\nTo get started with root finding, you need to find an interval in which the zero of f is guaranteed to lie.  This is easy: project the polygon&#39;s envelope (&quot;bounding box&quot;) into the direction of the line sweep.  The projection is the interval you want.\n\nThis question has a long history.  I implemented this algorithm for ArcView 3.x long ago and described it many times in the old ESRI user forums.  Google\n\n\n  huber split polygon site:forums.esri.com\n\n\nfor discussions, links to code, enhancements and variations (such as splitting polygons into parts of desired sizes which are as compact as possible) and algorithms for raster data.\n\nHere is what the continental US states look like (in an equal area projection) with the bottom third of each state shaded.  Evidently the sweep direction was vertical.\n\n\n The root finding is routine--you can use a generic chunk of code for it--so the <span class=\"highlight\">GIS</span> work comes down to coding f.  Doing so requires\n\n1.  Splitting the polygon by a line.\n2. &hellip; Both operations are implemented in almost any vector-based <span class=\"highlight\">GIS</span>.  If not, you can replace the line by a very large rectangle representing the half-plane to the right of the line.  Step 1 becomes\n\n1&#39;. &hellip; "
    },
    {
        "question": "Is it possible to look at the contents of Shapefile using Python without an ArcMap license?",
        "area": [
            "python",
            "shapefile"
        ],
        "text": "I would recommend becoming familiar with the Python GDAL/OGR API to work with both vector and raster data.  The easiest way to start using GDAL/OGR is via a python distribution such as python(x,y), Anaconda, or OSGeo4W.\nFurther details on using GDAL for your specific tasks:\n\nGet Shapefile Fields and Types\nGet Projection\n\nAdditionally, I would recommend the following tutorial from USU to get you started.\n\nGeoprocessing with Python using Open Source GIS\n\n\nBorrowing from the examples above, the following script uses FOSS tools to perform the following actions:\n\nCheck the spatial reference\nGet shapefile fields and types\nCheck if rows in a user-defined field contain some value\n\n\n\n Geoprocessing with Python using Open Source <span class=\"highlight\">GIS</span>\n\n\nBorrowing from the examples above, the following script uses FOSS tools to perform the following actions:\n\nCheck the spatial reference\nGet shapefile fields &hellip; "
    },
    {
        "question": "Downloading OpenStreetMap Data",
        "area": [
            "openstreetmap"
        ],
        "text": "JOSM\n\nPerhaps the easiest answer to both parts of your question, is to use JOSM. The Java OpenStreetMap Editor. It&#39;s easy to download data, and easy to &quot;use&quot; data.\n\nFor downloading, JOSM provides a simple interface to let you select a rectangular area to download, however it downloads this via the editing API. This will reject any request which is way too big, and if it&#39;s a little bit too big it will spend a long time thinking about it. Generally a whole city is way too big, but you might be able to get a good a chunk of data by requesting several rectangular areas.\n\nFor &quot;using&quot; the data JOSM lets you see the data and have a good poke around in all the tags. The search feature is quite powerful, allowing you to select elements with particular tags, but beyond that it really depends what kind of &quot;use&quot; you have in mind. You can configure the way JOSM displays the data to some extent, but for nice looking maps you&#39;d probably want to look at rendering tools designed to work with OSM files. You can also look at conversion e.g. to shapefile, but bare in mind the data is ...different ...to what you might be used to, so this conversion is always a bit lossy.\n\nAs an aside...  Although it&#39;s reasonably nice data viewer, the primary purpose of JOSM is to be an OpenStreetMap editor. Just click &#39;upload&#39; to send changes back to OpenStreetMap  (you&#39;ll need to create an OpenStreetMap account) If you didn&#39;t try OpenStreetMap editing yet, you really should. Anyone with even a passing interest in maps should give this a go. Add your local restaurant to the map or something like that. It&#39;s the only way to get a proper understanding of OpenStreetMap, and it&#39;s fun!\n\nBigger files\n\nWhat if a city is too big to load into JOSM? There&#39;s some other options (as follows) but when you&#39;re dealing with this amount of data there&#39;s no escaping the fact that it&#39;s going to be a little bit difficult to &quot;use&quot;. You&#39;re really out of the realm of fun little GUI tools and into big data GIS. The easiest entry to this (which is not all that easy) would probably be to load a large .osm file into PostGIS database using osm2pgsql, and then use GIS desktop tools to view it.\n\nCity extracts\n\nThis download.bbbike.org service offers ready-made downloads for some world cities.\n\nOsmosis\n\nIf you need a different city or different bounding box, then you need to get one of the massive downloads you mentioned (either a country extract, or the whole planet) and then extract a piece out of it.\n\nosmosis is the most widely used tool for this. It&#39;s a java command line tool letting you extract a bounding box on the unix command line with something like this:\n\n\n\nThis shows how you would typically avoid filling your disk with bloated XML data by uncompressing a .bz2 file, piping the output into osmosis and then piping the resulting XML into a bzipped file again.\n\nSo maybe this is not fitting with your definition of &quot;easy&quot;, but osmosis is a worthwhile tool to get the hang of if you&#39;re interested in manipulating big .osm files. You just have to figure out the right command! (good topic for another question I guess)\n You&#39;re really out of the realm of fun little GUI tools and into big data <span class=\"highlight\">GIS</span>. &hellip; The easiest entry to this (which is not all that easy) would probably be to load a large .osm file into PostGIS database using osm2pgsql, and then use <span class=\"highlight\">GIS</span> desktop tools to view it. &hellip; "
    },
    {
        "question": "Comparing different open source GIS servers?",
        "area": [
            "open-source-gis",
            "software-recommendations",
            "osgeo"
        ],
        "text": "I currently know the following open source GIS servers:\n\n\nGeoserver: java based, vector and bitmap support, also supports. Is now on par with mapserver (performance-wise).\nmapserver: c/c++, used to be the fastest server. Better for raster than vector?\nmapguide: do not know this\nmapnik: the new kid on the block? do not know much about it, but it looks appealing\nmapfish: as far as i know, only retrieves vector-data for display in openlayers. There does exist a rails implementation.\n\n\nIf possible i would like some kind of comparison, which did you choose or prefer and why?\n\nI am looking at building a rails website, and need some kind of GIS server. I will need raster and vector data (clickable). Is this doable with one server? Backend database will be Postgis.\n I currently know the following open source <span class=\"highlight\">GIS</span> servers:\n\n\nGeoserver: java based, vector and bitmap support, also supports. &hellip; I am looking at building a rails website, and need some kind of <span class=\"highlight\">GIS</span> server. I will need raster and vector data (clickable). Is this doable with one server? Backend database will be Postgis. &hellip; "
    },
    {
        "question": "Organizing GIS projects?",
        "area": [
            "maps",
            "workflow"
        ],
        "text": "Note: This rant will be updated as I go\n\nI&#39;m no computer or ArcGIS pro by any means, but here&#39;s what I do:\n\nBase Files/DBS\n\n\nThese are files that are &quot;raw&quot; in nature and constitute the base of all my analysis\nThese files, databases, and data are hosted outside of my  folder, and are hosted on my internet server, local computer, and dropbox. I always have access to them, and they are very organized, dis and aggregated. You&#39;ll spend a lot of time organizing these.\nI put them all in databases whether in Arc or PostGIS.\nTo each table, I add 3 fields in the table itself or the meta data: DATE_OBTAINED, DATA_DATE, SOURCE_NOTES\nAlso Base files could be queries of multiple other tables. For example, a table could aggregate all the traffic count I obtain into one large query/table.\nI also put here all other data that I find scouring the internet.\nI NEVER DO ANY DIRECT ANALYSIS ON ANY OF THE FILES IN THE BASE FILES\n\n\nProject Files\n\n\nAll my project files go in a  folder. It contains everything related to that project as in, if I copy and paste that folder somewhere else, it will contain everything.\nUsually I have the following structure: \n\nmy_project/\n\nadmin/\ncommunication/\nraw_data/\nanalyzed_data/\noutput_data/\nfrom_client/\nFINAL/\ncode/\nsome_document_date_time.doc\nREADME\n\n\nSlowly I&#39;ve been moving to a local GIT. (you can even host it locally or on your own server). The reason I do not put it on GitHub is that github has a 1.2gb limit which is useless for GIS analysis\nFor my projects, I usually replicate all the GIS tables that I need for my analysis into a new db: project_whatever.\n9 times out of 10, I work only in shp files and I save all my GIS (images, excel, coordinates, etc) to my , , and . \nWhen a project is complete, I put the final submitted copy in \nFor my MXD, I usually save to a new MXD every 2 or 3 hours  for example\nFor Ms Word documents, illustrations, and mostly editing documents, they go in my_projects folder  such as  and . Again all my final deliverables go in in the FINAL folder\nFor R, Python code and some C#, it gets a bit tricky, as I host it outside of the project but with a working copy to  folder. I do this as most of the python code is reusable. If you put all your python code besides the projects, you&#39;ll forget about them. Also, all my python code goes on github.\nTo me project files include any file types including time tracking, communications (I save all my emails as .msg files), I log all our verbal communications in a word file, and I put all those files my_project/communication\nWith ArcGIS use Models, LYR, and &quot;save selection as a new shp layer&quot;. These tools will make it easy to store files in smaller formats, reuse files, and with models, be able to use something in another place.\n\n\nFinal Output\n\n\nEach project when finalized gets zipped and put on my external harddrive.\nAll final products are converted to files from Tables, and to PDF from all other formats. \nEvery Project I do, gets printed for a hard copy backup\n\n\nThe Bottom Line\n\n\nEach person uses multiple and different software and tools. A lot of people I know get organized using basecamp, Harvest, or any other multitude of tools. Also people have different working habits and OCD tendencies. I&#39;m fairly obsessed with getting stuff organized maybe a bit more than others. So develop the system that causes you the least stress while guaranteeing you&#39;ll be consistent in applying and updating it\nBackup and replicate everything\nDon&#39;t work directly on your raw / base data\nFor your projects always use a replica file, as data changes over time, and you don&#39;t want to be scrambling to find the .\neach my_projects folder must have a README text file that you edit it while you&#39;re doing the projects to give some basic information that you know you&#39;ll forget later when you visit the project 2 years down the road\n\n The reason I do not put it on GitHub is that github has a 1.2gb limit which is useless for <span class=\"highlight\">GIS</span> analysis\nFor my projects, I usually replicate all the <span class=\"highlight\">GIS</span> tables that I need for my analysis into a new db &hellip; : project_whatever.\n9 times out of 10, I work only in shp files and I save all my <span class=\"highlight\">GIS</span> (images, excel, coordinates, etc) to my projects/my_project/raw_data, projects/my_projects/analyzed_data, and projects &hellip; "
    },
    {
        "question": "Learning to think spatially rather than just follow point and click tutorials",
        "area": [
            "education",
            "references"
        ],
        "text": "The college I work for is considering revamping their intro to GIS course. Traditionally, they&#39;ve used the ESRI suite but are now open to using other options. There are two factors responsible for the desire to make a change:\n\n\nThe text book provided by ESRI. The instructors feel that the point and click tutorials don&#39;t teach the students how to think about GIS but rather how to use ESRI software. They&#39;d like to have something that&#39;s more than a manual and that won&#39;t be out of date by the time they arrive.\nTraditionally graduates could expect jobs from either the Territorial Government or Parks Canada (both of which use ArcGIS), but with recent gov&#39;t cut backs these two are no longer the main destination for graduates. After consulting with industry representatives the college has been told that they should be training student to &quot;think spatially&quot; rather how to use just one type of software.\n\n\nAre there any resources the SE.GIS community would consider helpful for developing GIS thought and instruction (rather than tutorials)? And if you were going to commit to teaching with one program/suite which do you think would be most useful to learn such that the skills learned would be most broadly applicable to GIS software in general?\n The instructors feel that the point and click tutorials don&#39;t teach the students how to think about <span class=\"highlight\">GIS</span> but rather how to use ESRI software. &hellip; Are there any resources the SE.GIS community would consider helpful for developing <span class=\"highlight\">GIS</span> thought and instruction (rather than tutorials)? &hellip; "
    },
    {
        "question": "Working with PostGIS data in R?",
        "area": [
            "postgis",
            "postgresql",
            "r"
        ],
        "text": "If you have PostGIS driver capability in the rgdal package then its just a question of creating a connection string and using that. Here I&#39;m connecting to my local database  using default credentials, so my DSN is rather simple. You might need to add a host, username, or password. See gdal docs for info.\n\n\n\nWhat tables are in that database?\n\n\n\nGet one:\n\n\n\nWhat have I got?\n\n\n\nOtherwise you can use R&#39;s database functionality and query the tables directly.\n\n\n\nThat returns the feature geometry in , which you&#39;ll need to convert to  class objects (SpatialPolygons, SpatialPoints, SpatialLines) to do anything with. The readWKT function in rgeos can help with that.\n\nThe things to beware of are usually stuff like database columns that can&#39;t be mapped to R data types. You can include SQL in the query to do conversions, filtering, or limiting. This should get you started though.\n Here I&#39;m connecting to my local database <span class=\"highlight\">gis</span> using default credentials, so my DSN is rather simple. You might need to add a host, username, or password. See gdal docs for info. &hellip; &gt; require(rgdal)\n&gt; dsn=&quot;PG:dbname=&#39;<span class=\"highlight\">gis</span>&#39;&quot;\n\n\nWhat tables are in that database? &hellip; "
    },
    {
        "question": "Is there GIS Video &quot;that Mom can understand&quot;?",
        "area": [
            "references",
            "education"
        ],
        "text": "Working as a professional within the GIS discipline, I often find it challenging to describe to people what GIS is (in a face to face conversation).  Telling them that GIS stands for Geographic Information Systems, which encompasses a set of technologies that can be used to analyze, map, and organize spatial data is a bit over most people heads.  On the contrary, telling people that GIS can be used to make maps on a computer falls far short of its many potential uses.  With this, I&#39;m looking for some effective video examples that one could show somebody that explain both in words and visually what GIS is, and how the technology is utilized (something your Mom could understand :))?  \n Working as a professional within the <span class=\"highlight\">GIS</span> discipline, I often find it challenging to describe to people what <span class=\"highlight\">GIS</span> is (in a face to face conversation). &hellip; On the contrary, telling people that <span class=\"highlight\">GIS</span> can be used to make maps on a computer falls far short of its many potential uses. &hellip; "
    },
    {
        "question": "Great GIS, maps &amp; cartography quotes",
        "area": [
            "references"
        ],
        "text": "Programmers&#39; list has been a pleasure to read. Stats&#39; list is growing fast as well. So perhaps there is a place for separate one on this site?\n\nPlease share your nuggets of wisdom / humour / inspiration from the world of GIS, cartography and mapping.\n Please share your nuggets of wisdom / humour / inspiration from the world of <span class=\"highlight\">GIS</span>, cartography and mapping. &hellip; "
    },
    {
        "question": "Changing language of QGIS Interface",
        "area": [
            "qgis",
            "internationalization",
            "windows-xp"
        ],
        "text": "I want the QGIS interface in English, in order to share information with the GIS community. Using another language, when chatting with the GIS community, makes things more difficult. When I installed QGIS, it automatically set the language to French.\nI am using Windows XP in French, but I want QGIS in English.\n I want the QGIS interface in English, in order to share information with the <span class=\"highlight\">GIS</span> community. Using another language, when chatting with the <span class=\"highlight\">GIS</span> community, makes things more difficult. &hellip; "
    },
    {
        "question": "How do I develop my GIS programming skills?",
        "area": [
            "python",
            "c++",
            "references"
        ],
        "text": "I would like to develop my GIS programming skills, where do I start? People say learn C++ or Python but where can I learn this in a geographic context? Tutorials or anything would be very helpful, as would any information on languages/programmes to use.\n I would like to develop my <span class=\"highlight\">GIS</span> programming skills, where do I start? People say learn C++ or Python but where can I learn this in a geographic context? &hellip; "
    },
    {
        "question": "How to create an accurate Tissot Indicatrix?",
        "area": [
            "coordinate-system",
            "gis-principle"
        ],
        "text": "A Tissot Indicatrix is useful method for communicating at a glance the kinds of distortion a given projection is prone to (in the figure below, each of the red circles occupies the same area). I&#39;ve been told that popular methods for generating TI&#39;s have their own problems, to the point of being sometimes woefully inaccurate. \n\nWhat is the problem with the popular methods, and what is most correct way of generating a TI that is accessible to your average GIS dude(ette)?\n\n\n What is the problem with the popular methods, and what is most correct way of generating a TI that is accessible to your average <span class=\"highlight\">GIS</span> dude(ette)? &hellip; "
    },
    {
        "question": "EPSG 3857 or 4326 for Web Mapping",
        "area": [
            "coordinate-system",
            "leaflet",
            "openstreetmap",
            "google-maps",
            "web-mapping"
        ],
        "text": "There are a few things that you are mixing up.\n\nGoogle Earth is in a Geographic coordinate system with the wgs84\ndatum. (EPSG: 4326)\n\nGoogle Maps is in a projected coordinate system  that is based on the\nwgs84 datum. (EPSG 3857)\n\nThe data in Open Street Map database is stored in a gcs with units\ndecimal degrees &amp; datum of wgs84. (EPSG: 4326)\n\nThe Open Street Map tiles and the WMS webservice, are in the\nprojected coordinate system  that is based on the wgs84 datum. (EPSG\n3857)\n\n\nSo if you are making a web map, which uses the tiles from Google Maps or tiles from the Open Street Map webservice, they will be in Sperical Mercator (EPSG 3857 or srid: 900913) and hence your map has to have the same projection.\n\nI&#39;ll like to expand the point raised by mkennedy\nAll of this further confused by that fact that often even though the map is in Web Mercator(EPSG: 3857), the actual coordinates used are in lat-long (EPSG: 4326). This convention is used in many places, such as:\n\nIn Most Mapping API,s You can give the coordinates in Lat-long, and the API automatically transforms it to the appropriate Web Mercator coordinates.\nWhile Making a KML, you will always give the coordinates in geographic Lat-long, even though it might be showed on top of a web Mercator map.\nMost mobile mapping Libraries use lat-long for position, while the map is in web Mercator.\n\n This convention is used in many places, such as:\n\nIn Most <span class=\"highlight\">Mapping</span> API,s You can give the coordinates in Lat-long, and the API automatically transforms it to the appropriate Web Mercator coordinates. &hellip; Most mobile <span class=\"highlight\">mapping</span> Libraries use lat-long for position, while the map is in web Mercator. &hellip; "
    },
    {
        "question": "EPSG 3857 or 4326 for Web Mapping",
        "area": [
            "coordinate-system",
            "leaflet",
            "openstreetmap",
            "google-maps",
            "web-mapping"
        ],
        "text": "The discussion at What is the difference between WGS84 and EPSG4326? shows that 4326 is just the EPSG identifier of WGS84..\n\nWikipedia entries for Google Maps and OpenStreetMap shows that they both use  WGS 84.\n\nhttp://wiki.openstreetmap.org/wiki/EPSG:3857 states that \n\nEPSG:3857 is a Spherical Mercator projection coordinate system popularized by web services such as Google and later OpenStreetMap. \n\nLeaflet&#39;s help states:\n\nEPSG3857 The most common CRS for online maps, used by almost all free and commercial tile providers. Uses Spherical Mercator projection. Set in by default in Map&#39;s crs option.|\n\nEPSG4326 A common CRS among GIS enthusiasts. Uses simple Equirectangular projection.\n\nThis is confusing - it seems that Google Maps and OpenStreetMap use EPSG3857 but they use WGS84 which &#39;is&#39; EPSG4326. Something can&#39;t be right here, most likely my understanding. \n\nCould someone help me understand?\n The discussion at What is the difference between WGS84 and EPSG4326? shows that 4326 is just the EPSG identifier of WGS84..\n\nWikipedia entries for Google Maps and OpenStreetMap shows that they both us &hellip; "
    },
    {
        "question": "Comparing various JavaScript mapping libraries?",
        "area": [
            "javascript",
            "web-mapping"
        ],
        "text": "I am working on a web-based mapping system and I&#39;m trying to figure out which library to use.\n\nThese are links to comparisons of available libraries:\n\n\nLaurent Jegou&#39;s benchmark (from 2010) is a global outlook on web mapping solutions (both client and server).\ncomparison of FOSS libraries by German Carrillo can be found here:\n\n\n\n\nThe list of libraries so far:\n\n\nGoogle Maps\nMicrosoft Virtual Earth\nMapQuest\nLeaflet - &quot;The comment smaller, faster, newer, and more straightforward can also be read as less features and less tested.&quot; -Geographika (see below) \nArcGIS API for JavaScript - Works best with ArcGIS Server (see below). Google Maps and Bing maps extensions are also available, letting you use the ESRI API with Google/Bing maps (though this is true of most libraries).\nYahoo Map API&#39;s\nVia Michelin\nOpenLayers - Extensive documentation and a good amount of functionality plus the ability to use different map providers. \nMapquery - MapQuery has been released and now has some useful documentation It has the very worthwhile goal of combining OpenLayers and jQuery. If you&#39;re particularly keen on the idea of OpenLayers + jQuery, or if you want to contribute to a JavaScript Mapping Library then get involved and contribute your efforts. However if you just want to be an end user, or are new to this area it may not be for you.\nMapstraction - Makes things very simple, especially working with multiple basemap providers. However it is still a work in progress and the functionality is lacking in places, as is the documentation. (E.g. &quot;A GeoJSON object with the type \u201cFeatureCollection\u201d is a feature collection object.&quot; Not very informative.) It appears that it is still being actively developed but as of 4/4/11 there hasn&#39;t been a commit on Github since January.\ndeCarta - Has a mobile and desktop javascript - first is HTML5/CSS3 compliant and the second has more browser compatibility. Source code provided. Friendliest developer terms for a commercial API. You are allowed to brand the map and there are several different map styles. You can choose NAVTEQ or OSM data. They also have several Mobile APIs as well. - edited by TheSteve0 - a deCarta employee\nCloudmade\nPolymaps - Makes it very easy to composite raster and vector data from many different sources. Lets you easily add your own colouring, grouping, and interaction. Runs quickly, manages background tile loading well, and is only 30k of Javascript. One potential down side: it uses SVG which means it does not and will not work in MSIE 7 or 8. It works great in every other browser and should work in IE9\nJump - jump is a light weight maps library that works on its own, meaning, it is not a wrapper for OpenLayers or GoogleMaps API. Currently it is under development, but a lot of essential features work well.\nModestMaps - Another smaller, faster, newer JS mapping library from the makers of Mapbox and TileMill. \nMapiator\n\n\nOpenLayers is the one I am currently using. You can do a lot with it and it supports most data types. However it&#39;s not the best for everything. For example, Leaflet seems smoother in many ways, with image fading and other visual tweaks. If you&#39;re into jQuery you might like to check out MapQuery which is like a combination of jQuery and OpenLayers.\n I am working on a web-based <span class=\"highlight\">mapping</span> system and I&#39;m trying to figure out which library to use. &hellip; ModestMaps - Another smaller, faster, newer JS <span class=\"highlight\">mapping</span> library from the makers of Mapbox and TileMill. \nMapiator\n\n\nOpenLayers is the one I am currently using. &hellip; "
    },
    {
        "question": "Does Y mean latitude and X mean longitude in every GIS software?",
        "area": [
            "coordinate-system",
            "mapinfo",
            "latitude-longitude"
        ],
        "text": "I am using Mapinfo and it has Y as latitude and X as longitude. Is that the same case for all mapping software? As for any country their respective value is multiple of 1 or -1. So for Nepal can I say it is on positive side +1 for both latitude and longitude? And for USA to be +1 Y and -1 X.\n Is that the same case for all <span class=\"highlight\">mapping</span> software? As for any country their respective value is multiple of 1 or -1. So for Nepal can I say it is on positive side +1 for both latitude and longitude? &hellip; "
    },
    {
        "question": "Measuring accuracy of latitude and longitude",
        "area": [
            "coordinates",
            "latitude-longitude",
            "gis-principle",
            "accuracy",
            "precision"
        ],
        "text": "Here&#39;s my rule of thumb table...\n\nLatitude coordinate precision by the actual cartographic scale they purport:\n\n\n of a strand of hair.\n10               10 microns         A speck of pollen.\n11               1.0 micron         A piece of cigarette smoke.\n12               0.1 micron         You&#39;re doing virus-level <span class=\"highlight\">mapping</span> &hellip; What are you <span class=\"highlight\">mapping</span>? &hellip; "
    },
    {
        "question": "Comparing various JavaScript mapping libraries?",
        "area": [
            "javascript",
            "web-mapping"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\nFor non-GIS background devs creating single-function mapping apps - I&#39;d probably recommend Leaflet (now supported by MapBox). Easy to use and small. More functionality relies on plugins of varying quality and support. \n\nGIS online type application - use OpenLayers3 - has the full suite of data sources, controls etc. in a single library. It can also be used for simple mapping apps, so if you have a mix then I&#39;d use this for everything. \n\nGoogle still has the library/data combination (e.g. StreetView is not available anywhere else). \n\nEsri has GUI web app builders, and as noted below, why complicate things if you already use their stack. \n\nCommercial APIs (Google, Bing, Yahoo)\n\nUsing any commercial API leaves you at the mercy of whatever changes the provider makes to the API or Terms of Service. What happens for example if suddenly your local government portal that uses Google Maps suddenly has adverts popping up all over it? Want to reuse your JavaScript Google Maps code for an Intranet site? You&#39;ll find yourself having to pay the $10,000 licencing fee. \n\nMicrosoft often have more defined and fixed terms for their services (if paying) so there may be less of a risk here. \n\nThe recent backlash against Twitter is a good example of developers having an API that changed beneath them. If you aren&#39;t paying for a service then you (or your system) are the one being sold. \n\nGoogle started charging for use of their maps from October 2011. \n\nEsri\n\nAs others have mentioned if you are using an Esri stack then the ArcGIS API for JavaScript will no doubt work well on top of it. Coming from a GIS background Esri have probably thought more about traditional GIS tasks and features than the &quot;neo-geography&quot; web-giants (though this is just an opinion/feeling). \n\nOpenLayers has built in support for ArcGIS REST layers, and if you are looking to reuse your code for non-ESRI based websites then again an open API serves you best. \n\nUse OpenLayers...\n\nI can&#39;t really think why developers would use an API other than OpenLayers. Open Source projects lead to related Open Source projects so there are a wealth of reusable components out there such as the GeoExt library, MapQuery,  and GeoPrisma. \n\nI&#39;ll just add that just because a project is Open Source does not automatically make it better than commercial equivalents - but the OpenLayers API matches the commercial competition in this case, and the ability to see how the source works, the unit tests, the build scripts etc. mean that you can easily build new features on top of it. \n\nThere has been some recent criticism of OpenLayers, mainly related to complexity, styling, and size. There have been counter-arguments made to these here and here by Christopher Schmidt one of the lead developers of OpenLayers. \n\nIt is worth noting that if you need a simple Open Source mapping API then take a look at Cloudmade&#39;s Leaflet. \n\nThe comment smaller, faster, newer, and more straightforward can also be read as less features and less tested.\n\nScan the API documentation for Leaflet and OpenLayers. The latter includes items such as WFS layers, editing tools, and SLD support. It has also been tested in many different environments, and works in IE6 (allowing government and local authority users). \n\nFor simpler display of spatial data Leaflet looks ideal, and easier to get started. However I&#39;ll be sticking with OpenLayers for more feature-rich GIS applications. \n\nCaveats\n\nOne possible downside is often new innovations are seen first in commercial providers&#39; systems - however these nearly always filter through to OpenLayers in time. \n\nFinally I&#39;m sure there are certain scenarios where other APIs are more suitable - on custom hardware, to fit in with an organisations other IT systems, or if you already know an API inside-out and can get a system developed in half the time. \n\nAll the APIs you mentioned are capable of producing great online mapping systems, but your choice should also fit in with you or your company&#39;s future development needs. \n For non-GIS background devs creating single-function <span class=\"highlight\">mapping</span> apps - I&#39;d probably recommend Leaflet (now supported by MapBox). Easy to use and small. &hellip; It is worth noting that if you need a simple Open Source <span class=\"highlight\">mapping</span> API then take a look at Cloudmade&#39;s Leaflet. &hellip; "
    },
    {
        "question": "Seeking examples of beautiful maps?",
        "area": [
            "cartography"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\nRADICAL CARTOGRAPHY showcases couple of really nice examples. \n\nMy two favourites:\n\n\nMississippi meanders\n\n\n\n\n\nStatistical Atlas of 1870 US Census\n\n\n\n\n\n\nEduard Imhof&#39;s work, especially his hand-drawn hillshading maps:\n\n\n\n\n\nAs the question does not specify that a map has to be a traditional static map, I would like to propose the Mapnificent London travel times map.\n\n\n\nAs per usualy, Google are really pushing what you can do with Online Mapping APIs.\nIn terms of map design, the v3 API now gives you greater control over tweaking the underlying base map.\n\nThe map is also very user-friendly, but I think usability probably falls outside the realm of beauty.\n As per usualy, Google are really pushing what you can do with Online <span class=\"highlight\">Mapping</span> APIs.\nIn terms of map design, the v3 API now gives you greater control over tweaking the underlying base map. &hellip; "
    },
    {
        "question": "When to use ModelBuilder over Python scripting and vice versa?",
        "area": [
            "arcgis-desktop",
            "arcpy",
            "modelbuilder"
        ],
        "text": "I believe that the user should clearly define their objectives before deciding which set of tools to use.  ModelBuilder and Python scripting excel at different tasks.  A few thoughts: \n\n\nModelBuilder has no mapping capabilities, whereas\narcpy.mapping does.\nPython can be used to optimize workflows, such as with the\nmultiprocessing package or with parallel processing.\nPython allows for nested loops and other handy iterative logic\ntools.  To accomplish a similar result in ModelBuilder, you would\nhave to construct intricate, and complicated, nested models.\nSimple text manipulation is very easy with Python and either very\ndifficult or not possible with ModelBuilder.\n\ne.g. to rename a list of file names from, for example &quot;m_2010_naip_2310345_nw.img&quot; to &quot;2310345nw.img&quot; can easily be accomplished with Python using the  module.\n\n\nOn the other hand:\n\n\nModelBuilder is very useful for quickly putting together common tools\nand eliminating the need for debugging scripts.\nModelBuilder has a very useful recursive iterator that is easy to\nimplement in order to loop through folders and subfolders.\nModelBuilder excels at visually and intuitively depicting the workflow for\ncomplicated tasks.\nModelBuilder can incorporate Python script tools.\n\n A few thoughts: \n\n\nModelBuilder has no <span class=\"highlight\">mapping</span> capabilities, whereas\narcpy.mapping does. &hellip; "
    },
    {
        "question": "Displaying coordinates and inputs as LatLon or LonLat?",
        "area": [
            "labeling",
            "coordinate-system",
            "annotation",
            "latitude-longitude"
        ],
        "text": "I&#39;m trying to get a sense if this is an issue for others or every input/output should be labeled so user is not confused and just go with it?\n\nI think almost everyone pronounces it as &quot;LatLon&quot;.  \n\nWho started it?  \n\nIs it because it&#39;s in alphabetical order compared to &quot;LonLat&quot;?  \n\nMapping Lat and Lon to Cartesian plane Lon is &quot;x&quot; and Lat is &quot;y&quot; so since we say &quot;(x,y)&quot; it should be said as &quot;LonLat&quot;.  And now for display of information.  \n\nShould the status bar on a mapping application display La,Lo or Lo,Lat?  \n\nShould it just be labeled as one way and let user deal with it?  \n\nAnd same with input, what&#39;s the right way to order the fields?\n\nKML&#39;s format is Lon,Lat,Altitude.  While other apps is Lat,Lon and so have to be very vigilant about when converting formats.\n\nIs there a standard?\n <span class=\"highlight\">Mapping</span> Lat and Lon to Cartesian plane Lon is &quot;x&quot; and Lat is &quot;y&quot; so since we say &quot;(x,y)&quot; it should be said as &quot;LonLat&quot;.  And now for display of information. &hellip; Should the status bar on a <span class=\"highlight\">mapping</span> application display La,Lo or Lo,Lat?  \n\nShould it just be labeled as one way and let user deal with it? &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "I want to start working on a web map at work to map some of our statistics by city.  \n\nI have an idea, but I&#39;m not exactly sure where to start. \n\nAre there any definitive resources that provide step by step guidance on how to do this?\n I want to start working on a web map at work to map some of our statistics by city.  \n\nI have an idea, but I&#39;m not exactly sure where to start. \n\nAre there any definitive resources that provide step b &hellip; "
    },
    {
        "question": "How accurate is approximating Earth as sphere?",
        "area": [
            "coordinate-system",
            "distance",
            "spherical-geometry",
            "datum",
            "accuracy"
        ],
        "text": "What level of error do I encounter when approximating the earth as a sphere? Specifically, when dealing with the location of points and, for example, the great circle distances between them.\n\nAre there any studies on the average and worst case error compared to an ellipsoid? I&#39;m wondering how much accuracy I&#39;d be sacrificing if I go with a sphere for the sake of easier calculations.\n\nMy particular scenario involves directly mapping WGS84 coordinates as if they were coordinates on a perfect sphere (with the mean radius defined by the IUGG) without any transformation.\n My particular scenario involves directly <span class=\"highlight\">mapping</span> WGS84 coordinates as if they were coordinates on a perfect sphere (with the mean radius defined by the IUGG) without any transformation. &hellip; "
    },
    {
        "question": "Learning ArcPy?",
        "area": [
            "arcpy",
            "references"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nLook at posts here and on other websites that use Python scripts and try to deconstruct them and see what techniques the authors are using to accomplish their task.  Our self-assembling FAQ on ArcPy is well worth reviewing for this purpose.\nYou will find it educational to try to solve other people&#39;s problems.  We have a self-assembling list of unanswered questions on ArcPy to help you find them.\nDo not forget that you can right-click any geoprocessing result and click &quot;Copy as Python Snippet&quot; if you just want to get the syntax of a function call, which is especially useful for things like field mappings and code blocks.  It is also possible to export ModelBuilder models to Python code, but there is no guarantee that the code exported from a working model will also work in Python, and for all but the simplest models the code that results is often difficult for beginners to debug.\nArcGIS Documentation:\nRead the help files!!  90% of ArcPy is just the same as using the GUI tools, only you are starting them using Python.  The help files all have example Python code at the bottom.\n\nWhat is ArcPy? is the front page to Help on using ArcPy with ArcMap from versions 10.3 - 10.8\n\n\n\nArcGIS Desktop Help (9.3)\nArcGIS Desktop Help (10)\nArcGIS Desktop Help (10.1)\nArcGIS Desktop Help (10.2)\nArcGIS Desktop Help (10.3)\nArcGIS Desktop Help (10.4)\nArcGIS Desktop Help (10.5)\nArcGIS Desktop Help (10.6)\nArcGIS Pro Help\nPython migration from 10.x to ArcGIS Pro\nArcGIS for Python API (not ArcPy)\n\nOnline Books:\n\nHow to Think Like a Computer Scientist\nDive into Python\nA Byte of Python (2.x)\nLearn Python the Hard Way\n\nOnline Courses:\n\nCodecademy Python Track offers free online coding lessons, including Python.  Use this to get the feel of how Python works before working on ArcPy.\nGoogle\u2019s Python Class\nPenn State \u2013 GEOG 485 \u2013 GIS Programming and Automation\nArcPy for Python Developers using ArcGIS Pro\n\nTutorials:\n\nNon-Programmer\u2019s Tutorial for Python 2.6\nOfficial Python Tutorial (2.5.4)\nOfficial Python Tutorial (2.6.5)\nOfficial Python Tutorial (2.7)\nDoug Hellmann&#39;s Python Module of the Week (PyMOTW) site\nCode Like a Pythonista: Idiomatic Python\nProgression path - using Python for GIS: from apprentice to guru\n\nPython Documentation:\n\nPython.org\nPython 2.5.4 Documentation (for ArcGIS 9.3)\nPython 2.6.5 Documentation (for ArcGIS 10)\nPython 2.7 Documentation (for ArcGIS 10.1-10.6)\nPython 3.6 Documentation (for ArcGIS Pro)\n\nPresentations:\n\nGetting Started with Python in ArcGIS 10 (from 2010)\nArcGIS Geoprocessing: Python Scripting \u2013 Advanced Techniques (from 2009)\nPython Scripting for Map Automation in ArcGIS 10 (from 2010)\n\nPaper Books:\n\nPython in a Nutshell, 2nd Ed\nLearning Python, 3rd Ed\nProgramming Python, 3rd Ed\nPython Cookbook, 2nd Ed\nA Python Primer for ArcGIS\nPython Scripting for ArcGIS\nGIS Tutorial for Python Scripting (coming June 2014)\n\nUser Communities:\n\nStack Overflow\nGIS Stack Exchange\nESRI Python Forum\nESRI Geoprocessing Forum\n\nBlogs:\n\nESRI Geoprocessing Blog\nESRI ArcGIS Desktop Blog\nArcGIS Team Python blog\n\nSample Code:\n\nArcScripts\nGeoprocessing Model and Script Tool Gallery\n\nTools/Integrated Development Environments (IDEs) - Non-commercial:\n\nPythonWin\nPyScripter\nPyDev (plug-in for the Eclipse software development environment)\nPython Tools for Visual Studio\nWinpdb (debugger)\n\nModules/Frameworks:\n\nDjango (web application framework)\ncomtypes (for using ArcObjects in Python)\nscipy/numpy\nPyPI - the Python Package Index\nSeeking Python tools/modules/add-ins for GIS?\n\nAlso see these general tips for new Python programmers in this answer to Exporting mxds into pdfs using ArcPy?.\n \nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It &hellip; "
    },
    {
        "question": "What Makes a Map be classed as Badly Designed?",
        "area": [
            "cartography"
        ],
        "text": "A poorly designed map can not only look visually unappealing, but can convey the wrong message, which could lead to bad decisions being made.\n\nI would like to ask people to post examples (that are in the public realm) of poorly designed maps, WITH justification on why it is bad design.   \n\nAlthough this &#39;question&#39; does not have a clear answer, I think it will prove a useful resource to see what merits bad design, so others can learn what NOT to do.  I will let the votes choose the &#39;right&#39; answer.\n\nI would also like to see examples of bad design around web-mapping.\n\nI would argue that although GIS Professionals generally know how to create a good looking map, I would say that they also have a tendency to over-complicate web-maps, by trying to re-create a GIS desktop application on the web:\n\nAlso slow to use, and hard to even get to the map.\n\nI think now that normal people are more used to Google Maps style/simplicity, web-maps should follow a similar approach.\n\nWith the explosion of &#39;NeoGeography&#39; particularly in the web realm, we now have a lot of non-GIS professionals creating maps for the web.  A lot of these developers are often very good at user-interface design, but not trained in cartographic principles.\n\nI think, with web maps, its all about combining the skills of both cartography and user interface design.\n I would also like to see examples of bad design around web-<span class=\"highlight\">mapping</span>. &hellip; "
    },
    {
        "question": "Writing Shapely geometries to shapefiles",
        "area": [
            "python",
            "shapefile",
            "shapely"
        ],
        "text": "Well-known binary is a good binary exchange format that can be exchanged with plenty of GIS software, including Shapely and  GDAL/OGR.\nThis is a tiny example of the workflow with :\n\n\nAlthough the poster has accepted the GDAL/OGR answer, here is a Fiona equivalent:\n\n geom = None  # destroy these\n\n# Save and close everything\nds = layer = feat = geom = None\n\n\nAlthough the poster has accepted the GDAL/OGR answer, here is a Fiona equivalent:\nfrom shapely.geometry import <span class=\"highlight\">mapping</span> &hellip; int&#39;},\n}\n\n# Write a new Shapefile\nwith fiona.open(&#39;my_shp2.shp&#39;, &#39;w&#39;, &#39;ESRI Shapefile&#39;, schema) as c:\n    ## If there are multiple geometries, put the &quot;for&quot; loop here\n    c.write({\n        &#39;geometry&#39;: <span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Reading attribute values using PyQGIS",
        "area": [
            "qgis",
            "pyqgis",
            "fields-attributes",
            "values"
        ],
        "text": "To loop over every feature in a layer, use the  generator. This returns an iterator of features () in the layer.\n\nIf you&#39;re only interested in a particular feature, instead of all of the features in the layer, you can access it using the  and its :\n\nOnce you have a  object you can use the  method to retrieve the attributes (a.k.a. columns or fields) associated with that feature (a.k.a. row), e.g.:\n\nIf you want to index the field by its name, rather than a number, you need to use the field mappings:\n\nThe field index shouldn&#39;t change during the loop, so you only need to call it once.\nThere is more information and examples in the PyQGIS cookbook:\nhttp://www.qgis.org/pyqgis-cookbook/vector.html#iterating-over-vector-layer\nYou can access feature attributes much more easily by using the  like a , e.g.\n\nI&#39;m not sure which version came in or if it&#39;s always been there.\n To loop over every feature in a layer, use the getFeatures() generator. This returns an iterator of features (QgsFeature) in the layer.\nfor feature in layer.getFeatures():\n    pass # do something with &hellip; "
    },
    {
        "question": "Seeking QGIS user interface tutorials and web resources",
        "area": [
            "qgis",
            "qgis-3",
            "references"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\nFor QGIS 3.x users:\n\n\nQGIS User Manual - includes both 2.x and 3.x documentation and links to many of the resources listed here\nGIS SE&#39;s self-assembling FAQ on QGIS 3.0\nQGIS Planet blog for more technical and development stuff.\n\n\nFor QGIS 3.x developers:\n\n\nGIS SE&#39;s self-assembling FAQ on PyQGIS in QGIS 3.0\n\n\n\n\nFor QGIS 2.x users:\n\n\nQGIS Training Manual ... covers a wide range of topics\nQGIS User Manual\nQGIS Tutorials and Tips\nLearning QGIS ... if you already know GIS concepts and you are looking for a resource to quickly get started using QGIS\nQGIS Map Design ... for tutorials on making maps\nA Gentle Introduction to GIS Brought to you with Quantum GIS, a Free and Open Source Software GIS Application for everyone; by T. Sutton, O. Dassau, M. Sutton - 115 page manual for beginners with video lectures [here][49]\nDesktop GIS: Mapping the Planet with Open Source Tools by Gary E. Sherman\nQGIS Workshop from Harvard University\nTutorial: QGIS basics for Journalists from UC Berkeley\nIntroducing GIS worksheets\n\n\nFor QGIS 2.x developers:\n\n\nGeneral API documentation\nPyQGIS Cookbook ... on developing python plugins\nMy own notes on developing Python plugins\n\n Sutton - 115 page manual for beginners with video lectures [here][49]\nDesktop GIS: <span class=\"highlight\">Mapping</span> the Planet with Open Source Tools by Gary E. &hellip; "
    },
    {
        "question": "Bypassing 10 character limit of field name in shapefiles?",
        "area": [
            "shapefile",
            "geotools",
            "dbf"
        ],
        "text": "I&#39;m exporting geometry with attached text attributes from oracle database to esri shapefile format (.shp) with Java and Geotools library.\n\nAttribute columns in our database have names with more than 10 characters, and Geotools forces to truncate them. I understand that it&#39;s due to .shp or .dbf files specification.\n\nI can workaround this, by creating some simple txt file with &quot;shrtname&quot;=&quot;The full and long name&quot;, but obviously it won&#39;t be understand and imported by any other software than ours.\n\nIs there official way to do the mapping from short field names to long full-text names?\n\nFor example, xml file next to all other .shp .dbf .shx files.\n Is there official way to do the <span class=\"highlight\">mapping</span> from short field names to long full-text names?\n\nFor example, xml file next to all other .shp .dbf .shx files. &hellip; "
    },
    {
        "question": "One dimensional map of the world?",
        "area": [
            "cartography",
            "coordinate-system"
        ],
        "text": "Bit of a strange question but hope this is OK to ask here.\n\nHas anyone heard of a &#39;1-dimensional&#39; projection of the world map - that is mapping all the points on the globe to a single line?\n\nI was thinking of doing such a thing - trying to keep cities that are &#39;close&#39; on the globe &#39;close&#39; on the line. \n\nBefore I do this, I wondered what the state of the art might be in this area? \n Has anyone heard of a &#39;1-dimensional&#39; projection of the world map - that is <span class=\"highlight\">mapping</span> all the points on the globe to a single line? &hellip; "
    },
    {
        "question": "Why is the &#39;straight line&#39; path across continent so curved?",
        "area": [
            "coordinate-system",
            "google-maps",
            "distance",
            "spherical-geometry",
            "curvature"
        ],
        "text": "This is the result of mapping the straight line path from a point in US to Poland using Distance Measurement Tool.\n\nAlso, planes from Asia to US would travel almost over North Pole.\n\n\n\nWhy is the path so curved? I agree that this is a flat representation of a sphere, so I do expect some arc, but I don&#39;t think earth has this much curvature.\n\nWhat am I missing here?\n This is the result of <span class=\"highlight\">mapping</span> the straight line path from a point in US to Poland using Distance Measurement Tool.\n\nAlso, planes from Asia to US would travel almost over North Pole. &hellip; "
    },
    {
        "question": "Why has Web Mercator (auxiliary sphere) become the web map standard?",
        "area": [
            "arcgis-server",
            "coordinate-system",
            "google-maps",
            "web-mapping",
            "cartography"
        ],
        "text": "I understand what the difference is between the Web Mercator projection and Web Mercator Auxiliary Sphere (WMAS). I also understand that both Google and Esri have adopted this projection as their primary projection for their web-maps which is why we have specialized functions that not only re-project between all projections, but are specific functions for WM, such as webMercatorToGeographic. So ultimately I was wondering why we use the WMAS projection, and the reason it has become a standard in web mapping. Is it a purely a result of two spatial giants moving in that direction or was it just solely because of accuracy reasons?\n\nAdditional Links:\nMercator Projection\n So ultimately I was wondering why we use the WMAS projection, and the reason it has become a standard in web <span class=\"highlight\">mapping</span>. &hellip; "
    },
    {
        "question": "Alternatives to ArcGIS Online?",
        "area": [
            "web-mapping",
            "software-recommendations"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nThere are quite a few alternatives and I&#39;ve actually written a short book on the subject entitled &quot;Online GIS - Meet the Cloud Publication Platforms that Will Revolutionize our Industry&quot; but that&#39;s a little outdated now.\nHere&#39;s an updated summary:\nMangoMap: Very easy to use, no coding required. Lots of tools and functionality available to make really polished map applications. Much more competitive pricing than ArcGIS Online organisational accounts.\nGISCloud: Online alternative to traditional client/server GIS setup. Many features but hampered by a frustrating user interface.\nMapBox: Making maps sexy again. Programmer focused. Great for maps that need to fit a brand and be able to scale for high traffic. Good fit for consumer internet sites.\nCartoDB: Attractive UX and scales very well. Also lets you preserve the Google Maps experience for end users. Postgres + postgis database on the cloud with a set of API&#39;s on top of it to fetch/save and render data.\nDisclosure: Original answer posted by Founder of MangoMaps and includes  an edit by the CTO of CartoDB - these two products are described in this answer.\n\nI&#39;ve had good luck using GeoCommons for more lightweight mapping.\nThe upside is that the service is free within a certain limit, and includes some fairly powerful analysis tools. I believe any mapping is free if using or creating open data, and while my organization did not end up paying for the service, the prices seemed reasonable.\nI didn&#39;t realize until I visited today, though, that this service is now a part of esri, so their terms may have changed.\n I&#39;ve had good luck using GeoCommons for more lightweight <span class=\"highlight\">mapping</span>.\nThe upside is that the service is free within a certain limit, and includes some fairly powerful analysis tools. &hellip; I believe any <span class=\"highlight\">mapping</span> is free if using or creating open data, and while my organization did not end up paying for the service, the prices seemed reasonable. &hellip; "
    },
    {
        "question": "What free programs should every GIS user have installed?",
        "area": [
            "open-source-gis",
            "software-recommendations",
            "free-software"
        ],
        "text": "Benjamin already mentioned SAGA GIS, but just the name so I would like to add more info about this excellent SW:\n\nSAGA (System for Automated Geoscientific Analyses)\n\n\n\nSAGA is also free and opensource like QGIS, but it is focused on raster data analysis and processing.\n\nThe standard modules are:\n\n\nFile access: interfaces to various table, vector, image and grid file formats, including shapefiles, Esri grids (ASCII and binary), and numerous grid file formats that are supported by the GDAL library, in addition to the native SGRD format of SAGA GIS.\nFilter for grids: Gaussian, Laplacian, multi-directional Lee filter.\nGridding: interpolation from vector data using triangulation, nearest neighbour, inverse distance. (my favourite is Multilevel B-Spline interpolation)\nGeostatistics: residual analysis, ordinary and universal kriging, single and multiple regression analysis, variance analysis.\nGrid calculator: combine grids through user defined functions.\nGrid discretisation: skeletonisation, segmentation.\nGrid tools: merging, resampling, gap filling.\nImage classification: cluster analysis, box classification, maximum likelihood, pattern recognition, region growing.\nProjections: various coordinate transformations for vector and grid data (using Proj4 and GeoTrans libraries), georeferencing of grids.\nSimulation of dynamic processes: TOPMODEL, nitrogen distributions, erosion, landscape development.\nTerrain analysis: geomorphometrical calculations such as slope, aspect, curvatures, curvature classification, analytical hillshading, sink eliminition, flow path analysis, catchment delineation, solar radiation, channel lines, relative altitudes.\nVector tools: polygon intersection, contour lines from grid.\n\n\nAccording to the users it can partially replace commercial tools like Spatial analyst in ArcGIS and some people say, that the hydrological tools are even better than ArcHydroTools.\n\nIn my opinion it is good choice for people who are not familiar with GRASS and who need user friendly and free solution which can share data with other GIS tools.\n\nI use it together with QGIS and it works really nice - SAGA for raster data, QGIS for vectors and final map finishing and for quick mapping.\n I use it together with QGIS and it works really nice - SAGA for raster data, QGIS for vectors and final map finishing and for quick <span class=\"highlight\">mapping</span>. &hellip; "
    },
    {
        "question": "One dimensional map of the world?",
        "area": [
            "cartography",
            "coordinate-system"
        ],
        "text": "A general technique for mapping a collection of points (for which distances are given) into a Euclidean space (such as three-space, a plane, or even a line) with minimal distortion of the distances is called Multidimensional Scaling (MDS).  There are several algorithms.  Solutions are freely available in R and often are supplied with commercial statistics packages.\n\nThe largest 20 cities in the US are mapped here with Stata 11&#39;s default MDS settings.  The ticks denote 100 km intervals.\n\n\n A general technique for <span class=\"highlight\">mapping</span> a collection of points (for which distances are given) into a Euclidean space (such as three-space, a plane, or even a line) with minimal distortion of the distances is &hellip; "
    },
    {
        "question": "Map material from China not allowed to leave that country",
        "area": [
            "data",
            "license",
            "china"
        ],
        "text": "I am not sure if the context of your question is really on-topic here, but since the answer and its implications is very much relevant for travellers as well, I&#39;ll give it a try.\n\nThe explanation you have read is not entirely accurate. The problem is that accurate map material is neither allowed to be published, nor to leave the country. The Chinese National Bureau of Surveying and Mapping require all companies to obtain permits for map surveying and published map data must be obfuscated, resulting in a deviation of up to 700m between the map and the real world. Sounds strange, but that is how it is.\n\nYou can easily see the result of this obfuscation if you e.g. in Google Maps look at the satellite imagery with a map overlay. It is especially obvious in border proximity, where you will see that the map data for China is skewed, while the map outside China is correct. If you look at this area, the Shenzhen Bay with the border between China and Hong Kong, you can see that the map over Hong Kong in the lower right area is correct, while in the middle of the bay, the map seem to indicate that the bridge makes a sharp bend to the right, while you on the satellite image can see that the bridge in reality is straight. In the upper left area (mainland China), you can then see that there is a significant discrepancy between the imagery and the map. Roads seem to float on the water, pass through buildings and what else not.\n\nSome additional information based on questions in the comments:\n\nThe Chinese Surveying and Mapping Law does not explain why the restriction is in place. It is commonly quoted that it is for national security purposes, but I am not really sure if there is any official statement on that subject at all. Similar regulations and restrictions are actually quite common in many other countries as well, but usually do not apply to the entire country, just to &#39;places of interest&#39;.\n\nThe obfuscation algorithm is prespecified, not publicly known, but is obviously deterministic. Since a lot of example data is available, there have been attempts to reverse-engineer the algorithm and there are more or less reliable software libraries available allowing a backwards mapping from obfuscated to real coordinates. There is more information and links to further resources on the Wikipedia page &#39;Restrictions on geographic data in China&#39;.\n The Chinese National Bureau of Surveying and <span class=\"highlight\">Mapping</span> require all companies to obtain permits for map surveying and published map data must be obfuscated, resulting in a deviation of up to 700m between &hellip; Some additional information based on questions in the comments:\n\nThe Chinese Surveying and <span class=\"highlight\">Mapping</span> Law does not explain why the restriction is in place. &hellip; "
    },
    {
        "question": "Comparing various JavaScript mapping libraries?",
        "area": [
            "javascript",
            "web-mapping"
        ],
        "text": "There is a new player on javascript mapping front - Leaflet. Developed by CloudMade under BSD licence.\n\nLooks really promising.\n\n\n\n(Source)\n There is a new player on javascript <span class=\"highlight\">mapping</span> front - Leaflet. Developed by CloudMade under BSD licence.\n\nLooks really promising.\n\n\n\n(Source) &hellip; "
    },
    {
        "question": "Enabling CORS in GeoServer (jetty)?",
        "area": [
            "geoserver",
            "cors",
            "jetty"
        ],
        "text": "Edit the  file. There are two references to CORS in this file:\n\n\n\n\n\nand \n\n\n\n\n\nYou must uncomment both blocks (that is remove  and  from the  and  blocks.\n\nThen when you restart Jetty you can test that everything is working by using a command like:\n\n\n\nwhich if all is well will give a result like:\n\n\n\nUpdate 24th Oct 2019\n\nIt it is no longer necessary to add the following jar to GeoServer (at least with versions 2.13.x and later) and it will cause an error. I&#39;m leaving this note here for people fighting older versions.\n\n\nAdd the Jetty-Utility Servlets Jar to match the version of Jetty - for current versions of GeoServer (2.15.x) it is 9.4.12.v20180830, copy this to  inside the geoserver-2.15.0 directory (or wherever you unpacked the zip file).\n\n -- Uncomment following filter to enable CORS --&gt;\n&lt;filter-<span class=\"highlight\">mapping</span>&gt;\n   &lt;filter-name&gt;cross-origin&lt;/filter-name&gt;\n   &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n&lt;/filter-<span class=\"highlight\">mapping</span>&gt;\n\n\n\nYou must uncomment both blocks (that is &hellip; -- and --&gt; from the filter and filter-<span class=\"highlight\">mapping</span> blocks. &hellip; "
    },
    {
        "question": "Turn on QGIS Dark Mode",
        "area": [
            "qgis"
        ],
        "text": "When you open  you should see .\n\n\n\nYou need to exit and restart to see the change.\n When you open Settings-&gt;Options-&gt;General you should see Night <span class=\"highlight\">Mapping</span>.\n\n\n\nYou need to exit and restart to see the change. &hellip; "
    },
    {
        "question": "Free GIS workshops, tutorials, and applied learning material",
        "area": [
            "references",
            "education"
        ],
        "text": "This Q&amp;A lists free as in $0 workshops in GIS and related fields that have their material available to view or download online. The list is not limited to FOSS GIS, as GISers usually use a combination of open and closed source tools to accomplish their tasks. Some of these tools are easier than others and some are better documented. This list will be a great benefit to the community especially for new comers to the field.\nGeneral GIS\n\nGIS Project Video Tutorial on Acquiring, Analyzing, and Mapping US Census Data in QGIS from @A.S\nGIS Tutor: Beginner / Intermediate Level GIS from @radek\nBostonGIS from @simo\nLectures on GIS for the Social Sciences from @ubernatural\n\nOpen-source GIS\n\nOpenGEO Education Center from @radek\nQGIS Videos (faunitalia) from @simo\nGIS SE Question: Geoserver Tutorials from @com\nGIS SE Question: Open Source Training Materials from @MarkIreland\nQGIS for Newbies from @IanAllan\n\nESRI Products\n\nGIS SE Question: Best place for (structured) ArcGIS tutorials from @robintw\nArcGIS Automation and Programming from @Bethany\n\nTransportation\nThese links include either theoretical or applied transportation knowledge in transportation planning\n\nGIS primer for Transportation\nTransit Capacity and Quality of Service Manual\nUrbanSim: FOSS Urban development, socio economic, and land use planning package\nMOVES(Motor Vehicle Emission Simulator) Workshop and technical background\nTransit GIS tutorials\nRemote sensing in transportation workshop\nFlorida&#39;s CBT planning model explained\n\nDisaster Management\n\nGeo-information Technology for Crisis Management \n\nDatabases\n\nSpatial Database Course Material from @radek\n\nGeo Statistics\n\nLearn R Lectures and Classes\nGeodatabase Mining Course from @radek\nA Practical Guide to Geostatistical Mapping\n\n General GIS\n\nGIS Project Video Tutorial on Acquiring, Analyzing, and <span class=\"highlight\">Mapping</span> US Census Data in QGIS from @A.S\nGIS Tutor: Beginner / Intermediate Level GIS from @radek\nBostonGIS from @simo\nLectures on GIS &hellip; for Crisis Management \n\nDatabases\n\nSpatial Database Course Material from @radek\n\nGeo Statistics\n\nLearn R Lectures and Classes\nGeodatabase Mining Course from @radek\nA Practical Guide to Geostatistical <span class=\"highlight\">Mapping</span> &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "Penn State has an Open Web Mapping class. It should be enough to teach you how web mapping works, and also the technologies involved. Most, if not all, of the tools used in the class are free so you cost shouldn&#39;t be a problem. Here&#39;s the Table of Contents:\nlink to course materials\nhttps://www.e-education.psu.edu/geog585/node/508\n\nLesson 0: Orientation\nLesson 1: Introduction to Open Web Mapping\nLesson 2: Web Map Servers (WMS)\nLesson 3: Web Feature Servers (WFS)\nLesson 4: Extensible Markup Language (XML)\nLesson 5: Advanced Web Map Servers\nLesson 6: Geographic Markup Language (GML)\nLesson 7: WFS Revisited\nLesson 8: Building a Web Mapping Application\nLesson 9: Building a Thin Custom Web Mapping Client\n\n Penn State has an Open Web <span class=\"highlight\">Mapping</span> class. It should be enough to teach you how web <span class=\"highlight\">mapping</span> works, and also the technologies involved. &hellip; Application\nLesson 9: Building a Thin Custom Web <span class=\"highlight\">Mapping</span> Client &hellip; "
    },
    {
        "question": "Obtaining up-to-date list of US ZIP Codes with Latitude and Longitude Geocodes?",
        "area": [
            "data",
            "geocoding",
            "united-states",
            "centroids"
        ],
        "text": "ZIP codes are a habitually abused geography.  It&#39;s understandable that people want to use them because they are so visible and well-known but they aren&#39;t well suited to any use outside the USPS.  ZIP codes aren&#39;t associated with polygons, they are associated with carrier routes and the USPS doesn&#39;t like to share those.  Some ZIP codes are points e.g.  a ZIP code may be associated with a post office, a university or a large corporate complex.  They are used to deliver mail.\n\nThe Census Bureau creates ZIP Code Tabulation Areas (ZCTA) based on their address database.  If it&#39;s appropriate to your work you could try taking the centroid of the ZCTAs.  ZCTA Geography from the 2010 Census is available on the Census Bureau website.\n\nSee also: ZIP Code Geography and Mapping \n See also: ZIP Code Geography and <span class=\"highlight\">Mapping</span> &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "Google Fusion Tables is looking promising with mapping and spatial queries\n\npros:easy to set up\n\ncons: all your data is on google servers (good? or bad?)\n\nhttp://sites.google.com/site/fusiontablestalks/stories\n\n\n\nNote: Lots of Media/News Companies are using it - Example Guardian UK Newspaper \nhttp://www.guardian.co.uk/environment/datablog/interactive/2011/mar/07/carbon-emissions-public-buildings-map\n\nThere is a neat Fusion Wizard now to get you set up faster\nhttp://gmaps-samples.googlecode.com/svn/trunk/fusiontables/fusiontableslayer_builder.html\n\nExamples:\nhttp://www.latimes.com/news/local/la-me-us-congress-census-map,0,4500533.htmlstory\n\nOne of the best:\nhttp://tinyurl.com/England-Deprivation-Mapped\n Google Fusion Tables is looking promising with <span class=\"highlight\">mapping</span> and spatial queries\n\npros:easy to set up\n\ncons: all your data is on google servers (good? or bad?) &hellip; "
    },
    {
        "question": "Is there a Carto CSS Gallery which also contains code?",
        "area": [
            "tilemill",
            "cartocss"
        ],
        "text": "Unfortunately, there isn&#39;t one yet. \n\nI&#39;ve asked myself the same thing occasionally but I&#39;ve found a handful of examples through the years that I&#39;ve drawn some inspiration and learned through. Unfortunately, most authors aren&#39;t putting their all or some of their work public. Also, there&#39;s been a couple small changes in carto, some of the code may not be 100% up to date or may not take advantage of carto&#39;s current capabilities and you&#39;ll also have to change things as people use different data types (postgis queries, shapefiles, json, etc) for your needs.\n\nhttps://github.com/andrewharvey/osm-hybrid-carto\n\nhttps://github.com/aaronlidman/Toner-for-Tilemill \n\nhttps://github.com/ajashton/simple-osm\n\nnice Transit map by Code for america participant jlord - https://github.com/codeforamerica/Transit-Map-in-TileMill \n\nhttps://github.com/mapbox/osm-bright - A great way to start learning carto. This is what really helped me to learn carto and I often use it as a base layer for projects or begin with it for a project. \nA fork of it. \n\nLA Times&#39; &#39;Quiet LA&#39; Map style \n\nPandonia - style made by flickr\n\nhttps://github.com/wboykinm/geosprocket-carto\n\nSome examples from Dane Springmeyer, Tilemill and mapnik developer These are very experimental and push the bounds of what can be done in Carto. \n\nA mapping style for humanitarian contexts from HOT, the humanitarian openstreetmap team. \n\nAdditionally, the cartocss port of the OSM default style mentioned by maning is a nice work.\n\nLastly, this one in my github repo is a decent take off of osm-bright as well: \n\nExperimenting with these styles and modifying them will really help you learn. \n\n\n\nCarto is also used in Mapbox-Studio-Classic (aka tilemill2) but the processing of source data is different because it uses vector tiles. You have to first convert your data source into a vector tile source before using it. \n\nThe following styles, written for use in Mapbox-Studio, use Mapbox-Streets as the source data unless noted. \n\nHigh-contrast black and white style similar aesthetics to Ello - viewable here  \n\nVetiver \n\nAn orienteering map made by Rafa of Mapbox - uses external data sources\n\nDarkly-Neon, from Stephen Smith \n\nn\\|/0, a Halloween-themed carto style that I made that uses numerous regular expressions. If you&#39;re looking to understand how to use regular expressions in Carto, this can help. Viewable here. \n\nLastly, as you experiment with Mapbox-streets as a data source, you&#39;ll also learn that some assumptions are baked into the data source. For example, you cannot display some POIs that are nodes in the #poi_label at a zoom level below 15 or 16. \n A <span class=\"highlight\">mapping</span> style for humanitarian contexts from HOT, the humanitarian openstreetmap team. \n\nAdditionally, the cartocss port of the OSM default style mentioned by maning is a nice work. &hellip; "
    },
    {
        "question": "What is the current Web Mercator projection code?",
        "area": [
            "coordinate-system",
            "google-maps",
            "openlayers-2",
            "epsg",
            "bing-maps"
        ],
        "text": "This has been an annoying problem for a while, and hopefully will no longer be an issue.  \n\n3857 looks to be the current and correct code (I hope, that&#39;s what all my tile caches are in!).\n\nUpdate 9/7/11 - as noted by Vadim below in comments, Esri did in fact revert back to 102100 from 3857 at Service Pack 1.  Oddly, ArcGIS Server with SP1 applied returns a WKID of 102100 for a web mercator map service, but in the Services Directory, a web mercator map service has a spatial reference of &#39;102100 (3857)&#39;. EPSG has no entry for 102100. Not sure why Esri has chosen this route, but Esri&#39;s 102100 and 3857 are treated as equivalent by their products.\n\nEPSG - (no direct link)\n\n\n  Code: EPSG::2008.114\n  Reporter: OGP\n  Request: Revisit spherical mercator used for some web mapping applications\n  Actions Taken: Deprecated ellipsoid 7059, datum 6055, method 9841, projection 19847, CRSs 4055 and 3785, tfm 15973. Added methods 1024 and 1026, proj 3856 and projCRS 3857.\n  Entity Types Affected: Ellipsoid; Datum; Coordinate Operation Method; Coordinate Operation; Coordinate Reference System\n  Codes Affected: 7059; 6055; 9841; 15973 19847; 4055 3785\n  Report Date (UTC): 2008-12-11\n  Closed Date (UTC): 2009-02-10\n\n\nOpenLayers  - \n\n\n  Today, there is an officially registered EPSG code 3857 whose projection is identical to EPSG:900913. (http://www.epsg-registry.org/export.htm?gml=urn:ogc:def:crs:EPSG::3857). So, if you need to combine overlay layers that are using either an alias or the official EPSG code with an OpenLayers SphericalMercator layer, you have to make sure that OpenLayers requests EPSG:3857 or other alias in stead of EPSG:900913.\n\n\nESRI - \n\n\n  @jamie - For a long time EPSG refused to assign a code to this coordinate system; therefore ESRI created the WKID codes 102113 and 102100.\n  When EPSG did assign a code, they used 3785, but later changed it to 3857. ArcGIS 10 will follow ESRI practice of using an EPSG code when one exists, and will advertise the coordinate system of the service as 3857. ArcGIS 10 and all Web APIs are being designed to recognize EPSG 3857, ESRI WKID 102113, and ESRI WKID 102100 as equivalent.\n\n EPSG - (no direct link)\n\n\n  Code: EPSG::2008.114\n  Reporter: OGP\n  Request: Revisit spherical mercator used for some web <span class=\"highlight\">mapping</span> applications\n  Actions Taken: Deprecated ellipsoid 7059, datum 6055, method &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "There are so many options out there and many great answers already. Two of my favorite choices that haven&#39;t already been listed here are CartoDB and MapBox. Both of these provide web based hosting and visualization of data and some very fancy tools with prices starting at FREE. \n\nYou&#39;ll benefit from having desktop software to get your data setup. ArcMap and Quantum GIS are both great choices for the desktop part. \n\nI&#39;d say the strength of MapBox is making beautiful web maps with really great, easy to use templates and ready to go user interface elements. MapBox requires a desktop program called TileMill (also free) which makes use of a styling interface very similar to CSS. \n\nThe strength of CartoDB is that it exposes its PostGIS roots through an SQL API. \n\nBoth of these can be used on their own or in combination with other javascript mapping libraries (e.g. Leaflet, Google Maps, OpenLayers).\n\nNo matter which platforms you decide to start using to get into web mapping, you will most certainly benefit from learning some javascript.  Codecademy is a great place to start (also FREE!!).\n Both of these can be used on their own or in combination with other javascript <span class=\"highlight\">mapping</span> libraries (e.g. Leaflet, Google Maps, OpenLayers). &hellip; No matter which platforms you decide to start using to get into web <span class=\"highlight\">mapping</span>, you will most certainly benefit from learning some javascript.  Codecademy is a great place to start (also FREE!!). &hellip; "
    },
    {
        "question": "Running simple Python script for QGIS from outside",
        "area": [
            "pyqgis",
            "standalone",
            "qgs"
        ],
        "text": "You can&#39;t get a reference to the  object here because it doesn&#39;t exist in this context.  The  () object is a convenience object for plugins, or scripts running inside QGIS, to access the main objects e.g. the map canvas, legend, composer, etc, and only exists when the main application is running.\n\nWhen you create a standalone Python script using the QGIS APIs none of this stuff exists because you are making your own mapping application.\n\nThere are three different situations:\n\n\nA QGIS plugin\nA script that runs inside QGIS (not a plugin) for automation\nStandalone app using QGIS APIs\n\n\n and  have access to , the last one doesn&#39;t.\n\nFor  if you want to create a script that opens a layer in a map canvas you would do this after \n\n\n\nHowever if you are really looking for something like  then you can just write this in your script editor \n\n\n\nbut this has to be run inside QGIS for  to work.  That can be done by putting the script on  and running  in the Python console or by using the ScriptRunner plugin.\n\nNote the following isn&#39;t QGIS yet\n\nThere is a number  that hasn&#39;t been added yet, and hopefully will be in the future, and that is the option to run QGIS with a commandline arg to say run this code.\n\nFor example:\n\n\n\nPlugin logging (version 1.8)\n\nYou can use the QgsMessageLog class to log information to the QGIS log window.  The yellow exclamation mark in the bottom right corner.\n\n\n\nor without using lambda\n\n\n\nI prefer the lambda based one as it is shorter and less typing any time you want to log something. \n When you create a standalone Python script using the QGIS APIs none of this stuff exists because you are making your own <span class=\"highlight\">mapping</span> application. &hellip; "
    },
    {
        "question": "Simple thematic mapping of shapefile using Python?",
        "area": [
            "python",
            "shapefile",
            "visualisation",
            "matplotlib"
        ],
        "text": "I wish to visualize geographical data in Python, without using ArcGIS/ArcPy, and make a map. \n\nOn the internet I found how to make a thematic map using Python: \n\nHere is some code that I tried:\n\n\n\nHowever, when I run this, it gives me random colors. \n\nIf I want to visualise one certain column of my shapefile, how can I implement this using similar code? \n\nThis is very unclear in the link provided above where he only discusses the usage of colors...\n\nWould I perhaps need extra modules to accomplish this, like descartes and PySAL?\n I wish to visualize geographical data in Python, without using ArcGIS/ArcPy, and make a map. \n\nOn the internet I found how to make a thematic map using Python: \n\nHere is some code that I tried:\n\nimpor &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "I also just attended a conference where they presented the OpenGeo Suite, which is a stack of OpenLayers, GeoServer, GeoExt &amp; PostGIS.  They offer both the &quot;Enterprise Edition&quot; (paid for version with support) or the &quot;Community Edition&quot; (free) versions.\n(Update) OpenGeo Suite is now Boundless Suite.\n\nAnother package that was demonstrated at the conference was GeoMoose, which is a stack of MapServer and OpenLayers.\n\nYou might consider downloading the OSGEO Live DVD, which you can run in a virtual machine environment in case you don&#39;t want to install a bunch of stuff on your machine while testing it out.  It comes pre-packaged with a bunch of different open source GIS software packages, including web mapping tools.\n It comes pre-packaged with a bunch of different open source GIS software packages, including web <span class=\"highlight\">mapping</span> tools. &hellip; "
    },
    {
        "question": "The GIS of War - Tracking Conflicts and Their Effects",
        "area": [
            "data"
        ],
        "text": "\nDiego Valle-Jones has done some interesting work analysing and mapping Mexico&#39;s drug war (R code on github). Wikinarco provides webmap interface to some drug related crime statistics in Mexico. \n\n\n\n\nNow interactive map is also available:\n\n\n\n\nThe Economist has also done some mapping of drug related deaths, cartel areas and traffic routes.\n\n\n\n\n\n\n\n\n\nFrench OWNI provides nice web frontend for Wikileak&#39;s diplomatic cables. There seems to be map app, but it didn&#39;t work for me. Telegraph came with a web map as well.\n\n\n\n\n\n\n\nFor Iraq Wikileaks data visualization mentioned already by Kirk there is also interesting visualization from placr. For &#39;nonspatial&#39; browsing check OWNI&#39;s \napp.\nAnd before Iraq, Guardian  and The Atlantic also tried to visualize selection of Afgan Wikileaks data. \n\n\n\n\n\nOWNI provides &#39;nonspatial&#39; browser again. Nai&#39;s MediaWatch team provides spatio-temporal overview of the violence against journalists.\n\n\n\n\n\n\n\nAs for contrast to wars, Vision of Humanity provides interactive map of Global Peace Index.\n\n\n\n\nUpdate 1: Recently stumbled upon Guardian&#39;s visualization of Nato attacks in Libya. \n\n\n\n\n\nUpdate 2: Although not a military conflict per se, London riots start to fit description of this question as well. Slashgeo points to few geovisualizations on the topic. Guardian maps location of suspects, riots against poverty. And GENeSIS analyzes geolocated tweets.\n\n\n\nUpdate 3: Interesting visualization of protected areas &amp; civil conflicts in Democratic Republic of Congo.\n\n\n\nUpdate 4: Somalian Piracy Threat Map 2010 from Wikipedia article.\n\n\n Diego Valle-Jones has done some interesting work analysing and <span class=\"highlight\">mapping</span> Mexico&#39;s drug war (R code on github). Wikinarco provides webmap interface to some drug related crime statistics in Mexico. &hellip; Now interactive map is also available:\n\n\n\n\nThe Economist has also done some <span class=\"highlight\">mapping</span> of drug related deaths, cartel areas and traffic routes. &hellip; "
    },
    {
        "question": "Why has Web Mercator (auxiliary sphere) become the web map standard?",
        "area": [
            "arcgis-server",
            "coordinate-system",
            "google-maps",
            "web-mapping",
            "cartography"
        ],
        "text": "I&#39;m pretty sure we have Google to thank. Take a look at the original EPSG code WKID for Web Mercator. What does 900913 look like? Helps if you&#39;re at least a little l33t.\n\nWhen Google Maps blew up a few years ago (2005ish), everyone started copying Google. This included Virtual Earth/Bing, Mapquest, Yahoo Maps and eventually Esri. Everyone wanted/needed to be compatible with the most popular web mapping platform. It has been the standard ever since.\n\nEdit:  per mkennedy&#39;s comment, changed EPSG code to WKID\n Everyone wanted/needed to be compatible with the most popular web <span class=\"highlight\">mapping</span> platform. It has been the standard ever since.\n\nEdit:  per mkennedy&#39;s comment, changed EPSG code to WKID &hellip; "
    },
    {
        "question": "Check if a point falls within a multipolygon with Python",
        "area": [
            "shapefile",
            "ogr",
            "shapely",
            "point-in-polygon"
        ],
        "text": "Shapefiles have no type MultiPolygon (type = Polygon), but they support them anyway (all rings are stored in one feature = list of polygons, look at Converting huge multipolygon to polygons)\n\nThe problem\n\n\n\nIf I open a MultiPolygon shapefile, the geometry is &#39;Polygon&#39; \n\n\n\nSolution 1 with Fiona\n\n\n\nFiona interprets the feature as a MultiPolygon and you can apply the solution presented in More Efficient Spatial join in Python without QGIS, ArcGIS, PostGIS, etc (1)\n\n\n\nSolution 2 with pyshp (shapefile) and the  geo_interface  (GeoJSON like) protocol\n\nThis is a supplement to the answer of xulnik. \n\n\n\nSolution 3 with ogr and the geo_interface protocol (Python Geo_interface applications)\n\n\n\nSolution 4 with GeoPandas as in More Efficient Spatial join in Python without QGIS, ArcGIS, PostGIS, etc (2)\n\n\n\nThe points 1,3,5,6 falls within the boundaries of the MultiPolygon\n fiona.open(&quot;multipol.shp&quot;)\nmultipolys.schema\n{&#39;geometry&#39;: &#39;Polygon&#39;, &#39;properties&#39;: OrderedDict([(u&#39;id&#39;, &#39;int:10&#39;)])}\nlen(multipolys)\n1\n\n\nSolution 1 with Fiona\n\nimport fiona\nfrom shapely.geometry import shape,<span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Writing Shapely geometries to shapefiles",
        "area": [
            "python",
            "shapefile",
            "shapely"
        ],
        "text": "I&#39;ve designed Fiona to work well with Shapely. Here is a very simple example of using them together to &quot;clean&quot; shapefile features: \n\n\n\nFrom https://github.com/Toblerity/Fiona/blob/master/examples/with-shapely.py.\n Here is a very simple example of using them together to &quot;clean&quot; shapefile features: \n\nimport logging\nimport sys\n\nfrom shapely.geometry import <span class=\"highlight\">mapping</span>, shape\n\nimport fiona\n\nlogging.basicConfig(stream=sys.stderr &hellip; clean = geom.buffer(0.0)\n                    assert clean.is_valid\n                    assert clean.geom_type == &#39;Polygon&#39;\n                    geom = clean\n                f[&#39;geometry&#39;] = <span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Great GIS, maps &amp; cartography quotes",
        "area": [
            "references"
        ],
        "text": "Programmers&#39; list has been a pleasure to read. Stats&#39; list is growing fast as well. So perhaps there is a place for separate one on this site?\n\nPlease share your nuggets of wisdom / humour / inspiration from the world of GIS, cartography and mapping.\n Please share your nuggets of wisdom / humour / inspiration from the world of GIS, cartography and <span class=\"highlight\">mapping</span>. &hellip; "
    },
    {
        "question": "Comparing two spatial point patterns?",
        "area": [
            "point",
            "spatial-statistics",
            "visualisation",
            "gis-principle"
        ],
        "text": "As always, it depends on your objectives and the nature of the data.  For completely mapped data, a powerful tool is Ripley&#39;s L function, a close relative of Ripley&#39;s K function.  Lots of software can compute this.  ArcGIS might do it by now; I haven&#39;t checked.  CrimeStat does it.  So do GeoDa and R.  An example of its use, with associated maps, appears in\n\nSinton, D. S. and W. Huber. Mapping polka and its ethnic heritage in the United States. Journal of Geography Vol. 106: 41-47. 2007\n\nHere is a CrimeStat screenshot of the &quot;L function&quot; version of Ripley&#39;s K:\n\n\n\nThe blue curve documents a very non-random distribution of points, because it does not lie between the red and green bands surrounding zero, which is where the blue trace for the L-function of a random distribution should lie.\n\nFor sampled data, much depends on the nature of the sampling.  A good resource for this, accessible to those with limited (but not entirely absent) background in math and stats, is Steven Thompson&#39;s textbook on Sampling.\n\nIt is generally the case that most statistical comparisons can be illustrated graphically and all graphical comparisons correspond to or suggest a statistical counterpart.  Therefore any ideas you get from the statistical literature are likely to suggest useful ways to map or otherwise graphically compare the two datasets.\n <span class=\"highlight\">Mapping</span> polka and its ethnic heritage in the United States. &hellip; "
    },
    {
        "question": "What is the Difference between Geometric and Geographic columns?",
        "area": [
            "postgis"
        ],
        "text": "You can find your answer in &quot;PostGIS in Action&quot;, from Regina O. Obe and Leo S. Hsu, Edited by Manning\n\nThe difference from geometry and geographyc type:\n\n\n  &quot;PostGIS 1.5 introduced a new spatial type called geography, which uses geodetic\n  measurement instead of Cartesian measurement. Coordinate points in the geography\n  type are always represented in WGS 84 lon lat degrees (SRID 4326), but measurement\n  functions and relationships ST_Distance, ST_DWithin, ST_Length, and ST_Area always\n  return answers in meters or assume inputs in meters.&quot;\n\n\nWhat is best to use? It depends:\n\n\n  &quot;When choosing between the geometry and geography type for data storage, you should consider what you\u2019ll be using it for. If all you do are simple measurements and relationship checks on your data, and your data covers a fairly large area, then most likely you\u2019ll be better off storing your data using the new geography type. Although the new geography data type can cover the globe, the geometry type is far from obsolete. The geometry type has a much richer set of functions than geography, relationship checks are generally faster, and it has wider support currently across desktop and web-mapping tools.&quot;\n\n\nAlso, take a look in an already answered question here.\n The geometry type has a much richer set of functions than geography, relationship checks are generally faster, and it has wider support currently across desktop and web-<span class=\"highlight\">mapping</span> tools.&quot; &hellip; "
    },
    {
        "question": "Seeking Mobile GIS applications for Android Tablets?",
        "area": [
            "software-recommendations",
            "android",
            "mobile-gis"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\n\nGPSLogger for Android is a lightweight GPS logger with lots of useful tweaks [control over time/distance of logs, OSM integration, auto email of tracks, and easy on your battery].\nEpiCollect developed at Imperial College London together with web based management tools looks as really good option for data collection (more info here).\nOpen Data Kit (ODK) also looks very promising on data collection front. Check for instance ODK, GeoServer, Leaflet combo.\nAntiMap - was newcomer to the market, accompanied by desktop package that can synchronize with video. Currently it&#39;s website is unresponsive.\nFunf Journal - part of Funf Open Sensing Framework developed by MIT Media Lab\nGIS Cloud&#39;s Mobile Data Collection for Android. Another data collection tool.\nOpenPaths - yet another data collection option from New York Times Company\nInput App: QGIS in your pocket - Free and open source iOS/Android app designed to streamline the whole process behind geo-surveys by Lutra Contsulting Ltd.\nQField for QGIS (Former QGIS on Android) is a very active project and is now at version 1.0:\nBlog: http://opengis.ch/\nFrom an answer deleted for recommending the same software as this one:\n\n\nI like QGIS for android as it accepts both esri shape files and\nmapinfo tab files, and you can do thematic mapping as well as\ndisplaying geotiffs. You can edit shape files easily and use the built\nin gps if you have one, however it crashes my tablet if you are not\nlocated within the bounds of the map. Otherwise it is excellent and\nthe devs are working on python compatibility meaning you will be able\nto use google and bing maps as well as open streets etc.\nThe main issues are that the gui is designed for  a standard screen\nand all the buttons and icons are tiny on anything smaller than a 10&quot;\nscreen.\nFor basic navigation and data entry on a custom map, i was using\navenzas&#39; pdf maps on iOs, which imports geo-registered PDFs. They have\na beta for android which I haven&#39;t used but am planning on trialling.\nyou can make geo-registered pdfs in mapinfo or arcmap.\n\n\nSo far I have settled on collecting KML based vector data with limited attribution.\nApps I have used:\n\nLocus (free and paid version) https://market.android.com/details?id=menion.android.locus&amp;feature=related_apps\nOruxMaps https://market.android.com/details?id=com.orux.oruxmaps\nGoogle Tracks (pre-installed on my phone)\n\nLocus and Orux allow connecting to WMS services, Google/Bing, etc... I believe there is a separate add-on to allow Google maps in Locus.\n\nI came across this interesting application that looks (have not used it) interesting for collection of data.\nhttp://code.google.com/p/geopaparazzi/\nSome more info:\nGeopaparazzi is a tool developed to do very fast qualitative engineering/geologic surveys. Even if the main aim is in the field of surveying, it contains tools that can be of great use also to OpenStreetMappers as well as tourists that want to keep a geo-diary. Geopaparazzi is available on the Android Market.\nTo get started jump into the documentation section: https://code.google.com/p/geopaparazzi/wiki/Docs\nThe main aim of Geopaparazzi is to have a tool that:\n\nfits in any pocket and can be always at hand, when needed\ngives the possibility to take georeferenced and possibly orientated pictures during the survey, with further possibility to import them into the main GIS application BeeGIS\nis able to exploit easily internet connection, if available.\nis extremely easy to use and intuitive, providing just few important functionalities.\n\nThe main features available in Geopaparazzi are:\n\ngeoreferenced notes\ngeoreferenced and orientated pictures\ngps tracks logging\neasy export of collected data\na map view for the navigation of the environment\n\nThis recent presentation might give more insight: http://www.slideshare.net/moovida/geopaparazzi-state-of-the-art\n\nWe develop a mobile GIS solution for Android tablets called Mappt, which has a free trial available from the Google Play store.  The trial version allows you access to all functionality of the software, with the exception that you can not export your data.\nYou can grab the trial for free from the Google Play Store:\nhttps://play.google.com/store/apps/details?id=au.com.mappt\nWith Mappt, you can:\n\nCapture and work with your vector data offline.\nImport and export in Shapefile and KML formats.\nWork with WGS84 and UTM-based Coordinate Reference Systems.\nImport directly from Google Drive and export to email.\nImport your own large imagery, fully available offline, via the ArcGIS Compact Cache Bundle format.  We are also actively implementing other options to import imagery.\nRecord GPS paths.\nDefine geofences, with audible and visual alerts.\n\nSee the Mappt website for further information: www.mappt.com.au\n\n\n\nFulcrum is a cost-effective and customizable GIS mobile data collection platform. Includes a 30-day trial at sign up!\nhttp://fulcrumapp.com/\nhttps://play.google.com/store/apps/details?id=com.spatialnetworks.fulcrum&amp;hl=en\n\n\nI&#39;m working on this and I have just published a GIS application: ItacaMap for Android ( https://play.google.com/store/apps/details?id=com.itacasoft.itacamap ). At the moment you can see basic functionality (zoom, pan, view info, browse, select by rectangle, etc.), but I have already implemented edit functionalities (at least on the server side) and more is cooking.\n\nGeospago is a new application.  It is a software-as-a-solution (SaaS) because it has a mobile application working in conjunction with a web application.  Both may be used for collecting/inputting data, editing/updating data, viewing/sharing data, and importing/exporting data.  The web portal runs on amazon with geoserver and syncs with the android app, which uses SQLite.\nThe web portal is used to invite/manage users, control user access to projects, create projects and custom forms, deploy the forms to users, and manage data.  It can import SHP &amp; CSV files for data maintenance workflows.  It can export data to the standard formats (CSV, KML, SHP), but aslo provides feeds and an API.  This allows users to add a WFS feed to ArcMap or QGIS to see the data live from the cloud, a network link to Google Earth, or create your own script to pull the data through API requests to integrate with other systems.  Collecting data is easy as well as quickly getting new or updated data back into a enterprise system of record.  Geospago is the only app I have seen so far that provides this.\nThe mobile app is used to collect, view, and edit data (point, line, and polygon).  It runs on both phones and tablets.  It handles connected and disconnected environments through the use of mbtiles.  It allows multiple photos to be attached to a single record.  It also has barcode scanning and signature capabilities.  Synchronization is set to user specified intervals or can be manually forced.  This prevents overlap and duplication if you have multiple people collecting data for the same projects in connected areas.\nGeospago is very affordable and available on a monthly, per-license pricing model that it can be frozen between projects or cancel-at-any-time basis so you can use it only when you need it.  Data is secure on Amazon cloud and can be download it at any time.\nThe Geospago website has more information and has a sign up link.  The website also has a link to the mobile app on the Google Play Store.\n\nFound an app called MapItFast that is easy to use.  A free version that lets you gather point, line, polygon features and even photos.  I&#39;ve used it for its basemaps and to calculate distance and area.  Unfortunately, the data stays on the device (no way to export or share..that I can find) without upgrading to the cloud services.  But that looks interesting since data can be exported to CSV, GPX, SHP and KMZ, it has built in synchronization to collaborate on mapping and location, full attribution, editing, and probably a bunch of other stuff I don&#39;t know about yet.  Might be useful to those folks doing group mapping on an Android and wanting a way to get it into Google Maps or ArcGIS.  I like the idea of a low cost Internet Map Server and tools.\nTheir website (http://www.mapitfast.com) has YouTube video.  I downloaded from Google Play.  Found the brochure online:\nhttp://www.mapitfast.com/Documents/MIF_Brochure_2013.pdf\n http://opengis.ch/\nFrom an answer deleted for recommending the same software as this one:\n\n\nI like QGIS for android as it accepts both esri shape files and\nmapinfo tab files, and you can do thematic <span class=\"highlight\">mapping</span> &hellip; Might be useful to those folks doing group <span class=\"highlight\">mapping</span> on an Android and wanting a way to get it into Google Maps or ArcGIS.  I like the idea of a low cost Internet Map Server and tools. &hellip; "
    },
    {
        "question": "How can I conduct Geographically Weighted Principal Component Analysis using ArcGIS, Python and SPSS/R?",
        "area": [
            "r",
            "spatial-statistics"
        ],
        "text": "I am after a description/methodology for conducting a Geographically Weighted Principal Components Analysis (GWPCA). I am happy using Python for any portion of this and I imagine SPSS or R being used to run the PCA on the geographically weighted variables.\n\nMy dataset is composed of roughly 30 independent variables that are measured throughout ~550 census tracts (vector geometry).\n\nI know this is a loaded question. But, as I search and search, there does not seem to be any solutions out there. What I have come across are mathematical equations that explain the fundamental composition of GWPCA (and GWR). What I am after is more applied in a sense, that I am looking for what major steps I need to accomplish to get from raw data to the GWPCA results.\n\n\n\nI would like to expand on the first part with this edit due to the comments received below.\n\nTo address Paul...\n\nI am basing my interest in GWPCA off of the following paper:\n\nLloyd, C. D., (2010). Analysing population characteristics using geographically weighted principal components analysis: A case study of Northern Ireland in 2001. Computers, Environment and Urban Systems, 34(5), p.389-399.\n\nFor those who do not have access to the literature, I have attached screenshots of the particular sections which explain the mathematics below:\n\n\n\nAnd to address whuber...\n\nWithout going into detail (confidentiality), we are attempting to reduce the 30 variables, which we believe are all very good indicators (albeit globally), to the set of components with eigenvalues greater than 1. By computing the geographically weighted components, we attempt to understand the local variances explained by these components.\n\nI think our primary goal will be to proof the concept of GWPCA, that is, show the spatially explicit nature of our data and that we cannot consider all independent variables to be explanatory on a global scale. Rather, the local scale (neighbourhoods) that each component will identify will aid us in understanding the multi-dimensional nature of our data (how variables can be combined with one another to explain a certain neighbourhoods in our study area).\n\nWe hope to map the percentage of variance accounted for by each component (separately), to understand the extent of the neighbourhood explained by the component in question (aid us in understanding local spatiality of our components). Perhaps some other mapping examples but none come to mind at the moment.\n\nAdditionally:\n\nThe mathematics behind the GWPCA is beyond what I understand given my background in geographic analysis and social statistics. The application of the maths is most important, that is, what do I plug in to these variables/formulas.\n Perhaps some other <span class=\"highlight\">mapping</span> examples but none come to mind at the moment. &hellip; "
    },
    {
        "question": "What&#39;s next if our KML is too big/complex for the Google Maps API?",
        "area": [
            "google-maps",
            "kml"
        ],
        "text": "Our web app includes simple mapping capabilities (currently just markers and KML overlays on an embedded Google Map). This works pretty well; the only real limitation we face is KML overlays that go beyond Google&#39;s size &amp; complexity restrictions for KML. \n\nWe&#39;re considering standing up our own server (e.g. GeoServer or ArcGIS Server); but that seems like a huge step just to serve up (for example) 15 MB of KML when Google&#39;s limit is 10 MB.\n\nI need a sanity check: Is there some middle ground between Google&#39;s free and easy API for KML overlays, and setting up my own tile server? \n Our web app includes simple <span class=\"highlight\">mapping</span> capabilities (currently just markers and KML overlays on an embedded Google Map). &hellip; "
    },
    {
        "question": "Implementing version control system for geospatial data?",
        "area": [
            "versioning",
            "version-control"
        ],
        "text": "Not that I am in any immediate need of a right answer here, but I&#39;ve lately seen some efforts to introduce the concept of &quot;(distributed) version control systems&quot; for geographic data. Some examples (that I know of) are the three whitepapers from OpenGeo (1, 2 &amp; 3) and the &quot;Geosynkronisering (geosyncronization)&quot; project by Norwegian GIS Software vendors and the Norwegian Mapping Agency. I&#39;ve also found Distributed versioning of geospatial data?, which mentions GeoGit (by OpenGeo), and Applying version control to ArcGIS ModelBuilder models? about version control in ArcGIS.\n\nBeing a developer I know (at least enough to be able to use them) how version control systems for source code (like SVN and Git) works, and my background in geomatics tells me that there are some unique challenges with geographical data that makes the approach not completely similar to the way source code (which is basically text) are handled.\n\nWhat are the challenges when dealing with (d)VCS&#39;es for geographical data, how would you solve them, do we need them and are there other attempts to solve these issues than the ones I have mentioned?\n\nI know that the OpenGeo whitepapers will answer some of my questions, but what I&#39;m really is after is a more &quot;pedagogical&quot; answer, in the style of &quot;tell me like I&#39;m a 10-year-old&quot;, so that I can refer people to a great explanation of the challenges and solutions that geographical data brings to the mix.\n\nI hope that someone with some insight will take time to provide some thoughts on the matter, as I said I&#39;m not currently looking to solve a particular problem, but this topic is one that interests me. \n Some examples (that I know of) are the three whitepapers from OpenGeo (1, 2 &amp; 3) and the &quot;Geosynkronisering (geosyncronization)&quot; project by Norwegian GIS Software vendors and the Norwegian <span class=\"highlight\">Mapping</span> Agency &hellip; "
    },
    {
        "question": "Switching career from GIS Technician/Analyst to GIS Web Map Developer/Programmer?",
        "area": [
            "web-mapping",
            "development",
            "career"
        ],
        "text": "I am a GIS Analyst at work that dabbles in python scripting in ArcGIS and the Google Maps JavaScript API V3.  \n\nMy professional goal is to either be in web mapping development or desktop/server GIS application development.  \n\nI have seem to hit a plateau and I am not sure how to progress with my learnings or professionally to reach my goal.  \n\nI ask those of you out there that made the jump from technician/analyst how did you do it? \n\nHow can I land a job in web mapping/application development with little to no experience.\n My professional goal is to either be in web <span class=\"highlight\">mapping</span> development or desktop/server GIS application development. &hellip; How can I land a job in web <span class=\"highlight\">mapping</span>/application development with little to no experience. &hellip; "
    },
    {
        "question": "Can you point me to an example of a modern-day John Snow?",
        "area": [
            "references",
            "medical-geography"
        ],
        "text": "It&#39;s become pretty much a custom to start spatial epidemiology or medical geography textbook / lecture with an example of John Snow&#39;s cholera investigation in 1854 Soho.\n\n\n\nHe&#39;s definitely still remembered in the current literature and even appeared on top answer to a recent question on this site.\n\nCould you give some recent examples where mapping, GIS or spatial analysis provided significant contribution to understanding and explaining an epidemiological issue?\n Could you give some recent examples where <span class=\"highlight\">mapping</span>, GIS or spatial analysis provided significant contribution to understanding and explaining an epidemiological issue? &hellip; "
    },
    {
        "question": "Listing all polygon vertices coordinates using GeoPandas",
        "area": [
            "polygon",
            "geopandas",
            "vertices",
            "order"
        ],
        "text": "Not sure if one line method exists, but the following ways could work. (Solutions are for the first feature&#39;s geometry, and they are just for , not for )\nSolution 1:  property of a polygon returns exterior and all interiors of the polygon.\n\n\nResult:\n\n\nSolution 2:  returns  object which consists of  objects.\n\nResult:\n\n\nSolution 3:  function returns the GeoJSON-like mapping of a geometric object.\n\nResult:\n\n .]]])#9\n\n\nSolution 3: shapely.geometry.mapping function returns the GeoJSON-like <span class=\"highlight\">mapping</span> of a geometric object.\nimport geopandas as gpd\nfrom shapely.geometry import <span class=\"highlight\">mapping</span>\n    \ndf = gpd.read_file(&#39;/home &hellip; /bera/geodata/Rectangle_with_hole.shp&#39;)\n\ng = [i for i in df.geometry]\ngeojson_ob = <span class=\"highlight\">mapping</span>(g[0]) # for first feature/row\nall_coords = geojson_ob[&quot;coordinates&quot;]\nall_coords\n\nResult:\n(((0.0, 0.0), (0.0, 4.0 &hellip; "
    },
    {
        "question": "Using SRTM Global DEM for Slope calculation",
        "area": [
            "arcgis-desktop",
            "arcgis-10.0",
            "dem",
            "srtm"
        ],
        "text": "This seems like a good place to describe a simple, fast, and more than reasonably accurate way to compute slopes for a globally extensive DEM.\nPrinciples\nRecall that the slope of a surface at a point is essentially the largest ratio of &quot;rise&quot; to &quot;run&quot; encountered at all possible bearings from that point. The issue is that when a projection has scale distortion, the values of &quot;run&quot; will be incorrectly computed. Even worse, when the scale distortion varies with bearing--which is the case with all projections that are not conformal--how the slope varies with bearing will be incorrectly estimated, preventing accurate identification of the maximum rise:run ratio (and skewing the calculation of the aspect).\nWe can solve this by using a conformal projection to ensure that the scale distortion does not vary with bearing, and then correcting the slope estimates to account for the scale distortion (which varies from point to point throughout the map).  The trick is to use a global conformal projection that allows a simple expression for its scale distortion.\nThe Mercator projection fits the bill: assuming scale is correct at the Equator, its distortion equals the secant of the latitude.  That is, distances on the map appear to be multiplied by the secant.  This causes any slope calculation to compute rise:(sec(f)*run) (which is a ratio), where f is the latitude.  To correct this, we need to multiply the computed slopes by sec(f); or, equivalently, divide them by cos(f).  This gives us the simple recipe:\n\nCompute the slope (as rise:run or a percent) using a Mercator projection, then divide the result by the cosine of the latitude.\n\nWorkflow\nTo do this with a grid given in decimal degrees (such as an SRTM DEM), perform the following steps:\n\nCreate a latitude grid.  (This is just the y-coordinate grid.)\n\nCompute its cosine.\n\nProject both the DEM and the cosine of the latitude using a Mercator projection in which scale is true at the Equator.\n\nIf necessary, convert the elevation units to agree with the units of the projected coordinates (usually meters).\n\nCompute the slope of the projected DEM either as a pure slope or a percent (not as an angle).\n\nDivide this slope by the projected cosine(latitude) grid.\n\nIf desired, reproject the slope grid to any other coordinate system for further analysis or mapping.\n\n\nThe errors in the slope calculations will be up to 0.3% (because this procedure uses a spherical earth model rather than an ellipsoidal one, which is flattened by 0.3%).  That error is substantially smaller than other errors that go into slope calculations and so can be neglected.\n\nFully global calculations\nThe Mercator projection cannot handle either pole.  For work in polar regions, consider using a polar Stereographic projection with true scale at the pole.  The scale distortion equals 2 / (1 + sin(f)).  Use this expression in place of sec(f) in the workflow. Specifically, instead of computing a cosine(latitude) grid, compute a grid whose values are (1 + sin(latitude))/2 (edit: use -latitude for the South Pole, as discussed in the comments).  Then proceed exactly as before.\nFor a complete global solution, consider breaking the terrestrial grid into three parts--one around each pole and one around the equator--, performing a slope calculation separately in each part using a suitable projection, and mosaicing the results.  A reasonable place to split the globe is along circles of latitude at latitudes of 2*ArcTan(1/3), which is about 37 degrees, because at these latitudes the Mercator and Stereographic correction factors are equal to each other (having a common value of 5/4) and it would be nice to minimize the sizes of the corrections made.  As a check of the computations, the grids should be in very close agreement where they overlap (tiny amounts of floating point imprecision and differences due to resampling of the projected grids ought to be the only sources of discrepancies).\nReferences\nJohn P. Snyder, Map Projections--A Working Manual.  USGS Professional Paper 1395, 1987.\n If desired, reproject the slope grid to any other coordinate system for further analysis or <span class=\"highlight\">mapping</span>. &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "Edit\nDue to the popularity of this question and answer, I am adding editing some content on this post due to changes with providers and APIs over the past several months.\n\nI recently stumbled upon this website, which also provides some metrics on different software platforms in this area.\n\nAPI choice is related to the scope and purpose of your project, not to mention your budget if you in fact want to use some specific functionality.  The other major caveat is your web development experience, and what language you prefer or have an interest in.\nI think the best way to answer your question is to provide a nice listing of API&#39;s available to you.  Here are three that come to mind.  These are not by any means all of them!\nArcGIS\nAPIs:\n\nJavaScript\nEsri Leaflet\nSilverlight (please see this blog post on last release notes)\nFlex (please see this blog post on last release notes)\n.NET\n...and more (see here)\n\nPros:\n\nThe Experience Builder solution provides one of the most dynamic non-coding web application building experience on the market\nThe Web AppBuilder has made creating web map applications very simple for those not well-versed in web development\nEasy to use application builders (Flex, Silverlight, and JavaScript, just be mindful of the deprecation plans)\nExpansive online forums (Plenty of Stack Exchange Posts)\nWith many solutions available within the ArcGIS stack that require little to no development work, ArcGIS can also be a good choice for deploying solutions in a timely manner.\nGitHub repositories for many of the solutions\n\nCons:\n\nPrice (not for use of API&#39;s, but more-so if you want to publish your own data, also see ArcGIS Online)\nCustomizing application code can be cumbersome\n\nSummary:\nArcGIS has a lot to offer for web GIS products, and has many resources to help you along the way.  Just be aware of the potential costs you run into when wanting to publish your own data.\nGoogle\nAPIs:\n\nJavaScript\nMobile (Android, iOS)\n\nPros:\n\nBy far the most recognized name in web mapping\nExpansive JavaScript API\nMany online samples\nRecently, Google released their Pricing and Plans, which is a great breakdown of services offered\n\nCons:\n\nPotential licensing issues (read up on the terms of service)\nRestrictions on web services\n\nSummary:\nGoogle has a strong name in the market and pretty reliable online services.  Just be sure to understand the ins and outs of their usages, so you don&#39;t step on any legal toes.  The new Pricing and Plans page is quite helpful in that regard.\nOpen Source\nAPIs (all JavaScript based):\n\nLeaflet\nOpenLayers\nGeoServer\n\nPros:\n\nVery easy to use and completely free\nEver growing API\nEver growing developer base with custom plugins being published all the time\nTutorials for beginners\n\nCons:\n\nOfficial support is not as well known BUT the community involved is more than helpful (perhaps even better than commercial GIS support)\n\nSummary:\nOpen Source is truly a great option for anyone who wants to test the waters of Web GIS.  With changes and enhancements made every day in the community, open source can be the inexpensive way to address your geospatial needs.\n\nAs I said, this is not all of the choices you have, but at least now there is a post with links for yourself and others to get familiar with some of the major players in the Web GIS world.\n Google\nAPIs:\n\nJavaScript\nMobile (Android, iOS)\n\nPros:\n\nBy far the most recognized name in web <span class=\"highlight\">mapping</span>\nExpansive JavaScript API\nMany online samples\nRecently, Google released their Pricing and Plans, which &hellip; "
    },
    {
        "question": "Donating and volunteering geographical knowledge?",
        "area": [
            "openstreetmap",
            "google-maps",
            "crowdsourcing"
        ],
        "text": "I know a lot about the places I visit, and I want to share it with everyone. \n\nI have been donating and volunteering at OpenStreetMap, and I am also aware of Google Maps. \n\nWhere else can I help with collaborative mapping?\n Where else can I help with collaborative <span class=\"highlight\">mapping</span>? &hellip; "
    },
    {
        "question": "What strategies, criteria, or rules to use for selecting coordinate systems?",
        "area": [
            "coordinate-system",
            "datum",
            "gis-principle"
        ],
        "text": "a.  It is good practice to store a version of the data in the projection in which it was captured.  Re-projection can be a lossy process, and it is important to have the original.  I have a preference for storing in WGS84 for the sake of simplicity. \n\nb.  Depending on your software you may need to re-project into a metre based projections such as UTM.  Support for native geodetic is being added (PostGIS, SQL server). For raster analysis it can be preferable to keep the data in the format it was supplied to avoid data loss through interpolation.  \n\nc.  Web mapping systems have standardised on spherical mercator, and to overlay tiles they need to be in this projection.  For overlaying vector on google maps you use  WGS84.  If you are not targeting web mapping there will usually be a local projection that is standard.\n Web <span class=\"highlight\">mapping</span> systems have standardised on spherical mercator, and to overlay tiles they need to be in this projection.  For overlaying vector on google maps you use  WGS84. &hellip; If you are not targeting web <span class=\"highlight\">mapping</span> there will usually be a local projection that is standard. &hellip; "
    },
    {
        "question": "Seeking tutorials, books, papers, blogs, etc to handle spatial data in R",
        "area": [
            "r",
            "spatial-statistics",
            "references"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nThere&#39;s quite a few resources for learning &#39;spatial&#39; R online:\n\nspatial-analyst.net\n\nA really solid blog post by\nFrank Davenport, with notes on some basic spatial data manipulation in R\n\nR Spatial Tips (Internet Archive link, original site seems to be gone)\n\nBarry Rowlingson&#39;s site containing some great examples and a cheatsheet\n\nI&#39;d strongly recommend Analysing spatial point patterns in &#39;R&#39;\nby Prof. Adrian Baddeley at the CSIRO in Australia. It covers\nthe  module in depth and I think it&#39;s a great resource\nfor cluster analysis.\n\nApplied Spatial Data Analysis in R (Bivand, Roger S., Pebesma,\nEdzer J., G&#243;mez-Rubio, Virgilio) and Spatial Statistics and\nModeling (Gaetan, Carlo, Guyon, Xavier) are also both great\nbooks.\n\nVirgilio G&#243;mez Rubio&#39;s (he is the author of the famous/superuseful ASDAR book, mentioned in other answers) website provides materials to his tutorials from useR! conferences - slides, data and code are available.\n\nApart from ADAR, there is now new book &#39;An Introduction to R for Spatial Analysis and Mapping&#39; by Brundson &amp; Comber with code available for download.\n\nCSDE (University of Washington) course on GIS has some spatial R materials, focusing on ESDA, GWR, spatial regression\n\nMaps with R I (II, III) series of blog posts offer a lot of extensively commented code that you can learn from.\n\nUC Davis Soil Resource Laboratory has a nice collection of tips and examples of spatial R\n\nFrancisco Rodriguez-Sanchez has a nice materials on &#39;Spatial data in R: Using R as a GIS&#39;.\n\nA Practical Guide to Geostatistical Mapping by T. Hengl\n\nComprehensive Tutorial for Spatio-Temporal R Package (Bergen et al., 2013)\n\nggmap: Spatial Visualization with ggplot2 (Kahle and Wickham)\n\nD.G Rossiter (lecture notes)\n\nSpatial.ly\n\n\nA few nice tutorials, including some with a focus on interactivity (often listed as a weakness of doing GIS with R)\n\nSpatial data in R: Using R as a GIS: A tutorial to perform basic operations with spatial data in R, such as importing and exporting data (both vectorial and raster), plotting, analysing and making maps. by Francisco Rodriguez-Sanchez\nUsing RStudio as an interactive GIS with\nLeaflet by  Kyle Walker,\nTexas Christian University\nWorking with PostGIS from R by\nDuncan Golicher\nGeospatial Data Processing and Analysis in\nR by Andy Lyons\n\nI also made a quick easy and holistic tutorial you folks can check out here https://github.com/mattjbayly/MapsProj. All you need is the R text script and all other material is downloaded remotely from R.\nMy tutorial covered GIS data imports/exports, basic manipulation of vector &amp; raster data, some of basic plotting and a brief overview of projections.\nEstimated time to complete: 60mins\n Apart from ADAR, there is now new book &#39;An Introduction to R for Spatial Analysis and <span class=\"highlight\">Mapping</span>&#39; by Brundson &amp; Comber with code available for download. &hellip; A Practical Guide to Geostatistical <span class=\"highlight\">Mapping</span> by T. &hellip; "
    },
    {
        "question": "How does what3words build a grid of squares on the surface of the Earth?",
        "area": [
            "mercator",
            "what3words"
        ],
        "text": "You&#39;re on the right lines. The what3words grid is algorithmically generated to be nearly exactly 3m by 3m to within a couple of centimetres at latitudes between -85&#186; and +85&#186;. Between +/- 85&#186; north and south and the poles, the notional grid squares expand the closer to the poles you get and at their largest extent are ~4.5m by ~4.5m with some deformation at the poles.\n\nIt&#39;s not easy to visualise the deformation, hence my use of the word notional in the previous paragraph. The datum that what3words works with is EPSG:4326 and the algorithm at the heart of what3words &quot;understands&quot; this and so it&#39;s always algorithmically able to map a 3 word address to coordinates and vice versa. But most web maps, Google&#39;s included, are displaying that data once it&#39;s been (re)projected CRS; Google uses EPSG:3857. It&#39;s really challenging to display the deformation as you&#39;re working against how the underlying mapping API wants you to work. The closest you&#39;ll get is the slight shifts in the notional grid that occur as you move north of south from the meridian, as shown near evens.response.fishes if you zoom in enough that the grid will be shown.\n\n\n\n(disclaimer - in my day job I work for what3words)\n It&#39;s really challenging to display the deformation as you&#39;re working against how the underlying <span class=\"highlight\">mapping</span> API wants you to work. &hellip; "
    },
    {
        "question": "Determining which US zipcodes map to more than one state or more than one city?",
        "area": [
            "united-states",
            "zip-codes",
            "borders",
            "postal-code"
        ],
        "text": "There are 13 multi-state US Census&#39; ZIP Code Tabulation Areas (ZCTAs): 02861, 42223, 59221, 63673, 71749, 73949, 81137, 84536, 86044, 86515, 88063, 89439 &amp; 97635.\n\nAs others have mentioned, there are a few different ways to figure out the area covered by a ZIP Code, but ZCTAs are the easiest, and the only official version that I know of. \n\nSo your example of 42223 does span a state border, but it looks like it is actually between Maryland and Virginia. that between Kentucky and Tennessee.\n\nHere&#39;s the full list with states:\n\n\n\nHere&#39;s how I generated it (with Pandas in Python):\n\n\n\nEdit: It seems the Census has two different two-digit codings for states. Both are numbers assigned based on the state&#39;s alphabetical ordering, but one seems to apply the numbers directly from 1-51 (50 states + DC), while the other skips some numbers. I was using the first, while I should have been using the second, so the state names I listed were wrong. I&#39;ve updated the code and results with the correct list.\n\nEdit: new state mapping confirmed by the OpenCongress API: https://gist.github.com/gabrielgrant/89f883d093e2abf129ad\n Edit: new state <span class=\"highlight\">mapping</span> confirmed by the OpenCongress API: https://gist.github.com/gabrielgrant/89f883d093e2abf129ad &hellip; "
    },
    {
        "question": "How can I generate irregular grid containing minimum n points?",
        "area": [
            "r",
            "clustering",
            "quadtree"
        ],
        "text": "I see MerseyViking has recommended a quadtree. I was going to suggest the same thing and in order to explain it, here&#39;s the code and an example.  The code is written in  but ought to port easily to, say, Python.\n\nThe idea is remarkably simple: split the points approximately in half in the x-direction, then recursively split the two halves along the y-direction, alternating directions at each level, until no more splitting is desired.\n\nBecause the intent is to disguise actual point locations, it is useful to introduce some randomness into the splits. One fast simple way to do this is to split at a quantile set a small random amount away from 50%. In this fashion (a) the splitting values are highly unlikely to coincide with data coordinates, so that the points will fall uniquely into quadrants created by the partitioning, and (b) point coordinates will be impossible to reconstruct precisely from the quadtree.\n\nBecause the intention is to maintain a minimum quantity  of nodes within each quadtree leaf, we implement a restricted form of quadtree.  It will support (1) clustering points into groups having between  and 2*-1 elements each and (2) mapping the quadrants.\n\nThis  code creates a tree of nodes and terminal leaves, distinguishing them by class.  The class labeling expedites post-processing such as plotting, shown below.  The code uses numeric values for the ids. This works up to depths of 52 in the tree (using doubles; if unsigned long integers are used, the maximum depth is 32).  For deeper trees (which are highly unlikely in any application, because at least  * 2^52 points would be involved), ids would have to be strings.\n\n\n\nNote that the recursive divide-and-conquer design of this algorithm (and, consequently, of most of the post-processing algorithms) means that the time requirement is O(m) and RAM usage is O(n) where  is the number of cells and  is the number of points.   is proportional to  divided by the minimum points per cell, .  This is useful for estimating computation times. For instance, if it takes 13 seconds to partition n=10^6 points into cells of 50-99 points (k=50), m = 10^6/50 = 20000. If you want instead to partition down to 5-9 points per cell (k=5), m is 10 times larger, so the timing goes up to about 130 seconds.  (Because the process of splitting a set of coordinates around their middles gets faster as the cells get smaller, the actual timing was only 90 seconds.) To go all the way to k=1 point per cell, it will take about six times longer still, or nine minutes, and we can expect the code actually to be a little faster than that.\n\nBefore going further, let&#39;s generate some interesting irregularly spaced data and create their restricted quadtree (0.29 seconds elapsed time):\n\n\n\nHere&#39;s the code to produce these plots.  It exploits &#39;s polymorphism:  will be called whenever the  function is applied to a  object, for instance.  The power of this is evident in the extreme simplicity of the function to color the points according to their cluster identifier:\n\n\n\nPlotting the grid itself is a little trickier because it requires repeated clipping of the thresholds used for the quadtree partitioning, but the same recursive approach is simple and elegant.  Use a variant to construct polygonal representations of the quadrants if desired.\n\n\n\nAs another example, I generated 1,000,000 points and partitioned them into groups of 5-9 each.  Timing was 91.7 seconds.\n\n\n\n\n\n\n\nAs an example of how to interact with a GIS, let&#39;s write out all the quadtree cells as a polygon shapefile using the  library.  The code emulates the clipping routines of , but this time it has to generate vector descriptions of the cells.  These are output as data frames for use with the  library.\n\n\n\nThe points themselves can be read directly using  or by importing a data file of (x,y) coordinates.\n\nExample of use:\n\n\n\n(Use any desired extent for  here to window into a subregion or to expand the mapping to a larger region; this code defaults to the extent of the points.)\n\nThis alone is enough: a spatial join of these polygons to the original points will identify the clusters. Once identified, database &quot;summarize&quot; operations will generate summary statistics of the points within each cell.\n It will support (1) clustering points into groups having between k and 2*k-1 elements each and (2) <span class=\"highlight\">mapping</span> the quadrants. &hellip; convert.to.shapefile(polys, polys.attr, &quot;id&quot;, 5)\nwrite.shapefile(polys.shapefile, &quot;f:/temp/quadtree&quot;, arcgis=TRUE)\n\n\n(Use any desired extent for xylim here to window into a subregion or to expand the <span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Is it possible to look at the contents of Shapefile using Python without an ArcMap license?",
        "area": [
            "python",
            "shapefile"
        ],
        "text": "There are many modules to read shapefiles in Python, older than ArcPy, look at the Python Package Index (PyPi): shapefiles. There are also many examples in GIS SE (search for [Python] Fiona, for example)\n\nAll can read the geometry, the fields and  the projections.\n\n\nThe older is osgeo (GDAL/OGR), look at the Python GDAL/OGR Cookbook for example\nanother solution is Fiona, also based on GDAL/OGR, but easier to use (with Python dictionaries: GeoJSON format).\npyshp (shapefile) is a pure Python solution \nGeoPandas use Fiona to read/write the shapefiles and Pandas, for data analysis tools. You need to know Pandas to use it. \n\n\nBut other modules as PySAL:the Python Spatial Analysis Library, Cartopy (which use pyshp) or Matplotlib Basemap can also read shapefiles, among other things.\n\nThe easiest to use is Fiona, but if you only know ArcPy, use pyshp, because osgeo and Fiona require that the GDAL C/C++ library be installed, GeoPandas needs the Pandas module and PySAL is too big (many, many others  treatments) \n\nIf you only want to read the content of a shapefile, you don&#39;t need complex things, simply use the geo interface protocol (GeoJSON) also implemented in ArcPy (ArcPy: AsShape)\n\nWith Fiona (as Python dictionaries):\n\n\n\nWith pyshp (as Python dictionaries)\n\n\n\nWith osgeo/ogr (as Python dictionaries)\n\n\n\nWith GeoPandas (as Pandas dataframe)\n\n\n\n*note on geopandas \nYou have to use older versions of Fiona and GDAL with it or it won&#39;t install.\nGDAL: 1.11.2\nFiona: 1.6.0\nGeopandas: 0.1.0.dev-\n\nThere are many tutorials on the Web and even books (Python Geospatial Development , Learning Geospatial Analysis with Python and Geoprocessing with Python, in press)\n\nMore generally, if you want to use Python without ArcPy, look at Simple thematic mapping of shapefile using Python?\n books (Python Geospatial Development , Learning Geospatial Analysis with Python and Geoprocessing with Python, in press)\n\nMore generally, if you want to use Python without ArcPy, look at Simple thematic <span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "What is this GIS Principle Called?",
        "area": [
            "gis-principle",
            "spatial-analysis"
        ],
        "text": "General\n\nGeographers among other scientists seek for geographical patterns hoping that this will help them to better understand the processes that have produced these patterns. As you shown, this process begins with the mapping of the locations at which the phenomena are located. Oftentimes, such maps as you have produced above are known as point pattern maps.\n\nSpatial distribution\n\nWhen a reader examines such a map, she is trying to find the spatial distribution (or the spatial or geographic arrangement) of the variable of interest and whether there is any sort of pattern. Usually, there are four types of distribution that are defined for point pattern map (which you have also drawn above). These are:\n\n\nclustered\nnormal\nrandom \nregular/uniform/dispersed\n\n\nFrom Wikipedia:\n\n \n\nBeside the visual investigation, one often needs to use the analysis of frequency or the density of points across a region (done with the help of quadrat analysis) or of the distance between adjacent points (done with the help of nearest neighbor analysis).\n\nModifiable units problem\n\nYou have also mentioned the Modifiable areal unit problem (also known as modifiable units problem). \n\n\n  In spatial analysis, four major problems interfere with an accurate\n  estimation of the statistical parameter: the boundary problem, scale\n  problem, pattern problem (or spatial autocorrelation), and modifiable\n  areal unit problem (Barber 1988)\n\n\nI think it&#39;s relevant in this example, but I would also like to mention some other problems:\n\nBoundary problem\n\n\n  A boundary problem in analysis is a phenomenon in which geographical\n  patterns are differentiated by the shape and arrangement of boundaries\n  that are drawn for administrative or measurement purposes.\n\n\nFor a simple example, if you have your points representing a number of people of a certain ethnic group, depending on the boundaries used you might get a different view on the distribution of the points among, for instance, census districts.\n\nIf the points are located close to each other yet are located in different census districts, you can get a false understanding of the distribution because it would indicate even distribution of the ethnic group in this study area. In contrast, if you would use some other boundaries, you might get another view that indicates significant areal concentration of the ethic group. In the end, you might be confused whether you observe ethnic segregation or ethnic integration.\n\nModifiable units problem\n\nThis can be discussed in two aspects - in terms of the &quot;scale&quot; and the &quot;shape&quot;.\n\nScale problem\n\nValues for various descriptive statistics can vary in a systematic manner when you use more and more aggregated areal data.\n\nA simple illustration: each cell is our polygon area with the count of points.\n\n6&#160;&#160;&#160;&#160;&#160;&#160;10&#160;&#160;&#160;&#160;&#160;&#160;3&#160;&#160;&#160;&#160;&#160;&#160;\n5&#160;&#160;&#160;&#160;&#160;&#160;\n2&#160;&#160;&#160;&#160;&#160;&#160;\n6&#160;&#160;&#160;&#160;&#160;&#160;\n4&#160;&#160;&#160;&#160;&#160;&#160;\n12&#160;&#160;&#160;&#160;&#160;&#160;\n3&#160;&#160;&#160;&#160;&#160;&#160;\n5&#160;&#160;&#160;&#160;&#160;&#160;\n8&#160;&#160;&#160;&#160;&#160;&#160;\n12&#160;&#160;&#160;&#160;&#160;&#160;\n4&#160;&#160;&#160;&#160;&#160;&#160;\n12&#160;&#160;&#160;&#160;&#160;&#160;\n1&#160;&#160;&#160;&#160;&#160;&#160;\n3&#160;&#160;&#160;&#160;&#160;&#160;\n\nThen we aggregate the polygons to get an average number of points:\n\n8&#160;&#160;&#160;&#160;&#160;&#160;4&#160;&#160;&#160;&#160;&#160;&#160;\n4&#160;&#160;&#160;&#160;&#160;&#160;\n8&#160;&#160;&#160;&#160;&#160;&#160;\n4&#160;&#160;&#160;&#160;&#160;&#160;\n10&#160;&#160;&#160;&#160;&#160;&#160;\n8&#160;&#160;&#160;&#160;&#160;&#160;\n2&#160;&#160;&#160;&#160;&#160;&#160;\n\nAnd one more time:\n\n6&#160;&#160;&#160;&#160;&#160;&#160;\n6&#160;&#160;&#160;&#160;&#160;&#160;\n6&#160;&#160;&#160;&#160;&#160;&#160;\n6&#160;&#160;&#160;&#160;&#160;&#160;\n\nHey, we got an even distribution! In a word: spatial aggregation usually tends to minimize the variation shown on a map.\n\nFor another really simple example, it really depends at what scale you are looking at your points. Look at the Wikipedia image for point pattern; the normal distribution might look as clustered one when you zoom out in your digital map. \n\nShape problem\n\nWe could have aggregated the polygons in the table above using vertical or horizontal (joining contiguous north-south rather instead of east-west neighbors). This means that various areal definitions might have a significant impact on the values of your data distribution and descriptive statistics.\n\nThe pattern problem\n\nIn short, the above mentioned methods are not very good at evaluating the type of problem that a human would read easily on a map. To be able to distinguish between the areal patterns and point distributions, one would need to use the spatial autocorrelation methods).\n As you shown, this process begins with the <span class=\"highlight\">mapping</span> of the locations at which the phenomena are located. Oftentimes, such maps as you have produced above are known as point pattern maps. &hellip; "
    },
    {
        "question": "Exporting each image from collection in Google Earth Engine",
        "area": [
            "google-earth-engine",
            "google-earth-engine-javascript-api",
            "sentinel-1",
            "synthetic-aperture-radar"
        ],
        "text": " is a client-side function, and you cannot call it from a server-side function (the one you are mapping over), so you have to do it all in the client side. I have a repo where you can find a bunch of useful functions: https://github.com/fitoprincipe/geetools-code-editor\nThere is a function to export all images from an ImageCollection to the Drive cloud.\n\n\n\nYou can find the complete code in here and the documentation here\n Export.image.toDrive is a client-side function, and you cannot call it from a server-side function (the one you are <span class=\"highlight\">mapping</span> over), so you have to do it all in the client side. &hellip; "
    },
    {
        "question": "Enabling CORS in GeoServer (jetty)?",
        "area": [
            "geoserver",
            "cors",
            "jetty"
        ],
        "text": "I hope somebody has already figured this one out. I just installed Geoserver 2.9 on a vanilla Ubuntu 16.04 distro. The Geoserver 2.8 method of enabling CORS with the shanbe.hezoun class does no longer work with Jetty 9.2.13.\n\nThere are mentions that CORS support is already packaged with Jetty 9.2.13 in the jetty-servlets.jar.\n\nThe Jetty lib which is compiled with Geoserver contains a jetty-servlet-9.2.13.v20150730.jar in geoserver/lib but not jetty-servlets.9.2.13.v20150730.jar. Are these supposed to be the same jar with a different name?\n\nIt should be possible to enable CORS either in geoserver/etc/webdefault.xml or in geoserver/webapps/geoserver/WEB-INF/web.xml.\n\nMy understanding is that the webdefault.xml is applied first and the web.xml thereafter.\n\nI have tried following filter in both xml. I haven&#39;t got as far as adding a filter mapping. Adding the filter alone will cause the Geoserver/Jetty service to not start proper.\n\n\n I haven&#39;t got as far as adding a filter <span class=\"highlight\">mapping</span>. Adding the filter alone will cause the Geoserver/Jetty service to not start proper. &hellip; "
    },
    {
        "question": "Geodetic Coordinates And Latitude, Longitude",
        "area": [
            "coordinate-system"
        ],
        "text": "This is a great question because it uncovers important sources of common misunderstandings.  The brief answer is that although of course geodetic latitude and longitude are a form of latitude and longitude, they are not the only ones and the differences are not trivial, so we should be cautious not to confuse them.\n\nIn all cases, latitude and longitude are numbers used to designate points on the earth&#39;s surface.  Usually, the definition of longitude is straightforward because all but the most detailed models of the earth&#39;s surface assume it is rotationally symmetric.  (Geoids, which account for gravitational anomalies, are a possible exception, but this level of detail is normally used only to develop precise elevation coordinates without modifying the underlying latitude and longitude.)  Lines of longitude are meridians and can be designated by the angle they make with a designated meridian of origin, a &quot;prime meridian.&quot;\nThere are many different kinds of latitude.  They are best discussed in a context where an ellipsoidal model of the earth is given, such as the WGS84 or GRS80 ellipsoids.  The latitude depends on the reference ellipsoid.  (This is important when using data referenced to historical ellipsoids, such as the Clarke 1866 ellipsoid.  With more recent ellipsoids, established through satellite measurements, the differences are so small as to be of interest only when accuracy and precision needs are extremely high (sub meter).)\n\nGeodetic latitude is the (signed) angle between the local normal (&quot;straight up&quot; direction) and the plane of the equator.  This should be a professional&#39;s default understanding of what a &quot;latitude&quot; means, even though it differs from the definition taught to children--and therefore is the common understanding among laymen--which corresponds to the geocentric latitude (for a spherical model).  The two can differ by tens of kilometers, a sizable fraction of one degree.\n\nGeocentric latitude, on the other hand, is the (signed) angle determined by the direction from the center of the earth to the point.  The distinction between geocentric and geodetic latitudes is illustrated in the links and also in my reply at How do you compute the earth&#39;s radius at a given geodetic latitude?.\n\nAdditional latitudes have been defined to help create accurate maps that have particular properties, such as being conformal, equal-area (&quot;authalic&quot;), or isometric.  (By changing the latitude slightly we &quot;project&quot; the ellipsoid onto the sphere and then we apply a projection from the sphere to the plane to make a map.  This last step is relatively simple, because it does not need to handle the complicated ellipsoidal formulas, while the initial change of latitude increases the overall accuracy of the map.)\n\nAn &quot;isometric latitude&quot; isn&#39;t even in degrees; it&#39;s essentially the northing coordinate for a Mercator projection.\n\n\nWhen we change the model of the earth (the reference ellipsoid), we obtain a different set of latitudes altogether.  Frequently this happens when a latitude based on an ellipsoid is considered to be a latitude based on a spherical model.  I recently analyzed the resulting error at How accurate is approximating the Earth as a sphere?, finding the displacements (between the correct location designated by a latitude and the apparent location) can be as great as 20 km.  Differences among the various latitudes in use (see &quot;additional latitudes&quot; above) can be of the same order of magnitude, so even for very rough mapping purposes one should pay attention to what is going on.\n\nAdditional references\nA good, but highly technical, source of information on many forms of latitude is\nBugayevskiy, Lev M. &amp; John P. Snyder, Map Projections, A Reference Manual.  Taylor &amp; Francis, London (1995).\nSee pp. 33-37 for formulae and Appendix 5 for a table of isometric latitudes.\n Differences among the various latitudes in use (see &quot;additional latitudes&quot; above) can be of the same order of magnitude, so even for very rough <span class=\"highlight\">mapping</span> purposes one should pay attention to what is going &hellip; "
    },
    {
        "question": "Creating sectors for telecom towers",
        "area": [
            "pyqgis",
            "qgis-plugins",
            "c++"
        ],
        "text": "Telecom cell site plan and optimization using QGIS\n\nCreate Points or Site Locations:\n\n\nCreate database in CSV (make sure antenna sizes are sorted in descending order: highest first to lowest last, such that masking through overlay of cells could be avoided)\n\n\n\n 2. Import to QGIS using &quot;Add Delimited Text Layer&quot; \n\n\n\nChoose X and Y fields and pick Datum\n\n\nCreate Site Sectors:\nPlease utilize the Plugin &quot;Shape Tools&quot; to create site Sectors\n\n\nMake Sector from &quot;Azimuth&quot;:\nIn this scenario it requires 2 additionally defined columns to form a sector, it could be derived from actual &quot;Azimuth&quot; of the sector.\n\nPer se, an offset of -/+ 20 degrees to the actual orientation would make sector BW 40 degrees from node, or as maybe required based on user requirements.\n\n\nStarting angle field: 1st derived column with - 20 deg. angle: Pick corresponding column here\nEnding angle field: 2nd derived column with +20 deg. angle: Pick corresponding column here\nRadius field: Antenna size or Sector size should be derived in separate column as usual and input should be given to Radius under &quot;Shape Tools&quot;\n\n\n\n\n\nLayer properties--&gt; Style --&gt; Control feature rendering order --&gt; Expression --&gt; Antenna size --&gt; pick Descending under (Asc / Description) to have the sector overlay rendering order size large in bottom and size small on top for visibility onwards making map canvas in case CSV data or table data is not arranged earlier\n\n\n\nhttps://twitter.com/vamsi_uppala/status/984504617215049728\n\nDistance Matrix: Using this inbuilt algorithm distance between source site to its nearest neighbor could be identified to derive sector size of the site based on site density / frequency in an given geography, such that sector overlapping could be avoided while retaining appropriate visibility at all zoom levels (per se 1/3rd of distance calculated using the algorithm was used in below example. In case of multi technology / layer network, technology / layer wise magnitudes or sizes could be used to give visualization theme). \n\nThis process would facilitate better representation network with all proximities while working with KPIs or Neighbor analysis.\n\n\n\nNote: Unique Site list are to be processed since tool would generate null distances if cells from same site are processed to extract distance to nearest neighbor.\n\nFor faster processing NNJoin plugin could be utilized as an substitute for the nearest neighbour (conversation of distance in map units (degrees) to meters or km (metric) could be needed).\n\n\n\n\nCreate Neighbors:\n\nMake WKT format comprising of Line start and end points of neighbor markup\n\nStart point is Source Site&#39;s coordinated (Lat1 Long2) and end point is target site&#39;s coordinates (Lat2 Long2).\n\nMake a new column with formation of LineString(Long1 Lat1,Long2 Lat2), or it could be later derived with the help of Field Calculator via Layer Properties.\n\n\nUtilizing Sector centroids would be better for appropriate rendering and easy identification considering multi-techno sites.\n\nNeighbor relations can be patched with network stats such as &quot;Handover Count / Late HO / Early HO / HO Fail etc.&quot; to derive a thematic for line thickness or colour for easy identification. This excise could use &quot;Graduated&quot; under &quot;Style&quot; menu.\n\n\n\n\nThis process of creating nbrs with HO stats is almost instantaneous for a size which was given a try with HO relations over 800,000 and cells count of ~40,000.\n\nNeighbor Creation from Distance Matrix algorithm:\n\nNeighbor derived through Distance Matrix algorithm and representation on map by source site, however this is representation of nearest neighbor assuming omini presence, which could be used in case of site level neighbor addition like LNADJW and LNADJG where SON would define the relations from this defined profile (neighbour from interesting point of two directional points are yet to be evaluated to suit wireless scenario):\n\n\nBelow formula could be used in Geometry generator to represent the relations on the fly (Layer Properties-&gt;Single symbol-&gt;Marker-&gt;Simple marker-&gt;Symbol layer type-&gt;Geometry generator-&gt;Geometry type-&gt;LineString/MultiLineString):\nmake_line(centroid(geometry(get_feature(&#39;NetworkSiteDatabase&#39;,&#39;Site&#39;,&quot;InputID&quot;))),centroid(geometry(get_feature(&#39;NetworkSiteDatabase&#39;,&#39;Site&#39;,&quot;InputID&quot;))))\n\nMaking TAC, LAC boundaries are easy on QGIS (100,00 sites find this done with in 1 min):\n\n1. Make &quot;Voronoi Polygons&quot; from points\n\n\nUse &quot;Dissolve Boundaries&quot; algorithm under &quot;Process Toolbox&quot; Grass to merge individual cell boundaries to gross TAC, LAC, BSC or Cluster boundaries etc.\n\n\n\n\nA sample work flow is shown below taking 10 km x 10 km grid distance to place cell sites for Indian geography, which is resulted in 36,032 sites with 108,096 cells. And each district is depicted unique TAC boundary for easy understanding and then the output is as follows:\n\nThis is a rough representation of planning and mostly suits day to day capacity and coverage expansions by network operators unless they have very stringent approach methods where constraints are followed for dimensioning viz. Radio propagation models, Terrain, Clutter, Capacity and Service promises (Cell edge throughput, Avg. throughput, Coverage and type of services etc.)\n\n\n\n\nKPI interlacing onto Sectors:\nCSV or Excel could be used with additional Cell, Site, relation level KPIs.\n\nor\n  Use &quot;Join Button&quot; on &quot;Layer Properties&quot; popup window as VLOOKUP function to pullover data from regular KPI reports and represent on map as thematic using common field ex. Cell / Segment name in case of cell level KPI or relation when in case of Handover related etc.\n\n\n\nAnd arrange thematic accordingly: Use &quot;Rulebased&quot; with &quot;Graduated&quot; in case to generate with multiple conditions at one go.\n\nUse &quot;TimeManager&quot; plugin to check KPI plots to identify its dynamics by plying hourly, daily time interval timelapse through selected canvas.\n\nUseful plugins:\n\n&quot;SpreadSheet&quot; \n\n\nImport direct Excel worksheet onto QGIS\nClassification of column data (Integer, Decimal, String, etc.)\nFile data could be plotted at import with corresponding geo-data (Lat Long for points; WKT for HO Lines or Polygons, if any) on choosing datum\nKPI reports could be easily taken onto mapping through this process\n\n\n\n\n&quot;TableManager&quot; For editing column headers on the go\n\n\n&quot;OpenLayer&quot; and &quot;QuickMapservices&quot;: For Map overlays ex. Google Map, Bing Map, OSM, Aster elevation data etc.\n\nTiming Advance Plot:\nUse &quot;Diagrams&quot; option under &quot;Layer Properties&quot; popup and create &quot;pie&quot; chart or &quot;bar&quot; chart to visualize the site signal reachability by TA / PRACH samples.\n\n\n\nApplying diagrammatic thematic for TA and representing all samples in learner method:\n\n\nTA or PRACH thematic on applying variable magnitude or Scaled size method by aggregating overshooting TA samples&gt;6.9 km:\n\n\nTA aggregation through field calculator (in this case data was multiplied by 1 to convert to integer and made summation):\n\n\nSample drive test plot is shown below:\n\n\nQConsolidate: For sharing complete project files with team etc. while retaining all project&#39;s properties.\n\nOther tips: \n\n\nTake HO relations from collocated site sector of 4G (since it is being SON) and replicate same set of collocated site Sectors (on 2G &lt;-&gt; 2G or 3G &lt;-&gt; 2G or or 3G&lt;-&gt;2G or 23G -&gt; 4G, this could be scaled up to OSS level on monthly or bi-monthly basis, and limited to top performing HO count and max allowed relations count.\nSimilar to above could be utilized for neighbors of 3G&lt;-3G&gt; onto 3G&lt;-&gt;2G, where site misses 4G proximity.\nSaving Layer style to Spatlite database:\n\nDrive test plot thematic could be handled easily and process could be scaled up to typical cluster with file sizes over 200 MB or more. Pre to Post drive route matching could be done with much ease by buffering either of the plot to GPS error or bin distances (whichever is high per se ~20 m) such that Pre or Post plot could be clipped out and bin comparison could be done appropriately and hence benchmarking. QGIS has on-the-go layer styling while on processes (Copy/Past) of thematic properties which are saved in different active layer or saved on local m/c (user accessible and editable by Text editor like NotePad++, Submlime etc.), and thematics are also shareable between team etc. \n\n\n\n\nSample RSRP thro&#39; simple Pathloss calculations on omini directional radiation pattern (Bin / Point map with 100 m interval has been created along Indian railways line vector), individual distance (multi-ring buffer) could be utilized to represent the coverage prediction plot (Constraints omitted: Antenna tilts, Elevations, Reflections, Absorption, and many others):\n\n\nRepresentation of drive plot from regular coverage contours:\n\n\nDraw regular distance &quot;multi-ring buffer&quot; from chosen site location (lat long) to make variable distance rings around the given point, dissolving the distance buffers would facilitate representation better\nGenerate points along line vectors\nClip points vector over multi-distance ring buffer to pick corresponding distances to the site \nUse appropriate RF model formula to calculate free space pathloss and represent bin\nUse viewshed approach to involve Ground Elevation in prediction (*Currently under exploration)\nUse Antenna Tilts, Antenna pattern (*Currently under exploration)\nUse Clutter absorption model (*Currently under exploration)\n\n\n\n\nApply COST 231 (Urban RF propagation model) in association with distance calculated through MultiRingBuffer from site centroid. However this process could be further refined to plot directional antenna radiation pattern in association with interpolation of bins for desired pixelation.\n\n\nField calculator could be utilized to check coverage thematic of route map (made points along line) to make iteration checks on different Frequencies and other constants.\n\n\nCost 231 Urban RF model: Formula in field calculator: TX Power-(46.3+33.9*LOG10(Freq. Band in MHz)-13.82*LOG10(20)-(3.2*LOG10(11.75*1)^2-4.97)+(44.9-6.55*LOG10(BTS TX antenna Ht.))*LOG10(&quot;distance in km&quot;)+3)\n\n\nHata Urban RF model: Formula used in field calculator TX Power -(69.55+26.16*log10(1900)-13.89*log10(BTS TX antenna Ht.)-(0.8+(1.1*log10(1900)-0.7)*1.5-1.56*log10(Freq. Band in MHz))+(44.9-6.55*log10(BTS TX antenna Ht.))*log10(&quot;distance in km&quot;)):\n\n\nHata Rural RF model: Formula used: TX Power-((69.55+26.16*log10(Freq. Band in MHz)-13.89*log10(BTS TX antenna Ht.)-(0.8+(1.1*log10(Freq. Band in MHz)-0.7)*1.5-1.56*log10(Freq. Band in MHz))+(44.9-6.55*log10(BTS TX antenna Ht.))log10(&quot;distance in km&quot;))-4.78(log10(Freq. Band in MHz))^2+18.33*log10(Freq. Band in MHz)-40.94)\n\n\n\nServing cell representation using hublines (only ideal condition FSL):\n \n\nhttps://github.com/NationalSecurityAgency/qgis-shapetools-plugin/issues/9\n File data could be plotted at import with corresponding geo-data (Lat Long for points; WKT for HO Lines or Polygons, if any) on choosing datum\nKPI reports could be easily taken onto <span class=\"highlight\">mapping</span> through this &hellip; "
    },
    {
        "question": "Creating arcs between two points in ArcPy?",
        "area": [
            "arcpy",
            "polyline-creation",
            "flow-map"
        ],
        "text": "It seems the most common problem with these types of &quot;flow maps&quot; is that when many lines are included, they collide to such a great extent that it makes it difficult to discern any non-obvious pattern (when reciprocal flows are considered it happens to an even greater extent). Also the long lines tend to dominate the graphic, although it is quite possible the distribution of flows is predominately over short spaces (for instance a host of different distributions between places tend to be similar to Levy flights). I suppose this isn&#39;t necessarily a bad thing (the long lines may be more intrinsically interesting that the short lines for many phenomenon), but I don&#39;t think we want to lose the forest for the trees so to speak.\nAlthough I don&#39;t doubt I&#39;ve missed some potential &quot;solutions&quot; that have been proposed, I will try to sum up some of the ways individuals have tried to solve the problem in work that I have come across.\nDistorting the Lines\nIf you peruse some of the other threads on the sight you will see some examples of how people have dealt with this problem. In particular, the lines are distorted so they don&#39;t overlap with each other or other objects on the map. Whuber&#39;s answer on another similar question (already mentioned in a comment) is an example of this. A presentation by some researchers at Stanford demonstrates this same idea (Phan et al., 2005). Thanks for that presentation goes to dslamb for this answer on another thread (and all of the answers to that thread will be on interest for your question as well). I particularly find it interesting that one of the cardinal examples of this is the old immigration map by Minard is an example of a desirable output (circa 1864!).\nGiven your particular use case (small number of nodes and lines), this seems sufficient. The other &quot;solutions&quot; I present are more intended to visualize data with many lines and many origins-destinations (although I assume they will be useful summaries for the community in general, so I continue on regardless).\nUsing Alpha Blending, Color, and Line Width/Height\nThe maps I listed in that same thread previously noted, Representation of network flows are examples of these. The facebook friends is a good case of adjusting the alpha level of lines, so it takes many more flows to represent a darker (or brighter in that case) connection between the two places. This also demphasizes the longer lines because they tend to happen more infrequently. Similar logic comes from Value-by-Alpha maps for polygon areas (Roth et al., 2010) that have been mentioned on this forum before.\nThe other map I present in that same answer uses color, and a non-traditional 3d perspective arcing lines (Ratti et al., 2010). The authors used a clustering criteria to group homogenous areas together and color code them (so by definition the areas within the color have more similar flow patterns than between colors). The clustering criteria in and of itself could be interesting to identify patterns in the data, although it seems a likely problem with this, as Andrew Gelman has mentioned, is that it tells you pretty much what you already know, that places nearer to each other tend to have more connections.\nLastly, in this category I include techniques that weight the lines (similar to alpha blending) using either the line width, or in the case of the 3d perspective line height, to convey the volume of the flow. See the page on Tobler&#39;s flow mapping software page for some examples in 2d (and the other article I mentioned is an example in 3d using line heights). Also on that page Tobler has a very useful article describing the problems with flowmapping and their historical application (Tobler, 1987).\nAnother example in 3d is this answer by a mankoff on this site. This post on the Sociological images blog shows a useful way in a flow diagram to distinguish between in-flows and out-flows (although again it works because the number of nodes and relatively small, and the nodes on the network can be layed out in an arbitrary way to reduce overplotting). Those same types of arrows (and a few others using hashings) are also in (Tobler, 1987).\nIn the end though line width and color don&#39;t really solve the over-plotting problem. The arcs in 3d help somewhat, although with more complicated flow patterns I think they will have limited utility. IMO alpha blending seems to be the most useful in a wide variety of situations of these three, but color and line width could/should be used in conjunction with line distortion mentioned above.\nData Reduction\nI group two types of techniques here, 1) using small multiple maps (i.e. many maps with inherently less objects to visualize so overplotting is reduced), or 2) other graphical representions, that are not lines, but represent some of the flows via density or choropleth maps. Examples of these can be found in (Corcoran et al., 2009; Rae, 2009; Wood et al., 2010) (thanks to iant for the Rae reference). These tend to reduce the amount of visual information presented by either presenting a series of small multiple maps (or just a smaller area), or use a choropleth mapping scheme to represent some statistic (examples could be number of in-flows, number of outflows, direction of the flows, average distance of the flows). If you have point level data you could represent these statistics through kernal density raster maps, or aggregate them into quadrats.\nWhen information is reduced like this, overplotting isn&#39;t as much a problem. A very cool interactive online example is this migration map by Forbes magazine. You can only see one county at a time, but the reduction of information makes it much easier to parse the lines (and the difference between in-flows and out-flows). A recent post on the ESRI mapping blog also uses a similar technique with the small multiples (they also choose a particular projection for the world map to have &quot;pretty looking&quot; lines, and make good use of color to further highlight different international origins). In that example it works out pretty well because the end destination is the same for all flows, but if flows could be reciprocal it probably wouldn&#39;t work out as well.\nUsing Other Non-map Representations of Flows\nOthers on this site have suggested using alternative diagrams to the actual map to represent the flows (just mapping the origins and destinations in some other manner than their actual geographic location). Examples of these are either cicular visualizations (such as that produced by Circos), arc diagrams (see this example on Protovis, these are also called kriskograms (Xiao &amp; Chun, 2009)), or matrix heat maps (here is another example from the Protovis website). Another option would be to use some type of automated network layout to identify patterns in the flows (such as that capable by Graphviz). Besides Graphviz it appears Gephi, the NetworkX python library, and some R libraries are popular tools as well (see this answer on the stats site).\nThe libraries I cite are pretty cool as they have developed interactive visualizations as well. Here is an example with a similar style to the circular graphics (although not circular!). Here is another interactive visualization using some of the line distortion techniques discussed earlier, network placement (that appears similar to circular Dorling cartograms) as well as other useful statistical summaries (I saw both of those examples originally on the information aesthetics blog).\n\nSome other resources I think are useful are the software and articles coming from the Spatial Data Mining and Visual Analytics Lab. Also the crime travel demand modeling in the CrimeStat program is a gentle introduction to applicable regression techniques for such flow data. Either of these tools may allow you to identify interesting correlations in the flow patterns to other geographic information. Another place to perhaps recieve some useful inspiration for either graphically displaying the data or statistical analysis would be a recent issue of in the Journal of Computational and Graphical Statistics, Volume 20 Issue 2, on examining flight arrival/departure statistics for commercial carriers in the US from 1987 to 2008 (if you are interested in handling big data this would be worthwhile to examine as well). All the articles are free and they have associated posters with each paper.\nIn the end, the data and the medium will dictate how well some of these techniques work in reducing the visual clutter that comes along with flow data. I hope this is a useful place though to find ideas on how to deal with this visualization problem though. If you further refine your question into what you want to accomplish, then others can give useful feedback into actual programmatic implementations (if something is not already available).\n\nCitations\n\nCorcoran, Jonathan, Prem Chhetri &amp; Robert Stimson. (2009) Using circular statistics to explore the geography of the journey to work. Papers in Regional Science 88(1): 119-132.\nPhan, Doantam, Ling Xiao, Ron Yeh, Pat Hanrahan &amp; Terry Winograd. (2005) Flow Map Layout. In Information\nVisualization, 2005. INFOVIS 2005. IEEE Symposium: 219\u2013224.| PDF here\nRae, Alasdair. (2009) From spatial interaction data to spatial interaction information? Geovisualisation and spatial structures of migration from the 2001 UK census. Computers, Environment and Urban Systems 33(3): 161-178.|PDF here\nRatti, Carlo, Stanislav Sobolevsky, Francesco Calabrese, Clio Andris, Jonathan Reades, Mauro Martino, Rob Claxton &amp; Steven H. Strogatz. (2010) Redrawing the map of Great Britain from a Network of Human Interactions. PLoS ONE 5(12). Article is open access from link\nRoth Robert E., Andrew W. Wooddruff &amp; Zachary F. Johnson. (2010) Value-by-alpha maps: An alternative technique to the cartogram. The Cartographic Journal 47(2): 130-140.|PDF here\nTobler, Waldo R. (1987) Experiments in migration mapping by computer. Cartography and Geographic Information Science 14(2): 155-163|PDF here\nWood, Jo, Jason Dykes &amp; Aidan Slingsby. (2010). Visualisation of origins, destinations and flows with OD maps. The Cartographic Journal 47(2): 117-129.|PDF here\nXiao, Ninchuan &amp; Yongwan Chun. (2009) Visualizing migration flows using kriskograms. Cartography and Geographic Information Science 36(2): 183-191.\n\n*note, links to ungated pdf documents are included when I could find one\n See the page on Tobler&#39;s flow <span class=\"highlight\">mapping</span> software page for some examples in 2d (and the other article I mentioned is an example in 3d using line heights). &hellip; |PDF here\nTobler, Waldo R. (1987) Experiments in migration <span class=\"highlight\">mapping</span> by computer. Cartography and Geographic Information Science 14(2): 155-163|PDF here\nWood, Jo, Jason Dykes &amp; Aidan Slingsby. (2010). &hellip; "
    },
    {
        "question": "Seeking qml or sld file for QGIS + OpenStreetMap data?",
        "area": [
            "qgis",
            "openstreetmap",
            "sld",
            "qml"
        ],
        "text": "I&#39;m looking for a qml file (or equivalent e.g. sld) to allow me to use QGIS to take OpenStreetMap data and produce paper maps. I&#39;m re-asking this question (it was asked once or twice over a couple of years by other people) because I&#39;m really surprised not to easily find such a thing already (I looked hard). \n\nI have found Anita Graser&#39;s styles - which are good, but only style basic data like roads (and do so simply). I&#39;ve successfully followed the directions for getting OSM data to work with. I&#39;ve carried out some basic style editing successfully. I realise I could create my own styles for this purpose - but this seems like a very big job. I want a visually pleasing map taking into account most of the data available on OSM (i.e. not just streets, but tracks, paths, rivers, woods, lakes, buildings and so on). I&#39;d have thought that there would be other people out there already doing the same... It seems odd to have to re-invent the wheel when both OSM and QGIS are open source / open data projects. I feel like maybe I&#39;ve just missed the obvious repository of OSM qml files which resides out there on the internet somewhere if you know where to look.\n\nAdditional notes in response to query below...\n\nIdeally I&#39;m looking for a Mapnik style rendering of the OSM data, but any equivalent properly developed and complete style would be good.\n\nAt the moment the objective is to use this data to produce paper mapping, but simple use of the mapping as base data on which other geographic data can be displayed also requires a decent rendering. At work I use Ordnance Survey data completely styled to produce a full and very detailed UK map (the point being that I didn&#39;t have to design this styling, it came with the data). I realise that other tools exist for paper mapping, but the same issues tend to arise at one stage or another... I&#39;m more or less successful in making the tool work for me in really basic terms, but to get to something visually useful I end up back with me either needing to re-invent a complete rendering style from scratch (beyond my skill), or encountering such a complex set of requirements for database setups or whatever that the process crashes and burns before I get anywhere useful. With a few more years of GIS experience I&#39;ll maybe be a database, CartoCSS (or whatever else) wizz... but until then I&#39;m prevented from using the amazing resource that OSM provides by this one barrier.\n\nUpdate (July 2015): Please note that I&#39;m still looking for information on this, and given that I&#39;ve just been informed that the question has had 2500 views in the last year clearly others are too.\n At the moment the objective is to use this data to produce paper <span class=\"highlight\">mapping</span>, but simple use of the <span class=\"highlight\">mapping</span> as base data on which other geographic data can be displayed also requires a decent rendering. &hellip; I realise that other tools exist for paper <span class=\"highlight\">mapping</span>, but the same issues tend to arise at one stage or another... &hellip; "
    },
    {
        "question": "Where can I download the Google Road network as shapefile?",
        "area": [
            "shapefile",
            "google-maps",
            "download"
        ],
        "text": "No, Google&#39;s road data is proprietary and is not distributed in a GIS capable format. This is because Google spends a lot of money keeping their GIS accurate and current, and distributing it for free would allow Google&#39;s competitors (e.g. Microsoft, MapQuest, Apple, ESRI) to download it. This would forfeit Google&#39;s competitive advantage in the web mapping world.\n\nOpenStreetMap does offer downloads of their entire road dataset. The &quot;Downloading data&quot; Wiki page has some more information. The data download page is here. If you only need data for a single region or country, I recommend using the prepackaged downloads from geofabrik.de.\n This would forfeit Google&#39;s competitive advantage in the web <span class=\"highlight\">mapping</span> world.\n\nOpenStreetMap does offer downloads of their entire road dataset. &hellip; "
    },
    {
        "question": "Comparison of WMS and WFS services",
        "area": [
            "wms",
            "web-service",
            "wfs"
        ],
        "text": "You are really comparing chalk and cheese. WMS serves up raster tiles of data that have been created by a WMS server. This data can originally be vector or raster data and will have been drawn with style, but by the time it gets to your client it is just a raster image. WFS on the other hand, serves up vector data.\n\nGood places to look are the OGC website which has the standards documents as well as overview documents for the various services. This would be a reference to put in your bibliography. MapServer and GeoServer have lots of documentation on the way each of them deals with WMS and WFS. And of course, there is Wikipedia which has short but generally accurate pages on both, but I suspect you would lose marks if you actually cited the site in your thesis. Best just use it to get an overview.\n\nWith something like these geospatial web services, it usually pays dividends if you actually install a server and play around with creating maps. There are plenty of tutorials out there, and there are lots of previous posts on stackexchange.\n\nMy undergrad thesis is on the use of web mapping for the archaeology industry, and I have a virtual machine (VBox running JeOS Ubuntu 10.10) that runs mapserver and tinyows that I can connect to like a &quot;real&quot; server, and test what I&#39;m writing about.\n My undergrad thesis is on the use of web <span class=\"highlight\">mapping</span> for the archaeology industry, and I have a virtual machine (VBox running JeOS Ubuntu 10.10) that runs mapserver and tinyows that I can connect to like a &hellip; "
    },
    {
        "question": "Are ellipsoids a mathematical necessity?",
        "area": [
            "geodesy",
            "ellipsoid",
            "geoid"
        ],
        "text": "This summarizes my understanding of some of the basic ideas.  Because it is hard to find all of them clearly described and summarized in one place, I could be wrong or misleading about some of them: comments and corrections are welcome.\n\n&quot;Geoids&quot; are approximations to a surface of gravitational equipotential. \n\n\n  The geoid is a hypothetical Earth surface that represents the mean sea level in the absence of winds, currents, and most tides. The geoid is a useful reference surface. It defines the horizontal everywhere and gravity acts perpendicular to it. A carpenter\u2019s level aligns itself along the geoid and a carpenter\u2019s plumb bob points down the vertical or perpendicular to the geoid. Water will not flow in aqueducts if the pipes are perfectly aligned along the geoid. Surveyors use knowledge of the geoid and the horizontal when they lay out highways and boundaries.\n\n\n(NASA)\n\n\n\nTo get a sense of what is gained relative to a sphere or ellipsoid, note that\n\n\nThe difference in apparent elevations between a spherical model and a good ellipsoid is up to two dozen kilometers.  This translates to maximum positioning discrepancies of about 22 kilometers.  The relatively large amount of positioning discrepancy occurs because there is a systematic distortion of the sphere relative to the ellipsoid: it attains one extreme at the poles and another extreme at the Equator.\nThe difference in apparent elevations between a good ellipsoid and a geoid is typically less than 100 meters (about 0.1 kilometers).  This is not a systematic difference: it varies a lot across relatively short sections of the earth (on the order of hundreds of kilometers).  Consequently, the maximum horizontal positioning discrepancy resulting from any hypothetical geoid-based projection is likely on the order of meters or less (usually much less except perhaps over large, carefully chosen areas). \nHowever, the deflection of the geoid (which is the amount by which true gravitational vertical direction varies) reaches up to about an arc-second, which makes it unsuitable for any kind of very high-accuracy mapping based on measuring latitude in terms of a local upward-pointing angle.  An arc-second of deflection translates to almost 30 meters on the ground, and such deflections can vary from one extreme to the other over just a few hundred kilometers.\n\n\nIn return for squeezing out that last 0.5% of accuracy in describing how the geoid varies from the ellipsoid, you need hundreds to hundreds of thousands of parameters compared to two to describe an ellipsoid.  Yes, it is mathematically possible to define a projection based on a geoid instead of an ellipsoid.  [See &quot;Coordinate charts&quot; on pp 4-5 of this text, for instance.  The modern mathematical definition of smooth curved surfaces, like a geoid, is based on a set of projections.  The Implicit Function Theorem guarantees such projections exist for the geoid.]  Computation would be, to say the least, inefficient (although it could be sped up by interpolation in precomputed tables).  When necessary, the difference in vertical positioning can be computed after ellipsoid-based projection in terms of the geoid parameters or by interpolating in a precomputed grid of geoid values.\n\nA serious potential problem with basing map projections on a geoid as reference surface is that the geoid is constantly changing worldwide.  It will change with changes in sea level, for instance.  \n\nBecause nowadays much geopositioning is done in geocentric coordinates, rather than by means of gravitational-based triangulating devices (such as levels), use of a geoid is practically irrelevant: an ellipsoid--however well it might or not be related to gravity, sea level, or the actual shape of the earth--serves as a reasonably stable reference surface relative to which everything else can be located and mapped.  The geoid is then described relative to this reference.  Its description is used in mapping primarily to permit GPS satellites to improve their positioning accuracy.\n the deflection of the geoid (which is the amount by which true gravitational vertical direction varies) reaches up to about an arc-second, which makes it unsuitable for any kind of very high-accuracy <span class=\"highlight\">mapping</span> &hellip; Its description is used in <span class=\"highlight\">mapping</span> primarily to permit GPS satellites to improve their positioning accuracy. &hellip; "
    },
    {
        "question": "Calculating distortion on Equirectangular Projection",
        "area": [
            "coordinate-system",
            "software-recommendations"
        ],
        "text": "I am trying to calculate distortion so I can distort overlaying text and forms to precisely match an image of an equirectangular projection.\n\nHow does one calculate the distortion at a given latitude on an equirectangular projection 1:45,000,000 (say, 2000 pixels wide x 1000 pixels high)?  \n\nI&#39;ve been trying to figure out this post and its links to no avail:\nHow to create an accurate Tissot Indicatrix?\n\nI am not a professional, just a very interested amateur. \n\n\n\nHere&#39;s the long story.\n\nI am visualizing/mapping data using the Processing programming language and would like to have the 2D mapped data (different sized fonts and circles) appear undistorted when wrapped to a 3D globe. The data is mapped using equirectangular x, y&#39;s and the maps I want to use as backdrops are all this projection, so I&#39;m assuming I want to &quot;match&quot; this distortion (e.g. by calculating distortion via latitude using Tissot equations?). Using the programming language I can precisely distort both the text and the circles. I think all I need are the equations to do it correctly.\n\nHere is the original 2D data map:\n\n\n\nWhen wrapped it looks distorted, like this:\n\n\n\nHow can I make my 2D image look undistorted when wrapped to the 3D sphere?\n\nFor reference, here&#39;s the same question asked differently on the Processing forum.\n\n\n\nI&#39;m not sure I want to reproject to an orthographic projection.  I want my 2D data map to wrap to a 3D sphere model that can be interacted with (i.e. spun).\n\nI am using a 3D modeling program (Cinema 4D) to wrap a sphere with a 2MB &quot;Blue Marble&quot; image (equirectangular projection) from NASA.\n\nWhen wrapped it appears undistorted from all hemispheres (not just one hemisphere, as an orthographic projection would be?), see: still from 3D model above.  (The modeling program is doing the orthographic projection for me as I rotate the object, I suppose.)  Therefore, I think that if I distort my 2D data map in a similar way it too will appear undistorted on the 3D sphere.  Here&#39;s a shot I took with an equation that approximates equirectangular distortion.  You&#39;ll notice the egg shaped ellipses from the 2D image look like a circle when wrapped to the 3D sphere.  Similarly, the Tissot ellipses also appear as circles on the 3D sphere.\n\n\n\n\nThis is why I was looking at the Tissot equations...to more precisely figure out the distortion of the equirectangular projection at different latitudes so I could distort my overlay accordingly.\n\nPerhaps I should use a GIS program.  I just downloaded Cartographica and will see if I can figure it out.  \n\nAny Mac software suggestions for someone new undertaking this task?\n I am visualizing/<span class=\"highlight\">mapping</span> data using the Processing programming language and would like to have the 2D mapped data (different sized fonts and circles) appear undistorted when wrapped to a 3D globe. &hellip; "
    },
    {
        "question": "Intersecting lines to get crossings using Python with QGIS?",
        "area": [
            "qgis",
            "python",
            "intersection",
            "line",
            "crossing"
        ],
        "text": "The nodes:\n\nYou want two things, the end points of the polylines (without intermediate nodes) and the intersection points. There are an additional problem, some polylines end points are also intersection points:\n\n\n\nA solution is to use Python and the modules Shapely and Fiona\n\n1) Read the shapefile:\n\n\n\n2) Find the end Points of the lines (how would one get the end points of a polyline?):\n\n\n\n\n\n3) Compute the intersections (iterating through pairs of geometries in the layer with the itertools module). The result of some intersections are MultiPoints and we want a list of points:\n\n\n\n\n\n4) Eliminate duplicates between end points and intersection points (as you can see in the figures)\n\n\n\n5) Save the resulting shapefile\n\n\n\nFinal result:\n\n\n\nThe line segments\n\nIf you want also the segments between the nodes, you need to &quot;planarize&quot; (Planar Graph, no edges cross each other) your shapefile. This can be done by the unary_union function of Shapely\n\n\n\n\n end points and intersection points (as you can see in the figures)\n\nresult = endpts.extend([pt for pt in inters  if pt not in endpts])\n\n\n5) Save the resulting shapefile\n\nfrom shapely.geometry import <span class=\"highlight\">mapping</span> &hellip; &#39;,&#39;properties&#39;: {&#39;test&#39;: &#39;int&#39;}}\n# creation of the shapefile\nwith fiona.open(&#39;result.shp&#39;,&#39;w&#39;,&#39;ESRI Shapefile&#39;, schema) as output:\n    for i, pt in enumerate(result):\n        output.write({&#39;geometry&#39;:<span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Difference between projection and datum",
        "area": [
            "coordinate-system",
            "datum",
            "gis-principle",
            "terminology"
        ],
        "text": "Geographic projections are a way of showing the curved surface of the Earth on a flat surface like a piece of paper...\n\nFrom the Manifold user documentation:\n\n\n  Earth is not an exact ellipsoid. In fact, because the Earth is such a &quot;lumpy&quot; ellipsoid no single smooth ellipsoid will provide a perfect reference surface for the entire Earth. The practical solution to this is to measure the Earth&#39;s shape in different areas and to then create different reference ellipsoids used for mapping different regions on Earth. \n  A datum is a reference ellipsoid together with an offset from the center of the Earth. By specifying different offsets, you can use the same standard ellipsoids in many different regions of the Earth. Different countries will often use the same ellipsoid but with different offsets for standard government maps in those countries.\n\n The practical solution to this is to measure the Earth&#39;s shape in different areas and to then create different reference ellipsoids used for <span class=\"highlight\">mapping</span> different regions on Earth. &hellip; "
    },
    {
        "question": "Creating a small web-mapping/map-tiling service",
        "area": [
            "qgis",
            "openstreetmap",
            "openlayers",
            "web-mapping",
            "tiles"
        ],
        "text": "I am looking for a small-scale and easy way to present one or more polygon shapefiles online (on a municipal website without any existing map-server infrastructure, to be precise). Right now, I&#39;m doing all work with QGIS, and I would prefer to stay all open-source (there is no budget left for any big software investments).\n\nResearching this topic resulted in a overwhelming number of possible approaches, and left me quite confused. What I am looking for is\n\n\nbeing able to show categorized polygons in a thematic map\n(- if possible, it would be nice to get popups or to be able to retrieve attribute information - but that&#39;s highly optional)\nI would prefer to do most work (styling, etc) in QGIS\nOSM as base map would be perfectly fine\n\n\nSo far, custom map tiles on an OSM base map look like the thing I&#39;m looking for (or is there a better solution)? What would be the best way to create these tiles?\n I am looking for a small-scale and easy way to present one or more polygon shapefiles online (on a municipal website without any existing map-server infrastructure, to be precise). Right now, I&#39;m doin &hellip; "
    },
    {
        "question": "Publishing PostGIS Rasters in GeoServer?",
        "area": [
            "geoserver",
            "postgresql",
            "postgis-2.0"
        ],
        "text": "How do I publish PostGIS rasters using GeoServer?\n\nI have spent a lot of time trying to create a Raster datasource using Image Mosaic JDBC but with no luck. \n\nSteps performed: \n1. Downloaded and Installed the JDBC Image Mosaic extension (worked ok)\n2. Created the &quot;Connection Parameter&quot; files:\nconnect.postgis.xml.inc:\n\n\n\nmapping.postgis.xml.inc: \n\n\n\nosm.postgis.xml: \n\n\n\nwhere &quot;mosaic&quot; is a table (columns: name, titletable,minX,minY,maxX,maxY,resX,resY) containing one row: &quot;gfm, testrastertable, , , , , , ,&quot;\n 3. Saved the config files in ../geoserver/data_dir/coverages/\n 4. While trying to add an Image Mosaic JDBC data store I receive the following error:\n\n\n\nUpdate: Geoserver log\n\n\n /localhost:5432/db1&quot; /&gt;\n  &lt;driverClassName value=&quot;org.postgresql.Driver&quot;/&gt;\n  &lt;maxActive value=&quot;10&quot;/&gt;\n  &lt;maxIdle value=&quot;0&quot;/&gt;\n&lt;/connect&gt;\n\n\nmapping.postgis.xml.inc: \n\n&lt;spatialExtension name=&quot;postgis&quot;/&gt;\n&lt;<span class=\"highlight\">mapping</span> &hellip; ENTITY <span class=\"highlight\">mapping</span> PUBLIC &quot;<span class=\"highlight\">mapping</span>&quot;  &quot;mapping.postgis.xml.inc&quot;&gt;\n  &lt;! &hellip; "
    },
    {
        "question": "How to Start Web Mapping?",
        "area": [
            "web-mapping",
            "references"
        ],
        "text": "It looks like you have gotten the Open Source answers in the question above.  If your company has the budget, ESRI can be a very good option.  To clarify, the webmapping APIs in and of themselves are free to use, however the backend ArcGIS Server and SDE will cost you money.  Additioanlly, desktop software will be needed to create map services to be used in the web mapping application.  If you already have access to these resources or can purchase them, I would defintely recommend looking into ESRI solutions.\n\nOne benefit here is that you can code in a variety of languages.  There are ESRI specific APIs for Flex and Silverlight:\n\nFlex: http://help.arcgis.com/en/webapi/flex/index.html\nSilverlight: http://help.arcgis.com/en/webapi/silverlight/index.html\n\nCurrently it seems as if the trend in web programming is moving away from solutions that require plugins and are vendor specific (above), and towards more open source and standards based frameworks.  ESRI has this covered with the Javascript API:\n\nJavascript: http://help.arcgis.com/en/webapi/javascript/arcgis/\n\nIf you take a look at these API websites the documentation is very good.  Additionally, forums are available for community help on specific problems. Tech support through ESRI is also very good.  So it comes down to price and resources, if you already have these applications or have the budget this is an excellent path, if not the above open source solutions are worth looking into.\n Additioanlly, desktop software will be needed to create map services to be used in the web <span class=\"highlight\">mapping</span> application. &hellip; "
    },
    {
        "question": "Finding Nearest Line Segments to Point using shapely?",
        "area": [
            "intersection",
            "spatialite",
            "shapely",
            "nearest-neighbor",
            "fiona"
        ],
        "text": "I have reproduced your example with shapefiles. \n\nYou can use Shapely and Fiona to solve your problem.\n\n1) Your problem (with a shapely ):\n\n\n\n2) starting with an arbitrary line (with an adequate length):\n\n\n\n\n\n3) using shapely.affinity.rotate to create the radii (rotating the line from the point, look also the Mike Toews&#39;s answer at Python, shapely library: is it possible to do an affine operation on shape polygon?):\n\n\n\n\n\n4) now, using shapely:cascaded_union (or shapely:unary_union) to get a MultiLineString:\n\n\n\n5) the same with the original lines (shapefile)\n\n\n\n6) the intersection between the two multigeometries is computed and the result is saved to a shapefile:\n\n\n\nResult:\n\n\n\n7) but, problem, if you use a a longer radius, the result is different:\n\n\n\n8) And if you want to get your result, you need to select only the point with the shortest distance from the original point on a radius:\n\n\n\nFinal result:\n\n\n\nI hope that is what you want.\n schema = {&#39;geometry&#39;: &#39;MultiPoint&#39;,&#39;properties&#39;: {&#39;test&#39;: &#39;int&#39;}}\n with fiona.open(&#39;intersect.shp&#39;,&#39;w&#39;,&#39;ESRI Shapefile&#39;, schema) as e:\n      e.write({&#39;geometry&#39;:<span class=\"highlight\">mapping</span>(points), &#39;properties&#39;:{&#39;test&#39;: &hellip; ))\nsolution = cascaded_union(points_ok)\nschema = {&#39;geometry&#39;: &#39;MultiPoint&#39;,&#39;properties&#39;: {&#39;test&#39;: &#39;int&#39;}}\nwith fiona.open(&#39;intersect3.shp&#39;,&#39;w&#39;,&#39;ESRI Shapefile&#39;, schema) as e:\n     e.write({&#39;geometry&#39;:<span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Android devices and apps with support for Galileo positioning?",
        "area": [
            "android",
            "hardware-recommendations",
            "gps"
        ],
        "text": "I maintain the GPSTest app on Google Play, which is open-source on Github.\n\nI&#39;m actively interested in adding Galileo support in the app, but to do this I need to know what IDs the Galileo satellites show up as in the Android platform.  And, this requires that there be some agreement between Galileo hardware manufacturers of those IDs - see Is there an industry-standard official mapping of Galileo satellites to global &quot;PRN\u201d/ID values?.\n\nI personally haven&#39;t seen any Android devices reporting Galileo satellites yet - as soon as I do, and I&#39;m able to find out the ID range agreed upon for Galileo, I&#39;ll add support to GPSTest.\n\nIf you have an Android device that supports Galileo and you&#39;re willing to help identify the range, please comment on this Github issue.\n\nEDIT Sept. 19, 2016\n\nFor Android 7.0 (N) and higher, Google has added a new API in Android that allows apps to explicitly determine the GNSS type of each satellite for the following GNSS constellation (from https://developer.android.com/reference/android/location/GnssStatus.html).\n\nI&#39;ll work on adding this to GPSTest, and will update my answer when it&#39;s live.\n\nEDIT Oct. 6th, 2016\n\nI have a working build of GPSTest that I believe should support Galileo.  If you have and a device with Galileo support (i.e., hardware), please comment on the below pull request on Github - I&#39;d love to get feedback to know if it works!\n\nhttps://github.com/barbeau/gpstest/pull/59\n\nEDIT Oct. 26, 2016\n\nGPSTest v2.1.8 and up now supports Galileo!  Download on Google Play at https://play.google.com/store/apps/details?id=com.android.gpstest.  Supports all devices with Android 7.0 (N) that have a Galileo-compatible chipset. Support for Galileo on Android 6.0.1 (M) and lower will depend on your device OEM.\n\nSo far users have confirmed that they are able to see Galileo satellites using GPSTest on the following devices:\n\n\nBQ Aquaris X5 Plus (See this post)\nHuawei Mate 9 (See this post)\nSamsung Galaxy S8 and S8+ (See this post and official specs which say &quot;Location (GPS, Galileo, Glonass, BeiDou) *Galileo and BeiDou coverage may be limited.&quot;)\nOnePlus 5 (Android 7.1.1 / OxygenOS 4.5.8) (See this post)\nHuawei P10 (See this post - Android 7.0, firmware version L29C432B171)\nOnePlus 5T (See this post)\n\n\nEDIT Mar. 26, 2018\n\nThe site UseGalileo.eu (by the EU GSA that operates Galileo) now has a list of devices and chipsets that support Galileo:\n\n\nGalileo-compatible smartphones and chipsets\n\n And, this requires that there be some agreement between Galileo hardware manufacturers of those IDs - see Is there an industry-standard official <span class=\"highlight\">mapping</span> of Galileo satellites to global &quot;PRN\u201d/ID values? &hellip; "
    },
    {
        "question": "Extract raster values within shapefile with pygeoprocessing or gdal",
        "area": [
            "python",
            "gdal",
            "pygeoprocessing"
        ],
        "text": "You can use rasterio to extract the raster values within a polygon as in GIS SE: GDAL python cut geotiff image with geojson file\n\nI use here a one band raster file and GeoPandas for the shapefile ( instead of Fiona) \n\n\n\n\n\nThe out_image result is a Numpy masked array\n\n\n\nNow I use How to I get the coordinates of a cell in a geotif? or Python affine transforms to transform between the pixel and projected coordinates with   as the affine transform for the subset data\n\n\n\nCreation of a new resulting GeoDataFrame with the col, row and elevation values\n\n\n\n\n extract the geometry in GeoJSON format\ngeoms = shapefile.geometry.values # list of shapely geometries\ngeometry = geoms[0] # shapely geometry\n# transform to GeJSON format\nfrom shapely.geometry import <span class=\"highlight\">mapping</span> &hellip; geoms = [<span class=\"highlight\">mapping</span>(geoms[0])]\n# extract the raster values values within the polygon \nwith rasterio.open(&quot;raster.tif&quot;) as src:\n     out_image, out_transform = mask(src, geoms, crop=True)\n\n\nThe out_image &hellip; "
    },
    {
        "question": "What types of lat/long coordinates are these?",
        "area": [
            "latitude-longitude",
            "mapping"
        ],
        "text": "They are likely &quot;Degrees, Decimal Minutes&quot;.\n\nConversion to Decimal Degrees\n\nYou can convert it to &quot;Decimal Degrees&quot; by diving the &quot;Decimal Minutes&quot; by 60 and adding the result to the Degrees:\n\n\n\nConversion to Degrees Minutes Seconds\n\nOr you can convert to &quot;Degrees Minutes Seconds&quot; by multiplying the fractional side of the &quot;Decimal Minutes&quot; by 60 to get the Seconds:\n\n\n They are likely &quot;Degrees, Decimal Minutes&quot;.\n\nConversion to Decimal Degrees\n\nYou can convert it to &quot;Decimal Degrees&quot; by diving the &quot;Decimal Minutes&quot; by 60 and adding the result to the Degrees:\n\n21.440  &hellip; "
    },
    {
        "question": "Making beautiful maps in R?",
        "area": [
            "r",
            "cartography"
        ],
        "text": "In addition to the ones posted here, in the R gallery website there are a few examples: \n\n\nhttp://gallery.r-enthusiasts.com/graph/SuperStorm_Sandy_170\nhttp://gallery.r-enthusiasts.com/RGraphGallery.php?graph=146  \nhttp://gallery.r-enthusiasts.com/RGraphGallery.php?graph=113\n\n\n\n\nother websites with tutorials and good mapping examples in R:\n\n\nhttp://www.molecularecologist.com/2012/09/making-maps-with-r/\nhttp://www.r-bloggers.com/create-maps-with-maptools-r-package/\nhttp://procomun.wordpress.com/2012/02/18/maps_with_r_1/   \nhttp://www.nceas.ucsb.edu/scicomp/usecases/CreateMapsWithRGraphics\n\n\nI hope this helps. The last one gives you one example with vector data and another with satellite imagery, while the r-bloggers has many other mapping examples with R.\n graph=113\n\n\n\n\nother websites with tutorials and good <span class=\"highlight\">mapping</span> examples in R:\n\n\nhttp://www.molecularecologist.com/2012/09/making-maps-with-r/\nhttp://www.r-bloggers.com/create-maps-with-maptools-r-package &hellip; The last one gives you one example with vector data and another with satellite imagery, while the r-bloggers has many other <span class=\"highlight\">mapping</span> examples with R. &hellip; "
    },
    {
        "question": "Choosing between QGIS and GRASS for simple thematic maps with different layers",
        "area": [
            "qgis",
            "grass-gis"
        ],
        "text": "GRASS is usually used for scientific purposes. So unless you want to do some sophisticated spatial analysis or routine, just stick with QGIS. Also GRASS works with its own formats so you will have to import/export data to exchange data with someone. Even if you will need sophisticated spatial analysis or routine at some point you will be able to do it with SEXTANTE plugin (GRASS support included) for QGIS. In QGIS there was also a plugin for communication with GRASS but SEXTANTE took its place. I think for simple mapping purposes you should use QGIS. \n I think for simple <span class=\"highlight\">mapping</span> purposes you should use QGIS. &hellip; "
    },
    {
        "question": "Seeking introductory books or articles about Open Source GIS for students coming from Esri background",
        "area": [
            "open-source-gis",
            "references"
        ],
        "text": "I am preparing an intermediate GIS course for graduate and undergraduate students who have likely not been in touch with anything but Esri software. It is an existing course in the curriculum that I will be teaching for the first time. Currently, ArcGIS is the software of choice for the lab sections and practical assignments.\nI want to tweak the course a little to include an introduction to Open Source GIS alternatives. For now, this part of the course will only be two to four weeks (I&#39;m thinking a kind of extended epilogue) so I won&#39;t be able to dig too deep. I hope to branch this off into a full Open Source GIS course next year, but curriculum constraints prohibit me from doing that right away.\nHere&#39;s some reading I have been considering to support the Open Source GIS part of the course, to give you an idea of what I&#39;m (not) looking for:\n\nThe Geospatial Desktop is a book I&#39;d love to use for a full Open Source GIS course but is too much to cover in a few weeks. The chapter &#39;Survey Of Desktop Mapping Software&#39; looks like something I could use.\nThe Dekstop GIS book is of similar breadth but currently out of print.\nThe Grass Book seems too focused on GRASS. I think GRASS will put students with an ArcGIS mindset off. Also, I want them to learn about the breadth of the OS geospatial software spectrum.\n&#39;How to go from GIS novice to Pro without spending a Dime&#39; takes a good, practical approach to delving into OS GIS, and has good links for further reading.\nA white paper from OpenGeo talking about markets for geospatial software, and how that landscape is changing.\n\nCan you suggest other articles and / or books that would be useful to ease students coming from an Esri / ArcGIS background into becoming aware of and using Open Source alternatives?\n The chapter &#39;Survey Of Desktop <span class=\"highlight\">Mapping</span> Software&#39; looks like something I could use.\nThe Dekstop GIS book is of similar breadth but currently out of print.\nThe Grass Book seems too focused on GRASS. &hellip; "
    },
    {
        "question": "Seeking examples of beautiful maps?",
        "area": [
            "cartography"
        ],
        "text": "From the hip my answer would be Stephen Walter&#39;s &#39;The island&#39;: witty, irreverent, slightly subversive he has hand drawn a map of London representing it as an island (poking fun at Londoners&#39; London centric view of the world).  \n\nhttp://www.bl.uk/magnificentmaps/map4.html\n\nI think its beautiful as its highly original, detailed, fascinating and I interpret it as sending up the idea of maps themselves.\n\nHaving said that I think the question is too vague, it would be more useful if it were more specific. IMHO there are a number of separate characteristics that make up map beauty:\n\nFunction: Is it fit for purpose?  My vote for this type would be the London tube map: Original and highly functional it sacrifices distance representation to show the network with more clarity.\n\nAesthetics: The Island map\n\nHistorical Interest: A personal favourite is the Geological map of the UK by William Smith - a world first.\n\n\nhe did this pretty much by himself over 15 (I think) years, before him no one had thought of mapping what was below the ground.\n\nI&#39;d be most interested in hearing people&#39;s examples of maps representing outstanding functionality.\n he did this pretty much by himself over 15 (I think) years, before him no one had thought of <span class=\"highlight\">mapping</span> what was below the ground. &hellip; "
    },
    {
        "question": "Dissolving polygons based on attributes with Python (shapely, fiona)?",
        "area": [
            "python",
            "shapely",
            "fiona",
            "geopandas"
        ],
        "text": "The question is about Fiona and Shapely and the other answer using GeoPandas requires to also know Pandas. Moreover GeoPandas uses Fiona to read/write shapefiles. \n\nI do not question here the utility of GeoPandas, but you can do it directly with Fiona using the standard module itertools, specially with the command groupby (&quot;In a nutshell, groupby takes an iterator and breaks it up into sub-iterators based on changes in the &quot;key&quot; of the main iterator. This is of course done without reading the entire source iterator into memory&quot;, itertools.groupby).\n\nOriginal Shapefile coloured by the STATEFP field\n\n\n\n\n\nResult\n\n\n Original Shapefile coloured by the STATEFP field\n\n\n\nfrom shapely.geometry import shape, <span class=\"highlight\">mapping</span>\nfrom shapely.ops import unary_union\nimport fiona\nimport itertools\nwith fiona.open(&#39;cb_2013_us_county_20m.shp &hellip; feature in group])\n            # write the feature, computing the unary_union of the elements in the group with the properties of the first element in the group\n            output.write({&#39;geometry&#39;: <span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Which projection is best for mapping the contiguous United States?",
        "area": [
            "coordinate-system",
            "united-states"
        ],
        "text": "If I wanted to project latitude &amp; longitude data for the contiguous United States (the United States excluding Alaska and Hawaii), which projection would I use? I prefer more accurate distances followed by shapes\n If I wanted to project latitude &amp; longitude data for the contiguous United States (the United States excluding Alaska and Hawaii), which projection would I use? I prefer more accurate distances follow &hellip; "
    },
    {
        "question": "Comparing Google Earth Enterprise to ArcGIS for Server and GeoServer?",
        "area": [
            "geoserver",
            "arcgis-server",
            "google-earth",
            "software-recommendations",
            "google-earth-enterprise"
        ],
        "text": "I&#39;m working on a web app that includes mapping capabilities (currently just markers and KML overlays on an embedded Google Map). We&#39;re starting to outgrow the limitations of Google&#39;s free stuff, and Google Earth Enterprise initially seemed to be the natural upgrade path. But at least judging from the tags on this site, it doesn&#39;t seem like it gets a lot of use in the GIS community. \n\nHas anyone used GEE who could compare it to the more widely used server platforms?\n I&#39;m working on a web app that includes <span class=\"highlight\">mapping</span> capabilities (currently just markers and KML overlays on an embedded Google Map). &hellip; "
    },
    {
        "question": "How can EPSG:3857 be in meters?",
        "area": [
            "coordinate-system",
            "epsg"
        ],
        "text": "It is a projection of a spheroid on a flat surface.  Every projection has strengths and weaknesses and will preserve some elements of direction, distance or area better or worse than others (which is why careful selection of a suitable, that is local where possible,  projection is so important).\nSo, while the unit of measurement in EPSG:3857 is indeed meters, as you have correctly spotted, distance measurements become increasingly inaccurate away from the equator. All Mercator-style projections have the same limitation as they move away from their reference point. But, where they are not global, the error can be minimized by appropriate positioning of this point.  It is for this reason there are so many UTM zones for instance.  Other projections have different strengths and weaknesses depending on use (e.g. navigation vs cartography).\nSo what&#39;s the point of EPSG:3857?  To understand that, you must understand that it was designed for web mapping and is square so that the map tiles fit nicely into a powers-of-two schema as you progress through each successive zoom-level.  This is EPSG:3857&#39;s particular strength.  It is not designed for distance and area calculations.  There are many much better alternatives.  If you are not using the data for web mapping, I would strongly encourage you to consider some other projection that is more suitable to your use-case, especially if you intend to do distance calculations (or, in that event, cast your data in geographic coordinates and not Cartesian coordinates and use the Haversine formula to calculate distances on a sphere).\nEDIT (re comments):\nThe diagram added to the OP&#39;s question basically is a diagram of my first paragraph, viz that the project introduces distortion.  For more information on how the Earth is projected in this case see here.  The unit of measurement for Web Mercator is NOT pixels but meters.  The OP&#39;s question results from a misunderstanding.   Vector data can also be projected in Web Mercator.  In this case there are no pixels.  So you see, the concept of a unit of measurement as pixels has no relationship to the real world.  However, pixels-per-meter is relevant for a raster as this tells us the resolution of the image.  BUT the unit of measurement is still meters (in this case) and not pixels.\nWhere the confusion for the OP possibly arises is the use of Web Mercator at various zoom levels where tiles are usually set to be 256x256 pixels and a given zoom level has a certain nominal ground resolution, so some web mapping applications use screen pixels as a means of calculating distance.  But, the pixels are interpreted as a meters-distance in relation to the zoom level (and possibly latitude).\n To understand that, you must understand that it was designed for web <span class=\"highlight\">mapping</span> and is square so that the map tiles fit nicely into a powers-of-two schema as you progress through each successive zoom-level &hellip; If you are not using the data for web <span class=\"highlight\">mapping</span>, I would strongly encourage you to consider some other projection that is more suitable to your use-case, especially if you intend to do distance calculations &hellip; "
    },
    {
        "question": "Seeking Symbology for Interactive Mapping?",
        "area": [
            "symbology",
            "software-recommendations"
        ],
        "text": "When a user clicks on a map what should they expect to see? \n\nI would say a symbol for where they clicked.  A pushpin seems to be the most accepted icon for generic data. Google has pushed the upside down tear drop. \n\nWhat are other ideas/options and is there a place for finding professional gis oriented icon packs?\n\nI ended up creating this, \n\n\n\nThis just popped up from the guys at map box. Clean maki icons\n When a user clicks on a map what should they expect to see? \n\nI would say a symbol for where they clicked.  A pushpin seems to be the most accepted icon for generic data. Google has pushed the upside  &hellip; "
    },
    {
        "question": "What books, journals, and electronic resources are most valuable for expanding knowledge of GIS?",
        "area": [
            "references"
        ],
        "text": "Here&#39;s my &quot;recent&quot; favourites, both cartography-related:\n\n\nDesigning Better Maps: A Guide for GIS Users by Cynthia Brewer  \n\n\n\n\n\nMaking Maps: A Visual Guide to Map Design for GIS by John Krygier and Denis Wood\n\n\n\n\nUnfortunately, and this is kind of sad, I have to admit that I haven&#39;t read a single GIS book in years.\n\nThe basic principles and practices of GIS haven&#39;t changed more than incrementally in the last half-decade, and the cool new technologies--commercial mapping APIs, KML, REST, location-based games and services, etc--have all been advancing at a frenetic pace since 2005 (note the publication date of the two books above)\n\nIf new technology matters to you (and it should) and you think you can rely on books, you may as well give up and go home.  To survive in this environment, you need to be adept with blogs and online documentation, and be willing to experiment.\n The basic principles and practices of GIS haven&#39;t changed more than incrementally in the last half-decade, and the cool new technologies--commercial <span class=\"highlight\">mapping</span> APIs, KML, REST, location-based games and services &hellip; "
    },
    {
        "question": "Donating and volunteering geographical knowledge?",
        "area": [
            "openstreetmap",
            "google-maps",
            "crowdsourcing"
        ],
        "text": "It&#39;s worth noting that at Google Maps, you&#39;re not &#39;donating&#39; your geographic knowledge -- you are giving your geographic knowledge to a for-profit corporate entity, who have a duty to their shareholders to use their position as a majority data holder in the worldwide map data market to increase the value of their company.\n\nThis means that the data that you give to Google is not necessarily something that you can get back out and do what you want with. For example, if you imagine that you start a business making GPS Maps for Bikes, or some such, down the road, getting the data that you give to Google back out for use in the product you want to sell may be difficult, or simply a violation of the Terms of Service which you would not be allowed to pursue.\n\nOpenStreetMap is openly licensed dataset. It is created and supported by more than 500,000 editors, and the data is available for libre (that is, &#39;free as in freedom&#39;) use under the terms of the ODBL, which would allow you to make the GPS Maps For Bikes app without needing to pay a licensing fee to anyone.\n\nData you add to Google Maps is collectively licensed to Google. (Your individual contributions presumably have relatively limited value outside the collection of data, as is the case in almost any map-making effort.)  If you do something Google doesn&#39;t want, then they can say No, and shut you down. Innovation by third parties outside the scope of what limitations Google provides for is not allowed.\n\nOpenStreetMap data is openly licensed and managed by a non-profit organization dedicated to furthering the use of geographic information around the world. If no one has done the new cool thing that you want to do -- you can get the data, and do it. \n\nShort term, you may get more out of Google -- with a massive corporate investment in user-targeted tools, and a massive investment in initial data -- but over time, OpenStreetMap&#39;s openly licensed data is likely to be the more sustainable solution. With half a million editors, and the growing investment from national mapping agencies around the globe, I can&#39;t imagine any way in which OSM is not the more appropriate map provider to support for the long term.\n With half a million editors, and the growing investment from national <span class=\"highlight\">mapping</span> agencies around the globe, I can&#39;t imagine any way in which OSM is not the more appropriate map provider to support for the &hellip; "
    },
    {
        "question": "Seeking developer-friendly web GIS?",
        "area": [
            "web-mapping",
            "software-recommendations",
            "php"
        ],
        "text": "Fortunately for you (and all of us!), there are plenty of available (and mature!) options in the FOSS4G world!\n\nFollowing your technology preferences here&#39;s some examples:\n\n\nPython\n\n\nMapfish (not updated since 2011)\nGeoDjango \n\nPHP\n\n\nPMapper\n\npure Javascript\n\n\nOpenLayers\nLeafLet\nOpenLayers + ExtJS\nOpenLayers + Jquery Mapquery, jeobrowser\n\n\n\nFor a more complete reference please visit OSGeo.org. It&#39;s an umbrella organization for the most popular FOSS geospatial projects out there.\n\nMaybe if you&#39;re in the neighborhood you can visit the annual FOSS4G conference. Here&#39;s a list of workshops that happened in 2011 regarding web mapping technologies:\n\n\nMapFish in Production\nIntroduction to Geomajas\nThe Moose is loose, Mapping with GeoMoose\nOpenLayers Application Development\nWeb Mapping with GeoServer\nDeveloping OGC Compliant Web Applications With GeoExt\nInteractive space-time dynamics: A hands-on introduction to i2maps\nA complete open source web mapping stack\nThere&#39;s JavaScript in your backend: Front to Back JavaScript with NodeJS and Polymaps\n\n\nAs for my personal experience developing web mapping applications based on pure javascript/html/css frameworks (OpenLayers/jQuery) can be really straightforward. \n Here&#39;s a list of workshops that happened in 2011 regarding web <span class=\"highlight\">mapping</span> technologies:\n\n\nMapFish in Production\nIntroduction to Geomajas\nThe Moose is loose, <span class=\"highlight\">Mapping</span> with GeoMoose\nOpenLayers Application Development &hellip; Web <span class=\"highlight\">Mapping</span> with GeoServer\nDeveloping OGC Compliant Web Applications With GeoExt\nInteractive space-time dynamics: A hands-on introduction to i2maps\nA complete open source web <span class=\"highlight\">mapping</span> stack\nThere&#39;s JavaScript &hellip; "
    },
    {
        "question": "Changing Field Name in ArcGIS Desktop",
        "area": [
            "arcgis-desktop",
            "arcgis-10.2",
            "attribute-table",
            "fields-attributes"
        ],
        "text": "How can I change the field names (not the alias) in ArcGIS 10.2?\nI already found this page on ArcGIS support: &quot;Renaming shapefile fields (Defense Mapping)&quot; but there is is not &quot;Defense Mapping&quot; on Customized Mode Categories In my ArcCatalog!\nWithout access to Defense Mapping, how can I change the field names?\n I already found this page on ArcGIS support: &quot;Renaming shapefile fields (Defense <span class=\"highlight\">Mapping</span>)&quot; but there is is not &quot;Defense <span class=\"highlight\">Mapping</span>&quot; on Customized Mode Categories In my ArcCatalog! &hellip; Without access to Defense <span class=\"highlight\">Mapping</span>, how can I change the field names? &hellip; "
    },
    {
        "question": "GIS Related Information Governance",
        "area": [
            "privacy"
        ],
        "text": "I often work on mapping sensitive patient level data. Whilst I feel I have a good grasp of many of the governance issues around this (ie when to use binning and k-anonymity techniques) but I&#39;d like to improve my knowledge on this.\n\nHere is a good example of why this is of importance: Spatial confidentiality and GIS: re-engineering mortality locations from published maps about Hurricane Katrina\n\nDoes anyone have any good rules of thumb they employ when mapping sensitive data?\n\nAre there any good resources out there which cover different methods of protecting confidentiality or provide guidance on the matter?\n I often work on <span class=\"highlight\">mapping</span> sensitive patient level data. &hellip; of why this is of importance: Spatial confidentiality and GIS: re-engineering mortality locations from published maps about Hurricane Katrina\n\nDoes anyone have any good rules of thumb they employ when <span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Using customized Coordinate System in ArcGIS Desktop?",
        "area": [
            "arcgis-desktop",
            "coordinate-system",
            "epsg",
            "srid"
        ],
        "text": "I don&#39;t know so much about coordinate systems...\n\nIn my office we use to deal with spatial data coming from archaeological sites. Each site has its own x-y-z coordinate system (GCS). Three simple ortogonal cartesian axis.\nIn the last years we have been managing this spatial data through GIS software (ArcGIS), without using specific coordinate system (just leave it as &quot;undefined&quot;)\n\nI&#39;d like to know if there exisits any GCS designed to deal with such datasets using simple cartesian orthogonal axis, without grid distortions of the typical GCS. In addition, I&#39;d like to know if this system is suitable for using it in an online mapping application.\n\nBy the way, we manage 2D (ArcMap) and 3D (ArcScene) environments and work with &quot;mm&quot; as length base unit. \n\nIf such a thing doesn&#39;t exists, maybe someone knows how to create it.\n In addition, I&#39;d like to know if this system is suitable for using it in an online <span class=\"highlight\">mapping</span> application. &hellip; "
    },
    {
        "question": "Accounting for Colour Blindness when designing maps?",
        "area": [
            "cartography"
        ],
        "text": "I am slightly red-green colourblind (in that I can still see red and green fine, but have difficulty with say a red and green line next to each other). Does make it a bit easier for me to make maps for people that are red-green colourblind.\n\nIn addition to color brewer and vischeck mentioned above, the GIMP has colourblind filters built in so you can adjust images as part of post processing. Photoshop has the same kinds of filters if you have access.\n\nLastly the ESRI Mapping centre has a set of styles for download that include a colour set suitable for colour deficiency.\n\nHope that helps!\n Lastly the ESRI <span class=\"highlight\">Mapping</span> centre has a set of styles for download that include a colour set suitable for colour deficiency.\n\nHope that helps! &hellip; "
    },
    {
        "question": "Options for displaying PostGIS vectors in OpenLayers",
        "area": [
            "postgis",
            "openlayers",
            "web-mapping",
            "software-recommendations"
        ],
        "text": "I am very new to web-mapping, so this question may be a little misguided.\n\nI want to have a very simple web interface using OpenLayers (or even Google Maps if that will be easier) which can display a number of point and polygon tables that are currently in PostGIS.\n\nI want this to be as simple (and as low maintainence) as possible:\n\n\nI don&#39;t want to have to create tiles (unless there is a very good reason), or have a massive, complex layer of middleware.  \nPerformance doesn&#39;t need to be phenomenal, as this is for internal use and thus doesn&#39;t need to scale beyond a couple of concurrent users.\nStyling of the vector layers is of minimal importance.\nOpen source tools are much preferred as I have almost no budget for this.\n\n\nWhat is the recommended approach for this?\n I am very new to web-<span class=\"highlight\">mapping</span>, so this question may be a little misguided. &hellip; "
    },
    {
        "question": "Accessing ArcObjects from Python",
        "area": [
            "python",
            "arcobjects",
            "comtypes"
        ],
        "text": "\nHow do I access arcobjects from python?\n\nIf what you are looking for is specific functionality that exists and is in the C++ Arcobjects code, then your best bet would be to create C++ methods to call them.... and then create a python wrapper to access those C++ methods.\nThere are quite a few ways to access C++ methods from python, and lots of people that do so use a tool like SWIG to auto-generate the python classes from the C++ method signatures. It&#39;s been my experience that these autogenerated APIs get pretty nasty when passing non-native C++ types (int, floats) and are never very &#39;pythonic&#39;.\nMy recommended solution would be to use the ctypes API. A great tutorial is here: http://python.net/crew/theller/ctypes/tutorial.html\nThe basic steps are:\n\nwrite some of your core logic in C++, the ones where you believe python performance might be an issue\nCompile that core logic (in this case using the ArcObject C++ API method calls) from object files into a shared (.so) or dynamic library (.dll) using whatever system compiler (nmake,make, etc.)\nWrite a ctypes mapping between the python class and the C++ method signature [SWIG tries to automate this, but it&#39;s easy, even if using crazy object types]\nImport the compiled library into your python program and use the bound class/method bindings like any other python class!\n\nThis is probably more general way to reference C/C++ code from within python, it is probably going to be much simpler in the long run if you don&#39;t have to deal with COM objects. It also will allow all of the system specific functionality reside in the compilation of the linked library object (so the python will not be system/python implementation specific).\n Write a ctypes <span class=\"highlight\">mapping</span> between the python class and the C++ method signature [SWIG tries to automate this, but it&#39;s easy, even if using crazy object types]\nImport the compiled library into your python &hellip; "
    },
    {
        "question": "Calculating terrain Curvature in QGIS",
        "area": [
            "qgis",
            "raster",
            "dem",
            "terrain",
            "curvature"
        ],
        "text": "Curvature is a complex terrain derivative to compute, the equation that you use depends on the resolution of your input data, as you have to ensure that the curvature results you compute can be distinguished from noise in the data.\nA lot of research has been done recently on curvature calculations on high resolution LiDAR data which showed that a scaling break exists at around 2 or 3 metres resolution and above this point more different algorithms (which I am not as familiar with) need to be used. The best information about calculating topographic curvature probably comes from Hurst et al 2012 and the references therein.\nThe basic principle of curvature calculation, as with slope and aspect, is to pass a moving window over the elevation surface and fit the elevation values to a 6 term polynomial function, the coefficients of which will yield the slope, aspect and curvature of the centre cell of the moving window.\nArcGIS uses a 3x3 search window which will only yield good results in areas completely devoid of vegetation, which makes the tool fairly useless unless people are aware of this limitation, this may suggest why it is not present in QGIS.\nThe maths was derived originally (I think) in Evans (1980) and was simplified in a few pages in Principles of Geographical Information Systems (Amazon link) which I can recommend as a good guide to this kind of terrain analysis at a basic level.\nOne way to calculate curvature of a DEM is to convert the DEM into an ascii raster, read it into a numpy array and then perform the polynomial fitting on a moving window passing through the data. This is fairly easy to do, but is very slow to execute and needs a fair amount of optimization (these kind of operations often get ported to c++ to speed them up).\nTo perform the operation in QGIS you can use the GRASS plugin r.slope.aspect which is also limited by the 3x3 fixed window.\nI realize this is not the simple answer you were doubtless hoping for, but I hope you understand that curvature is complex to derive in a meaningful way. All the best.\n\n S. (1980), An integrated system of terrain analysis and slope <span class=\"highlight\">mapping</span>, Z. Geomorphol., 36, 274\u2013295. &hellip; "
    },
    {
        "question": "Creating &quot;average&quot; polygon?",
        "area": [
            "polygon",
            "vector",
            "algorithm"
        ],
        "text": "I&#39;ve figured out an algorithm for the grid approach using several Python tools. Rasterising and polygonising is done with rasterio, which is based on GDAL/OGR.  Here are most of the imports:\n\n\n\nFirst, get a few polygon shapes to do statistics with. The list of shape must be sort-of overlapping, otherwise this procedure won&#39;t work as well. There are many way to get these shape into Python, e.g., read a Shapefile with fiona.\n\n\n\nOr how about these five polygons:\n\n\n\n\n\nIn order to grid the vectors, some appropriate raster resolutions need to be determined, and applied to the data extents. E.g., I&#39;m doing everything on a 1 metre grid, but it can be modified to any number. Then build an affine geotransform from the upper-left corner.\n\n\n\nLoop through each polygon, and rasterise them to a grid, where each will be 0 outside the polygon and 1 inside. With each result, accumulate a values to the array , which we&#39;ll normalise to values 0.0 (zero coverage) to 1.0 (all covered). This raster is basically the probability that a polygon covers the grid.\n\n\n\n\n\nThe next step is really only needed if you want a smoothish result from only a few overlapping polygons. It will blur the sharp edges of probability array. You will need a modified  function with full convolution to avoid edge distortions, which modifies the geotransform size.\n\n\n\nNow use the function to do a Gaussian blur on a radius of 100 grid cells (or 100 m in this example), and return the larger-sized array and geotransform results:\n\n\n\n\n\nNow the &quot;average&quot; result can be extracted by selecting a quantile threshold. So, using 0.1 will select a larger area that 10% or more of the polygons cover, while 0.95 will choose a smaller area with 95% coverage. Using 0.5 is the median quantile threshold close to what could be called &quot;average&quot;. Because this example has an odd-number of shapes we get a nice result, but with even-numbers of samples the result is really sensitive.\n\n\n\n\n\nConvert the grid result back to vector, and simplify-away the jagged pixel shapes using a minimum distance of a grid diagonal (or more).\n\n\n\n\n Here are most of the imports:\n\nimport rasterio\nimport numpy as np\nfrom rasterio import Affine, features\nfrom shapely.geometry import <span class=\"highlight\">mapping</span>, shape\nfrom shapely.ops import cascaded_union\nfrom math import &hellip; if not any(poly_shapes):\n    raise ValueError(&quot;could not find any shapes&quot;)\navg_poly = cascaded_union(poly_shapes)\n# Simplify the polygon\nsimp_poly = avg_poly.simplify(sqrt(dx**2 + dy**2))\nsimp_shape = <span class=\"highlight\">mapping</span> &hellip; "
    },
    {
        "question": "Choosing between QGIS and GRASS for simple thematic maps with different layers",
        "area": [
            "qgis",
            "grass-gis"
        ],
        "text": "I was working with GIS and remote sensing in a university and professional environment some ten years ago (ArcInfo etc), so I have some experience even though somewhat outdated. \n\nNow I am looking for an GIS application for a small farming project and I found GRASS and QGIS projects which both sound very interesting.\nHowever, I do not really get the difference between the two programs. \n\nWhich one do I use best for simple thematic maps with different layers?\n I was working with GIS and <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> in a university and professional environment some ten years ago (ArcInfo etc), so I have some experience even though somewhat outdated. &hellip; "
    },
    {
        "question": "Free GIS workshops, tutorials, and applied learning material",
        "area": [
            "references",
            "education"
        ],
        "text": "This Q&amp;A lists free as in $0 workshops in GIS and related fields that have their material available to view or download online. The list is not limited to FOSS GIS, as GISers usually use a combination of open and closed source tools to accomplish their tasks. Some of these tools are easier than others and some are better documented. This list will be a great benefit to the community especially for new comers to the field.\nGeneral GIS\n\nGIS Project Video Tutorial on Acquiring, Analyzing, and Mapping US Census Data in QGIS from @A.S\nGIS Tutor: Beginner / Intermediate Level GIS from @radek\nBostonGIS from @simo\nLectures on GIS for the Social Sciences from @ubernatural\n\nOpen-source GIS\n\nOpenGEO Education Center from @radek\nQGIS Videos (faunitalia) from @simo\nGIS SE Question: Geoserver Tutorials from @com\nGIS SE Question: Open Source Training Materials from @MarkIreland\nQGIS for Newbies from @IanAllan\n\nESRI Products\n\nGIS SE Question: Best place for (structured) ArcGIS tutorials from @robintw\nArcGIS Automation and Programming from @Bethany\n\nTransportation\nThese links include either theoretical or applied transportation knowledge in transportation planning\n\nGIS primer for Transportation\nTransit Capacity and Quality of Service Manual\nUrbanSim: FOSS Urban development, socio economic, and land use planning package\nMOVES(Motor Vehicle Emission Simulator) Workshop and technical background\nTransit GIS tutorials\nRemote sensing in transportation workshop\nFlorida&#39;s CBT planning model explained\n\nDisaster Management\n\nGeo-information Technology for Crisis Management \n\nDatabases\n\nSpatial Database Course Material from @radek\n\nGeo Statistics\n\nLearn R Lectures and Classes\nGeodatabase Mining Course from @radek\nA Practical Guide to Geostatistical Mapping\n\n Quality of Service Manual\nUrbanSim: FOSS Urban development, socio economic, and land use planning package\nMOVES(Motor Vehicle Emission Simulator) Workshop and technical background\nTransit GIS tutorials\n<span class=\"highlight\">Remote</span> &hellip; <span class=\"highlight\">sensing</span> in transportation workshop\nFlorida&#39;s CBT planning model explained\n\nDisaster Management\n\nGeo-information Technology for Crisis Management \n\nDatabases\n\nSpatial Database Course Material from @radek &hellip; "
    },
    {
        "question": "Differences between DEM, DSM and DTM?",
        "area": [
            "terminology",
            "dem"
        ],
        "text": "Digital elevation models (DEM) are a superset of both digital terrain models (DTM) and digital surface models (DSM). Remote sensing generally captures the surface height, so the top of the tree canopy or buildings is returned, not the bare ground elevation. If this data is corrected to remove elements which extrude above the terrain height, you&#39;re left with a DTM.\n\nIn general, most people use DEM interchangeably with the other two terms, but it can matter: I once built a hydrology model using SRTM data in South America in very flat arid terrain, but because of the canopy height along the river itself, the true river location became the highest point on the terrain, causing a ruckus.\n\nThe Wikipedia article on digital terrain models also includes some useful background and examples you may find helpful.\n <span class=\"highlight\">Remote</span> <span class=\"highlight\">sensing</span> generally captures the surface height, so the top of the tree canopy or buildings is returned, not the bare ground elevation. &hellip; "
    },
    {
        "question": "How to perform Random Forest land cover classification?",
        "area": [
            "r",
            "land-classification",
            "random-forest",
            "machine-learning"
        ],
        "text": "This is a follow-up to a previous post: Machine Learning Algorithms for Land Cover Classification.  \n\nIt seems that the Random Forest (RF) classification method is gaining much momentum in the remote sensing world.  I am particularly interested in RF due to many of its strengths:\n\n\nA nonparametric approach suited to remote sensing data\nHigh reported classification accuracy\nVariable importance is reported\n\n\nGiven these strengths, I would like to perform Random Forest land classification using high resolution 4 band imagery.  There is a lot of material and research touting the advantages of Random Forest, yet very little information exists on how to actually perform the classification analysis.  I am familiar with RF regression using R and would prefer to use this environment to run the RF classification algorithm.  \n\nHow do I collect, process and input training data (i.e. based on high resolution CIR aerial imagery) into the Random Forest algorithm using R?  Any step-wise advice on how to produce a classified land cover raster would be greatly appreciated. \n It seems that the Random Forest (RF) classification method is gaining much momentum in the <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> world. &hellip; I am particularly interested in RF due to many of its strengths:\n\n\nA nonparametric approach suited to <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> data\nHigh reported classification accuracy\nVariable importance is reported\n\n\nGiven these &hellip; "
    },
    {
        "question": "What are the min and max values of Map.addLayer on Google Earth Engine?",
        "area": [
            "google-earth-engine",
            "layers",
            "google-earth-engine-javascript-api"
        ],
        "text": "Let&#39;s start from the beginning. \n\nHow satellite remote sensing work\n\nSatellites carry out sensors that can measure radiance at different wavelengths (it depends on the sensor)\n\n\n\nFor example,\n\n\n  Landsat 8 carries a two-sensor payload: the Operational Land Imager\n  (OLI), built by the Ball Aerospace &amp; Technologies Corporation; and the\n  Thermal Infrared Sensor (TIRS), built by the NASA Goddard Space Flight\n  Center (GSFC)\n  (https://landsat.usgs.gov/landsat-8-l8-data-users-handbook-section-2)\n\n\nOLI sensor measures radiance at 9 different wavelengths and TIRS at 2 different wavelengths:\n\n\n\nThe first measurement of the sensor (raw data) is taken in Digital Numbers and converted to radiance based on the rescaling factors provided in the metadata file. \n\nDepending on the sensor, the resulting data type can differ. Landsat 1 to 7 raw data is a 8-bits data (each band), so values can go from 0 to 255 (256 options). Landsat 8 raw is a 16-bit data, so values can go from 0 to 65535 (65536 options).\n\nIf you look the description for  (raw) in Google Earth Engine you&#39;ll see\n\n\n  Landsat 8 Collection 1 Tier 1 DN values, representing scaled,\n  calibrated at-sensor radiance.\n  (https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1)\n\n\nAnd you can check the data types in the code editor: \n\n\n\nRadiometric corrections\n\n\n  The energy that sensors onboard aircrafts or satellites record can\n  differ from the actual energy emitted or reflected from a surface on\n  the ground. This is due to the sun&#39;s azimuth and elevation and\n  atmospheric conditions that can influence the observed energy.\n  Therefore, in order to obtain the real ground irradiance or\n  reflectance, radiometric errors must be corrected for.\n  (http://gsp.humboldt.edu/olm_2015/courses/gsp_216_online/lesson4-1/radiometric.html)\n\n\n\n\nAfter the data has been corrected, the output depends on the process made and may be in a different data type, such as , , etc. (I couldn&#39;t find a good reference source for this).\n\nYou can check it in Google Earth Engine\n\n\n\nAs you can see in the results, Landsat 8 TOA has a  data type, which means that the data goes from 0 to 1, and SR has a  data type, which means that data goes from -32768 to 32767. Though, the latter has a particularity, real values go from 0 to 10000 (there isn&#39;t values lower than 0 neither greater than 10000).\n\nFinally,\n\nHow a monitor works\n\n\n  To create a single colored pixel, an LCD display uses three subpixels\n  with red, green and blue filters. Through the careful control and\n  variation of the voltage applied, the intensity of each subpixel can\n  range over 256 shades. Combining the subpixels produces a possible\n  palette of 16.8 million colors (256 shades of red x 256 shades of\n  green x 256 shades of blue).\n  (https://computer.howstuffworks.com/monitor4.htm)\n\n\nSo, if a pixel has a values Red: 0, Blue: 0, Green: 0, the pixel color will be black, and if values are Red: 255, Blue: 255, Green: 255, the pixel color will be white.\n\nThere are plenty of sites to play around with this, like this one: https://www.w3schools.com/colors/colors_picker.asp\n\nPutting all together\n\nYour monitor can show only three colors: Red, Green and Blue (RGB). So, to visualize a raster you first have to choose which bands will represent those colors. That is the parameter  of . Then, you have to tell the monitor which value (out of the range) will represent the 0 (min) and which the 255 (max). This are the parameters  and  of . You can also specify different  and  for each band using a list of three values instead of just one value.\n\nLet&#39;s say you want to visualize a Landsat 8 TOA image as you were sitting on top of the satellite (real color). So, you have to tell the monitor to use the Red band (band 4) of the raster for the Red subpixel of the monitor, the Green band (band 3) for the Green subpixel and the Blue band (band 2) for the Blue subpixel. Then, you have to tell the monitor how to stretch the values from the raster, that as we&#39;ve seen for Landsat 8 TOA can go from 0 to 1 (because it&#39;s a ), to the values of the subpixels (that go from 0 to 255). So,\n\n\n\nBut you&#39;ll find out that the image looks &quot;too dark&quot; for that stretching (it depends on the reflectance of the objects you are seeing), so make the  smaller to see it &quot;brighter&quot;, for example, \n\nI leave you a simple app I made to show this:\nhttps://fitoprincipe.users.earthengine.app/view/stretch\n\nsource: https://code.earthengine.google.com/cdf508ac8ae98a35364758d4c585bba2\n\nIf you want to see the same Landsat scene from other collections you have to know how the data is presented in each collection.\n\nFinally, there are some methods to stretch the values automatically using the raster histogram, such as Standard Deviations, Minimum-Maximum, Percent Clip, Sigmoid, etc. (http://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/stretch-function.htm).\nEarth Engine let&#39;s you use some\n\n\n How satellite <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> work\n\nSatellites carry out sensors that can measure radiance at different wavelengths (it depends on the sensor)\n\n\n\nFor example,\n\n\n  Landsat 8 carries a two-sensor payload: &hellip; "
    },
    {
        "question": "OpenSource Remote Sensing Tools for Classifying Roofs",
        "area": [
            "python",
            "remote-sensing",
            "satellite",
            "envi"
        ],
        "text": "with envi image processing and classification tools, you can get roofs from images with some spectral value and then you can convert it some vector data for your app.\n\nin python with OpenCV which have devoloped by Intel (has lots of Object Detection Algorithms) you can detect faces from images.  \n\nOpenCV Example:\n\n\n\nmy question is that can we detect roof or anything from coordinated or not-coordinated satellite images with opensource tools as python?\n\nSatellite Image Example:\n\n\n with envi image processing and classification tools, you can get roofs from images with some spectral value and then you can convert it some vector data for your app.\n\nin python with OpenCV which have &hellip; "
    },
    {
        "question": "Recommended programming language for remote sensing?",
        "area": [
            "python",
            "remote-sensing",
            "software-recommendations",
            "idl"
        ],
        "text": "IDL is a fantastic stand-alone programming language (you do not need ENVI). I particularity like it for very fast matrix processing on large arrays. @Aaron makes IDL sound much less flexible then it really is. The majority of IDL development came out of the Physics and Astronomy communities. There is robust support for mathematical and statistical programming. If bundled with ENVI, you have all the library calls (functions) available in ENVI including support for spatial vector objects. There are also a large number of functions and models developed by the user community. One advantage to learning IDL is that it will make you marketable in &quot;analytic&quot; remote sensing shops. \n\nAlso, do not forget that ERDAS has a scripting language (EML) that is quite good and easy to learn. EML is the backbone of the graphic modeler and gmd&#39;s are just packaged EML scripts that sit under the graphic modeler interface. The advantage of using EML directly is that you can use for/while loops and have access to more ERDAS functionality in a scripting language.         \n\nMATLAB is also very good for matrix processing and there are open source versions (e.g., Octave) that have exactly the same syntax with similar benchmarks. This is a highly flexible language with considerable power. It is one of the preferred language for applied mathematics and engineering.      \n\nThe Python alternatives NumPy and SciPy are flexible but not as optimized as IDL and MATLAB. As such, you need to deal with addressing space and speed when working with large arrays. One huge advantage of Python are the additional libraries for performing a variety of analytical tasks. There are packages for remote sensing,  nonparametric statistics, bindings to spatial classes (e.g. GDAL, LibLAS) to name just some of the added functionality available through packages. \n\nThis brings us to R. I am primarily a spatial statistician so, this is my everyday language. The number of available packages is staggering which, in turn, provides access to cutting edge cross-discipline statistical methodologies. However, I have to say that it is very cumbersome when dealing with large data problems. The spatial classes are getting much better and because of the raster package providing the ability to hold large data out of memory I am now able to implement some fairly complex statistical models utilizing large raster arrays. But still, R is slow when dealing with large memory problems. The BigMatrix package allows for writing and processing huge arrays from disk but the coding overhead is not insignificant There are also bindings to GDAL and GIS software (e.g., GRASS, SAGA) that allow spatial object processing to occur outside of R in a GIS specific software, which is how I interact with GIS software these days. This allows me to leverage functionality across multiple software without leaving R.                \n\nSo, now that the software cheerleading is out of the way, my recommendation is &quot;yes to all of the above options&quot;. Programming is a skill that, once learned, is easily applied to other languages. There are striking similarities between C++, R, IDL and Python. Aside from some coding idiocentricities, what one must learn are the available functions to implement a given model/task. Once this is done it is just a matter of syntax that implements common coding structures. \n\nSometimes there are things that just work better in a different software or language. I occasionally write code in FORTRAN or C++ because it is just the best choice for a given task. It is a matter of adaptability. You may want to start with Python because, as a  scripting language, it can be applied to numerous tasks it also provides availability of packages for specialized analysis, has a number of free online resources and is somewhat easy to learn.           \n One advantage to learning IDL is that it will make you marketable in &quot;analytic&quot; <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> shops. &hellip; There are packages for <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>,  nonparametric statistics, bindings to spatial classes (e.g. GDAL, LibLAS) to name just some of the added functionality available through packages. &hellip; "
    },
    {
        "question": "What is Change Detection and performing such analysis with open source tools?",
        "area": [
            "raster",
            "open-source-gis",
            "remote-sensing",
            "references",
            "change-detection"
        ],
        "text": "From wikipedia page:\n\nChange detection for GIS (geographical information systems) is a process that measures how the attributes of a particular area have changed between two or more time periods. Change detection often involves comparing aerial photographs or satellite imagery of the area taken at different times. The process is most frequently associated with environmental monitoring, natural resource management, or measuring urban development\n\nHow is the comparison done? With what tools?\nI feel that the description is not complete. Or something is missing.\nWhere or in which books can I find more information about Change Detection?\nWhat tools should I use to perform such an analysis using the data in a shapefile? (only open-source please)\n\nSome papers on change detection (theory and techniques)\nChange detection techniques (D. LU, E. BRONDI, ZIO and E. MORAN, 2004, pdf)\nTrend change detection in NDVI time series: Effects of inter-annual variability and methodology\nForkel, M. , Carvalhais, N. , Verbesselt, J. , Mahecha, M.D. , Neigh, C. , Reichstein, M. (2013)\nRemote Sensing 5 (2013)5. - ISSN 2072-4292 - p. 2113 - 2144.\nShifts in global vegetation activity trends\nJong, R. de , Verbesselt, J. , Zeileis, A. , Schaepman, M.E. (2013)\nRemote Sensing 5 (2013)3. - ISSN 2072-4292 - p. 1117 - 1133.\nRelationships between declining summer sea ice, increasing temperatures and changing vegetation in the Siberian Arctic tundra from MODIS time series (2000\u201311)\nDutrieux, L.P. , Bartholomeus, H.M. , Herold, M. , Verbesselt, J. (2012)\nEnvironmental Research Letters 7 (2012)4. - ISSN 1748-9326 - p. 12.\nNear real-time disturbance detection using satellite image time series\nVerbesselt, J.P. , Zeileis, A. , Herold, M. (2012)\nRemote Sensing of Environment 123 (2012). - ISSN 0034-4257 - p. 98 - 108.\nTrend changes in global greening and browning: Contribution of short-term trends to longer-term change\nJong, R. de , Verbesselt, J. , Schaepman, M.E. , Bruin, S. de (2012)\nGlobal Change Biology 18 (2012)2. - ISSN 1354-1013 - p. 642 - 655.\nPhenological change detection while accounting for abrupt and gradual trends in satellite image time series\nVerbesselt, J. , Hyndman, R. , Zeileis, A. , Culvenor, D. (2010)\nRemote Sensing of Environment 114 (2010)12. - ISSN 0034-4257 - p. 2970 - 2980.\nDetecting trend and seasonal changes in satellite image time series\nVerbesselt, J. , Hyndman, R. , Newnham, G. , Culvenor, D. (2010)\nRemote Sensing of Environment 114 (2010)1. - ISSN 0034-4257 - p. 106 - 115.\n(I&#39;ll add more in the future as If I discover more notable  papers)\n Shifts in global vegetation activity trends\nJong, R. de , Verbesselt, J. , Zeileis, A. , Schaepman, M.E. (2013)\n<span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> 5 (2013)3. - ISSN 2072-4292 - p. 1117 - 1133. &hellip; Near real-time disturbance detection using satellite image time series\nVerbesselt, J.P. , Zeileis, A. , Herold, M. (2012)\n<span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> of Environment 123 (2012). - ISSN 0034-4257 - p. 98 - 108. &hellip; "
    },
    {
        "question": "Seeking open source software package for Remote Sensing?",
        "area": [
            "remote-sensing",
            "open-source-gis",
            "software-recommendations"
        ],
        "text": "Here are many questions with great answers about open source GIS software.\n\nI am wondering, what is the best open source software package for Remote Sensing? I would like to learn it and to use in my work.\n\nI used to work with IDRISI, and I&#39;ve heard about Erdas and ENVI, but they all are not free. I am looking for a free and powerful leader, like Qgis for GIS or R for statistics. With powerful classification, segmentation, Fourier, filters, PCA, etc.\n\nCan anyone please advise me a good free RS software? What are the capabilities, user friendly or with command line? Do any comparison matrices exist?\n I am wondering, what is the best open source software package for <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>? I would like to learn it and to use in my work. &hellip; "
    },
    {
        "question": "Seeking top tier conference in GIScience?",
        "area": [
            "research"
        ],
        "text": "These three conferences are influential in my academic GIScience circles. \n\n(stalwarts)\n(1) Conference on Spatial Information Theory; http://www.cosit.info/\n(2) International Conference on Geographic Information Science (GIScience); http://www.giscience.org/\n\n(rising in importance)\n(3) ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems; http://www.sigspatial.org/sigspatial-conferences\n\nAn accepted paper for COSIT or GIScience might be somewhat equivalent to publication in International Journal of Geographic Information Science or Transactions in GIS (IJGIS Impact Factor in 2012:  1.613 &amp; TGIS Impact Factor in 2012: 0.906).\n\nOf course, the interdisciplinary spatial journals have the highest impact:\nhttp://www.aboutgis.com/gis-and-remote-sensing-journal-list-with-impact-factors/\n\nDue to the specialized nature of GIScience, I expect the most-influential papers on geospatial information research will begin to be published in journals with a wider reach. That same gravity also will pull the work to higher impact conferences, such as one of the Association of Computing Machinery specialty meetings -- or perhaps to large conferences, like the American Geophysical Union Fall Meeting.\n\nSimultaneously, the Internet minimizes the need for singular important conferences and journals. In the longer term, I expect closed, expensive, or proprietary channels to be diminished in importance.\n Of course, the interdisciplinary spatial journals have the highest impact:\nhttp://www.aboutgis.com/gis-and-<span class=\"highlight\">remote</span>-<span class=\"highlight\">sensing</span>-journal-list-with-impact-factors/\n\nDue to the specialized nature of GIScience, &hellip; "
    },
    {
        "question": "Recommend topics to be included in a Computer Science for Geospatial Technologies course",
        "area": [
            "python",
            "arcgis-platform",
            "industry",
            "gis-principle",
            "academic"
        ],
        "text": "I will be instructing a course at the local university titled Computer Science for Geospatial Technologies. This is an introductory course meant to introduce computer science concepts to geospatial technologies students (GIS &amp; Remote Sensing). In the past I have introduced programming concepts, but I found this went over many of the students&#39; heads.\n\nCurrently, I am planning to discuss computer hardware, spatial data types (i.e. shapefiles vs geodatabases), ESRI Geodatabase Model (the university works on an ESRI platform), basic database theory with ArcSDE Personal.\n\nCould anyone recommend some other computer science related topics that practitioners of GIS and Remote Sensing should know before entering the workforce?\n\nUPDATE:  Last years curriculum included:\n\n\nGoogle Maps Javascript API/HTML/Google Earth/KML - 5 weeks\nPython Scripting - 6 weeks\nDatabase Theory/MS Access - 2 weeks\nVBA - 2 weeks\n\n\nThe response I received from students was that not enough time was spent on each topic.  I am speaking to the university to offer a next level course in GIS Programming using Python.\n This is an introductory course meant to introduce computer science concepts to geospatial technologies students (GIS &amp; <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>). &hellip; Could anyone recommend some other computer science related topics that practitioners of GIS and <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> should know before entering the workforce? &hellip; "
    },
    {
        "question": "Seeking General GIS Questions for Job interviews?",
        "area": [
            "references"
        ],
        "text": "To be able to answer questions asked in a GIS interview not related to any particular software you should have the ability to explain the following topics:\n\n\nWhat is GIS?\nWhat is remote sensing?\nA bit about Image processing.\nWhat is georeferencing?\nThe role of GPS in GIS.\nWhat are projections?\nWhat is cartography? (Questions on map elements like scales, legends etc:)\nData structures that can hold spatial data. (Raster, Vector, ...)\nExamples of what can be achieved by GIS? (Geocoding or Network or Spatial Analysis giving real life examples)\nOpen Standards related to GIS. (OGC or otherwise)\n\n\nIf you have a development background, questions pertaining to which development language you know are bound to rise up. It will benefit the organization hiring to have someone who can develop custom GIS solutions. These questions could be either GIS related or not depending on your previous experience. As far as development is concerned, people with no GIS background are also hired to develop GIS solutions.\n\nFinally, if you&#39;re the interviewer, then confirm which GIS software the interviewee is already accustomed to working with. It would help to hire someone who already knows how to tinker with the solutions that are implemented in your organization.\n\nIf you&#39;re the interviewee, well, know that for a large part you&#39;ll be judged by what is in your CV/resume. The list of the above questions might give you an approximate direction on what you need to start looking at. \n What is <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>?\nA bit about Image processing.\nWhat is georeferencing?\nThe role of GPS in GIS.\nWhat are projections?\nWhat is cartography? &hellip; "
    },
    {
        "question": "What are LiDAR returns?",
        "area": [
            "remote-sensing",
            "lidar",
            "terminology"
        ],
        "text": "ESRI has a pretty good help section on LiDAR (below).  For more formal details on LiDAR, I would recommend the following books:\n\n\nTopographic Laser Ranging and Scanning: Principles and\nProcessing\nAirborne and Terrestrial Laser Scanning\nRemote Sensing and Image Interpretation\n\n\n\n  LiDAR Laser Returns\n  \n  Laser pulses emitted from a lidar system reflect from objects both on\n  and above the ground surface: vegetation, buildings, bridges, and so\n  on. One emitted laser pulse can return to the lidar sensor as one or\n  many returns. Any emitted laser pulse that encounters multiple\n  reflection surfaces as it travels toward the ground is split into as\n  many returns as there are reflective surfaces.\n  \n  The first returned laser pulse is the most significant return and will\n  be associated with the highest feature in the landscape like a treetop\n  or the top of a building. The first return can also represent the\n  ground, in which case only one return will be detected by the lidar\n  system.\n  \n  Multiple returns are capable of detecting the elevations of several\n  objects within the laser footprint of an outgoing laser pulse. The\n  intermediate returns, in general, are used for vegetation structure,\n  and the last return for bare-earth terrain models.\n  \n  The last return will not always be from a ground return. For example,\n  consider a case where a pulse hits a thick branch on its way to the\n  ground and the pulse does not actually reach the ground. In this case,\n  the last return is not from the ground but from the branch that\n  reflected the entire laser pulse.\n\n For more formal details on LiDAR, I would recommend the following books:\n\n\nTopographic Laser Ranging and Scanning: Principles and\nProcessing\nAirborne and Terrestrial Laser Scanning\n<span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> and Image &hellip; "
    },
    {
        "question": "What are the &quot;must read&quot; academic articles every GIS professional should read?",
        "area": [
            "references"
        ],
        "text": "There was a related question a while back that dealt with the top GIS blogs, but I&#39;m also very interested in &quot;academic&quot; sources of GIS information. I&#39;m currently updating my repository of information and am also considering some new journal subscriptions. \n\nEvery professional field has some big names and big articles. Who are the big names and what articles should everyone be aware of in GIS/cartography/remote sensing?\n\nI&#39;m looking for 3 things in particular:\n\n1) Recommendations on the top sources for GIS articles - important/reliable journals.\n\n2) Major articles from the past - those that paved the way towards the current state of our field.\n\n3) Recent articles showcasing major findings/methodologies.\n\nBonus: I&#39;ve recently been searching for a good source of information on cartographic design - any articles related to this would be a great help.\n Who are the big names and what articles should everyone be aware of in GIS/cartography/<span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>? &hellip; "
    },
    {
        "question": "Near real-time sources of lightning strike data",
        "area": [
            "data",
            "weather"
        ],
        "text": "I am wondering if anyone has any suggestions on sources of near real-time lightning strike data available for download?  For example, Intellicast.com has a map of strikes, but makes no mention of the source of the data they used.   \n\nKey attributes would be date/time and lat/long (any additional is just bonus), and strikes that occurred as much as 24 hours previously are logged and available.  It could be in a text/table form (which can be converted to a spatial table), but if it is in a GIS ready format, that would be great too.\n\nI know of a couple of paid sources:\n\n\nVaisala\nWeatherBank\nUSPLN, NAPLN, and GLN. (Update: Apparently Intellicast gets its data from WSI Corp, which runs the USPLN).\n\n\nOther sources I have stumbled across:\n\n\nblitzortung.org- I haven&#39;t figured out how to get the source strike data from the site\nAccording to an 2007 blog entry, GuiWeather.com used to supply weather data to Google Earth, but the site is no longer active.\n\n\nIs anyone aware of any other paid/free sources of lightning strike data?\n\nUPDATE: Someone posted &amp; deleted a good website for many resources of lightning data.  The NWA Remote Sensing Committee.  It provides a good overview of research and data providers, too.\n The NWA <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> Committee.  It provides a good overview of research and data providers, too. &hellip; "
    },
    {
        "question": "Spatial data? Geodata? Geographic Data? Geospatial data?",
        "area": [
            "data",
            "terminology"
        ],
        "text": "There is a good information about these terms on Basudeb Bhatta&#39;s Blog at this link, copied below. \n\n@Brad Nesom&#39;s definitions are good but I thought that geodata was an abbreviation of &quot;geographic data.&quot; However, Brad&#39;s definition of geodata is quite logical.\n\nBeside these in my opinion:\n\n\n\n...\n\n\n  Often my students ask about the difference(s) between spatial and\n  geospatial. These two words appear very frequently in remote sensing\n  and GIS literature.\n  \n  The word spatial originated from Latin &#39;spatium&#39;, which means space.\n  Spatial means &#39;pertaining to space&#39; or &#39;having to do with space,\n  relating to space and the position, size, shape, etc.&#39; (Oxford\n  Dictionary), which refers to features or phenomena distributed in\n  three-dimensional space (any space, not only the Earth&#39;s surface) and,\n  thus, having physical, measurable dimensions. In GIS, &#39;spatial&#39; is\n  also referred to as &#39;based on location on map&#39;.\n  \n  Geographic(al) means &#39;pertaining to geography (the study of the\n  surface of the earth)&#39; and &#39;referring to or characteristic of a\n  certain locality, especially in reference to its location in relation\n  to other places&#39; (Macquarie Dictionary). Spatial has broader meaning,\n  encompassing the term geographic. Geographic data can be defined as a\n  class of spatial data in which the frame is the surface and/or\n  near-surface of the Earth. &#39;Geographic&#39; is the right word for graphic\n  presentation (e.g., maps) of features and phenomena on or near the\n  Earth&#39;s surface. Geographic data uses different feature types (raster,\n  points, lines, or polygons) to uniquely identify the location and/or\n  the geographical boundaries of spatial (location based) entities that\n  exist on the earth surface. Geographic data are a significant subset\n  of spatial data, although the terms geographic, spatial, and\n  geospatial are often used interchangeably.\n  \n  Geospatial is another word, and might have originated in the industry\n  to make the things differentiate from geography. Though this word is\n  becoming popular, it has not been defined in any of the standard\n  dictionary yet. Since &#39;geo&#39; is from Greek &#39;gaya&#39; meaning Earth,\n  geospatial thus means earth-space. NASA says &#39;geospatial means the\n  distribution of something in a geographic sense; it refers to entities\n  that can be located by some co-ordinate system&#39;. Geospatial data is to\n  develop information about features, objects, and classes on Earth&#39;s\n  surface and/or near Earth&#39;s surface. Geospatial is that type of\n  spatial data which is related to the Earth, but the terms spatial and\n  geospatial are often used interchangeably. United States Geological\n  Survey (USGS) says &quot;the terms spatial and geospatial are equivalent&quot;.\n\n These two words appear very frequently in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>\n  and GIS literature.\n  \n  The word spatial originated from Latin &#39;spatium&#39;, which means space. &hellip; NASA says &#39;geospatial means the\n  distribution of something in a geographic <span class=\"highlight\">sense</span>; it refers to entities\n  that can be located by some co-ordinate system&#39;. &hellip; "
    },
    {
        "question": "Choosing DEM in France?",
        "area": [
            "dem",
            "srtm",
            "aster",
            "france",
            "tandem-x"
        ],
        "text": "The answer is not as simple as the question may imply. If we had one &quot;best one&quot; we would not need the others, we would just use the best. Horses for courses though, needs matter.\n\nSaying that.\n\nThis blog gives an excellent comparison of 90 m SRTM and 30m ASTER with some reasonable statistics. The winner is... well, actually you have no winner but 90m SRTM for me is nosing ahead. \n\n\n\nThe green line is SRTM and the red is ASTER.\n\nI can say I evaluated 30m SRTM (global 30 m SRTM is now available) and 30 m ASTER for Borneo and 30 m SRTM won my race, by a furlong. You see though, I wanted watersheds and had a hydrological algorithm in GRASS specifically built for the errors in SRTM so it was not a fair race. What you want to do with it matters greatly, as does where. GTOPO30 may work great at the continental scale, whereas I need LIDAR at 1 m resolution to calculate drainage on my agricultural fields. EU DEM is at approx. 25 m and may meet your needs and all the modeling information can be found online. Actually, this is the same for GTOPO, SRTM, and ASTER as well as in the LIDAR link given. All the construction information for the major free DEMS, and many of the minor ones, exists online.\n\nYou need to decide what DEM bests fits your application and needs. We cannot do that and you have not told us your needs or even the region you are working in. You can then search online and find the information about each DEM, usually in the metadata or on an accompanying website. This list will get you started but your region may well have improved resolution sources available, such as lidar.\n\nHere is some free literature:\n\nHirt, Christian, M. S. Filmer, and W. E. Featherstone. &quot;Comparison and validation of the recent freely available ASTER-GDEM ver1, SRTM ver4. 1 and GEODATA DEM-9S ver3 digital elevation models over Australia.&quot; Australian Journal of Earth Sciences 57.3 (2010): 337-347.\n\nChang, Hsing-Chung, Xiaojing Li, and Linlin Ge. &quot;Assessment of SRTM, ACE2 and ASTER-GDEM using RTK-GPS.&quot; 15 AUSTRALASIAN REMOTE SENSING &amp; PHOTOGRAMMETRY CONFERENCE. Sydney: University of New South Wales, 2010.\n\nHayakawa, Yuichi S., Takashi Oguchi, and Zhou Lin. &quot;Comparison of new and existing global digital elevation models: ASTER G\u2010DEM and SRTM\u20103.&quot; Geophysical Research Letters 35.17 (2008).\n &quot;Assessment of SRTM, ACE2 and ASTER-GDEM using RTK-GPS.&quot; 15 AUSTRALASIAN <span class=\"highlight\">REMOTE</span> <span class=\"highlight\">SENSING</span> &amp; PHOTOGRAMMETRY CONFERENCE. Sydney: University of New South Wales, 2010. &hellip; "
    },
    {
        "question": "Which Tools do you use for Classification of Remote Sensing Data?",
        "area": [
            "remote-sensing",
            "classification"
        ],
        "text": "Which tool do you prefer to use for classification of remote sensing data, e.g. classifying land use, and why? \n\nWhich other tools have you tried, and why did you decide against them?\n Which tool do you prefer to use for classification of <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> data, e.g. classifying land use, and why? \n\nWhich other tools have you tried, and why did you decide against them? &hellip; "
    },
    {
        "question": "Reading, modifying and writing a geotiff with GDAL in python",
        "area": [
            "python",
            "gdal",
            "geotiff-tiff",
            "landsat",
            "numpy"
        ],
        "text": "I&#39;m trying the learn the ropes of Remote Sensing image processing using Python GDAL bindings and numpy. As a first attempt, I&#39;m reading a Landsat8 geotiff file, do a simple manipulation and write the result to a new file. The code below appears to work fine, except that the original raster is dumped in the output file, rather than the manipulated raster. \n\nAny comments or suggestions are welcome, but particularly notes on why the manipulated raster does not show in the result. \n\n\n\nI use Python 2.7.1 on a Windows 7 32 bit machine. \n I&#39;m trying the learn the ropes of <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> image processing using Python GDAL bindings and numpy. &hellip; "
    },
    {
        "question": "Which remote sensing satellite is best used for vegetation extent mapping",
        "area": [
            "remote-sensing",
            "satellite",
            "landsat"
        ],
        "text": "I agree with @vascobnunes opinion but if you want to define certain objects you have to use LANDSAT TM because more classification needs more bands as (R, G, B, NIR, MIR, TIR, FIR)... and my choice is that you should use LANDSAT TM (I gave same information in the following explanation) for vegetation.\n\nThe important thing in this case is that you should look at  of your satellite. \n\n\n  Relative spectral response (RSR) measurements are assumed to be\n  constant for all detectors covered by a common filter and are\n  normalized to unity AT peak response. There are currently no methods\n  to check spectral stability with time from either on-orbit or Ground\n  measurements.\n\n\n(Source: Dr. John Barke)\n\nIn addition to RSR,  is so important for repetitive data acquisition cycle...\n\nThis is the relative spectral response for LANDSAT TM:\n\n\n\nThere is an information here about Assessment of NDVI- differences caused by sensor-\nspecific relative spectral response functions.\n\nAbstract is here:\n\n\n  The Normalized Difference Vegetation Index (NDVI)  is the most often\n  used remote sensing-based indicator to monitor  dynamics of land\n  surfaces and environmental changes. Due to  different sensor\n  characteristics, the NDVI values vary according  to the recording\n  system. This study focuses on the factor of  spectral sensor\n  characteristics, which can complicate the  interpretation of\n  multisensoral NDVI data. Therefore,  multispectral bands of Landsat\n  5TM, QuickBird and SPOT5  were simulated from hyperspectral data.\n  These simulated data  sets show identical characteristics (except\n  spectrally) like sensor  geometry, atmospheric conditions, topography\n  and spatial  resolution. This allows a direct comparison of NDVI\n  differences  caused by the factor of different spectral\n  characteristics.\n\n\nI have made a summary for you from this document about spectral values for NIR and Red band...\n\n\n\nRelative spectral response functions of the red and near-infrared \nbands of Landsat 5TM, QuickBird and SPOT5 with 2 typical land cover \nspectra. \n\nThe Result :\n\n\n  Especially in the NIR  region the RSR functions of the sensors vary\n  from each other.  Conspicuous is that the gap between the red and NIR\n  band of  Landsat 5TM as well as of SPOT5 is wider than the gap \n  between the QuickBird bands, where even an overlap exists.\n\n\n\n\n\n\nSensor-related differences (%) of the relative spectral response \nfunctions of the red (a) and near-infrared (b) bands of the sensors. \n\nThe Result:\n\n\n  Whereas the red bands of QuickBird and SPOT5 are  very similar, the\n  NIR bands of these sensors show the widest differences up to over 80%\n  at 0.77&#181;m. Due to the wide  differences between the NIR bands, the RSR\n  functions of these  bands affect the NDVI more than those of the red\n  bands.\n\n\nI hope it helps you...\n Abstract is here:\n\n\n  The Normalized Difference Vegetation Index (NDVI)  is the most often\n  used <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>-based indicator to monitor  dynamics of land\n  surfaces and environmental changes. &hellip; "
    },
    {
        "question": "Installing GDAL with Python on Windows",
        "area": [
            "python",
            "gdal",
            "installation",
            "windows"
        ],
        "text": "Another option is to install the Anaconda Python distribution which has packages for GDAL. If you are going to be doing a lot of work using GDAL with other Python packages (scipy, pandas, scikit-learn etc.,) this might be a better option than OSGeo4W. On the other hand if you want to use Python in combination with a number of open-source remote sensing and GIS packages (GRASS, QGIS etc.,) OSGeo4W is probably the better option.\nYou can get the full Anaconda distribution from: https://www.continuum.io/downloads which contains a lot of Python packages aimed at &#39;data science&#39; or a minimal installation from http://conda.pydata.org/miniconda.html\nAs part of the installation it will prompt you to add to the main path (so it is available from any terminal).\nOnce set up GDAL can be installed into a new environment using:\n\nThen activating it as shown when the command finishes. Installing into a new environment is recommended to avoid conflicts with other packages and make sure the environmental variables required are set.\nI&#39;ve suggested installing from the conda-forge channel (https://conda-forge.github.io/) as they are very active in keeping their GDAL builds up to date and making sure they work against a lot of libraries.\nOnce installed packages can be updated from within the environment using:\n\n On the other hand if you want to use Python in combination with a number of open-source <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> and GIS packages (GRASS, QGIS etc.,) OSGeo4W is probably the better option. &hellip; "
    },
    {
        "question": "What is Change Detection and performing such analysis with open source tools?",
        "area": [
            "raster",
            "open-source-gis",
            "remote-sensing",
            "references",
            "change-detection"
        ],
        "text": "Change detection is a common operation/module in remote sensing packages like ENVI or Orfeo toolbox. It usually involves raster data (satellite images for example).\n\n\n  How is the comparison done? With what tools? I feel that the\n  description is not complete. Or something is missing.\n\n\nChange detection is done by comparing two raster images that were taken at different times but which cover the same area. As the images cover the same area, the images overlay each other. Imagine two grids stacked on top of each other. \n\nIt is then a matter of comparing whether the value of a pixel in the new raster is the same as the value of the pixel in the old raster. Pixels that have changed are then marked. The output is usually a raster that covers the same extents as the two images with the changed areas highlighted. It&#39;s a simplification of course but you get the idea :)   \n\n\n\n\n  Where or in which books can I find more information about Change\n  Detection?\n\n\nYou can start with these documents\n\n\nReview Article Digital change detection techniques using remotely-sensed data\nTHE STATE OF CHANGE DETECTION IN GIS\nHow Change Detection Works\n\n\n\n  What tools should I use to perform such an analysis using the data in a shapefile? (only open-source please)\n\n\nYou can try out Opticks. It has a change detection plugin.\n Change detection is a common operation/module in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> packages like ENVI or Orfeo toolbox. It usually involves raster data (satellite images for example).\n\n\n  How is the comparison done? &hellip; "
    },
    {
        "question": "Automating preprocessing of LANDSAT data",
        "area": [
            "remote-sensing",
            "software-recommendations",
            "landsat"
        ],
        "text": "I&#39;m currently enrolled in a remote sensing course, using LANDSAT data.\nPart of my course is about standardizing the scenes based on radiance values. I assume that because this is such a tedious task, someone has already figured out a way to automate it.\nAre there any tools, Esri or otherwise that will standardize LANDSAT scenes?\n I&#39;m currently enrolled in a <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> course, using LANDSAT data.\nPart of my course is about standardizing the scenes based on radiance values. &hellip; "
    },
    {
        "question": "Which remote sensing satellite is best used for vegetation extent mapping",
        "area": [
            "remote-sensing",
            "satellite",
            "landsat"
        ],
        "text": "I&#39;m currently writing an assignment for my remote sensing class and while I think I have correct answer was wondering what people who do this stuff for a living think.\n\nThe question is: which satellite out the Landsat TM (Thematic Mapper) and SPOT 5 would you use to map general extent of a 300km x 300km study area.\n\nMy answer was that you would use the SPOT 5 as it is higher resolution and would let you get a finer extent vs the 30m resolution of the Landsat TM.  However the SPOT 5 has a small swath area so you have to use more images.  I also thought about the 2200km VMI swath on the SPOT 5 but the resolution is 1km.\n\nThoughts?\n I&#39;m currently writing an assignment for my <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> class and while I think I have correct answer was wondering what people who do this stuff for a living think. &hellip; "
    },
    {
        "question": "Difference Between Radiometric calibration and radiometric correction",
        "area": [
            "remote-sensing"
        ],
        "text": "I am new in remote sensing field.\nI sometimes got confused when I read about image pre-processing.\nCan someone please elaborate to me the difference and some example methods to do radiometric correction and radiometric calibration ? \nIs converting DN values to Top Of Atmospheric (TOA) reflectance values from 2 sets of images (e.g Landsat 7) from different time counted as correcting or calibrating ?\nAre DOS (Dark Object Subtraction) and Sun-angle correction parts of radiometric correction ?\n I am new in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> field.\nI sometimes got confused when I read about image pre-processing. &hellip; "
    },
    {
        "question": "Distinction between pixel-based and object based classification?",
        "area": [
            "remote-sensing",
            "classification",
            "machine-learning"
        ],
        "text": "I am struggling to clearly understand the distinction between pixel-based and object-based classification in the remote sensing domain and am hoping someone from this community can provide insight.\n\nBased on the information I have so far, my current understanding is along these lines:\n\nPixel-based classification:\nClassification is done on a per pixel level, using only the spectral information available for that individual pixel (i.e. values of pixels within the locality are ignored). In this sense each pixel would represent a training example for a classification algorithm, and this training example would be in the form of an n-dimensional vector, where n was the number of spectral bands in the image data. Accordingly the trained classification algorithm would output a class prediction for each individual pixel in an image.\n\nObject-based classification:\nClassification is done on a localized group of pixels, taking into account the spatial properties of each pixel as they relate to each other. In this sense a training example for a classification algorithm would consist of a group of pixels, and the trained classification algorithm would accordingly output a class prediction for pixels on a group basis. For a crude example, an image might be partitioned into n segments of equal size, and each segment would then be given a class (i.e. contains object / does not contain object).\n\nIs this thinking accurate regarding the meaning of these terms, or is there something that I have missed? \n I am struggling to clearly understand the distinction between pixel-based and object-based classification in the <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> domain and am hoping someone from this community can provide insight. &hellip; In this <span class=\"highlight\">sense</span> each pixel would represent a training example for a classification algorithm, and this training example would be in the form of an n-dimensional vector, where n was the number of spectral &hellip; "
    },
    {
        "question": "Distinction between pixel-based and object based classification?",
        "area": [
            "remote-sensing",
            "classification",
            "machine-learning"
        ],
        "text": "As far as pixel-based classification is concerned, you are spot on. Each pixel is an n-dimensional vector and will be assigned to some class according to some metric, whether using Support Vector Machines, MLE, some kind of knn classifier, etc.\n\nAs far as region based classifiers are concerned, though, there have been huge developments in the last few years, driven by a combination of GPUs, vast amounts of data, the cloud and wide availability of algorithms thanks to the growth of open source (facilitated by github). One of the biggest developments in computer vision/classification has been in convolutional neural networks (CNNs). The convolutional layers &quot;learn&quot; features which might be based on colour, as with traditional pixel-based classifiers, but also create edge detectors and all kinds of other feature extractors that could exist in an region of pixels (hence the convolutional part) that you could never extract from a pixel-based classification. This means they are less likely to mis-classify a pixel in the middle of an area of pixels of some other type -- if you have ever run a classification and got ice in the middle of the Amazon, you will understand this problem.\n\nYou then apply a fully connected neural net to the &quot;features&quot; learnt via the convolutions to actually do the classification. One of the other great advantages of CNNs is that they are scale and rotation invariant, as there are usually intermediate layers between the convolution layers and the classification layer that generalize features, using pooling and dropout, to avoid overfitting, and help with the issues around scale and orientation.\n\nThere are numerous resources on convolutional neural networks, although the best has to be the Standord class from Andrei Karpathy, who is one of the pioneers of this field, and the entire lecture series is available on youtube.\n\nSure, there are other ways of dealing with pixel versus area based classification, but this is currently the state of the art approach, and has many applications beyond remote sensing classification, such as machine translation and self-driving cars.\n\nHere is another example of region-based classification, using Open Street Map for tagged training data, including instructions for setting up TensorFlow and running on AWS.\n\nHere is an example using Google Earth Engine of a classifier based on edge detection, in this case for pivot irrigation -- using nothing more than a Gaussian kernel and convolutions, but again, showing the power of region/edge based approaches.\n\n\n\nWhile the superiority of object over pixel-based classfication is fairly widely accepted, here is an interesting article in Remote Sensing Letters assessing the performance of object-based classification.\n\nFinally, an amusing example, just to show that even with regional/convolutional based classifiers, computer vision is still really hard -- fortunately, the smartest people at Google, Facebook, etc, are working on algorithms to be able to determine the difference between dogs, cats, and different breeds of dogs and cats. So, those of use interested in remote sensing can sleep easy at night :D\n\n\n Sure, there are other ways of dealing with pixel versus area based classification, but this is currently the state of the art approach, and has many applications beyond <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> classification, such &hellip; So, those of use interested in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> can sleep easy at night :D &hellip; "
    },
    {
        "question": "Determining bare earth DEM from unclassified LAS file?",
        "area": [
            "dem",
            "lidar",
            "classification",
            "las",
            "unmanned-aerial-vehicle"
        ],
        "text": "Generating LiDAR DEMs from unclassified point clouds with:\n\n\nMCC-LIDAR - Multiscale Curvature Classification (MCC) algorithm.\n(supports LAS versions 1.1 to 1.3)  \n\n\n\n  MCC-LIDAR is a command-line tool for processing discrete-return LIDAR data in forested environments (Evans &amp; Hudak, 2007).\n\n\nWorkflow: \n\n\na) unclassified point cloud.\nb) ground returns classified.\nc) bare-earth DEM (raster).\n\n\n\n\n\n\nLet&#39;s create a hypothetical situation to further provide an example with code.\n\nMCC-LIDAR is installed in:  \n\n\n\nThe unclassified LiDAR point cloud (.las file) is in:  \n\n\n\nThe output which are going to be the bare-earth DEM is in:\n\n\n\nThe example below classifies ground returns with the MCC algorithm and create a bare-earth DEM with 1 meter resolution.\n\n\n\nTo understand better how the scale (s) and the curvature threshold (t) parameters work, read: How to Run MCC-LiDAR and; Evans and Hudak (2007).\n\nThe parameters need to be calibrated to avoid commission/labeling errors (when a point is classified as belonging to the ground but actually it belongs to vegetation or buildings). For example:  \n\n\n\nThe MCC-LIDAR uses Thin Plate Spline (TPS) interpolation method to classify ground points and generate the bare-earth DEM. \n\n\n\nReferences:\n\n\nEvans, Jeffrey S.; Hudak, Andrew T.  2007.  A multiscale curvature algorithm for classifying discrete return LiDAR in forested environments.   IEEE Transactions on Geoscience and Remote Sensing. 45(4): 1029-1038.  \n\n\nFor more options about ground point classification algorithms, see Meng et al. (2010): \n\n\nMeng, X.; Currit, N.; Zhao, K. (2010). Ground Filtering Algorithms for Airborne LiDAR Data: A Review of Critical Issues. Remote Sensing, 2(3), 833\u2013860. doi:10.3390/rs2030833\n\n IEEE Transactions on Geoscience and <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>. 45(4): 1029-1038. &hellip; <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>, 2(3), 833\u2013860. doi:10.3390/rs2030833 &hellip; "
    },
    {
        "question": "Is there a professional certification available for QGIS users?",
        "area": [
            "qgis",
            "education",
            "training",
            "certification",
            "gis-professional"
        ],
        "text": "Update Edit 06/03/2020. Yes - the QGIS open source project now offers a Certification program which one can apply to.\n\nThe QGIS Certificate Program is designed to promote both community involvement in the QGIS project and quality education for QGIS software. As such the application process requires applicants to both detail their contributions to the QGIS project and make their training materials available for review. Contributions to the QGIS project include activities such as:\nDevelopment/commits to QGIS\nContributions to the QGIS documentation and training materials\nTranslation of QGIS materials\nAuthoring plugins\nFiling bug reports\nFinancially supporting new feature development\nFinancial contributions to and sponsorship of QGIS\nInvolvement in your local QGIS User Group\nPublication of open QGIS course ware\nAuthoring QGIS books\n\n![QGIS Workflow Certification Diagram\n\nYou are required to provide the training material for each of your courses. This includes exercises, lectures and data. This material will be reviewed for currentness, accurate representation of the QGIS project and overall quality. If the material is not of adequate quality, this can be cause for refusal.\nFollowing an initial review, the application will be sent to local QGIS groups for their opinion. This portion of the review should take place in less than one month. If there is not a local QGIS user group the QGIS Project Steering Committee (PSC) will make a determination based on material provided and your reputation in the community. In this latter case you are encouraged to establish a local QGIS User Group. If you are not deemed to be a member of the QGIS community in good standing this can be cause for refusal.\nThe PSC will make the final determination. If accepted as a QGIS Certified Organization your contributions to the project will be published for transparency.\nIf approved you are required to make a \u20ac20 donation to the QGIS project for each certificate. This creates a mechanism for financial support of the project. Payments for certificates are made using online credit card transactions.\nYou can apply through this form (make sure to first create a login). You can find more details about the certification programme here (we advise you to read this before registering).\n\nHere are several other options, from March 2019 this is information I&#39;ve come across via this\n\nblog post from NRGS - &quot;NRGS and QGIS Certification&quot; where the author highlights\n\nAnother option for a QGIS &#39;certificate&#39; I found was a 5-sequence course offered by a College in the US - Del Mar College. That offer a certificate in &#39;Open Source Geospatial Technology&#39;. It was also covered by a GIS content Magazine here\nThe five courses include:\n\n\nGST 101\u2014Introduction to Geospatial Technology Using QGIS\n\nGST 102\u2014Spatial Analysis Using QGIS\n\nGST 103\u2014Data Management and Acquisition Using QGIS\n\nGST 104\u2014Cartography Using QGIS and Inkscape\n\nGST 105\u2014Remote Sensing Using QGIS and GRASS The courses are designed to be self-contained complete with all the theory, software instruction, and sample data required to learn at home or office, at your own pace.\n\n\n\nAlso, in elsewhere I found these programs available:\nIn British Columbia, Canada there is a program offered by Langara providing a certificate\n\nthe curriculum of this program is based on sound principles common to the entire field of GIS, and the classes will be conducted using QGIS\n\nIn India, there is a Certificate course in Public Health using QGIS here\n GST 101\u2014Introduction to Geospatial Technology Using QGIS\n\nGST 102\u2014Spatial Analysis Using QGIS\n\nGST 103\u2014Data Management and Acquisition Using QGIS\n\nGST 104\u2014Cartography Using QGIS and Inkscape\n\nGST 105\u2014<span class=\"highlight\">Remote</span> &hellip; <span class=\"highlight\">Sensing</span> Using QGIS and GRASS The courses are designed to be self-contained complete with all the theory, software instruction, and sample data required to learn at home or office, at your own pace. &hellip; "
    },
    {
        "question": "Are &quot;gridded data&quot; and &quot;raster data&quot; the same thing?",
        "area": [
            "raster"
        ],
        "text": "No, the two terms aren&#39;t equivalent: 1) Not all raster data is gridded -- not even all Earth observation imagery raster data. 2) And while gridded data is usually stored in a raster file format, not all gridded data represents a straightforward rectangular raster data structure.\n\nTo illustrate this:\n\n\n&quot;Gridded&quot; presumes that data in question represents values taken at some set of grid points. These points are presumed to be regular in some fashion, for example, the next row of values in the data structure corresponds the next row of the grid, geographically speaking, in some direction, such as the next row to the south. However, if you look at basic satellite remote sensing imagery, the &quot;raw&quot; (that is, sensor-calibrated, but not gridded) raster data usually called Level 1 corresponds to rows of imagery data as seen by the sensor. For example, a sensor might image 10 rows at an east-west swipe, with the next swipe taking in the next 10 rows, and each data pixel has a lat/long pair (on the ground) associated with it. But as the field of view of a satellite-borne sensor widens at the swath edges, the first row of the next swipe might well, at least partially, overlap and intertwine with the last row of the previous swipe. This makes gridding raster data from a satellite-borne sensor non-trivial in practice.\nConversely, &quot;raster&quot; primarily refers to a characteristic of a data structure, that is, a 2D array. If the gridded data is on a non-rectangular grid (such as triangular, hexagonal), it may be stored in a non-raster data structure such as a tree of some sort.\n\n\nIn your case, the main question is not whether you are dealing with &quot;gridded&quot; or &quot;raster&quot; data. Chances are, the data is either gridded or available on a raster with lat/long attributes in each cell and without overlaps and weird artefacts: processed data is usually corrected for this. The main question for you is whether your tools are compatible with the data format you have. \n However, if you look at basic satellite <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> imagery, the &quot;raw&quot; (that is, sensor-calibrated, but not gridded) raster data usually called Level 1 corresponds to rows of imagery data as seen by &hellip; "
    },
    {
        "question": "Recommended programming language for remote sensing?",
        "area": [
            "python",
            "remote-sensing",
            "software-recommendations",
            "idl"
        ],
        "text": "From a remote sensing perspective, the main benefit of IDL is that it extends the capability of ENVI similar to how the Python arcpy site-package extends the functionality of ArcGIS. If you will not have access to the ENVI platform, consider learning a different programming language. Additionally IDL is a commercial product whereas Python is open-source and has a huge support base.\n\nFrom a practical perspective, Python, R (open-source) and MATLAB (commercial) are the most important languages for my day-to-day remote sensing based work.  I use MATLAB for much of the digital image processing, Python for more GIS related tasks and R for graphics/analytical purposes.\n\nFinally, if I had to focus all of my efforts on one language, I would choose to learn Python mainly because Python functionality is much more suited to GIS-related processing in addition to RS based functionality.  In other words, Python is a jack-of-all-trades whereas IDL is not.  Besides, NASA uses Python!    \n From a <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> perspective, the main benefit of IDL is that it extends the capability of ENVI similar to how the Python arcpy site-package extends the functionality of ArcGIS. &hellip; From a practical perspective, Python, R (open-source) and MATLAB (commercial) are the most important languages for my day-to-day <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> based work. &hellip; "
    },
    {
        "question": "Difference Between Radiometric calibration and radiometric correction",
        "area": [
            "remote-sensing"
        ],
        "text": "It is sometimes difficult to distinguish calibration and correction in remote sensing, because we are not in a laboratory with full control on the measurement. Therefore the two are often mixed.\n\nSensu stricto, radiometric calibration is the conversion from the sensor measurement to a physical quantity. In remote sensing, the sensor is measuring a radiance from the top of the atmosphere. Therefore the image provider also provide calibration coefficients to convert from digit number (DN) to radiance. Because we can trust the amount of light energy that comes from the sun, the radiance is often normalized into a reflectance values (easier to work with because bounded by 0 and one), so this step can also be part of the calibration. So the calibration gives you a reflectance value, but it is the reflectance on top of the atmosphere (TOA).\n\nIndeed, the proportion of the incident light that is really reflected by the observed object is effected by different factors (mainly topography and atmospheric thickness). The reflectances measured TOA therefore need to be corrected if you need absolute values. This does not depend on the sensor itself, so I would not talk about calibration in this case: you need to correct the values measured TOA in order to estimate the values top of canopy. \n\nTo answer your question, I would thus say that DOS is a correction method and DN to TOA reflectance is a calibration. DOS require a stable dark object where you can assume that variability is due to atmospheric noise, which is difficult to find. \n\nEDIT: for more info on Landsat atmospheric correction, I recommend LEDAPS (Masek et al, 2013)\nFor Sentinel-2, different algorithms have been proposed and I cannot give a definitive answer yet. SEN2COR is used a lot, and MAJA is great if you work with time series (also for Landsat, by the way). \n It is sometimes difficult to distinguish calibration and correction in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, because we are not in a laboratory with full control on the measurement. Therefore the two are often mixed. &hellip; In <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, the sensor is measuring a radiance from the top of the atmosphere. Therefore the image provider also provide calibration coefficients to convert from digit number (DN) to radiance. &hellip; "
    },
    {
        "question": "Why choose open source software for remote sensing research?",
        "area": [
            "open-source-gis"
        ],
        "text": "If you judge by the amount of the questions regarding FOSS software that are being asked in GIS SE many users seems to prefer FOSS over proprietary software. \n\nI&#39;ve read some articles - more precisely some personal blogs - supporting this choice. Furthermore corporate giants like Esri seem to acknowledge the open source development movement. \n\nSo, I am asking your position in this matter. \n\nWhy do you use open source tools? \n\nWhat are the advantages or disadvantages of your choice, if any? \n If you judge by the amount of the questions regarding FOSS software that are being asked in GIS SE many users seems to prefer FOSS over proprietary software. \n\nI&#39;ve read some articles - more precisely &hellip; "
    },
    {
        "question": "Extracting tree crown areas from remote sensing data (visual images and LiDAR)",
        "area": [
            "remote-sensing",
            "lidar",
            "classification",
            "land-cover",
            "image-segmentation"
        ],
        "text": "I am looking for a method to process a remote sensing image and extract the crown areas of the individual trees from the image. \n\nI have both visual wavelength areal imagery, and lidar data from the area. The location in question is a desert area, so the tree cover isn&#39;t as dense as a forest area. The resolution of the aerial imagery is 0.5 feet by 0.5 feet. The lidar resolution is approximately 1 x 1 feet. Both the visual data and the lidar come from a Pima County, Arizona dataset. A sample of the type of aerial imagery I have is at the end of this post. \n\nThis question Single Tree detection in ArcMap? seems to be the same issue, but there does not seem to be a good answer there.\n\nI can obtain a reasonable classification of the vegetation types (and information about the overall percent cover) in the area by using the Iso Cluster classification in Arcmap, but this provides little information on individual trees. The closest I have to what I want is the results of passing the output of the isocluster classification through the Raster to Polygon feature in Arcmap. The problem is that this method merges near by trees into a single polygon. \n\nEdit: I probably should have included some more detail about what I have. The raw datasets I have are: \n\n\nFull las data, and a tiff raster generated from it.\nVisual imagery (like the sample image shown, but covering a much wider area) \nManual direct measurements of a subset of the trees in the area. \n\n\nFrom these I have generated: \n\n\nThe ground/vegetation classifications.\nThe DEM/DSM rasters.\n\n\n\n I am looking for a method to process a <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> image and extract the crown areas of the individual trees from the image. &hellip; "
    },
    {
        "question": "Is the reflectance required to get the NDVI, for Landsat 8 images?",
        "area": [
            "image",
            "landsat",
            "landsat-8",
            "toa-calibration",
            "reflectance"
        ],
        "text": "NDVI is defined for any two bands with near-infrared and infrared data (it is an empirical remote sensing index). As such, you can calculate it straight from the DNs. This is mostly OK if you are only classifying or analyzing vegetation on a single image without significant atmospheric effects (cirrus clouds...)\n\nHowever, if you are performing change detection (and therefore analysing two or more images), you will need to cope with two steps:\n\n\nRadiometric calibration converts the DNs to radiance using sensor-specific calibration equations. For Landsat, these can be found on the project website or built in most of the good software packages.\nAtmospheric correction tries to convert the radiance to reflectance (a dimensionless number describing the ratio of reflected radiation on the incoming radiation in the specific part of the spectrum). For this, atmosphere models are used such as QUAC or FLAASH.\n\n\nThis answer may provide some suggestions which software to use.\n NDVI is defined for any two bands with near-infrared and infrared data (it is an empirical <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> index). As such, you can calculate it straight from the DNs. &hellip; "
    },
    {
        "question": "Moving points onto lines (~neighborhood)",
        "area": [
            "qgis",
            "vector",
            "point",
            "line"
        ],
        "text": "I do have two vector layer, of which\none is a point layer based on &quot;events&quot; by remote sensing\nand the second one is a line layer from local research. \n\nIn my case these are earthquakes and tectonic faults, but\nI guess one could simply choose &quot;car-accidents and roads&quot;\nas a general example.\n\nSo what I&#39;d like to do is move/copy the points onto\nthe closest point of the lines, as long as its within a\ntolerance distance (say 1-2km or 0.0xx&#176;), with the new\npoint layer (+attr moved y/n).\n\nAny ideas ?\n\nLinux, QGIS 1.8\n I do have two vector layer, of which\none is a point layer based on &quot;events&quot; by <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>\nand the second one is a line layer from local research. &hellip; "
    },
    {
        "question": "Recommended programming language for remote sensing?",
        "area": [
            "python",
            "remote-sensing",
            "software-recommendations",
            "idl"
        ],
        "text": "I am beginning studies that hopefully will lead to a long career as a remote sensing specialist.  I am currently working with ArcGIS for some applications and learning ENVI for others.  I have realized that it is imperative that I learn a programming language, and am stuck facing a choice between IDL and Python.  I would love to hear which programming language the community recommends for the remote sensing of land surface processes.\n I am beginning studies that hopefully will lead to a long career as a <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> specialist.  I am currently working with ArcGIS for some applications and learning ENVI for others. &hellip; I would love to hear which programming language the community recommends for the <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> of land surface processes. &hellip; "
    },
    {
        "question": "Python resource for remote sensing?",
        "area": [
            "python",
            "remote-sensing"
        ],
        "text": "Form the (i)python basis to the more complex manipulation:\nDr M. Disney - Introduction to image data handling \nThese two blog have many examples:\nLuca Congedo  - From GIS to Remote Sensing\nREMOTESENSING.IO web.archive.org:RemoteSensing.io\nThings became more interesting with more spectral bands:\nhttp://www.spectralpython.net/\nAnother book about this topic:\nImage Analysis, Classification and Change Detection in Remote Sensing: With Algorithms for Envi/Idl and Python  by\nMorton J. Canty\n Disney - Introduction to image data handling \nThese two blog have many examples:\nLuca Congedo  - From GIS to <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>\nREMOTESENSING.IO web.archive.org:RemoteSensing.io\nThings became more interesting &hellip; with more spectral bands:\nhttp://www.spectralpython.net/\nAnother book about this topic:\nImage Analysis, Classification and Change Detection in <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>: With Algorithms for Envi/Idl and Python &hellip; "
    },
    {
        "question": "NDVI in urban environment",
        "area": [
            "remote-sensing"
        ],
        "text": "What considerations should be taken into account when trying to derive a NDVI from an urban environment? \n\nI pulled a tree canopy layer from LAR-IAC data and used an NDVI of 0.38. However, this FAQ on Vegetation in Remote Sensing recommends using &gt;0.8, while I&#39;ve read &gt;0.6 as a good NDVI for dense vegetation. Is 0.38 too low, and is it possibly lower because of an urban environment (Pasadena, CA)? Should I be using an alternative index, like SAVI (Soil Adjusted Vegetation Index), but maybe for urban areas? \n However, this FAQ on Vegetation in <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> recommends using &gt;0.8, while I&#39;ve read &gt;0.6 as a good NDVI for dense vegetation. &hellip; "
    },
    {
        "question": "Examples of GIS or Remote Sensing in movies",
        "area": [
            "gps",
            "remote-sensing",
            "aerial-photography"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\n\n\n\nIn What we Do in The Shadows, Stu, a human who hangs out with the vampire main characters, works with GIS. Here is great clip of him explaining what he does. It&#39;s what the actor does for a living in real life, as well.\nEnemy of the State (movie), has many scenes of tracking Will Smith&#39;s character movements via high resolution satellites.\nPatriot Games (1992) has a scene where Jack Ryan (Harrison Ford) is using satellite imagery to locate an IRA training camp in north Africa. Ryan gets the imagery analyst to &quot;zoom in and enhance&quot; and identifies the camp because the enhanced image reveals a womans cleavage.\nIn Man of Steel movie, they used CityEngine, which is a three-dimensional (3D) modeling software application developed by Esri, they transforms 2D Geographic Information System (GIS) data into 3D city models.\nLe Samoura&#239; (1967) (rated 8.1 on IMDB)\n\n\n\n  &quot;a network of undercover police officers track a hitman through the Paris\n  Metro, signaling their locations electronically to one big central map&quot;\n\n\n\nEsri had an embedded expert working on the TV show, The District. \n\n\nMost of the police procedural shows do the zoom-in-on-grainy-security-footage and miraculous clean it up to read a license plate or the reflection of logo on a ball cap. NCIS used to do that all the time. This season at least, the analyst has occasionally said, nope, can&#39;t improve the quality. \n\n\nCriminal Minds has also done simple mapping of crime locations to try to figure out the suspect&#39;s &#39;home range&#39; or the area that he&#39;s comfortable in.\nBones has done analysis of bugs and plants to identify where they came from.\nOf course, there&#39;s Sherlock Holmes who can identify the location of particular type of soil\nTV series Westworld also has many scenes where data is overlayed on a map.  They query the map about people&#39;s locations, paths, zone overlaps, timestamps, etc.  They also have a 3D map with elevation.\nMichael Crichton&#39;s novel &quot;Congo&quot; featured liberal use of Remote Sensing techniques for locating Solomon&#39;s fabled mines and the &quot;lost city of Zinj.&quot;  If you&#39;re teaching a class on film, though, you might not want to show the movie... \nAlso, some of those early episodes of Hawaii Five-O (1960s) feature McGarrett and team doing spatial analysis on a glass whiteboard with a map.  They hand-draw buffers and whatnot.  It&#39;s actually pretty clever.\nNot a movie, but in the TV series The Last Ship episode Eutopia (Season 3, episode 9) they used a system based on What 3 Words to identify the location of a target.  Details and promo video on the W3W website here\nThe Bourne Ultimatum featured scenes where maps are used to track assets and targets. Not sure if the previous movies in the series or the last release The Bourne Legacy had such scenes.\n\n Michael Crichton&#39;s novel &quot;Congo&quot; featured liberal use of <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> techniques for locating Solomon&#39;s fabled mines and the &quot;lost city of Zinj.&quot; &hellip; "
    },
    {
        "question": "Python resource for remote sensing?",
        "area": [
            "python",
            "remote-sensing"
        ],
        "text": "I am looking for a good resource (MOOC, book, etc..) to teach Python for remote sensing applications.  I am already familiar with http://www.rsgislib.org/ - are there any other resource out there for a beginning Python programmer?\n I am looking for a good resource (MOOC, book, etc..) to teach Python for <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> applications. &hellip; "
    },
    {
        "question": "Clipping raster with vector boundaries using QGIS",
        "area": [
            "qgis",
            "raster",
            "vector",
            "clip"
        ],
        "text": "If you are interested using Python, a good documentation is available at GeospatialPython.com, here.\n\nand clipraster.py source is here.\n\n\n\n\n  The Process:\n  \n  Clipping a raster is a series of simple button clicks in high-end\n  geospatial software packages.  In terms of computing, geospatial\n  images are actually very large, multi-dimensional arrays.  Remote\n  Sensing at its simplest is performing mathematical operations on these\n  arrays to extract information from the data. Behind the scenes here is\n  what the software is doing (give or take a few steps):\n  \n  \n  Convert the vector shapefile to a matrix which can be used as mask\n  Load the geospatial image into a matrix\n  Throw out any image cells outside of the shapefile extent\n  Set all values outside the shapefile boundary to NODATA (null) values\n  OPTIONAL: Perform a histogram stretch on the image for better visualization\n  Save the resulting image as a new raster.\n  \n\n <span class=\"highlight\">Remote</span>\n  <span class=\"highlight\">Sensing</span> at its simplest is performing mathematical operations on these\n  arrays to extract information from the data. &hellip; "
    },
    {
        "question": "Why choose open source software for remote sensing research?",
        "area": [
            "open-source-gis"
        ],
        "text": "Reasons to use FOSS:\n\n1) It&#39;s free!\n\n2) Ease of access and capabilities - most basic remote sensing tools (e.g. filtering) are available with FOSS, so there is no need to pay for it\n\n3) It&#39;s open - the algorithms you are using aren&#39;t &#39;black-boxed&#39;\n\n4) The ability to add/modify your own tools\n\nalso;\n\n5) Telling people you use FOSS makes you feel cool\n\n6) You enjoy encountering an assortment of interesting bugs and crashes while testing new beta releases\n\n7) You like the elitism of being one of five others using the softwares&#39; user forum\n\n8) Unexpected results are novel\n 2) Ease of access and capabilities - most basic <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> tools (e.g. filtering) are available with FOSS, so there is no need to pay for it\n\n3) It&#39;s open - the algorithms you are using aren&#39;t &#39;black-boxed &hellip; "
    },
    {
        "question": "What are technical skills that a GIS graduate should develop?",
        "area": [
            "arcgis-platform",
            "career"
        ],
        "text": "You&#39;ve really kind of answered your own question here, but I&#39;ll elaborate for the purposes of canonism. I&#39;ll provide you with some ideas based off of specific skills that I often see requested at the GIS jobs clearinghouse.  You can pretty much go two separate routes here (or both simultaneously) and both are pretty wide open:\n\n\n\nBuilding your analysis skills\n\n\n\n\nLearn about rasters. Zonal statistics, DEM/DSM&#39;s, viewshed analysis, local statistics, hydrologic modeling are all branches of Geostatistics, knowledge of which is important for analysis. The Geospatial Data Abstraction Library is a great repository for useful tools and information.\nLearn about remote sensing. I see plenty of job postings asking for expertise in analyzing and managing LiDAR datasets.\nBecome familiar with geocoding, pretty much any entity that keeps address data is usually interested in utilizing geocoding.\n\n\n\n\nBuilding your GIS Developer skills\n\n\n\n\nPython, Python, Python. You&#39;ll hear it over and over again here. This is the GIS scripting language. I used the free courseware from Udacity to learn Python, which I think they do a pretty good job of, but I suggest instead Learn Python the Hard Way.\nIf you want to stick to the ESRI suite, learn C#. At the very least, Microsoft is sticking with this as its go-to language for a very long time. It&#39;s future is more certain than the .NET alternative, VB.NET.\nLearn SQL. For the most part, basic SQL is standardized across all major RDBMS platforms, with all the extra bells and whistles integrated into the special SQL languages such as T-SQL and PL/SQL. Don&#39;t bother with all that yet, if you get the basic standardized language down, you&#39;ll cover 80% of the things you need to do with it and the other 20% you can pick up as you need. W3C has some great simple and straightforward samples to get you started here.\nLearn database architecture. Understand the concepts of normalization and relationships, what primary and foreign keys are, and how to build a database. There are a lot of jobs that involve structuring your GIS data. In the same vein, understanding the underlying structure of geodatabases is key if you want to become a developer in the ESRI suite of products.\nLearn web development. More importantly, learn Javascript. This is a rapidly growing field. I see tons of job postings from businesses that want web GIS applications. There are a few different API&#39;s you can familiarize yourself with. If you want to go open source, two popular ones are OpenLayers and leaflet.js. If you want to stick with ESRI, I wouldn&#39;t go with Flash or Silverlight API&#39;s, I would use Javascript and HTML only. \n\n Learn about <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>. I see plenty of job postings asking for expertise in analyzing and managing LiDAR datasets. &hellip; "
    },
    {
        "question": "Higher resolution of country borders",
        "area": [
            "data",
            "gis-principle",
            "boundaries",
            "borders"
        ],
        "text": "Short answer\nI think you should reevaluate your very concept of &quot;official&quot;, high detailed source for all country borders worldwide. OpenStreetMap data comes close to a worldwide dataset with acceptable level of details for many use cases - however, in each case, this must be evaluated critically.\n&quot;Official&quot; sources for borders\nFor a really &quot;official&quot; source, you would have to check 200 +/- official sources of all +/- 200 existing countries wordlwide. Borders are defined on a bilateral base. The actual delimitation takes place between two neighboring countries. For that reason, there cannot be an &quot;official&quot; registry of all worldwide borders, but at best +/- 200 &quot;national&quot; datasets. There is no international body (like UNO) registering the official definitions of all conturies, this is strictly a matter of bilateral agreements - and in many cases still of custom and practice (customary law) - at least for a precision of less then 100 meters and in more remote areas (deserts, swamps, forests, mountains, lakes etc.).\nSo every insititution that collects these data (like OSM) is not an official source any more by definition. If you really are to get official definitions, you can get them only at the national level.\nWhy it&#39;s difficult (if not impossible) to get a high precision, official dataset of worldwide borders\nTerritorial disputes: contested borders\nIn many cases, not even that does help much. Neighboring countries often have diverging definitions of what belongs to them and what to their neighbors. Georgia and Russia will have different definitions on their borders - not to speak about Crimea or the dispute between Armenia and Azerbaijan (not just about Nagorno Karabakh, but also their &quot;regular&quot; border like in this area).\nThis article makes it clear that no map is precise enough to establish a border - borders are\n\nestablished on the basis of international agreements.\n\nUnmarked segments of (uncontested) borders\nThere are many other cases: the delimitation of the borders between Uzbekistan, Kyrgyzstan and Tajikistan in the Ferghana valley have been an issue for decades now. We not only speak about clear cases of contested territories, but also of generelly undisputed portions of the border that are not delimited: there are many unmarked segments of the border, thus no unanimously shared definition in the terrain (like boundary stone) does exist.\nOnly if both parts sign an agreement that fixes a border in all it&#39;s details (most often still based on real boundary stones put in the terrain by a bilateral commission) can we speak about an &quot;official&quot; border.\nMany borders date back decades (or even centuries), but back then have not been defined very clearly (or there are contradictory sources from different periods so that it remains unclear which one should be considered the &quot;correct&quot; one).\nIn many parts of the world, borders drawn by colonial powers are still source of contestations. See this academic paper on the unresolved delimitation of some central Asian republics, dating back to Russian and Soviet rule: Dr Mirzohid Rahimov &amp; Dr Galina Urazaeva: Central Asian Nations &amp; Border Issues. Conflict Studies Research Centre, 2005.\nSee also the following link where the distintiction between delimited and demarcated borders is explained:\n\n\ndelimited borders: properly fixed, the countries on either side have agreed to the exact physical location of the border, and the\ncoordinates of that physical line have been thoroughly and accurately\ndocumented\n\ndemarcated borders: physically marked on the landscape, with reinforced concrete pillars, anchored by underground footings.\n\n\n\nhttps://www.atlasobscura.com/articles/cameroon-nigeria-border-dispute\nOdd borders\nBorders can date back centuries: see the curious case of a small town on the border of the Netherlands and Belgium with literally dozens of enclaves and exclaves on both side which goes back to medieval times and an agreement from 1843.\nOther oddities, going back centuries, include condominiums like the Pheasant Island, which is part of Spain for the first half of each year and part of France for the second half of the year. Here as well, it&#39;s difficult to draw a 100% exactly border, as it changes over time.\nPeaceful territorial exchanges\nThere are not few cases of peaceful territorial exchanges on the local level ( a few hectares) that normally do not make headlines. These are often tiny adjustments of existing, but not clearly demarcated parts of the border or border segments that create some problems for the infrastructure, economy etc. Examples inclue a territorial exchange between Ukraine and Moldova or Uzbikistan and Kyrgyzstan or others including China. Also the hundreds of enclaves on the border between India and Bangladesh have resulted in border revisions.\nOfficial definition/documentation of borders difficult to access\nAs border zones tend to be a delicate issue for security concerns, many states ar not keen to publish official documentations about this delimitation. There are even cases when maps are deliberately wrong for such reasons - as this post explains for the example of China.\nA map in always all cases is a derivative product that documents one kind or another of border-definitions, but it is not the (legally binding) definition in itself - so to get the &quot;official&quot; source would meen going to the archives (if you have access) to access protocols on the delimitation and demarcation (like the ones of the Kyrgyz-Uzbek borders mentioned here).\nShifting borders or borders not clearly defined\nAnd even today, not even such protocols exist. Many borders are not defined in such a precise way, but are still based on older principles like &quot;in the middle of the river&quot; - riverbeds change, however. There are sections of the border between Switzerland and Italy that are defined as &quot;the ridge of a glacier&quot;. With climate change and melting glaciers, the border changes, too: Melting glacier in Alps shifts border between Switzerland and Italy.\nAs well, there is no agreed definition of the border between Switzerland and Germany in the Lake of Constance - as there is no need for it:\n\nthere is no legally binding agreement as to where the borders lie\nbetween the three countries.\nSee: https://en.wikipedia.org/wiki/Lake_Constance#International_borders\n\nSee also this statement by Swisstopo (Swiss Federal Office of Topography):\n\nOur boundaries can change: Borders are commonly regarded as fixes, but depending on the terrain\nthey are subject to climatological changes and natural phenomena and\nmay thus change their course.\n\nhttps://www.swisstopo.admin.ch/en/knowledge-facts/sovereign-border/national-boundary/moving-boundaries.html\nSo even in the middle of Europe with it&#39;s sophisticated administrative institutions, high precision cartographic technologies, need for clear definitions in a denseily populated area and centuries-long tradition of border delimitation, borders to this day sometimes are still not defined &quot;on the meter&quot;. This is even more true for many parts of the world.\nCritical evalution of the very concept of &quot;official&quot;, detailed border\nSo I&#39;m not sure if the very concept you&#39;re after does makes sense. With no dataset you&#39;ll get a guarantee that it is correct or generally accepted. The more &quot;official&quot; and detailed the data gets, the more you&#39;ll get an illusion of precision and accuracy that in fact does not exist.\n definitions of all conturies, this is strictly a matter of bilateral agreements - and in many cases still of custom and practice (customary law) - at least for a precision of less then 100 meters and in more <span class=\"highlight\">remote</span> &hellip; Critical evalution of the very concept of &quot;official&quot;, detailed border\nSo I&#39;m not sure if the very concept you&#39;re after does makes <span class=\"highlight\">sense</span>. &hellip; "
    },
    {
        "question": "What free programs should every GIS user have installed?",
        "area": [
            "open-source-gis",
            "software-recommendations",
            "free-software"
        ],
        "text": "Whitebox Geospatial Analysis Tools (http://www.uoguelph.ca/~hydrogeo/Whitebox/) is an open-source GIS and remote sensing package that has extensive analytical capabilities. It runs on MS Windows, Mac OSX, and Linux. It has a user-friendly and intuitive user interface, extensive embedded help, and the ability to make cartographically pleasing maps.\n\n\n Whitebox Geospatial Analysis Tools (http://www.uoguelph.ca/~hydrogeo/Whitebox/) is an open-source GIS and <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> package that has extensive analytical capabilities. &hellip; "
    },
    {
        "question": "Burning stream network into DEM layer using ArcGIS Desktop?",
        "area": [
            "arcgis-desktop",
            "arcgis-10.0",
            "dem",
            "rasterization",
            "hydrography"
        ],
        "text": "Whitebox GAT (open-source hydrology and remote sensing package) has a method by this name in its Hydrology utilities. Whitebox is unique in that it exposes the source code and algorithms used by the analysis via the UI (note the View Code button). Even if you intend to isolate your procedures to ArcGIS, there may be some benefits to experimenting with another flavor.\n\n\n Whitebox GAT (open-source hydrology and <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> package) has a method by this name in its Hydrology utilities. &hellip; "
    },
    {
        "question": "Image processing using Python, GDAL and Scikit-Image",
        "area": [
            "python",
            "gdal",
            "remote-sensing"
        ],
        "text": "I am struggling with a processing and hopefully I will be able to solve here.\n\nI work with Remote Sensing applied to Forestry, especially working with LiDAR data. The idea is to use Scikit-image for tree top detection. Since I&#39;m new in Python, I considered a great personal triumph to do the following:\n\n\nImport a CHM (with matplotlib);\nRun a gaussian filter (with scikit-image package);\nRun a maxima filter (with scikit-image package);\nRun the peak_local_max (with scikit-image package);\nShow the CHM with the local maxima (with matplotlib);\n\n\nNow my problem. When I import with matplot, the image loses its geographic coordinates. So the coordinates I have are just basic image coordinates (i.e. 250,312). What I need is to get the value of the pixel under the local maxima dot in the image (red dots in the image). Here in the forum I saw one guy asking the same thing (Getting pixel value of GDAL raster under OGR point without NumPy?), but he already had the points in a shapefile. In my case the points were computed with scikit-image (It is an array with the coordinates of each tree top). So I do not have the shapefile.\n\nIn conclusion, what I want in the end is a txt file with the coordinates of each local maxima in geographic coordinates, for example:\n\n525412 62980123 1150\n...\n\n\n I work with <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> applied to Forestry, especially working with LiDAR data. The idea is to use Scikit-image for tree top detection. &hellip; "
    },
    {
        "question": "Freeware alternatives to eCognition?",
        "area": [
            "software-recommendations",
            "classification",
            "free-software"
        ],
        "text": "You might want to try Orfeo Toolbox.\n\n\n  OTB is based on the medical image processing library ITK and offers\n  particular functionalities for remote sensing image processing in\n  general and for high spatial resolution images in particular. Targeted\n  algorithms for high resolution optical images (SPOT, Quickbird,\n  Worldview, Landsat, Ikonos), hyperspectral sensors (Hyperion) or SAR\n  (TerraSarX, ERS, Palsar) are available.\n\n\nAmong it&#39;s documented capabilities are:\n\n\noptimized read/write access for most of remote sensing image formats, meta-data access, visualization;\nstandard remote sensing preprocessing: radiometric corrections, orthorectification;\nfiltering: blurring, denoising, enhancement;\nfeature extraction: interest points, alignments, lines;\nimage segmentation: region growing, watershed, level sets\nclassification: K-means, SVM, Markov random fields;\nchange detection;\ninformation extraction for integration in GIS and mapping systems.\n\n OTB is based on the medical image processing library ITK and offers\n  particular functionalities for <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> image processing in\n  general and for high spatial resolution images in particular. &hellip; Among it&#39;s documented capabilities are:\n\n\noptimized read/write access for most of <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> image formats, meta-data access, visualization;\nstandard <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> preprocessing: radiometric corrections &hellip; "
    },
    {
        "question": "How to remove clouds in High resolution Imagery(.5 mGeoeye)",
        "area": [
            "remote-sensing",
            "erdas-imagine",
            "envi"
        ],
        "text": "You can&#39;t &#39;remove&#39; clouds from optical imagery, what you see is what you get; they are photographs and there is no optical data recorded from below the clouds in the same way that there is no data underneath building roofs.\n\nIf you use remote sensing data of a longer wavelength than light such as microwave, the water particles in the clouds do not absorb the energy from the sensor, but this type of platform is typically of a lower spatial resolution than optical imagery, and is consequently used for different tasks, such as soil moisture estimation and surface roughness estimation.\n\nThe only solution as such is to try to find a satellite pass without clouds and combine all the clear segments of your study area to make a full clear coverage.\n If you use <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> data of a longer wavelength than light such as microwave, the water particles in the clouds do not absorb the energy from the sensor, but this type of platform is typically of &hellip; "
    },
    {
        "question": "Analyzing differences between two shapefiles to put results into new shapefile using ArcMap",
        "area": [
            "arcgis-desktop",
            "arcmap",
            "topology",
            "change-detection",
            "differences"
        ],
        "text": "I have two polygon shapefiles of the same region from two different years (1985 and 1997) and I need to analyse the differences between the two shapefiles resulting in a third polygon shapefile displaying only differences.\nThe shapefiles cover an inner-city area with buildings, parks, sealed/unsealed areas and water areas. I need to find out for example if a building was de-/constructed or if a park was moved or closed or similar things. Any differences between the shapes.\nI need the output to be in a third, new shapefile.\nIs there an automated way to achieve this?\nI am working with the proprietary file geodatabase in ArcGIS 10.1, so I&#39;d prefer solutions in ArcMap.\nI thought it might be possible to work with topology analysis in ArcGIS but I&#39;m not quite sure for example how to compare shapes by attributes: Each shape has a field &quot;type&quot; in the attribute table and I need to compare not only the shapes but the types of the polygons.\nNote, Finding differences between shapefiles using ArcGIS for Desktop? sounds similar, but I&#39;m looking for an output in a polygon shapefile format.\nThis is a change detection process on vector data (no remote sensing issue). There are some nice comments in this answer but no solutions at all.\n This is a change detection process on vector data (no <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> issue). There are some nice comments in this answer but no solutions at all. &hellip; "
    },
    {
        "question": "How do I convert the LST values on the MODIS LST Image to degree celsius",
        "area": [
            "modis"
        ],
        "text": "Information on how to convert the digital values (&quot;digital numbers&quot; or DN) in satellite remote sensing data that is operationally produced and distributed into physical quantities of interest is generally found in the data user guide. In this case, you need the user guide for the MODIS 11 Level 2 product. Under &quot;scientific data sets (SDS&quot; there is a table that contains the relevant information for the land surface temperature:\n\n\n\n&quot;Scale factor&quot; and &quot;add offset&quot; are used for a linear re-scaling of the DN values (which are going to be between 7500 and 65535) to temperatures in K. As the page explains:\n\n\n  The effective calibration formula for the &quot;LST&quot; SDS is \n         LST = the SDS data in uint16 * 0.02, giving a value in the range of 150-1310.7K.\n\n\nSo the person who gave you advice was almost right: Temperature in &#176;C will be:\n.\n Information on how to convert the digital values (&quot;digital numbers&quot; or DN) in satellite <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> data that is operationally produced and distributed into physical quantities of interest is generally &hellip; "
    },
    {
        "question": "How are kappa and overall accuracy related with respect to thematic raster data?",
        "area": [
            "raster",
            "r",
            "statistics",
            "accuracy"
        ],
        "text": "kappa does not quantifies the level of agreement between two datasets. It represents the level of agreement of two dataset corrected by chance. \n\nThe reason why you have a large difference between kappa and overall accuracy is that one of the classes (class 1) accounts for the large majority of your map, and this class is well described. Overall accuracy is therefore an optimistic index of the classifier performance, even if it is the true &quot;agreement&quot; in your case. As a trivial example, if I give you a map that says &quot;class 1&quot; everywhere, it will be 99% correct. Similarly, if 99% of the pixels are randomly assigned to &quot;class 1&quot;, the resulting map will still have a large agreement with your map. This is what kappa penalize with its &quot;c&quot; in the expression below (note that there are different kappa&#39;s, here is the most common). \n\nkappa = (OA-c)/(1-c), where e is the overall probability of random agreement\n\nOn your confusion matrix, you can see that classes 5 and 6 are always wrong and class 2 is not very reliable. This will have a large impact on your kappa index and this explains the large difference. The classifier is not better than chance for these classes. \n\nAs a remark, standard OA and kappa DO NOT take the distance between classes into account, so the fact that classes 5 and 6 are far off does not affect your results for any of those indices. Therefore, I suggest that you take advantage of the fact that your classes refer to quantities. The correlation between the two map could therefore make a good indicator. A confusion between 1 and 6 would then have more importance than a confusion between 1 and 2. Another way is to look at each class individually (user and producer accuracies). \n\nI do not agree on the fact that Kappa is largely considered to be more robust than OA. According to Pontius (2011), kappa has not provided the useful information that it is supposed to bring. \n\nEDIT : More recently, Olofsson, Foody, Herold, Stehman, Woodcock and Wulder (2014, Remote sensing of Environment) also advocated against kappa. Considering the importance of those authors, I would follow their recommendations.\n\n\n  The problems associated with kappa include but are not limited to: 1)\n  the correction for hypothetical chance agreement produces a measure\n  that is not descriptive of the accuracy a user of the map would\n  encounter (kappa would underestimate the probability that a randomly\n  selected pixel is correctly classified); 2) the correction for chance\n  agreement used in the common formulation of kappa is based on an\n  assumption of random chance that is not reasonable because it uses the\n  map marginal proportions of area in the definition of chance agreement\n  and these proportions are clearly not simply random; and 3) kappa is\n  highly correlatedwith overall accuracy so reporting kappa is redundant\n  with overall accuracy.\u201d (Foody, 1992; Liu et al., 2007; Pontius\n  &amp;Millones, 2011; Stehman, 1997). Consistentwith the recommendation in\n  Strahler et al. (2006) the use of kappa is strongly discouraged as,\n  despite its widespread use, it actually does not serve a useful role\n  in accuracy assessment or area estimation.\n\n EDIT : More recently, Olofsson, Foody, Herold, Stehman, Woodcock and Wulder (2014, <span class=\"highlight\">Remote</span> <span class=\"highlight\">sensing</span> of Environment) also advocated against kappa. &hellip; "
    },
    {
        "question": "How do you explain that band width and relative spectral response of MODIS band do not match?",
        "area": [
            "remote-sensing",
            "modis"
        ],
        "text": "To define relative spectral response, I referred to EFFECT OF RELATIVE SPECTRAL\nRESPONSE ON MULTI-SPECTRAL MEASUREMENTS AND NDVI FROM DIFFERENT REMOTE SENSING SYSTEMS by David James Fleming, 2006.\n\n\n  One factor that is often overlooked is the effect of a sensor\u2019s\n  relative spectral response (RSR), or spectral response function (SRF),\n  on broadband spectral measurements. The RSR describes the quantum\n  efficiency of a sensor at specific wavelengths over the range of a\n  spectral band. Currently, general descriptors, such as bandwidth and\n  average bandpass, are often the only spectral characteristics\n  considered in analysis of sensor spectral measurements. However,\n  cross-sensor wavelength variations in RSR can lead to measurement\n  discrepancies between sensor measurements that make them not directly\n  comparable (Teillet et al., 1997). In order to provide consistent\n  quantitative spectral measurements of vegetation land cover and\n  derived metrics, such as spectral vegetation indices, the effect of a\n  sensor\u2019s SRF must be considered and understood.\n  \n  [...]\n  \n  Spectral bands are often generalized (Pagnutti et al., 2003) in terms\n  of full width at half maximum bandwidth and central wavelength\n  corresponding to the maximum value of the response function (Liang,\n  2004) as shown in Figure 11.\n\n\n\n\nIn view of this, I was a bit surprised that, for example, the bandwidth of MODIS band 7 (dotted line) as defined here, seems to not match with the relative spectral response in the way defined above. \n\n\nIs my understanding of these concepts incorrect?\n To define relative spectral response, I referred to EFFECT OF RELATIVE SPECTRAL\nRESPONSE ON MULTI-SPECTRAL MEASUREMENTS AND NDVI FROM DIFFERENT <span class=\"highlight\">REMOTE</span> <span class=\"highlight\">SENSING</span> SYSTEMS by David James Fleming, 2006. &hellip; "
    },
    {
        "question": "Working with LiDAR data using other than Esri software?",
        "area": [
            "open-source-gis",
            "lidar",
            "software-recommendations"
        ],
        "text": "I develop an open-source GIS called Whitebox Geospatial Analysis Tools that can be used to perform a range of tasks geared towards processing LiDAR data. It works with the popular LAS file format as well as shapefiles. The software can be used to interpolate raster grids, including bare-Earth DEMs and vegetation canopy models. Many of the interpolators are specifically developed to handle LiDAR data. It can also be used to examine LAS metadata, convert LAS files into ASCII or shapefile formats, tile LiDAR data, and assess point density. There are many tools available in Whitebox for analyzing LiDAR interpolated DEM files as well. This includes everything from typical digital terrain analysis operations (slope, aspect, measures of relative landscape position, etc.), hydrological analysis (e.g. extract watersheds and map streams), removal of off-terrain objects, filling in missing data holes, etc. For more information, I have a blog that describes the use of Whitebox for processing LiDAR data here. I teach GIS and remote sensing courses and have used Whitebox in LiDAR labs before. Here is an example (though dated now) lab assignment that you may find useful as well. I&#39;m fairly responsive to requests, so if there are some LiDAR related analysis functions that aren&#39;t currently in there, send me a request and I&#39;ll add it to my To-Do list. One current limitation is that Whitebox doesn&#39;t contain a 3D point cloud viewer. I&#39;m working on this, but if point cloud visualization is your main interest, then at the moment, you&#39;d be better looking at something like plas.io.\n\n\n\nLAS files can now be natively displayed within Whitebox&#39;s map area:\n\n\n\n\n I teach GIS and <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> courses and have used Whitebox in LiDAR labs before. Here is an example (though dated now) lab assignment that you may find useful as well. &hellip; "
    },
    {
        "question": "Automated detection of tracks",
        "area": [
            "qgis",
            "remote-sensing",
            "fme-form",
            "feature-extraction"
        ],
        "text": "Given an area with depressions in open area from; say all terrain vehicles driving on soft surface. The vehicles will cause parallel depressions (paths) of about 10-20 centimeters in depth and around 15-30 cms in width, with lengths varying with the robustness of the surface.\n\n\nWhich remote sensing platforms would be relevant for later analysis? Quickbird, smaller drones, lidar, aerial photography?\nAre there any available procedures in tools (FME/QGIS/ESRI/other)\nwhich can be used to document the paths?\n\n\nLet us for the sake of simplifying this question assume that we positively know that there are no other paths in the area, or that they have been filtered out of the imagery.\n\nFull automation is not necessary, and probably not even possible.\n\nThis is an example of what tracks would look like.\n\n Which <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> platforms would be relevant for later analysis? Quickbird, smaller drones, lidar, aerial photography? &hellip; "
    },
    {
        "question": "Extracting tree crown areas from remote sensing data (visual images and LiDAR)",
        "area": [
            "remote-sensing",
            "lidar",
            "classification",
            "land-cover",
            "image-segmentation"
        ],
        "text": "There is a considerable body of literature on individual crown detection in spectral and lidar data. Methods wise, perhaps start with: \n\nFalkowski, M.J., A.M.S. Smith, P.E. Gessler, A.T. Hudak, L.A. Vierling and J.S. Evans. (2008). The influence of conifer forest canopy cover on the accuracy of two individual tree measurement algorithms using lidar data. Canadian Journal of Remote Sensing 34(2):338-350.  \n\nSmith A.M.S., E.K. Strand, C.M. Steele, D.B. Hann, S.R. Garrity, M.J. Falkowski, J.S. Evans (2008) Production of vegetation spatial-structure maps by per-object analysis of juniper encroachment in multi-temporal aerial photographs. Canadian Journal Remote Sensing 34(2):268-285\n\nIf you are interested in the Wavelet method (Smith et al., 2008), I have it coded in Python but, it is very slow. If you have Matlab experience, this is where it is implemented in production mode. We have two papers where we identified ~6 million acres of juniper encroachment in eastern Oregon using the wavelet method with NAIP RGB-NIR imagery so, it is well proven. \n\nBaruch-Mordo, S., J.S. Evans, J. Severson, J. D. Naugle, J. Kiesecker, J. Maestas, and M.J. Falkowski (2013) Saving sage-grouse from the trees: A proactive solution to reducing a key threat to a candidate species Biological Conservation 167:233-241 \n\nPoznanovic, A.J., M.J. Falkowski, A.L. Maclean, and J.S. Evans (2014) An Accuracy Assessment of Tree Detection Algorithms in Juniper Woodlands. Photogrammetric Engineering &amp; Remote Sensing 80(5):627\u2013637  \n\nThere are some interesting approaches, in general object decomposition, from the applied mathematics state space literature using multiresolution Gaussian processes to decompose object characteristics across scale. I use these types of models to describe multi-scale process in ecological models but it could be adapted to decompose image object characteristics. Fun, but a bit esoteric.    \n\nGramacy, R.B., and H.K.H. Lee (2008) Bayesian treed Gaussian process models with an application to computer modeling. Journal of the American Statistical Association, 103(483):1119\u20131130\n\nKim, H.M., B.K. Mallick, and C.C. Holmes (2005) Analyzing nonstationary spatial data using piecewise Gaussian processes. Journal of the American Statistical Association, 100(470):653\u2013668\n Canadian Journal of <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> 34(2):338-350.  \n\nSmith A.M.S., E.K. Strand, C.M. Steele, D.B. Hann, S.R. Garrity, M.J. Falkowski, J.S. &hellip; Canadian Journal <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> 34(2):268-285\n\nIf you are interested in the Wavelet method (Smith et al., 2008), I have it coded in Python but, it is very slow. &hellip; "
    },
    {
        "question": "Difference between irradiance and radiance, remote sensing reflectance and water leaving radiance",
        "area": [
            "remote-sensing",
            "aerial-photography",
            "reflectance",
            "waterways",
            "hyperspectral-sensor"
        ],
        "text": "I&#39;ve found two sources that appear to provide easy to read explanation between Radiance vs. Irradiance and remote sensing reflectance and water leaving radiance.\nStarting with Radiance vs. Irradiance:\n\nIrradiance is simple: exchange of energy (in the form of photons) across a given area of flat surface per time. Radiance is more complicated: exchange of energy (in the form of photons) across a given area of flat surface per time and then divided by the amount of steradians from which the &quot;given area&quot; is collecting light.\n\nThe author uses two figures to discuss Radiance and Irradiance with respect to Illuminance.\n\n\nAlso, a good reference may be The Light Handbook provides additional information.\nIn terms of remote sensing reflectance and water leaving radiance\nThis comment here\n\nRemote sensing reflectance (Rrs) contains the spectral colour information of the water body (below the sea surface). Rrs is the ratio between water-leaving radiance (Lw, above the sea surface) and downwelling irradiance (Ed, above the sea surface). Lw can be estimated from above-water radiometric measurements, in this case reflected skylight must be removed using a &quot;surface reflectance factor&quot; (rho).\nFurther comment: In ocean colour, often the term &quot;water-leaving reflectance&quot; (rho_w) is used instead of Rrs. The difference is:  rho_w = pi*Rrs (with related change in units)\n\nIllustration of light rays contributing to the irradiance reflectance\n\nIllustration of light rays contributing to the remote-sensing reflectance\n\n Irradiance and <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> reflectance and water leaving radiance.\nStarting with Radiance vs. &hellip; In terms of <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> reflectance and water leaving radiance\nThis comment here\n\n<span class=\"highlight\">Remote</span> <span class=\"highlight\">sensing</span> reflectance (Rrs) contains the spectral colour information of the water body (below the sea surface). &hellip; "
    },
    {
        "question": "Seeking top tier conference in GIScience?",
        "area": [
            "research"
        ],
        "text": "My perspective is skewed toward the U.S., but both the AAG and AGU conferences heavily feature the bread and butter of GIS: spatial analysis, remote sensing, spatial statistics, cartographic methods, geographic demography and others. at AAG in particular it is a minority of sessions that do not feature GIS (the toolkit), and there are dozens of sessions on GIS (the science/perspective).\n\nGIScience publishing for maximum cred is fairly venue-agnostic. Conference papers have a fairly equal value with journal pubs when tenure is being considered.\n My perspective is skewed toward the U.S., but both the AAG and AGU conferences heavily feature the bread and butter of GIS: spatial analysis, <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, spatial statistics, cartographic methods, geographic &hellip; "
    },
    {
        "question": "Is it scientifically correct to pansharpen landsat reflectance product with pan band",
        "area": [
            "remote-sensing",
            "digital-image-processing",
            "landsat-8",
            "pansharpening"
        ],
        "text": "Fundamentally the question here is &quot;what does &#39;scientifically valid&#39; mean&quot;. If you are looking to do spectral modelling on the data, then the answer is possibly different than if you are looking at doing classification / image segmentation. Pansharpening (depending on the method) is simply going to change the range of the values a fairly small amount and shouldn&#39;t put your reflectance values outside the realm of possibility.\n\nAll in all, it depends a lot on what application you are going to be using the data for. Furthermore, the impact of pansharpening may also be worth documenting as a partial side result in whatever study you are performing. The result may be that it doesn&#39;t add anything, except four times as many pixels, meaning four times as long a processing time, which in some cases is a showstopper.\n\nEdit: My database of articles on this topic is not huge, but I have these two where pansharpend data is used (with reasonable results) for image segmentation:\n\nShackelford, A. K., &amp; Davis, C. H. (2003). A combined fuzzy pixel-based and object-based approach for classification of high-resolution multispectral data over urban areas. IEEE Transactions on Geoscience and Remote Sensing, 41(10), 2354\u20132364. http://doi.org/10.1109/TGRS.2003.815972\n\nFern&#225;ndez, I., Aguilar, F. J., Aguilar, M. A., &amp; &#193;lvarez, M. F. (2014). Influence of Data Source and Training Size on Impervious Surface Areas Classification Using VHR Satellite and Aerial Imagery Through an Object-Based Approach. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 7(12), 4681\u20134691.\n IEEE Transactions on Geoscience and <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>, 41(10), 2354\u20132364. http://doi.org/10.1109/TGRS.2003.815972\n\nFern&#225;ndez, I., Aguilar, F. J., Aguilar, M. A., &amp; &#193;lvarez, M. F. (2014). &hellip; IEEE Journal of Selected Topics in Applied Earth Observations and <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>, 7(12), 4681\u20134691. &hellip; "
    },
    {
        "question": "Difference between irradiance and radiance, remote sensing reflectance and water leaving radiance",
        "area": [
            "remote-sensing",
            "aerial-photography",
            "reflectance",
            "waterways",
            "hyperspectral-sensor"
        ],
        "text": "I&#39;ve been trying to lay my hands on textbooks, etc, that explain the differences between the remote sensing terms in lay man language.\n\n\n\nJust wondering if anybody can point me the right direction or shed more light on those terms.\n I&#39;ve been trying to lay my hands on textbooks, etc, that explain the differences between the <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> terms in lay man language. &hellip; radiance and irradiance\n<span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> reflectance and water leaving radiance\n\n\nJust wondering if anybody can point me the right direction or shed more light on those terms. &hellip; "
    },
    {
        "question": "OpenSource Remote Sensing Tools for Classifying Roofs",
        "area": [
            "python",
            "remote-sensing",
            "satellite",
            "envi"
        ],
        "text": "I am afraid satisfying roof detection cannot be achieved with only one single satellite image. You should try to use other sources of information.\n\nThe following article describes a method using a DEM + aerial image pairs + cadastral data:\n\nM. Durupt, F. Taillandier. Automatic Building Reconstruction from a Digital Elevation Model and Cadastral Data: An Operational Approach. International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences. Vol. 36 (Part 3), Bonn, Germany, September 2006.\n\nSee also other papers in the bibliography section (like that one).\n\nI suspect such methods are not implemented in python opensource softwares.\n International Archives of Photogrammetry, <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> and Spatial Information Sciences. Vol. 36 (Part 3), Bonn, Germany, September 2006. &hellip; "
    },
    {
        "question": "Training signature file for supervised classification in ArcGIS Desktop?",
        "area": [
            "arcgis-desktop",
            "arcgis-9.3",
            "classification"
        ],
        "text": "I have tried supervised classification in ArcGIS.\n\nFirstly I would say that it is not the best software for classification.\n\nAs I did it, you can create training sites as points. Just create a shapefile (or geodatabase), add Integer field, click points over your image and assign classes as numbers. (I think you can also use polygon shapefile).\n\n\n\nFor signatures, go to ArcToolbox &gt; Spatial Analyst Tools &gt; Multivariate &gt; Create Signatures. There just put your bands and training points. \n\n\n\nArcGIS doesn&#39;t show you the resulting signature file, however it is ASCII file and you can look inside, for example using Notepad++. For each band you can see something like this:\n\n\n\nIf you wish, you can plot the Means manually to see if they are separated, for example in Excel.\n\nYou can do a dendrogram for your classes Spatial Analyst Tools &gt; Multivariate &gt; Dendrogram.\n\n\n\nThen you do actually classification Multivariate &gt; Maximum Likelihood Classification. There you have only two tunable options: to say, how much uncertain pixels will remain unclassified (rejected), and probability weighting for classes; and request a confidence raster.\n\n\n\nAnd the result looks like this:\n\n\n\nFor theorical information check classification help and signature help.\n\nActually, after several attempts I switched to Remote Sensing software.\n Actually, after several attempts I switched to <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> software. &hellip; "
    },
    {
        "question": "Raster data viewshed analysis with Python",
        "area": [
            "python",
            "analysis",
            "viewshed",
            "jupyter-notebook",
            "raster-dataset"
        ],
        "text": "The easiest way to calculate a visibility raster in python is to call the ad hoc functions of a GIS from your code. This can be done in several ways (non-exhaustive list):\n\nUsing the r.viewshed module from grass\nUsing the visibility module of saga GIS\nUsing the gdal_viewshed function from gdal.\n\nDepending on the tool chosen, the method of calling will be slightly different. You should therefore look at the api documentation to know how to do this in detail. Here are some links that may help to do this:\n\nGrass and Python: https://grasswiki.osgeo.org/wiki/GRASS_and_Python\nSAGA GIS API for Python: http://www.saga-gis.org/saga_api_python/index.html\nPython bidings for gdal_viewshed: https://github.com/jonnyhuck/Viewshed\n\nAn other solution is to write directly an algorithm of visibility. The easiest way to do this is to implement the algorithms that have been used in the tools included in the GIS. For example r.viewshed use an algorithm write by Haverkort, Toma and Zhuan, presented in the documentation and in this research paper :\n\nHaverkort, H.,Toma L. and Zhuang Y. Computing Visibility on Terrains in External Memory. In the Proceedings of the 9th Workshop on Algorithm Engineering and Experiments / Workshop on Analytic Algorithms and Combinatoric. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.4282&amp;rep=rep1&amp;type=pdf.\n\ngdal_viewshed use a Wang, Robinson and White algorithm, presented in this research paper :\n\nWang, Jianjun, Robinson, Gary J., and White, Kevin, Generating Viewsheds without Using Sightlines. Photogrammetric Engineering and Remote Sensing. https://www.asprs.org/wp-content/uploads/pers/2000journal/january/2000_jan_87-90.pdf\n\nYou can also use the Pixscape algorithm, prensented here:\n\nSahraoui, Y, Vuidel, G, Joly, D, Folt&#234;te, J-C. Integrated GIS software for computing landscape visibility metrics. Transactions in GIS. 2018; 22: 1309\u2013 1323. https://doi.org/10.1111/tgis.12457\n\n Photogrammetric Engineering and <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>. https://www.asprs.org/wp-content/uploads/pers/2000journal/january/2000_jan_87-90.pdf\n\nYou can also use the Pixscape algorithm, prensented here:\n\nSahraoui &hellip; "
    },
    {
        "question": "What is the difference between Ground Sampling Distance (GSD) and spatial resolution?",
        "area": [
            "resolution",
            "terminology"
        ],
        "text": "In research papers on remote sensing, I see some authors referring to spatial resolution (expressed as pixel/distance) and others to Ground Sampling Distance (GSD) (also expressed as pixel/distance). Why would you use one over the other, and what is the actual difference between GSD and spatial resolution?\nI found this explanation by Pix4D, but as far as I can tell, GSD and spatial resolution can be used interchangeably.\n In research papers on <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, I see some authors referring to spatial resolution (expressed as pixel/distance) and others to Ground Sampling Distance (GSD) (also expressed as pixel/distance). &hellip; "
    },
    {
        "question": "Is a master&#39;s degree needed for a GIS career?",
        "area": [
            "education",
            "career",
            "belarus"
        ],
        "text": "Pursuing a MS is dependent upon your goals.  If you are interested in conducting scientific research, a MS (or PhD) is for you.  Having a MS opens doors in academia that would not normally exist with a BS.  For example, these are the education requirements for a mid-level research position in academia:  \n\n\n  Master\u2019s degree (or higher) in remote sensing, GIS, oceanography, or\n  related degree including a strong background in statistics,\n  mathematics, computer science, and/or engineering, and 2 years of\n  experience. \n  \n  OR \n  \n  Bachelor\u2019s degree in remote sensing, GIS, or related\n  science degree including a strong background in statistics,\n  mathematics, computer science, and/or engineering, and 5 years of\n  experience.\n\n\nLooking at the government sector, a MS is virtually required these days unless you have significant experience already.  The following are typical qualifications for a mid-level GIS job with the feds:\n\n\n  FOR THE GS-09 LEVEL, in addition to the educational requirements\n  listed above, applicants must have at least one year or twelve (12)\n  months of specialized experience equivalent to grade level GS-07 that\n  demonstrates:  work performing duties such as providing geographic\n  information systems (GIS) training and support with guidance for\n  resource conservation planning and the integration of GIS and planning\n  tools into daily operations; this would include business tools for a\n  variety of disciplines such as engineering, ecological, etc., and\n  other software applications as assigned; provide support with\n  assistance to state, field, and soil survey offices regarding ArcGIS,\n  soil data viewer, and other GIS software;  OR  applicants must have\n  two (2) years of progressively higher level graduate education leading\n  to a master&#39;s degree or master&#39;s or equivalent graduate degree\n  directly related to cartography.   Equivalent combinations of\n  education and experience are qualifying for this grade level.\n\n\nFor a mid-level private sector job (ESRI Support Analyst), the following requirements are nearly industry-wide:\n\n\n  Requirements:\n  \n  \n  Bachelor\u2019s in GIS, a related field, or equivalent work experience    while using GIS as a primary tool\n  \n  \n  Recommended Qualifications:\n  \n  \n  Master\u2019s in GIS, environmental science, geography, or other relevant    field\n  \n\n\nThe bottom line is a MS will jump start your career, provide increased opportunities and almost certainly yield a higher salary.\n For example, these are the education requirements for a mid-level research position in academia:  \n\n\n  Master\u2019s degree (or higher) in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, GIS, oceanography, or\n  related degree including a &hellip; OR \n  \n  Bachelor\u2019s degree in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, GIS, or related\n  science degree including a strong background in statistics,\n  mathematics, computer science, and/or engineering, and 5 years of\n  experience &hellip; "
    },
    {
        "question": "Reprojected MODIS NDVI has range from -32768 to 32767, expected -1 to 1",
        "area": [
            "remote-sensing",
            "modis",
            "envi",
            "ndvi"
        ],
        "text": "I&#39;m new to StackExchange and to remote sensing.  I am working with MOD13Q1 250m 16-day MVCs.  My goal is to use NDVI time-series to classify cropping pattern and crop type, then link this data to water issues and rainfall.  I am working with ENVI 5.1, which is also new to me.  I have used the Modis Reprojeciton Tool to reproject and mosaic two MODIS tiles covering Sri Lanka.  The data has been reprojected into WGS84_UTM_44N.  I output the data as a GeoTiff and have successfully loaded this into ENVI.  \n\nHere&#39;s my question:  the pixels in the reprojected/mosaicked raster for the NDVI band (which is what i will need for the time-series analysis) run from -32768 to 32767, not from -1 to 1.  Is this just some silly misinterpretation on my part, do I need to manipulate the raster somehow with ENVI, or have I distorted the data when reprojecting it?  \n I&#39;m new to StackExchange and to <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>.  I am working with MOD13Q1 250m 16-day MVCs. &hellip; "
    },
    {
        "question": "Why did Esri create .zlas compressed LiDAR files instead of adopting .laz?",
        "area": [
            "lidar",
            "references",
            "file-formats",
            "compression",
            "laz"
        ],
        "text": "I am talking about the Esri Optimized LAS file format for compressed LiDAR files (.zlas).\n\nWhile the uncompressed format (.las) from ASPRS was adopted by practically  the entire Remote Sensing and GIS industries (including Esri) and made interoperability among software/platforms an enormous advantage for LiDAR data users, it seems it did not go the same way for compressed LiDAR files.\n\nIs there any technical documentation (from Esri or third parties) comparing  and rapidlasso&#39;s early format .laz, which shows advantages from  over ?\n\nI am trying to understand why Esri created  instead of adopting the early format  (open source).\n While the uncompressed format (.las) from ASPRS was adopted by practically  the entire <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> and GIS industries (including Esri) and made interoperability among software/platforms an enormous &hellip; "
    },
    {
        "question": "What is the difference between Ground Sampling Distance (GSD) and spatial resolution?",
        "area": [
            "resolution",
            "terminology"
        ],
        "text": "In remote sensing, ground sample distance (GSD) refers to the dimensions of a single pixel in an image as measured on the ground. The calculation of GSD uses the focal length (FL in figure below) and sensor array dimensions, which are properties of the sensor, as well as the distance between the sensor and the ground at the moment of image capture (D in figure below), normally represented by the altitude of an aircraft or orbital distance of a satellite.\nHere is a visual aid to illustrate:\n\nSo when the ground is flat, things are as you described and the distance D is similar across the entire image which means that spatial resolution and GSD are equal across the scene ((&quot;1&quot; above). However, since spatial resolution can be used to describe the dimensions of a pixel relative to any object in focus, consider two other scenarios. First, some objects can stand relatively high above the ground compared to the altitude of a low flying aircraft (&quot;2&quot; above). Second, image footprints can  cover large areas which contain variable surface relief (&quot;3&quot; above). In both of these scenarios, the spatial resolution of objects across the image would deviate from the correctly calculated GSD in such a way that objects closer to the sensor than the ground are more resolute, and those farther away are less resolute.\nSo in short, Spatial resolution refers to the size of the pixels in an image with respect to some real world object in focus, and GSD is a standardized metric used to describe the spatial resolution of remotely sensed imagery on the ground, while image resolution without georeferencing typically refers to solely to the number of pixels in the sensor array, which is the product of the height and width and usually expressed in megapixels (i.e., 8192 &#215; 5460 = ~45MP). The former two describe the size of the smallest detectable features within a particular image, while the latter describes the level of detail recorded by a particular sensor configuration.\n In <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, ground sample distance (GSD) refers to the dimensions of a single pixel in an image as measured on the ground. &hellip; "
    },
    {
        "question": "GIS Software Choice for a small university research centre",
        "area": [
            "spatial-database",
            "software-recommendations"
        ],
        "text": "Desktop\n\nFor many users, GIS means ESRI ArcGIS.  While expensive in a commercial setting, they have rather generous educational licensing, including the provision of free copies to educators for distribution to students, one per licensed seat per year.  I would advise at least ticking this box; I don&#39;t think people who learned GIS in other ways are less capable, but they might be less employable given the keyword-filtering resumes go through these days.  The extensions to ArcGIS range from basic things that should be integrated into the main application to the amusingly archaic to essential tools for a certain niche.\n\nThe OSGeo stack is an obvious addition to this, but I don&#39;t think it&#39;s yet capable of being a full replacement in desktop GIS, at least not with the usability of Arc.  Due to constant complaining about ESRI&#39;s annoyances, I tried to replace it for an entire summer with mostly QGIS, and failed.  QGIS w/ plugins + GRASS + POSTGIS can be hacked around to achieve a lot of GIS functionality, I can believe that, but for learning GIS rapidly, I wouldn&#39;t recommend it.  There are a lot of different projects under the OSGeo heading, though - in all likelihood you&#39;ll find use for some of them even if you don&#39;t touch the desktop functionality.\n\nI&#39;m always seeing MapInfo installations mentioned, but the one I used wasn&#39;t really mature / feature-ful in the same sense ArcGIS has been.  The user interface was lacking, so perhaps it just hid the functionality from me.\n\nManifold has been highly regarded as an ArcGIS competitor that is at once commercially affordable, comprehensive, and extensively higher-performance than the sometimes antiquated ArcGIS code.  They seem to be dragging their feet on updates &amp; bug-fixes in the last few years, though.  At the least, if ArcGIS fails to operate on extreme datasets, try this.\n\nRS\n\nRemote sensing software is its own niche, with lots of features that aren&#39;t present in the ESRI stack.  I&#39;ve been exposed to ERDAS, and heard about ENVI and PCI.  Those three constitute a majority share, but I&#39;m aware that there are a decent number of options out there, some open source (I&#39;ve heard good things about Opticks).  In my own research area, 3D remote sensing is rapidly becoming a thing, as well - LIDAR and automated photogrammetry would be short topics in any RS course I&#39;d teach.  See: Meshlab, VSFM, &amp; Photoscan.\n\nCarto\n\nFor static-map cartography, you&#39;ll ideally want Adobe Illustrator, but there are several less expensive commercial choices that may suffice.  My experience with Inkscape is a lot like my experience with QGIS - almost there, but missing crucial features like an effective layer dialog.\n\nScripting\n\nIn the field of data manipulation, you&#39;ll definitely want to look at a thorough exploration of Python w/ LabPy.  It&#39;s too versatile not to teach as a general tool at this point, there&#39;s the added inducement of ArcPy, and RPy adds the capability to use basically every statistical algorithm in the world.  In addition, very big datasets are typically more amenable to a scripting environment than desktop GIS.\n\nCAD\n\nCAD &amp; CAD-like GIS software, often used for surveyors / engineers, has a broad number of options led by Autocad which I&#39;m not qualified to compare, but may not be necessary for a pure GIS program.\n\nClient - Server\n\nHosting client-server stacks, which becomes important for some classes of GIS user, is the last niche I&#39;m going to mention, but the requirements here are so varied as to make comparison difficult.  Other than ArcSDE, The software here is often free, but the server setup and sysadmin to use it is not.\n\nEDIT: I&#39;ve had the opportunity to revisit QGIS recently and it does seem to have considerably improved, going from 1.5 -&gt; 1.8, in stability &amp; features.\n RS\n\n<span class=\"highlight\">Remote</span> <span class=\"highlight\">sensing</span> software is its own niche, with lots of features that aren&#39;t present in the ESRI stack.  I&#39;ve been exposed to ERDAS, and heard about ENVI and PCI. &hellip; In my own research area, 3D <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> is rapidly becoming a thing, as well - LIDAR and automated photogrammetry would be short topics in any RS course I&#39;d teach. &hellip; "
    },
    {
        "question": "Examples of GIS or Remote Sensing in movies",
        "area": [
            "gps",
            "remote-sensing",
            "aerial-photography"
        ],
        "text": "Looking for examples where GIS or RS has been a part of a movie plot. I&#39;m trying to put together a &quot;GIS &amp; RS and the Cinema&quot; class, in which examples of GIS &amp; RS are shown. Those examples will then be used a jumping off point for discussion around either the truth or utter wrongness of the GIS technique or RS data being shown. \n\nMy best example right now is VOLCANO, where Anne Heche drives a jeep around LA (without any traffic!!!) monitoring lava flows - in 1997! Clearly there are a few issues here which would be a great start to a discussion about GIS and emergency management and other technical aspects. \n\nMy other example is any, ANY, movie where a grainy satellite image is shown, and person in charge demands that it be &quot;ENHANCED!&quot;. Magically, the satellite is capable of zooming in and staying in one spot to see some new detail or event happen. \n\nWhat other examples of movies that involve some plot around Satellite Imagery, GPS, Aerial Photos, or GIS are there?\n Looking for examples where GIS or RS has been a part of a movie plot. I&#39;m trying to put together a &quot;GIS &amp; RS and the Cinema&quot; class, in which examples of GIS &amp; RS are shown. Those examples will then be &hellip; "
    },
    {
        "question": "Editing LiDAR point cloud to remove noise/outliers present below and above ground?",
        "area": [
            "lidar",
            "delete",
            "point-cloud",
            "noise",
            "outlier"
        ],
        "text": "You seem to have outliers: \n\n\ni) below the ground surface; \nii) above the ground surface and vertically among other above ground real features; \niii) above ground points with height greater than all objects of interest, for example the ones caused by clouds or birds (this is not shown in the picture, but I am assuming it might also be the case).\n\n\nFor &#39;i&#39;, the option is to use a ground filter algorithm that can take into account &#39;negative blunders&#39; to get a clean LiDAR ground point cloud. See the Multiscale Curvature Classification (MCC) algorithm from Evans and Hudak (2007). It is said on page 4:\n\n\n  Negative blunders are a common occurrence in LiDAR data, which may be caused by the scattering of the photons in a returned laser pulse. Scattering lengthens the time for an emitted laser pulse to return to the aircraft sensor, inflating the calculation of distance traveled, hence causing a measurement\n  error where the surface elevation is erroneously recorded as being below the surrounding measurements. It should be noted that curvature classification approaches can potentially remove valid returns surrounding negative blunders, which can expand the edge artifact around a negative blunder to create a\n  distinct \u201cbomb crater\u201d effect. To address negative blunders, Haugerud and Harding suggested setting the curvature tolerance parameter to four times the interpolated cell size and selecting returns exceeding this negative curvature threshold. However, it should be noted that under certain circumstances, returns that appear to be negative blunders can be in fact valid\n  returns (e.g., sinkholes). Therefore, the preceding suggestion to remove potential negative blunders can be implemented as an optional last model loop to employ at the discretion of the user if needed.\n\n\nBelow there is a post with an example about using MCC-LIDAR:\n\n\nDetermining bare earth DEM from unclassified LAS file?\n\n\nOnce you have an accurate LiDAR ground point cloud to make an accurate DEM, it is possible to normalize the point cloud, and exclude points which are beneath the DEM surface (the ones with negative values). Using the same approach, it is also possible to address point number &#39;iii&#39; removing points above some fixed threshold. See, for example:\n\n\nDeleting anomalous points in *.lasd using ArcGIS for Desktop?\n\n\nThen, it leaves us with &#39;ii&#39;, which is addressed by AlecZ&#39;s answer recommending  from LAStools. It will also handle &#39;iii&#39;, and perhaps part of &#39;i&#39; as well (LAStools requires a license though). Other tools specifically created for checking/removing outliers were cited here: PDAL&#39;s  tool in Charlie Parr&#39;s answer which has a detailed explanation about how the tool works, and with the advantage PDAL is a free software.\n\nThen, what is left from the automated process (if any outlier) can be removed manually. For example:\n\n\n(LAStools; ArcGIS Pro) Cleaning LiDAR points that classification algorithm misses?\n(QT Modeler) --&gt; auslander&#39;s answer).\n\n\n\n\nEvans, Jeffrey S.; Hudak, Andrew T.  2007.  A multiscale curvature algorithm for classifying discrete return LiDAR in forested environments.   IEEE Transactions on Geoscience and Remote Sensing. 45(4): 1029-1038.  \n IEEE Transactions on Geoscience and <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>. 45(4): 1029-1038. &hellip; "
    },
    {
        "question": "Are there Python packages for Landsat 8 processing?",
        "area": [
            "python",
            "remote-sensing",
            "landsat",
            "landsat-8",
            "pymodis"
        ],
        "text": "I just thought I&#39;d add that there are some &#39;pure&#39; Python solutions for several nodes in this workflow, also. \n\nSome file reading and basic processing:\n\nSpectral Python: http://spectralpython.sourceforge.net/\n\nMore classification than you&#39;ll find in pure remote sensing and GIS packages:\n\nhttp://scikit-learn.org/stable/\n\nMore links I can&#39;t share:\n6S Python atmospheric correction, Shapely, gdal bindings for reading geoTIFF (relatively trivial to parse metadata from Landsat 8 and read all images into a cube). There are other processing options in SciPy general and MDP (modular data processing, too).\n Some file reading and basic processing:\n\nSpectral Python: http://spectralpython.sourceforge.net/\n\nMore classification than you&#39;ll find in pure <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> and GIS packages:\n\nhttp://scikit-learn.org/ &hellip; "
    },
    {
        "question": "Is PhD in GIS useful in non-educational career path?",
        "area": [
            "career"
        ],
        "text": "If you like GIS and want to go through the effort of getting an advanced degree - get a degree in something halfway definable like biology, hydrology, geology, env. engineering, epidemiology, public health, forestry, env. chemistry, transportation, economics, agriculture. Take these fields to new areas by using GIS. That said, if you just want a PhD, it&#39;s an easy way to go according to a former colleague.\n\nHope I don&#39;t offend anyone here, but in many ways GIS and geography is just a catch all for things having a spatial component. If you must study GIS, at least include a lot of stats and imagery and remote sensing where you can do some real science.\n\nWhat&#39;s really lacking in a lot of consultancy involving GIS is the &quot;IS&quot; part of GIS. Help us out and get a computer science degree. Understand databases, programming, security, networks, scalability, project management, helping integrate GIS into an organization is incredibly tech centric with a large helping of people skills.\n If you must study GIS, at least include a lot of stats and imagery and <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> where you can do some real science. &hellip; "
    },
    {
        "question": "Creating a Time series NDVI map",
        "area": [
            "arcgis-10.1",
            "time",
            "envi",
            "erdas-imagine",
            "ndvi"
        ],
        "text": "When remote sensing vegetation, the time of year is very important. In most climates, vegetation has significantly more biomass (i.e., leaves etc.) during the summer, which means that it is easier for the sensor to discern the health of vegetation at that time of year. Two NDVI images of the same location from different times of the year may look different because they were taken at different points of the plants&#39; growing cycles. For this reason, and because of differences in illumination, it is advisable to use images from the same time of year when developing a multi-year time series.\n\nTo answer your question, the image above seems to do this. All of the images are taken during the summer over a number of years. When developing your time series, you should pick a time of year that you have good data for (ideally near the peak of plant growth) and then create single NDVI images of that date for each year from 2002 to 2013. When developing your final product, you can put the images side by side like the image above. You do not create an NDVI for each month and then create a composite of them. For the aforementioned reasons, the images from each month of the year would look very different and a composite wouldn&#39;t be effective to achieve what you want.\n\nThe values outputted by NDVI indicate the relative health and abundance of the vegetation by comparing reflectance values in the red and near infrared bands. The maps above seems to be indicating that the health and abundance of vegetation in Mongolia increased between 1989 and 2001. The individual maps do not indicate change in plant growth over time; only collectively do they show how plant growth has changed over time.\n When <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> vegetation, the time of year is very important. &hellip; "
    },
    {
        "question": "Is there an easier way to edit polygons in ArcMap?",
        "area": [
            "arcgis-10.0",
            "arcmap",
            "polygon",
            "editing"
        ],
        "text": "Instead of moving individual vertices for a feature you can use the Reshape Feature tool on the Editor toolbar.\n\nDepending on how accurate your polygons need to be you could also leverage remote sensing algorithms to automate polygon creation against aerial imagery that has 4 bands (fourth band that is NIR) or LAS lidar data sets, see:\n\nLand Cover Feature Extraction from Satellite Imagery\n Depending on how accurate your polygons need to be you could also leverage <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> algorithms to automate polygon creation against aerial imagery that has 4 bands (fourth band that is NIR) or LAS &hellip; "
    },
    {
        "question": "what&#39;s the difference between spectral signature and features in remote sensing?",
        "area": [
            "features",
            "remote-sensing",
            "classification"
        ],
        "text": "I would like to understand if is there any difference or relation between spectral signature concept and features in remote sensing?\n I would like to understand if is there any difference or relation between spectral signature concept and features in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>? &hellip; "
    },
    {
        "question": "Remote sensing for Nepal Earthquake",
        "area": [
            "remote-sensing",
            "emergency-services",
            "sentinel-1",
            "natural-disaster",
            "nepal"
        ],
        "text": "To any experts who can provide remote sensing data that can help assess impact and damage of nepal earthquake we really need your help to ensure aid is well targeted.\n\nExisting data so far is here\n\nIf you can supplement with for example sentinel-1 SAR data, building damage, population densities etc. This could be very useful\n\nPlease add relevant dataset in well labelled formats that are accessible and understandable to non gis experts to the humanitarian data exchange and or other networks you known.\n\nPlease explain any uncertainties and document clearly.\n To any experts who can provide <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> data that can help assess impact and damage of nepal earthquake we really need your help to ensure aid is well targeted. &hellip; "
    },
    {
        "question": "Remote Sensing Landsat Surface Reflectance and Albedo",
        "area": [
            "remote-sensing",
            "landsat"
        ],
        "text": "I&#39;m pretty green when it comes to RS and I&#39;m doing this school project that I need help with. The project is to measure albedo changes for the tongue of a glacier and I&#39;m using R programming to do it. So I got my data from earth explorer and went for the surface reflectance product in order to save some steps. However, the values for these cells are higher than expected, around 2000 depending on the band. I say higher because when I use a weighted average formula for calculating albedo, which I found in some papers cited below, the outcome gives me cell values of around 1000, not the 0 to 1 I would expect for and albedo. The paper mentions its using a surface reflectance as well for this formula. \n\nMy question is, is this formula wrong? Albedo = 0.493Band2 + 0.203 Band + 0.150 Band5 + 0.154Band\n\nOr does some other processing need to be done to my Earth Explorer Surface Reflectance Product. https://landsat.usgs.gov/landsat-surface-reflectance-high-level-data-products\n\nAlso I&#39;m using Landsat 4-7 images. \n\nsources:\n\n\n  Pimentel, Rafael, et al. &quot;Comparison between Snow Albedo Obtained from\n  Landsat TM, ETM+ Imagery and the SPOT VEGETATION Albedo Product in a\n  Mediterranean Mountainous Site.&quot; Hydrology 3.1 (2016): 10.\n\n\nAlso, this is really similar but uses TOA instead of surface reflectance:\nhttp://yceo.yale.edu/how-convert-landsat-dns-albedo\n I&#39;m pretty green when it comes to RS and I&#39;m doing this school project that I need help with. The project is to measure albedo changes for the tongue of a glacier and I&#39;m using R programming to do it. &hellip; "
    },
    {
        "question": "What does ArcGIS have that QGIS doesn&#39;t?",
        "area": [
            "qgis",
            "arcgis-desktop"
        ],
        "text": "ArcGIS has certain benefits and advantages if you are running an organization, or if you&#39;re part of a local government, through its Enterprise applications (ArcCollector for iPad, for example). However, it is proprietary and costs a lot of money. If you&#39;re an individual GIS/Mapmaker, QGIS is the way to go.\n\nQGIS is free and covers most of what ArcGIS can do through various plugin contributors. Need to do something in QGIS that isn&#39;t part of the standard interface? There&#39;s probably a plugin for it. \n\nQGIS can also be finnicky at times (certain plugins not working, or not working as well as you might like), and new versions come out far more frequently than versions of ArcGIS, meaning staying up to date on your versions. I don&#39;t mind that, personally. It&#39;s enjoyable to be a part of an Open Source community, while at the same time, being able to accomplish pretty much any GIS or Remote Sensing need I have.\n\nAlso, to be more specific to your question, Land Cover Classification tools in ArcGIS are much more sophisticated than they are in QGIS. If I had to work with satellite imagery in ArcGIS or QGIS, it would definitely be the former. ArcGIS also allows Time-Series mapping, which, as far as I know, isn&#39;t available in QGIS.\n It&#39;s enjoyable to be a part of an Open Source community, while at the same time, being able to accomplish pretty much any GIS or <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> need I have. &hellip; "
    },
    {
        "question": "What is difference between GeoTIFF and Esri ASCII grid file formats for SRTM data?",
        "area": [
            "arcgis-desktop",
            "geotiff-tiff",
            "srtm",
            "esri-ascii-raster"
        ],
        "text": "In a nutshell, the ESRI ASCII grid format is human-readable and is text. This means you can open it in a text editor and see the actual values for yourself without needing specialized software. TIFFs are binary and are therefore not human-readable. You&#39;d need some specialized software like GIS to read it. TIFFs are supported by almost all GIS packages though. SRTM images are available for download in those two formats due to their ease of use of use and widespread support in most GIS and Remote Sensing software applications. The two files should contain the same information.\n SRTM images are available for download in those two formats due to their ease of use of use and widespread support in most GIS and <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> software applications. &hellip; "
    },
    {
        "question": "Opening MOD17A3 in ENVI so it is properly georeferenced?",
        "area": [
            "georeferencing",
            "modis",
            "envi",
            "hdf"
        ],
        "text": "I am using ENVI 5.1 on Windows 8. I am trying to open a MOD17A3 (MODIS Net Primary Productivity standard product - L4) .hdf file which I downloaded from the USGS website. I am still a beginner at ENVI, IDL, Remote Sensing, and GIS. \n\nMy problem is when I try to use the ENVI GUI and open the file. \n\nWhen I open the .hdf file as a EOS&gt;MODIS file, it appears properly georeferenced when overlaid with other vector layer that I am using, BUT it does not show the data for each pixel. What I mean is, the shapes of the landmasses are present, but they are all in black, not showing any NPP data which should have made the pixels appear in varying shades of grey.\n\nWhen I open the .hdf file as Generic Format&gt;HDF4, ENVI asks me to select which datasets in the .hdf file I should open, and I select NPP. The values of each pixel are displayed, such that they appear in varying shades of grey, BUT they don&#39;t seem to be properly georeferenced since they don&#39;t align with other georeferenced layers. The map has shrunk, but is in the same general location as the other layers.\n\nIt might be possible to use the IDL controls to solve this problem but I wouldn&#39;t have any idea where to start.\n I am still a beginner at ENVI, IDL, <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>, and GIS. \n\nMy problem is when I try to use the ENVI GUI and open the file. &hellip; "
    },
    {
        "question": "Preferred programming language and software for entire remote sensing workflow?",
        "area": [
            "open-source-gis",
            "remote-sensing",
            "geoprocessing"
        ],
        "text": "I have been involved in remote sensing for some years now during studies.  I am wondering which combination of software and image processing modules would be most suitable for an entire process chain for professional image processing solutions and products. I am very curious about what other users think and perhaps it will even lead into an interesting discussion from experienced users.\n\nWhat I mean in detail is the combination of:\n\n\na database storing geographical data like shapefiles but especially huge amounts of satellite imagery with its corresponding metadata \nimage processing modules automatically using appropriate data from the database useful for the chosen processing step (e.g. all satellite data with at least a certain spatial resolution for a given time span and geographic area to produce change detection maps)\nthe results then should be integrated into the database and perhaps even be available for distribution via a web server\n\n\nUnfortunately I do not have any advanced knowledge on databases for geographic data. Perhaps GeoNetwork/GeoServer with PostGIS would be an option?\n\nFor the image processing modules I thought of either implementing necessary algorithms in C++/GDAL or JAVA/Geotools. Also there would need to be some kind of module connecting to the database in order to fetch the needed data for processing and the creation of metadata for the processed images/products. My thoughts were that generally open source solutions would be best as such a system would be developed for a long run and being independent of commercial companies would be desired.\n I have been involved in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> for some years now during studies. &hellip; "
    },
    {
        "question": "Pixel-based and object-based classification!",
        "area": [
            "remote-sensing",
            "classification",
            "land-classification",
            "random-forest",
            "land-use"
        ],
        "text": "Classification algorithms such as Maximum Liklihood, random forests, and SVM are statistical methods for grouping data.  These data may be words, colors, sounds or anything you can imagine.  In a remote sensing context, these algorithms are used to group pixels or image objects (segments) based on statistical properties, or spectral profiles.  \n\nTo answer the first part of your question, all three of these algorithms can be used to classify image objects (e.g. segments created in Matlab or eCognition).  Since these image objects, or segments, are essentially created by drawing a line around statistically similar groups of pixels, these segments can be classified into further classes too (e.g. forest, grassland, etc) if you create a set of rules or statistical properties deciding which objects are grouped together.\n\nFor the second part of the question, all three of these algorithms can also be used as pixel-based classifiers.  The same principle holds true for classifying pixels as it does image objects or segments; the specific algorithm determines how the pixels are grouped together based on a given set of statistical rules.\n\nFrom a software point of view, you can implement these classification algorithms at the pixel level or the image object level in software such as eCognition.  You can also implement an object-based classification on image objects, or a pixel-based classification within image objects.  \n In a <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> context, these algorithms are used to group pixels or image objects (segments) based on statistical properties, or spectral profiles. &hellip; "
    },
    {
        "question": "How to easily identify/classify coniferous forest from one date Landsat image?",
        "area": [
            "remote-sensing",
            "classification",
            "landsat",
            "land-cover",
            "forest-ecology"
        ],
        "text": "I am pretty new in remote sensing and I am trying to identify/classify coniferous forest cover from single date Landsat scene. According to my preliminary web research I have these possibilities:\n\n\nconvert scene to NDVI values. Using modal values of NDVI histogram, I can separate scene pixels into forested and non-forested area \nuse modal value of band 2,3 and 5 (B2) to identify &quot;forest peak&quot; and class scene to forest/non-forest (Huang, 2008: Use of a dark object concept and support vector machines to automate forest cover change analysis). Other scenes characteristics (rocks, rivers) have to be removed using Tasseled cap brightness values\n\n\nDo you know another simple approach to classify forest cover in mountainous area? I dont really want to apply maximum likelihood classification. Maybe it is better to used unsupervised classification?\n\nI am using ERDAS, ArcGIS 10.2 and R\n I am pretty new in <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> and I am trying to identify/classify coniferous forest cover from single date Landsat scene. &hellip; "
    },
    {
        "question": "Seeking free elevation data for Europe?",
        "area": [
            "data",
            "elevation",
            "europe"
        ],
        "text": "In 2016, the Japan Aerospace Exploration Agency (JAXA) released a new free 30 m (1 arcsec) resolution global topographic data set called ALOS Global Digital Surface Model &quot;ALOS World 3D - 30m&quot; (AW3D30) (http://www.eorc.jaxa.jp/ALOS/en/aw3d30/). It is stated as having a 5 m height accuracy and has been compiled from images taken with the Advanced Land Observing Satellite (ALOS). There are indications that the product has been derived from an even higher resolution data set; there is a 15 m resolution DEM for Japan. The coverage spans 82&#176;N to 82&#176;S. There are some voids in the current data that can be readily filled using other data sets such as SRTM. Like the SRTM data set, these data are described as a digital surface model since the heights of off-terrain objects (vegetation, buildings, etc) are included. The following is an example of an AW3D30 DEM of the Canadian Province of New Brunswick.\n\n\n\nReferences\n\nJ. Takaku, T. Tadono, K. Tsutsui : Generation of High Resolution Global DSM from ALOS PRISM, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, pp.243-248, Vol. XL-4, ISPRS TC IV Symposium, Suzhou, China, 2014. \n\nT. Tadono, H. Ishida, F. Oda, S. Naito, K. Minakawa, H. Iwamoto : Precise Global DEM Generation By ALOS PRISM, ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, pp.71-76, Vol.II-4, 2014. \n Tsutsui : Generation of High Resolution Global DSM from ALOS PRISM, The International Archives of the Photogrammetry, <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> and Spatial Information Sciences, pp.243-248, Vol. &hellip; Iwamoto : Precise Global DEM Generation By ALOS PRISM, ISPRS Annals of the Photogrammetry, <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> and Spatial Information Sciences, pp.71-76, Vol.II-4, 2014. &hellip; "
    },
    {
        "question": "Maps zoomed around specific locations (magnifying glass effect)",
        "area": [
            "web-mapping",
            "scale"
        ],
        "text": "How do I create a static map where the scale varies based on location? \n\nExample: to drive from a specific location X in Albuquerque to a \nspecific location Y in Chicago, I want to &quot;zoom&quot; around X and Y as follows: \n\n\nNear X and Y, the scale is fairly large, so you can see minor \nstreets, buildings, etc, near X and Y. \nFar away from both X and Y, the scale is fairly small, so you might \njust see long lengths of highway, but no details. \n\n\nIn other words, it&#39;s like a regular map with a &quot;magnifying glass \neffect&quot; around X and Y. The effect should &quot;fade off&quot; smoothly, so \nthere isn&#39;t a break in the map. \n\nReasoning: when traveling between remote cities, the highway travel is \noften easy (in the sense it doesn&#39;t require details), but getting from \nX to the highway and from the highway to Y can require detailed \ninstructions, knowing minor streets, etc. \n\nEDIT: I&#39;ve attached a horrible example of what I want to do. Notes:\n\n\nThis only zooms in on one city, not two.\nThis is just plain old image zoom. What I would want is more detail in the Albuquerque area.\nNotice, however, that the roads/highways are continuous: the magnifying does not have a &quot;cutoff&quot; problem.\n\n\n\n Reasoning: when traveling between <span class=\"highlight\">remote</span> cities, the highway travel is \noften easy (in the <span class=\"highlight\">sense</span> it doesn&#39;t require details), but getting from \nX to the highway and from the highway to Y can require detailed &hellip; "
    },
    {
        "question": "Why does Landsat 8 panchromatic band NOT include the infrared?",
        "area": [
            "remote-sensing",
            "landsat-8",
            "landsat-7"
        ],
        "text": "Forgive me if this is too basic an answer: panchromatic and infrared are mutually exclusive.\n\nPanchromatic means all visible light, which is generally considered to range 0.4\u03bcm to 0.7\u03bcm in wavelength.\n\nNear (or reflected) infrared energy is generally considered to range 0.7\u03bcm to 0.9\u03bcm in wavelength, just beyond visible.\n\nSee Infrared vs. Panchromatic - Mt. Reynolds, for example.\n\nOne might ask instead why the panchromatic band on Landsat 7 included near infrared.\n\nDesigners of remote sensing scanners have specific spectral windows in mind for each band. Someone else more au fait or more au courant (much more knowledgeable than me) should provide detailed reasons.\n Designers of <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> scanners have specific spectral windows in mind for each band. &hellip; "
    },
    {
        "question": "GIS Certification",
        "area": [
            "education",
            "certification"
        ],
        "text": "Personally think that for development work, there&#39;s not too much a programmer can get from a GIS course, unless the course is run specifically for Computer Science students (which is rare). My learning (coming from a similar background to yours with lesser experience at the time) after enrolling in a Master&#39;s course was applied physics, spatial/locational modelling and statistical theory used in Remote Sensing amd Urban planning. It was all very interesting then, but I haven&#39;t used it since. Most of the work in GIS I have done has been standard IT work with basic GIS data model concepts involved. However, one of the biggest benifits of doing a Master&#39;s for me was learning how to write and present better and more confidently, which is a transferrable skill.\n\nQuestions you might want to ask yourself :\nDo you prefer open-source development or would you rather work with vendors such ESRI/Manifold/MapInfo etc.?\n\n\n  My personal choice for programming was\n  open source tools and I picked up GIS\n  specific Java tools such as\n  JTS/GeoTools etc on my own and more\n  recently GeoServer/gdal.\n\n\nDo you prefer Desktop or web? \n\n\n  web development jobs are harder to\n  find and the user base can be hard to\n  please as they are used to highly\n  interactive desktop apps\n\n\nWhat field would you like to work in - government, military, environment?\n\n\n  By far the biggest advantages of a GIS\n  career is opens up avenues into\n  fields you might not have considered\n  or had access to with just an IT background\n\n\nHope this helps \n\nsfk\n learning (coming from a similar background to yours with lesser experience at the time) after enrolling in a Master&#39;s course was applied physics, spatial/locational modelling and statistical theory used in <span class=\"highlight\">Remote</span> &hellip; <span class=\"highlight\">Sensing</span> amd Urban planning. &hellip; "
    },
    {
        "question": "Why can&#39;t lines plotted on google maps suffice for legal determination of property boundaries?",
        "area": [
            "google-maps",
            "land-survey"
        ],
        "text": "I&#39;m no lawyer, but i am 99% sure the very short answer to your question is &quot;no&quot;.\n\nThe legally admissible boundaries are recorded in the cadastral record which you can obtained from city hall. That record is generated by surveyors who do the similar process to what you describe (start at an origin, draw lines at certain angles etc) but with real life measurements. \n\nAny software generated boundaries will be prone to different types of errors which will make them inadmissible. Courts like dealing in absolutes. There exists a reliable method of doing this, and its how they generate the  cadastral record.\nEven with highly accurate lidar or remote sensing images, when it comes time to plot out the property in real life, the process requires professional surveyors who will then sign off on the results.  \n\n\n  Is there some way to estimate the maximum error in real world distances of such lines as shown on the map from their actual location?\n\n\nYou would have to draw the polygon in your software, get some coordinates from the software (the corners of the lot for example), and then go to the property and measure the real boundaries with a high accuracy GPS device ($$$) and then compare the two sets of readings. Doing this for one property would give you an idea of the margin of error of the process, doing it for multiple properties will help you dial in the margin of error. That would be the process you are asking about in this above quote... but it still wont be admissible.\n\nYou could compare those results to the cadastral files to guage the margin of error, but once you have the cadastral file i&#39;m not sure i see the point of making another record/file. \n\nthe context might greatly change what is admissible. Trying to move a boundary between two houses is very different than say, trying to estimate the surface area of a very large property. \n Even with highly accurate lidar or <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> images, when it comes time to plot out the property in real life, the process requires professional surveyors who will then sign off on the results. &hellip; "
    },
    {
        "question": "Creating a 3D voxel plot with LAD values in lidR",
        "area": [
            "r",
            "lidr"
        ],
        "text": "Your question is closely related to this one: Apply a function to a catalog. It is the exact same issue.\nThere are several confusion in your example. You tried to use the &quot;metrics syntax&quot; in a wrong way. When defining a &quot;metric&quot; function the input should be some attributes of a LAS object and the output must be a number or a  of numbers.\n\nIs a valid statement (you can write ) but the output is not a number. The output is a  is thus it is not a metrics and it cannot be used in  functions.\n has been designed from Bouvier et al. (2015). If you read the paper the metric used was the coefficient of variation of the LAD above 2m (if I remember well).\n\nmight be a valid metric. The following works (notice the use of uppercase . This is an attribute of the  object):\n\nHowever it makes sense at the pixel level but it does not really make sense at the voxel level\n\nwon&#39;t crash because the computation is valid and works but the numbers won&#39;t really have a valid meaning in my opnion (edit: it returns NA everywhere actually).\nIn your case you wrote:\n\nThis did not failed because R is very permissive but what it actually does is the computation of the same  from the whole point cloud as many times as the number of voxel. All the  were ed.\n\nBouvier, M., Durrieu, S., Fournier, R. a, &amp; Renaud, J. (2015). Generalizing predictive models of forest inventory attributes using an area-based approach with airborne las data. Remote Sensing of Environment, 156, 322-334. http://doi.org/10.1016/j.rse.2014.10.004\n at the pixel level but it does not really make <span class=\"highlight\">sense</span> at the voxel level\nvoxelsLAD = voxel_metrics(las, ~as.numeric(cv(LAD(Z, dz = 1, k= 0.5)$lad)), 5)\n\nwon&#39;t crash because the computation is valid and &hellip; <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> of Environment, 156, 322-334. http://doi.org/10.1016/j.rse.2014.10.004 &hellip; "
    },
    {
        "question": "Calculating relative share of an area of circle that has slope &gt;15% in Germany",
        "area": [
            "qgis",
            "arcgis-desktop",
            "dem",
            "area",
            "slope"
        ],
        "text": "Doing this kind of processing is pretty straight-forward, but there are some tricks along the way that will determine how accurate your analysis will be. Your data will be generated from a slope raster of the area, and you usually have to build it yourself. The easiest way is to use a DEM raster to calculate the slope, so you should start with that.\n\nStep 1: Acquire the DEM\n\nYou can get DEMs for free from pretty much the entire world, and from many sources, depending on the area. But said you need a 90m&#178; resolution DEM, that&#39;s about a 9.5m pixel, which is pretty high where DEMs are concerned, and not readily available for free.\n\nYou said you were using ArcGIS Online&#39;s DEMs. Looking through their documentation, it appears they did a mosaic of DEMs ranging from 2m to 900m spatial resolution, you&#39;ll have to see if the cities you&#39;re working with are below the 10m range. Geospatial companies like Airbus and DigitalGlobe can generate a custom DEM for you, though a 9m res of 50km radius of 15 cities could be pretty expensive, you&#39;ll have to check with them.\n\nBut most of all, you have to ponder if you really need this resolution. Are you doing a precision work, or just a viability study? Because there are plenty of freely available DEMs within the 30m resolution, most famously the SRTM, that could fit on a broader study.\n\nIf you really need a 90m&#178; pixel, then another problem arises. There are two types of DEMs - the Terrain DEM, which covers only ground elevation, and the Surface DEM, which also covers tree tops, buildings, etc. You generally want a terrain DEM, smaller resolutions it matters less; on a &lt; 10m resolution DEM, however, it&#39;s a must, and DTMs (as they are known) are harder to generate and to come by. It&#39;s almost a certain that any freely available DEM will be surface.\n\nStep 2: Generating the slope\n\nWith your DEM in hand, you&#39;ll create the slope raster. Both ArcGIS and QGIS can do this, as well as any other good GIS or remote sensing software. But first, you need to know what Spatial Reference System your DEM raster is in. There are two types of SRS - geographic and projected. Geographic ones have coordinates in degrees (usually latitude and longitude), whereas projected ones have planar coordinates (usually meters).\n\nSince your elevation data is likely in meters, you need to make sure your coordinates are as well. If they&#39;re not, you&#39;ll need to convert (some softwares do that automatically whilst calculating the slope, but don&#39;t count on it). To convert in QGIS, go to Raster -&gt; Projection -&gt; Warp, and choose the projection that best suits your area (can&#39;t help you with that, but you can find this info online). In ArcGIS, you&#39;ll want the Project Raster tool that&#39;s in the Data Management toolbox.\n\nNext, you&#39;ll want to isolate your area of interest. Create a point vector for each of your city centers, and generate a 50km buffer from it. Again, make sure your point vector is in a projected SRS, else you&#39;ll create a 50 degrees buffer encompassing most of Eurasia. For QGIS, that&#39;s Vector -&gt; Geoprocessing Tools -&gt; Buffer, whereas for ArcGIS it&#39;s Analysis toolbox -&gt; Proximity toolset -&gt; Buffer. Remember to put it 50000, not 50. Then you&#39;ll need to cut your DEM raster with it. In QGIS, that&#39;s Raster -&gt; Extration -&gt; Clipper, and in ArcGIS it&#39;s Data Management toolbox -&gt; Raster toolset -&gt; Raster Processing toolset -&gt; Clip.\n\nWith your isolated DEM raster in hand, go generate the slope. In QGIS, that&#39;s Raster -&gt; Analysis -&gt; DEM, and then select Slope on the Mode. In ArcGIS, it&#39;s part of the Spatial Analyst toolbox and the 3D Analyst toolbox, under Surface toolset. Now, parts of both toolboxes are only available as payed extensions, and I don&#39;t know if that&#39;s the case for Slope. Anyway, regardless of the software, slope can be calculated in degrees as well as percentage. Since you want areas with &lt; 15% slope, beware not to choose degrees during the process.\n\nStep 3: Analysing the slope\n\nNext, you&#39;ll turn your slope raster (in which currently pixels have a slope value) into a binary raster (that is, each pixel will either be 0 - non-acceptable slope - or 1 - acceptable slope). To do so, you&#39;ll need map algebra. In QGIS it&#39;s in Raster -&gt; Raster Calculator, and in ArcGIS it&#39;s Spatial Analyst toolbox -&gt; Map Algebra toolset -&gt; Raster Calculator. Your expression should be something like &quot;Raster1&quot; &lt;= 15.\n\nNow, what the sloping algorithm does is calculate the probable slope of each pixel based on the surrounding pixels. For a more in-depth view, read about it here. That may leave your area with a salt-and-pepper look after you turn it into binary, with plenty of isolated pixels of &quot;possible&quot; buildable land. If that&#39;s what you wanted, then you&#39;re done! If, however, you want a minimum contiguous area to be able to call it a building area, then you&#39;ll have to generalize your data.\n\nMany softwares do that, but, afaik, ArcGIS isn&#39;t one of them. But QGIS does, in Raster -&gt; Analysis -&gt; Sieve. Here you&#39;ll define the minimum number of pixels to be part of a set; any number smaller than that will be mixed with surrounding pixels. The number of pixels should be a reflection of the minimum area you want, based on the spatial resolution of the original DEM. Note, however, that this alters your accuracy somewhat, so use it with care.\n\nElse, this is it. You can later isolate water and wetland by overlaying a vector layer with those informations and further clipping your raster with it.\n Both ArcGIS and QGIS can do this, as well as any other good GIS or <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> software. But first, you need to know what Spatial Reference System your DEM raster is in. &hellip; "
    },
    {
        "question": "How to make 3D building models from lidar data in ArcGIS?",
        "area": [
            "arcgis-desktop",
            "arcgis-10.0",
            "lidar",
            "3d-analyst",
            "arcscene"
        ],
        "text": "I have Lidar data, ground points and first returns. I have processed it and have ready tiles from which I am trying to build 3D building models. \n\nSo far I was able to just extrude the buildings in the ArcScene and that is it.\n\nI am a beginner in GIS/Remote Sensing and any help would be highly appreciated.\n\nAlso, I am trying to work this out in Arc10.\n I am a beginner in GIS/<span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> and any help would be highly appreciated.\n\nAlso, I am trying to work this out in Arc10. &hellip; "
    },
    {
        "question": "How to perform Random Forest land cover classification?",
        "area": [
            "r",
            "land-classification",
            "random-forest",
            "machine-learning"
        ],
        "text": "I know that this thread is a little old, but for anyone wanting to try classification of remote sensing data in , a very promising new package has been released.\n\n\n\nIt comes with functions for both unsupervised and supervised classification (using random forests). More information can be found here - http://bleutner.github.io/RStoolbox/\n I know that this thread is a little old, but for anyone wanting to try classification of <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> data in R, a very promising new package has been released. &hellip; "
    },
    {
        "question": "Filling in missing values in raster using R",
        "area": [
            "raster",
            "r",
            "imagery",
            "digital-image-processing"
        ],
        "text": "I am looking for a robust way to fill in missing values in some rasters. They all have a single layer. Missing values consist of single pixels to medium sized patches. Rasters are around 1000 x 1000 pixels in size and the largest patches are like 20x20 pixels.\nI&#39;m tempted to use aregImpute in the Hmisc R package.\nHas anyone used it for this purpose?\nthis approach looks seems very cool but I think it is only meant to produce aesthetically pleasing corrections.\nDetailed explanation of this:\nAll the rasters (I have 36 in total) share the same extent, they overlap and are aligned. Each raster is a different variable, I gathered variable from various sources (remote sensing, topographic and climatological). The original rasters come in various resolutions. The smallest being 30m. From there up they get as high as 1km. I resampled everything using cubic convolution (all the variables are continuos) to 1km. I have another 1km raster where I have data of a variable of interest for some sampled points. So I trained a model using those points and the other rasters as covariates to be able to generate a full raster of that variable. Unfortunately most covariate rasters have some missing values in them, actually not much but I would want to eliminate the problem entirely.\nI would like to use R for this.\n Each raster is a different variable, I gathered variable from various sources (<span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span>, topographic and climatological). The original rasters come in various resolutions. &hellip; "
    },
    {
        "question": "Free open satellite or other remote sensing data for night time?",
        "area": [
            "raster",
            "data",
            "remote-sensing",
            "satellite"
        ],
        "text": "I usually work with daytime satellite images to do some image classification (mostly Landsat data from the USGS EarthExplorer). Right now I&#39;d like to check at some night time images to work on city lights but I don&#39;t know which data sets or web services I should take a look at. Ideally, I&#39;d like it to be a data set with long historical data 1970s-now but everything is welcome. Any ideas please?\n I usually work with daytime satellite images to do some image classification (mostly Landsat data from the USGS EarthExplorer). Right now I&#39;d like to check at some night time images to work on city li &hellip; "
    },
    {
        "question": "Imagery Database/Metadata Store",
        "area": [
            "remote-sensing",
            "database"
        ],
        "text": "I&#39;m a Remote Sensing PhD student, and as such I have a large number of satellite images that I&#39;m working with. I&#39;m starting to fail to keep track of them all and I have a lot of metadata that I want to track for each image (sensor, resolution, processing steps, format, source etc).\n\nI have been using the SPECCHIO database for storing Spectral Libraries for a while, and was wondering whether anything similar exists for storing images. I&#39;ve had a search and can&#39;t seem to find anything, but that doesn&#39;t mean that it doesn&#39;t exist!\n\nIdeally I&#39;m looking for something which can store a database of metadata and allow you to search for images that meet certain criteria (spatial resolution &gt; 10m, or includes a certain lat/long co-ordinate).\n\nDoes anyone know if anything like this exists?\n\nIf it doesn&#39;t exist then I might have a go at writing something, which may involved SQLite, ENVI, IDL and a lot of late nights...\n I&#39;m a <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span> PhD student, and as such I have a large number of satellite images that I&#39;m working with. &hellip; "
    },
    {
        "question": "How to speed up extract(rstr,shp) ? - R",
        "area": [
            "raster",
            "polygon",
            "r",
            "rasterization",
            "extract"
        ],
        "text": "I am trying to create a function that takes in a shapefile and a binary (1&#39;s and 0&#39;s) raster, with the same extent, and extracts the values from the raster. Once this occurs I desire to sum up those values and get a percentage of pixels within those boundaries that are 1. Then rasterize these percentages. Here is what I have so far. It is working just fine BUT IS EXTREMELY SLOW! \n\n\n\nI read elsewhere it is faster to rasterize() the polygon first and use getValues() but I do not know how to apply this to my situation.\n\nThe project is for urban build-up/density using remote sensing data, hence the names. \n The project is for urban build-up/density using <span class=\"highlight\">remote</span> <span class=\"highlight\">sensing</span> data, hence the names. &hellip; "
    },
    {
        "question": "Best Landsat-5 TM band combination for detecting fire scars",
        "area": [
            "qgis-2",
            "remote-sensing",
            "landsat",
            "landsat-5"
        ],
        "text": "This varies greatly on the characteristics of the scene.  Fire scar mapping studies using Landsat-5 TM have used the following three band combinations:\n\n\nSpain: Bands 4, 5, 7\n\n\nCHUVIECO, E., and CONGALTON, R., 1988, Mapping and inventory of forest fires from digital\nprocessing of TM data. Geocarto International, 4, 41\u201353.\n\n\nAmazonia: Bands 3, 4, 5\n\n\nPEREIRA, M. C., and SETZER, A. W., 1993, Spectral characteristics of fire scars in Landsat-5 TM images of Amazonia. International Journal of Remote Sensing, 14, 2061\u20132078.\n\n\nGreece: Bands 4, 7, 1 or Bands 4, 7, 2\n\n\nKOUTSIAS, N., and KARTERIS, M., 1998, Logistic regression modeling of multitemporal\nThematic Mapper data for burned area mapping. International Journal of Remote\nSensing, 19, 3499\u20133514.\n\nKOUTSIAS, N., and KARTERIS, M., 2000, Burned area mapping using logistic regression\nmodeling of a single post-fire Landsat-5 Thematic Mapper image. International\nJournal of Remote Sensing, 21, 673\u2013687.\n International Journal of <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>, 14, 2061\u20132078. &hellip; International\nJournal of <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>, 21, 673\u2013687. &hellip; "
    },
    {
        "question": "Identifying individual trees and segmenting crowns from LiDAR CHM data?",
        "area": [
            "remote-sensing",
            "lidar",
            "image-segmentation",
            "forest-ecology",
            "canopy-height-model"
        ],
        "text": "I would encourage you to investigate the spatial wavelet analysis (SWA) method. This is an automated object oriented approach used to identifying individual tree canopies. The method has the potential to identify both tree height and canopy diameter from LiDAR derived canopy height models. The output is usually composed of a table with tree centroid coords, tree diameter and tree height (when coded for use with CHM&#39;s). The following paper goes into detail on the SWA method:\n\nFalkowski, M. J., Smith, A. M., Hudak, A. T., Gessler, P. E., Vierling, L. A., &amp; Crookston, N. L. (2006). Automated estimation of individual conifer tree height and crown diameter via two-dimensional spatial wavelet analysis of lidar data. Canadian Journal of Remote Sensing, 32(2), 153-161.\n\n\n Canadian Journal of <span class=\"highlight\">Remote</span> <span class=\"highlight\">Sensing</span>, 32(2), 153-161. &hellip; "
    },
    {
        "question": "Benefits of using GIS in business intelligence software?",
        "area": [
            "business"
        ],
        "text": "I work in business intelligence and I am the responsible GIS admin. We are a health care firm and since we&#39;ve added geospatial data to our Cognos reports, the users have told me that their workflow and the possibilities I&#39;ve opened to them, has evolved ever since. It is now easier for them to visualize certain data quicker and act from that data. Some decisions are made because of regional disease frequency. Its easier to value a cluster then a whole list of &quot;some&quot; values.\n I work in business <span class=\"highlight\">intelligence</span> and I am the responsible GIS admin. &hellip; We are a health care firm and since we&#39;ve added <span class=\"highlight\">geospatial</span> data to our Cognos reports, the users have told me that their workflow and the possibilities I&#39;ve opened to them, has evolved ever since. &hellip; "
    },
    {
        "question": "Transformation functions for EPSG:3395 projection vs. EPSG:3857",
        "area": [
            "coordinate-system"
        ],
        "text": "You have discovered the reason for the following information extracted from an NGA Advisory Notice on &quot;Web Mercator&quot;. \n\n&quot;The NGA Geomatics Office has assessed the use of Web Mercator and other non-WGS 84 spatial reference systems may cause geo-location / geo-coordinate errors up to 40,000 meters. This erroneous geospatial positioning information poses an unacceptable risk to global safety of navigation activities, and department of defense, intelligence community, and allied partner systems, missions, and operations that require accurate and precise positioning and navigation information. The NGA Geomatics Office reminds the community to use DoD approved World Geodetic System 1984 (WGS 84) applications for all mission critical activities.&quot;\n\nEPSG:3395 is WGS 84 compliant.  EPSG:3857 is NOT!  You are seeing the reason why. \n\nI didn&#39;t realize that either until I was most of the way thru a project and I was finally told that I couldn&#39;t use EPSG:3857 for the above reasons.  I scrambled to find a replacement and came up with EPSG:3395.  It was a relatively painless conversion as all I had to do was change the projection declaration in the code.  However, a major issue then came up when I ran into the problem of conversions between EPSG:3395 and the other projection I was using, EPSG:4326 which is in LAT/LON rather than meters.  Openlayers only supports conversions between EPSG:4326 and EPSG:3857 out of the box.  If you want to use any other projection, such as EPSG:3395, you need to use proj4.js and OpenLayers knows to automatically look into proj4.js for the routines it needs.  However, you need to prime the pump, so to speak.  You need to declare the projection definition string, an example for EPSG:3395 follows.\n\n\n\nThis one can be found at https://epsg.io/3395.  I&#39;ve run into another problem with this though that I am trying solve.  The projections don&#39;t work the same. I have documented the problem here and I am looking for any information anyone has as to why.\n\nhttps://stackoverflow.com/questions/51528830/epsg3395-projection-not-providing-map-wrapping\n This erroneous <span class=\"highlight\">geospatial</span> positioning information poses an unacceptable risk to global safety of navigation activities, and department of defense, <span class=\"highlight\">intelligence</span> community, and allied partner systems, missions &hellip; "
    },
    {
        "question": "The GIS of War - Tracking Conflicts and Their Effects",
        "area": [
            "data"
        ],
        "text": "The NGA (National Geospatial-Intelligence Agency) makes available up-to-date &quot;Anti-Shipping Activity Messages&quot; (aka &quot;pirate data&quot;) which includes locations and descriptive accounts of specific hostile acts against ships world-wide.  The data is also available in GIS data formats such as shapefiles, KML and file geodatabase.\n\nhttp://msi.nga.mil/NGAPortal/MSI.portal?_nfpb=true&amp;_pageLabel=msi_portal_page_65\n The NGA (National <span class=\"highlight\">Geospatial</span>-<span class=\"highlight\">Intelligence</span> Agency) makes available up-to-date &quot;Anti-Shipping Activity Messages&quot; (aka &quot;pirate data&quot;) which includes locations and descriptive accounts of specific hostile &hellip; "
    },
    {
        "question": "Support viewing correctly and creating NSG GPKG RASTER TILES",
        "area": [
            "leaflet"
        ],
        "text": "The NSG GeoPackage spec defines permitted extensions and restrictions on top of the OGC GeoPackage spec.  It does not define base GeoPackage spec breaking changes to how tiles are stored.\nNational System for Geospatial-Intelligence (NSG) GeoPackage Encoding Standard 1.1\nInteroperability Standard\n(2017-08-10)\nVersion 2.1\n\nThis Interoperability Standard is a Class 2 conformance profile as defined by ISO 19106, Geographic Information \u2013 Profiles date 2004-07-01 that includes a single standard with permitted NSG extensions and restrictions to the standard. An Interoperability Standard provides detailed direction on how to use the clauses, options, and parameters of the base standard(s).\n\nThe GeoPackage spec stores tiles in a tile pyramid which has nothing to do with XYZ tiles (although you can configure a GeoPackage to mirror XYZ tiles).\n\nThe gpkg_tile_matrix_set table defines the spatial reference system (srs_id) and the maximum bounding box (min_x, min_y, max_x, max_y) for all possible tiles in a tile pyramid user data table.\nThe tile coordinate (0,0) always refers to the tile in the upper left corner of the tile matrix at any zoom level, regardless of the actual availability of that tile.\n\nThe NSG GeoPackage spec restricts the tile dimensions to 256x256, zoom levels by a factor of 2, and bounding boxes to represent the full global tile indexing scheme.\n\nNSG Req 20: The gpkg_tile_matrix table SHALL contain tile_width and tile_height column values of 256 for every table_name tile pyramid data table.\nNSG Req 21: Every tile_data tile in every table_name tile pyramid data table shall have a width and height of 256 pixels.\nNSG Req 22: The gpkg_tile_matrix table SHALL contain pixel_x_size and pixel_y_size column values that differ by a factor of 2 between all adjacent zoom levels for each tile pyramid data table per OGC GeoPackage Clause 2.2.3.  It SHALL NOT contain pixel sizes that vary by irregular intervals or by regular intervals other than a factor of 2 between adjacent zoom levels per OGC GeoPackage Clause 2.2.3.\nNSG Req 23: The (min_x, min_y, max_x,  max_y) values in the gpkg_tile_matrix_set table SHALL be the maximum bounds of the CRS specified for the tile pyramid data table and SHALL be used to determine the geographic position of each tile in the tile pyramid data table.\n\nThe geopackage-js library does support NSG GeoPackages since they adhere to the base GeoPackage specification.  I ran through the U.S. Naval Research Laboratory NSG GeoPackage examples and all worked on the geopackage-js demo page.  The Blue Marble GeoPackage revealed a bug when using proj4js causing high level tiles and further in edge tiles to not display.  This has now been fixed.  NSG GeoPackages with a SRS organization of NGA are currently not supported (see this issue for more details).  Feel free to submit geopackage-js issues if you run into additional problems.\nEdit: Load Black Marble GeoPackage in geopackage-js\n National System for <span class=\"highlight\">Geospatial</span>-<span class=\"highlight\">Intelligence</span> (NSG) GeoPackage Encoding Standard 1.1\nInteroperability Standard\n(2017-08-10)\nVersion 2.1\n\nThis Interoperability Standard is a Class 2 conformance profile as &hellip; "
    },
    {
        "question": "When did the word &quot;geospatial&quot; first come into usage?",
        "area": [
            "history",
            "terminology"
        ],
        "text": "I&#39;ve been in the business since 1976.    I first heard the term from two people who claimed to have coined it in the 90s.   Rationale was that they were looking for a word that emphasized the precision needed for geographic analysis.     Geospatial was intended to convey a greater level of spatial precision within GIS and Geographic Analysis.    The follow-on term, Geospatial-Intelligence made its way into the names of several national government organizations\n <span class=\"highlight\">Geospatial</span> was intended to convey a greater level of spatial precision within GIS and Geographic Analysis. &hellip; The follow-on term, <span class=\"highlight\">Geospatial</span>-<span class=\"highlight\">Intelligence</span> made its way into the names of several national government organizations &hellip; "
    },
    {
        "question": "How Many UTM Cylinders are there?",
        "area": [
            "coordinate-system",
            "utm"
        ],
        "text": "I found two references that I think lock in the most likely answer at 60 cylinders, but a close reading of the definition, could reasonably lead to an interpretation of 30, 60, or 120.\n\nIf one ignores the potential for flipping the opposite side map (antipodal?) then 30 cylinders could be the smallest number, as mkennedy spelled out above.\n\nThe 60 cylinders model is the most common approach used to visualize them, but interestingly enough, the two references only mention 120 Spatial Reference Frames or instances.\n\nFirst up, the US National Geospatialintelligence Agency (NGA) defines UTM as follows: \n\nUTM is a family of 120 instances of the general form of the transverse \nMercator projection. Each instance is called a zone and is given a \nzone number Z between -60 and +60 excluding zero. \n\nSource:NATIONAL GEOSPATIAL-INTELLIGENCE AGENCY STANDARDIZATION DOCUMENT Implementation Practice The Universal Grids and the Transverse Mercator and Polar Stereographic Map Projections 2014-03-25, NGA.SIG.0012_2.0.0_UTMUPS, Section 7.1 page 32.   \n\nSecond, the International Standards Organization (ISO) group has published the standard for Spatial Reference Models, and it defines UTM as: \n\nA set of 120 localized Spatial Reference Frames (SRFs), \nwhere limited overlap is modelled by extended validity regions in the member SRFs. \n\nSource: International Standard ISO / IEC 18026, Information Technology: Spatial Reference Model, ISO / IEC 18026, Section 8.7.7 - Table 8.6.0, page 192.\n\nSo, one could also make a case for 120 cylinders (half cylinders?) since each UTM zone could be aligned to a unique one.  If the mappers use different ellipsoids for their UTM projections, then the cylinders will naturally be different too.\n\nI think the UTM standard for the US to only use the WGS 1984 ellipsoid - and that is the standard.  The referenced NGA document also spelled out approaches for TM to be applied to many other ellipsoids, starting at page 20. \n\nI hope this helps - corrections welcome.\n Source:NATIONAL <span class=\"highlight\">GEOSPATIAL</span>-<span class=\"highlight\">INTELLIGENCE</span> AGENCY STANDARDIZATION DOCUMENT Implementation Practice The Universal Grids and the Transverse Mercator and Polar Stereographic Map Projections 2014-03-25, NGA.SIG &hellip; "
    },
    {
        "question": "List of US government free GIS data online",
        "area": [
            "data",
            "government"
        ],
        "text": "\n\nThe National Geospatial-Intelligence Agency offers an impressive POI list called &quot;Complete Files of Geographic Names for Geopolitical Areas&quot;, which seems to comprehensively cover every spot of the world.\n\nI had a brief, but good, experience with the POI list of Isreal.\n\nThe data is updated as to 18 July 2002.\n The National <span class=\"highlight\">Geospatial</span>-<span class=\"highlight\">Intelligence</span> Agency offers an impressive POI list called &quot;Complete Files of Geographic Names for Geopolitical Areas&quot;, which seems to comprehensively cover every spot of the world &hellip; "
    },
    {
        "question": "Where do map services get their town name data from?",
        "area": [
            "web-mapping",
            "cartography"
        ],
        "text": "The US Gov also provide lots of geographical data for free including place name for the whole world at : http://geonames.nga.mil/gns/html/namefiles.html \n\nI dont know if this is up to the level of detail you seek but that could be a good starting point (for exemple Netherlands data contain 22887 record).\n\nI download and have a quick look to some place I know, the locations are not very accurate (could be off to 100 or 1000 meters sometime) but it seem to have most of city, town, hamlet and small populated place as well as a lot of non populated place like mountain, rivers, forest, name of point of interest and other geographical feature. I would say it is as complete as what google map display if not more complete (of course disregarding street name/adresses...) for the small area I checked.\n\nSo to answer your question most map service probably get their name data from US National Geospatial-Intelligence Agency who give it freely for the whole world (Some other country have similar database, sometime in open data sometime to buy, but generally they covers only their national territories)\n So to answer your question most map service probably get their name data from US National <span class=\"highlight\">Geospatial</span>-<span class=\"highlight\">Intelligence</span> Agency who give it freely for the whole world (Some other country have similar database &hellip; "
    },
    {
        "question": "When is data created in datums other than WGS84?",
        "area": [
            "wgs84",
            "datum",
            "nad83"
        ],
        "text": "One important reason is that only the US military, NATO, and other allies or contractors, and other US government departments with clearance have access to true WGS84 coordinates and the control network. Everybody else is getting degraded values. It is true that the National Geospatial Intelligence Agency (NGA prior NIMA prior DMA) states that WGS84 is aligned at least to centimeters with the corresponding ITRFxx reference frame (International Terrestrial Reference Frame, xx = year). \n\nIf you can perform real-time kinematics or have other access to control points or are post-processing the data, you can recover that degradation in accuracy but to whatever coordinate reference system (CRS) that the control network is broadcasting. That will be some variant of ITRFxx or the local geographic CRS like NAD83 (2011) (USA) or NAD83 (CSRS) (Canada) or GDA2020 (upcoming in Australia). \n\nThe local systems have been derived using the ITRF network, plus the country&#39;s control network and usually fixed. This enables surveyors, GIS, etc. to not worry about the coordinates jiggling continuously. USA, in particular, keeps their control network fixed to the North American, Pacific, or Mariana plates to minimize the change in coordinates over time. When there&#39;s been enough movement (plate motion, subsidence, glacial rebound, earthquakes), the geodetic agency may do a re-adjustment or calculate a new realization and update the coordinates of the control network.\n\nSeveral countries are planning to go to dynamic or semi-dynamic CRS which will more closely match what IERS does with the ITRF realizations. This is possible for a few reasons including the ability to obtain data and process it in a timely manner.\n It is true that the National <span class=\"highlight\">Geospatial</span> <span class=\"highlight\">Intelligence</span> Agency (NGA prior NIMA prior DMA) states that WGS84 is aligned at least to centimeters with the corresponding ITRFxx reference frame (International &hellip; "
    },
    {
        "question": "Populated Places Names",
        "area": [
            "data",
            "natural-earth",
            "places"
        ],
        "text": "One good source for place name is : Geonames page of The National Geospatial-Intelligence Agency (US government) who give file for the whole world, it come as several .txt file (tab separated value) for each country, each .txt file beeing for a different kind a place . (you will find link for each country but the USA and all info about these data on the linked page)\n\nBe careful as the locations are not always accurate (could be off up to 100 or 1000 meters sometime) but it seem to have most of city, town, hamlet and small populated place as well as a lot of non populated place like mountain, rivers, forest, name of point of interest and other geographical feature. I would say it is as complete as what google map display if not more complete (of course disregarding street name/adresses...) for the small area I checked\n One good source for place name is : Geonames page of The National <span class=\"highlight\">Geospatial</span>-<span class=\"highlight\">Intelligence</span> Agency (US government) who give file for the whole world, it come as several .txt file (tab separated value) for &hellip; "
    },
    {
        "question": "Import ECW file",
        "area": [
            "geoserver",
            "ecw"
        ],
        "text": "is it possible to add an ecw file as a data source?\nI have the gdal extension installed:\nModule Name: ImageI/O-Ext GDAL Coverage Extension\nModule ID: gs-gdal\nVersion: 2.24.2\nComponent: GridCoverage2DReader\nMessage:\nJNI GDAL Wrapper Version: 3.0.0\nGDAL Version: 3.0.4\nGDAL Release Date: 20200128\nGDAL Build Info: PAM_ENABLED=YES\nOGR_ENABLED=YES\nGEOS_ENABLED=YES\nGEOS_VERSION=3.8.0-CAPI-1.13.1\nImageIO-Ext Version: 1.4.7\nGeoserver image version: kartoza/geoserver:2.24.2\nI still don&#39;t have the option to import a file from ecw:\n\ngdalinfo --formats\nSupported Formats:\nVRT -raster- (rw+v): Virtual Raster\nDERIVED -raster- (ro): Derived datasets using VRT pixel functions\nGTiff -raster- (rw+vs): GeoTIFF\nNITF -raster- (rw+vs): National Imagery Transmission Format\nRPFTOC -raster- (rovs): Raster Product Format TOC format\nECRGTOC -raster- (rovs): ECRG TOC format\nHFA -raster- (rw+v): Erdas Imagine Images (.img)\nSAR_CEOS -raster- (rov): CEOS SAR Image\nCEOS -raster- (rov): CEOS Image\nJAXAPALSAR -raster- (rov): JAXA PALSAR Product Reader (Level 1.1/1.5)\nGFF -raster- (rov): Ground-based SAR Applications Testbed File Format (.gff)\nELAS -raster- (rw+v): ELAS\nAIG -raster- (rov): Arc/Info Binary Grid\nAAIGrid -raster- (rwv): Arc/Info ASCII Grid\nGRASSASCIIGrid -raster- (rov): GRASS ASCII Grid\nSDTS -raster- (rov): SDTS Raster\nDTED -raster- (rwv): DTED Elevation Raster\nPNG -raster- (rwv): Portable Network Graphics\nJPEG -raster- (rwv): JPEG JFIF\nMEM -raster- (rw+): In Memory Raster\nJDEM -raster- (rov): Japanese DEM (.mem)\nGIF -raster- (rwv): Graphics Interchange Format (.gif)\nBIGGIF -raster- (rov): Graphics Interchange Format (.gif)\nESAT -raster- (rov): Envisat Image Format\nFITS -raster- (rw+): Flexible Image Transport System\nBSB -raster- (rov): Maptech BSB Nautical Charts\nXPM -raster- (rwv): X11 PixMap Format\nBMP -raster- (rw+v): MS Windows Device Independent Bitmap\nDIMAP -raster- (rov): SPOT DIMAP\nAirSAR -raster- (rov): AirSAR Polarimetric Image\nRS2 -raster- (rovs): RadarSat 2 XML Product\nSAFE -raster- (rov): Sentinel-1 SAR SAFE Product\nPCIDSK -raster,vector- (rw+v): PCIDSK Database File\nPCRaster -raster- (rw+): PCRaster Raster File\nILWIS -raster- (rw+v): ILWIS Raster Map\nSGI -raster- (rw+v): SGI Image File Format 1.0\nSRTMHGT -raster- (rwv): SRTMHGT File Format\nLeveller -raster- (rw+v): Leveller heightfield\nTerragen -raster- (rw+v): Terragen heightfield\nGMT -raster- (rw): GMT NetCDF Grid Format\nnetCDF -raster,vector- (rw+vs): Network Common Data Format\nHDF4 -raster- (ros): Hierarchical Data Format Release 4\nHDF4Image -raster- (rw+): HDF4 Dataset\nISIS3 -raster- (rw+v): USGS Astrogeology ISIS cube (Version 3)\nISIS2 -raster- (rw+v): USGS Astrogeology ISIS cube (Version 2)\nPDS -raster- (rov): NASA Planetary Data System\nPDS4 -raster,vector- (rw+vs): NASA Planetary Data System 4\nVICAR -raster- (rov): MIPL VICAR file\nTIL -raster- (rov): EarthWatch .TIL\nERS -raster- (rw+v): ERMapper .ers Labelled\nJP2OpenJPEG -raster,vector- (rwv): JPEG-2000 driver based on OpenJPEG library\nL1B -raster- (rovs): NOAA Polar Orbiter Level 1b Data Set\nFIT -raster- (rwv): FIT Image\nGRIB -raster- (rwv): GRIdded Binary (.grb, .grb2)\nRMF -raster- (rw+v): Raster Matrix Format\nWCS -raster- (rovs): OGC Web Coverage Service\nWMS -raster- (rwvs): OGC Web Map Service\nMSGN -raster- (rov): EUMETSAT Archive native (.nat)\nRST -raster- (rw+v): Idrisi Raster A.1\nINGR -raster- (rw+v): Intergraph Raster\nGSAG -raster- (rwv): Golden Software ASCII Grid (.grd)\nGSBG -raster- (rw+v): Golden Software Binary Grid (.grd)\nGS7BG -raster- (rw+v): Golden Software 7 Binary Grid (.grd)\nCOSAR -raster- (rov): COSAR Annotated Binary Matrix (TerraSAR-X)\nTSX -raster- (rov): TerraSAR-X Product\nCOASP -raster- (ro): DRDC COASP SAR Processor Raster\nR -raster- (rwv): R Object Data Store\nMAP -raster- (rov): OziExplorer .MAP\nKMLSUPEROVERLAY -raster- (rwv): Kml Super Overlay\nWEBP -raster- (rwv): WEBP\nPDF -raster,vector- (rw+vs): Geospatial PDF\nRasterlite -raster- (rwvs): Rasterlite\nMBTiles -raster,vector- (rw+v): MBTiles\nPLMOSAIC -raster- (ro): Planet Labs Mosaics API\nCALS -raster- (rwv): CALS (Type 1)\nWMTS -raster- (rwv): OGC Web Map Tile Service\nSENTINEL2 -raster- (rovs): Sentinel 2\nMRF -raster- (rw+v): Meta Raster Format\nPNM -raster- (rw+v): Portable Pixmap Format (netpbm)\nDOQ1 -raster- (rov): USGS DOQ (Old Style)\nDOQ2 -raster- (rov): USGS DOQ (New Style)\nPAux -raster- (rw+v): PCI .aux Labelled\nMFF -raster- (rw+v): Vexcel MFF Raster\nMFF2 -raster- (rw+): Vexcel MFF2 (HKV) Raster\nFujiBAS -raster- (rov): Fuji BAS Scanner Image\nGSC -raster- (rov): GSC Geogrid\nFAST -raster- (rov): EOSAT FAST Format\nBT -raster- (rw+v): VTP .bt (Binary Terrain) 1.3 Format\nLAN -raster- (rw+v): Erdas .LAN/.GIS\nCPG -raster- (rov): Convair PolGASP\nIDA -raster- (rw+v): Image Data and Analysis\nNDF -raster- (rov): NLAPS Data Format\nEIR -raster- (rov): Erdas Imagine Raw\nDIPEx -raster- (rov): DIPEx\nLCP -raster- (rwv): FARSITE v.4 Landscape File (.lcp)\nGTX -raster- (rw+v): NOAA Vertical Datum .GTX\nLOSLAS -raster- (rov): NADCON .los/.las Datum Grid Shift\nNTv1 -raster- (rov): NTv1 Datum Grid Shift\nNTv2 -raster- (rw+vs): NTv2 Datum Grid Shift\nCTable2 -raster- (rw+v): CTable2 Datum Grid Shift\nACE2 -raster- (rov): ACE2\nSNODAS -raster- (rov): Snow Data Assimilation System\nKRO -raster- (rw+v): KOLOR Raw\nROI_PAC -raster- (rw+v): ROI_PAC raster\nRRASTER -raster- (rw+v): R Raster\nBYN -raster- (rw+v): Natural Resources Canada&#39;s Geoid\nARG -raster- (rwv): Azavea Raster Grid format\nRIK -raster- (rov): Swedish Grid RIK (.rik)\nUSGSDEM -raster- (rwv): USGS Optional ASCII DEM (and CDED)\nGXF -raster- (rov): GeoSoft Grid Exchange Format\nDODS -raster- (ro): DAP 3.x servers\nBAG -raster- (rwv): Bathymetry Attributed Grid\nHDF5 -raster- (rovs): Hierarchical Data Format Release 5\nHDF5Image -raster- (rov): HDF5 Dataset\nNWT_GRD -raster- (rw+v): Northwood Numeric Grid Format .grd/.tab\nNWT_GRC -raster- (rov): Northwood Classified Grid Format .grc/.tab\nADRG -raster- (rw+vs): ARC Digitized Raster Graphics\nSRP -raster- (rovs): Standard Raster Product (ASRP/USRP)\nBLX -raster- (rwv): Magellan topo (.blx)\nEPSILON -raster- (rwv): Epsilon wavelets\nPostGISRaster -raster- (rws): PostGIS Raster driver\nSAGA -raster- (rw+v): SAGA GIS Binary Grid (.sdat, .sg-grd-z)\nIGNFHeightASCIIGrid -raster- (rov): IGN France height correction ASCII Grid\nXYZ -raster- (rwv): ASCII Gridded XYZ\nHF2 -raster- (rwv): HF2/HFZ heightfield raster\nJPEGLS -raster- (rwv): JPEGLS\nOZI -raster- (rov): OziExplorer Image File\nCTG -raster- (rov): USGS LULC Composite Theme Grid\nE00GRID -raster- (rov): Arc/Info Export E00 GRID\nZMap -raster- (rwv): ZMap Plus Grid\nNGSGEOID -raster- (rov): NOAA NGS Geoid Height Grids\nIRIS -raster- (rov): IRIS data (.PPI, .CAPPi etc)\nPRF -raster- (rov): Racurs PHOTOMOD PRF\nRDA -raster- (ro): DigitalGlobe Raster Data Access driver\nEEDAI -raster- (ros): Earth Engine Data API Image\nDAAS -raster- (ro): Airbus DS Intelligence Data As A Service driver\nSIGDEM -raster- (rwv): Scaled Integer Gridded DEM .sigdem\nGPKG -raster,vector- (rw+vs): GeoPackage\nCAD -raster,vector- (rovs): AutoCAD Driver\nPLSCENES -raster,vector- (ro): Planet Labs Scenes API\nNGW -raster,vector- (rw+s): NextGIS Web\nGenBin -raster- (rov): Generic Binary (.hdr Labelled)\nENVI -raster- (rw+v): ENVI .hdr Labelled\nEHdr -raster- (rw+v): ESRI .hdr Labelled\nISCE -raster- (rw+v): ISCE raster\nHTTP -raster,vector- (ro): HTTP Fetching Wrapper\n\n SAR Processor Raster\nR -raster- (rwv): R Object Data Store\nMAP -raster- (rov): OziExplorer .MAP\nKMLSUPEROVERLAY -raster- (rwv): Kml Super Overlay\nWEBP -raster- (rwv): WEBP\nPDF -raster,vector- (rw+vs): <span class=\"highlight\">Geospatial</span> &hellip; data (.PPI, .CAPPi etc)\nPRF -raster- (rov): Racurs PHOTOMOD PRF\nRDA -raster- (ro): DigitalGlobe Raster Data Access driver\nEEDAI -raster- (ros): Earth Engine Data API Image\nDAAS -raster- (ro): Airbus DS <span class=\"highlight\">Intelligence</span> &hellip; "
    },
    {
        "question": "Measuring accuracy of latitude and longitude",
        "area": [
            "coordinates",
            "latitude-longitude",
            "gis-principle",
            "accuracy",
            "precision"
        ],
        "text": "Accuracy is the tendency of your measurements to agree with the true values.  Precision is the degree to which your measurements pin down an actual value.  The question is about an interplay of accuracy and precision.\nAs a general principle, you don&#39;t need much more precision in recording your measurements than there is accuracy built into them.  Using too much precision can mislead people into believing the accuracy is greater than it really is.\nGenerally, when you degrade precision--that is, use fewer decimal places--you can lose some accuracy.  But how much?  It&#39;s good to know that the meter was originally defined (by the French, around the time of their revolution when they were throwing out the old systems and zealously replacing them by new ones) so that ten million of them would take you from the equator to a pole.  That&#39;s 90 degrees, so one degree of latitude covers about 10^7/90 = 111,111 meters.  (&quot;About,&quot; because the meter&#39;s length has changed a little bit in the meantime.  But that doesn&#39;t matter.)  Furthermore, a degree of longitude (east-west) is about the same or less in length than a degree of latitude, because the circles of latitude shrink down to the earth&#39;s axis as we move from the equator towards either pole.  Therefore, it&#39;s always safe to figure that the sixth decimal place in one decimal degree has 111,111/10^6 = about 1/9 meter = about 4 inches of precision.\nAccordingly, if your accuracy needs are, say, give or take 10 meters, than 1/9 meter is nothing: you lose essentially no accuracy by using six decimal places.  If your accuracy need is sub-centimeter, then you need at least seven and probably eight decimal places, but more will do you little good.\nThirteen decimal places will pin down the location to 111,111/10^13 = about 1 angstrom, around half the thickness of a small atom.\nUsing these ideas we can construct a table of what each digit in a decimal degree signifies:\n\nThe sign tells us whether we are north or south, east or west on the globe.\nA nonzero hundreds digit tells us we&#39;re using longitude, not latitude!\nThe tens digit gives a position to about 1,000 kilometers.  It gives us useful information about what continent or ocean we are on.\nThe units digit (one decimal degree) gives a position up to 111 kilometers (60 nautical miles, about 69 miles).  It can tell us roughly what large state or country we are in.\nThe first decimal place is worth up to 11.1 km: it can distinguish the position of one large city from a neighboring large city.\nThe second decimal place is worth up to 1.1 km: it can separate one village from the next.\nThe third decimal place is worth up to 110 m: it can identify a large agricultural field or institutional campus.\nThe fourth decimal place is worth up to 11 m: it can identify a parcel of land.  It is comparable to the typical accuracy of an uncorrected GPS unit with no interference.\nThe fifth decimal place is worth up to 1.1 m: it distinguish trees from each other.  Accuracy to this level with commercial GPS units can only be achieved with differential correction.\nThe sixth decimal place is worth up to 11 cm: you can use this for laying out structures in detail, for designing landscapes, building roads.  It should be more than good enough for tracking movements of glaciers and rivers.  This can be achieved by taking painstaking measures with GPS, such as differentially corrected GPS.\nThe seventh decimal place is worth up to 1.1 cm: this is good for much surveying and is near the limit of what GPS-based techniques can achieve.\nThe eighth decimal place is worth up to 1.1 mm: this is good for charting motions of tectonic plates and movements of volcanoes.  Permanent, corrected, constantly-running GPS base stations might be able to achieve this level of accuracy.\nThe ninth decimal place is worth up to 110 microns: we are getting into the range of microscopy.  For almost any conceivable application with earth positions, this is overkill and will be more precise than the accuracy of any surveying device.\nTen or more decimal places indicates a computer or calculator was used and that no attention was paid to the fact that the extra decimals are useless.  Be careful, because unless you are the one reading these numbers off the device, this can indicate low quality processing!\n\n The seventh decimal place is worth up to 1.1 cm: this is good for much <span class=\"highlight\">surveying</span> and is near the limit of what GPS-based techniques can achieve. &hellip; For almost any conceivable application with earth positions, this is overkill and will be more precise than the accuracy of any <span class=\"highlight\">surveying</span> device. &hellip; "
    },
    {
        "question": "How much math does a GIS Analyst need to know?",
        "area": [
            "education"
        ],
        "text": "I make my living applying mathematics and statistics to solving the kinds of problems a GIS is designed to address.  One can learn to use a GIS effectively without knowing much math at all: millions of people have done it.  But over the years I have read (and responded to) many thousands of questions about GIS and in many of these situations some basic mathematical knowledge, beyond what&#39;s usually taught (and remembered) in high school, would have been a distinct advantage.\n\nThe material that keeps coming up includes the following:\n\n\nTrigonometry and spherical trigonometry.  Let me surprise you: this stuff is overused.  In many cases trig can be avoided altogether by using simpler, but slightly more advanced, techniques, especially basic vector arithmetic.\nElementary differential geometry.  This is the investigation of smooth curves and surfaces.  It was invented by C. F. Gauss in the early 1800&#39;s specifically to support wide-area land surveys, so its applicability to GIS is obvious.  Studying the basics of this field prepares the mind well to understand geodesy, curvature, topographic shapes, and so on.\nTopology.  No, this does not mean what you think it means: the word is consistently abused in GIS.  This field emerged in the early 1900&#39;s as a way to unify otherwise difficult concepts with which people had been grappling for centuries.  These include concepts of infinity, of space, of nearness, of connectedness.  Among the accomplishments of 20th century topology was the ability to describe spaces and calculate with them.  These techniques have trickled down into GIS in the form of vector representations of lines, curves, and polygons, but that merely scratches the surface of what can be done and of the beautiful ideas lurking there.  (For an accessible account of part of this history, read Imre Lakatos&#39; Proofs and Refutations.  This book is a series of dialogs within a hypothetical classroom that is pondering questions that we would recognize as characterizing the elements of a 3D GIS.  It requires no math beyond grade school but eventually introduces the reader to homology theory.)\n\nDifferential geometry and topology also deal with &quot;fields&quot; of geometric objects, including the vector and tensor fields Waldo Tobler has been talking about for the latter part of his career.  These describe extensive phenomena within space, such as temperatures, winds, and crustal movements.\nCalculus. Many people in GIS are asked to optimize something: find the best route, find the best corridor, the best view, the best configuration of service areas, etc.  Calculus underlies all thinking about optimizing functions that depend smoothly on their parameters.  It also offers ways to think about and calculate lengths, areas, and volumes.  You don&#39;t need to know much Calculus, but a little will go a long way.\nNumerical analysis. We often have difficulties solving problems with the computer because we run into limits of precision and accuracy.  This can cause our procedures to take a long time to execute (or be impossible to run) and can result in wrong answers.  It helps to know the basic principles of this field so that you can understand where the pitfalls are and work around them.\nComputer science. Specifically, some discrete mathematics and methods of optimization contained therein.  This includes some basic graph theory, design of data structures, algorithms, and recursion, as well as a study of complexity theory.\nGeometry. Of course.  But not Euclidean geometry: a tiny bit of spherical geometry, naturally; but more important is the modern view (dating to Felix Klein in the late 1800&#39;s) of geometry as the study of groups of transformations of objects.  This is the unifying concept to moving objects around on the earth or on the map, to congruence, to similarity.\nStatistics. Not all GIS professionals need to know statistics, but it is becoming clear that a basic statistical way of thinking is essential.  All our data are ultimately derived from measurements and heavily processed afterwards.  The measurements and the processing introduce errors that can only be treated as random.  We need to understand randomness, how to model it, how to control it when possible, and how to measure it and respond to it in any case.  That does not mean studying t-tests, F-tests, etc; it means studying the foundations of statistics so that we can become effective problem solvers and decision makers in the face of chance.  It also means learning some modern ideas of statistics, including exploratory data analysis and robust estimation as well as principles of constructing statistical models.\n\n\n\n\nPlease note that I am not advocating that all GIS practitioners need to learn all this stuff!  Also, I am not suggesting that the different topics should be learned in isolation by taking separate courses.  This is merely an (incomplete) compendium of some of the most powerful and beautiful ideas that many GIS people would deeply appreciate (and be able to apply) were they to know them.  What I suspect we need is to learn enough about these subjects to know when they might be applicable, to know where to go for help, and to know how to learn more if it should be needed for a project or a job.  From that perspective, taking a lot of courses would be overkill and would likely tax the patience of the most dedicated student.  But for anyone who has an opportunity to learn some mathematics and has a choice of what to learn and how to learn it, this list might provide some guidance.\n I make my living applying mathematics and statistics to solving the kinds of problems a GIS is designed to address.  One can learn to use a GIS effectively without knowing much math at all: millions o &hellip; "
    },
    {
        "question": "Creating point features with exact coordinates in QGIS",
        "area": [
            "qgis",
            "point",
            "coordinates",
            "point-creation"
        ],
        "text": "How do I create point features with exact (manually entered) coordinates in QGIS?\nI get precise GPS coordinates from a survey team which I need to add to a point layer. What I want: add point, type in the coordinates and when pressing enter the point is created where it is supposed to be.\n I get precise GPS coordinates from a <span class=\"highlight\">survey</span> team which I need to add to a point layer. &hellip; "
    },
    {
        "question": "Seeking administrative boundaries for various countries?",
        "area": [
            "data",
            "global"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\nGlobal\n\nFor non-commercial use, try GADM.\nFor small scale global dataset try Natural Earth: Natural Earth is a public domain map dataset available at 1:10m, 1:50m, and 1:110 million scales\nDIVA-GIS is free data. Just click on &#39;Global level&#39; and a zip file will download of all country boundaries.  Under &#39;Country level&#39; you&#39;ll find administrative areas and a few other things that may interest you but you have to pick the country you want so it could take a little time if you want every country\nOpenStreetMap has a lot of data. It isn&#39;t necessarily authoritative, but if you are just trying to get data it may be suitable.\nhttp://wiki.openstreetmap.org/wiki/Potential_Datasources: This wiki has the most comprehensive (reviewed by data quality) list of freely available data sources\nhttp://wiki.openstreetmap.org/wiki/Shapefiles\nhttp://osmdata.thinkgeo.com/openstreetmap-data/\nThe UN has a dataset for many (but not all) countries, known as the Second Administrative Level Boundaries data set project (SALB).   The dataset is standardized in terms of the international border, metadata profile, spelling, coding scheme, editing protocols used and can be downloaded at no cost. However, as it is licensed under the creative commons by-nc-nd license it cannot be used for commercial purposes.\nyou can find world boundaries shapefile on http://thematicmapping.org/downloads/world_borders.php\n\nAustralia\nThe Bureau of Statistics provides most of the information:\n\nCountry boundaries should be produced by merging all the state boundaries (below) into a single polygon feature.\nState level boundaries are available.\nThe states can be geographically disaggregated in a number of ways - perhaps the most similar to county boundaries are Local Government Areas (LGAs).\nTo find the area of cities, the standard dataset to use is the urban centres and localities digital boundaries.\nZipcodes (or postcodes as they are known here) are more difficult to model.  Because they are based on the rules by which Australia Post deliver the post, they are rather fuzzily defined.  The free option approximates postcodes as the census collection district level, and is available for 2006 from the ABS.\nthe updated 2011 datasets and census results are available via the Data Packs section of the ABS site, which requires free registration.\n\nNew Zealand\n\nKoordinates - This site has free and pay data for New Zealand and various international areas (like Florida!). A range of free layers, boundaries, urban areas, land use, digital elevation, coastline, rivers etc... and topo maps, contours, aerials for some areas - pay for these. Excellent interface and system for ordering downloads.\n\nhttp://www.stats.govt.nz/browse_for_stats/people_and_communities/Geographic-areas/digital-boundary-files.aspx is the Statistics Department&#39;s set of administrative boundaries. They&#39;ve got regions and territorial authorities (the rough equivalent of counties), urban areas (roughly city boundaries) and much more, including meshblocks, which most statistical data is tied to.\n\n\nCanada\n\nAdministrative Boundaries are available at GeoBase.  Note that these boundaries are actually Administrative Boundaries and not coastlines (particularly relevant for the north coast).\nThe Political Boundaries layer in the GeoGratis North American Atlas has nice physical boundaries for North America and surroundings, as well as U.S. States and Canadian Provinces.\n\nGreat Britain\nFor a wide range of free data for Great Britain, visit the Ordnance Survey website:\nhttps://www.ordnancesurvey.co.uk/opendatadownload/products.html\nThere&#39;s a product description page too (but I can&#39;t provide another hyperlink sigh)\nThe Boundary-Line dataset has a number of administrative boundary layers (though why they couldn&#39;t provide a simple, continuous, GB county boundary dataset in it is beyond me). However, there&#39;s a lot of good stuff on this site, including a GB post code gazetteer.\nEuropean Union\nEurostat provides several geo-datasets for EU and a few more countries for free for non-commercial use: Countries, NUTS, Communes, LAUs (municipalities) and coastlines: https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units\n Great Britain\nFor a wide range of free data for Great Britain, visit the Ordnance <span class=\"highlight\">Survey</span> website:\nhttps://www.ordnancesurvey.co.uk/opendatadownload/products.html\nThere&#39;s a product description page too &hellip; "
    },
    {
        "question": "Map material from China not allowed to leave that country",
        "area": [
            "data",
            "license",
            "china"
        ],
        "text": "I am not sure if the context of your question is really on-topic here, but since the answer and its implications is very much relevant for travellers as well, I&#39;ll give it a try.\n\nThe explanation you have read is not entirely accurate. The problem is that accurate map material is neither allowed to be published, nor to leave the country. The Chinese National Bureau of Surveying and Mapping require all companies to obtain permits for map surveying and published map data must be obfuscated, resulting in a deviation of up to 700m between the map and the real world. Sounds strange, but that is how it is.\n\nYou can easily see the result of this obfuscation if you e.g. in Google Maps look at the satellite imagery with a map overlay. It is especially obvious in border proximity, where you will see that the map data for China is skewed, while the map outside China is correct. If you look at this area, the Shenzhen Bay with the border between China and Hong Kong, you can see that the map over Hong Kong in the lower right area is correct, while in the middle of the bay, the map seem to indicate that the bridge makes a sharp bend to the right, while you on the satellite image can see that the bridge in reality is straight. In the upper left area (mainland China), you can then see that there is a significant discrepancy between the imagery and the map. Roads seem to float on the water, pass through buildings and what else not.\n\nSome additional information based on questions in the comments:\n\nThe Chinese Surveying and Mapping Law does not explain why the restriction is in place. It is commonly quoted that it is for national security purposes, but I am not really sure if there is any official statement on that subject at all. Similar regulations and restrictions are actually quite common in many other countries as well, but usually do not apply to the entire country, just to &#39;places of interest&#39;.\n\nThe obfuscation algorithm is prespecified, not publicly known, but is obviously deterministic. Since a lot of example data is available, there have been attempts to reverse-engineer the algorithm and there are more or less reliable software libraries available allowing a backwards mapping from obfuscated to real coordinates. There is more information and links to further resources on the Wikipedia page &#39;Restrictions on geographic data in China&#39;.\n The Chinese National Bureau of <span class=\"highlight\">Surveying</span> and Mapping require all companies to obtain permits for map <span class=\"highlight\">surveying</span> and published map data must be obfuscated, resulting in a deviation of up to 700m between &hellip; Some additional information based on questions in the comments:\n\nThe Chinese <span class=\"highlight\">Surveying</span> and Mapping Law does not explain why the restriction is in place. &hellip; "
    },
    {
        "question": "Differences between triangulation and trilateration",
        "area": [
            "gps",
            "gis-principle",
            "trilateration",
            "triangulation-survey",
            "triangulation"
        ],
        "text": "These two illustations are from the field of surveying but they should still apply.\n\nTriangulation\n\nAs Martin has said, in triangulation, you work with angles as illustrated in the following figure.\n\nThe positions of the points of interest are computed based on measured angles and two know points. From those angles, the distances are computed which are in turn used to calculate coordinates for the target points.\n\n\n\nTrilateration\n\n\n\nIn trilateration, you work with distances. From those distances, you compute the angles. Once computed, you can use them in conjunction with the distances to get the position of the target points.\n\nA simpler example would the one at HowStuffWorks. It is quite similar to how GPS works except that this one&#39;s in 2D.\n\nGiven only one distance, you only know you are within a certain distance from Boise (which could be anywhere in that radius)\n\n \n\nGiven another distance from Minneapolis, you can now tell that you are at the intersection of two circle. Still gives you two positions though.\n\n \n\nA position from a third location (Tucson), would narrow down your location to only one point. \n\n\n\nThat&#39;s pretty much how GPS works except that GPS is in 3D and you&#39;re dealing with spheres instead of circles. You&#39;d also end up with two points instead of a single point with the third satellite but you can eliminate the other point as it&#39;s not on the surface of the earth as the illustration shows.\n\n\n\n\n\nIf you would look closely, their goal is the same. To get both distance and direction so that you can get the positions of the points you&#39;re interested in. Both of these techniques were invented before GPS and electronic measuring devices (EDM).\n\nBefore EDMs, triangulation was favored as it was very hard to measure long distances accurately while it was comparatively easy to measure angles. With the advent of electronic distance measurement tools (total stations and their ilk), trilateration also became popular as it was no longer hard to measure distances.\n\nI hope that clarifies things for you.\n\n\n\nDisclaimer: Images are from the ICSM site.\n These two illustations are from the field of <span class=\"highlight\">surveying</span> but they should still apply.\n\nTriangulation\n\nAs Martin has said, in triangulation, you work with angles as illustrated in the following figure. &hellip; "
    },
    {
        "question": "Seeking Mobile GIS applications for Android Tablets?",
        "area": [
            "software-recommendations",
            "android",
            "mobile-gis"
        ],
        "text": "\nThis question has been converted to Community Wiki and wiki locked\nbecause it is an example of a question that seeks a list of answers\nand appears to be popular enough to protect it from closure.  It\nshould be treated as a special case and should not be viewed as the\ntype of question that is encouraged on this, or any Stack Exchange\nsite, but if you wish to contribute more content to it then feel free\nto do so by editing this answer.\n\n\n\nGPSLogger for Android is a lightweight GPS logger with lots of useful tweaks [control over time/distance of logs, OSM integration, auto email of tracks, and easy on your battery].\nEpiCollect developed at Imperial College London together with web based management tools looks as really good option for data collection (more info here).\nOpen Data Kit (ODK) also looks very promising on data collection front. Check for instance ODK, GeoServer, Leaflet combo.\nAntiMap - was newcomer to the market, accompanied by desktop package that can synchronize with video. Currently it&#39;s website is unresponsive.\nFunf Journal - part of Funf Open Sensing Framework developed by MIT Media Lab\nGIS Cloud&#39;s Mobile Data Collection for Android. Another data collection tool.\nOpenPaths - yet another data collection option from New York Times Company\nInput App: QGIS in your pocket - Free and open source iOS/Android app designed to streamline the whole process behind geo-surveys by Lutra Contsulting Ltd.\nQField for QGIS (Former QGIS on Android) is a very active project and is now at version 1.0:\nBlog: http://opengis.ch/\nFrom an answer deleted for recommending the same software as this one:\n\n\nI like QGIS for android as it accepts both esri shape files and\nmapinfo tab files, and you can do thematic mapping as well as\ndisplaying geotiffs. You can edit shape files easily and use the built\nin gps if you have one, however it crashes my tablet if you are not\nlocated within the bounds of the map. Otherwise it is excellent and\nthe devs are working on python compatibility meaning you will be able\nto use google and bing maps as well as open streets etc.\nThe main issues are that the gui is designed for  a standard screen\nand all the buttons and icons are tiny on anything smaller than a 10&quot;\nscreen.\nFor basic navigation and data entry on a custom map, i was using\navenzas&#39; pdf maps on iOs, which imports geo-registered PDFs. They have\na beta for android which I haven&#39;t used but am planning on trialling.\nyou can make geo-registered pdfs in mapinfo or arcmap.\n\n\nSo far I have settled on collecting KML based vector data with limited attribution.\nApps I have used:\n\nLocus (free and paid version) https://market.android.com/details?id=menion.android.locus&amp;feature=related_apps\nOruxMaps https://market.android.com/details?id=com.orux.oruxmaps\nGoogle Tracks (pre-installed on my phone)\n\nLocus and Orux allow connecting to WMS services, Google/Bing, etc... I believe there is a separate add-on to allow Google maps in Locus.\n\nI came across this interesting application that looks (have not used it) interesting for collection of data.\nhttp://code.google.com/p/geopaparazzi/\nSome more info:\nGeopaparazzi is a tool developed to do very fast qualitative engineering/geologic surveys. Even if the main aim is in the field of surveying, it contains tools that can be of great use also to OpenStreetMappers as well as tourists that want to keep a geo-diary. Geopaparazzi is available on the Android Market.\nTo get started jump into the documentation section: https://code.google.com/p/geopaparazzi/wiki/Docs\nThe main aim of Geopaparazzi is to have a tool that:\n\nfits in any pocket and can be always at hand, when needed\ngives the possibility to take georeferenced and possibly orientated pictures during the survey, with further possibility to import them into the main GIS application BeeGIS\nis able to exploit easily internet connection, if available.\nis extremely easy to use and intuitive, providing just few important functionalities.\n\nThe main features available in Geopaparazzi are:\n\ngeoreferenced notes\ngeoreferenced and orientated pictures\ngps tracks logging\neasy export of collected data\na map view for the navigation of the environment\n\nThis recent presentation might give more insight: http://www.slideshare.net/moovida/geopaparazzi-state-of-the-art\n\nWe develop a mobile GIS solution for Android tablets called Mappt, which has a free trial available from the Google Play store.  The trial version allows you access to all functionality of the software, with the exception that you can not export your data.\nYou can grab the trial for free from the Google Play Store:\nhttps://play.google.com/store/apps/details?id=au.com.mappt\nWith Mappt, you can:\n\nCapture and work with your vector data offline.\nImport and export in Shapefile and KML formats.\nWork with WGS84 and UTM-based Coordinate Reference Systems.\nImport directly from Google Drive and export to email.\nImport your own large imagery, fully available offline, via the ArcGIS Compact Cache Bundle format.  We are also actively implementing other options to import imagery.\nRecord GPS paths.\nDefine geofences, with audible and visual alerts.\n\nSee the Mappt website for further information: www.mappt.com.au\n\n\n\nFulcrum is a cost-effective and customizable GIS mobile data collection platform. Includes a 30-day trial at sign up!\nhttp://fulcrumapp.com/\nhttps://play.google.com/store/apps/details?id=com.spatialnetworks.fulcrum&amp;hl=en\n\n\nI&#39;m working on this and I have just published a GIS application: ItacaMap for Android ( https://play.google.com/store/apps/details?id=com.itacasoft.itacamap ). At the moment you can see basic functionality (zoom, pan, view info, browse, select by rectangle, etc.), but I have already implemented edit functionalities (at least on the server side) and more is cooking.\n\nGeospago is a new application.  It is a software-as-a-solution (SaaS) because it has a mobile application working in conjunction with a web application.  Both may be used for collecting/inputting data, editing/updating data, viewing/sharing data, and importing/exporting data.  The web portal runs on amazon with geoserver and syncs with the android app, which uses SQLite.\nThe web portal is used to invite/manage users, control user access to projects, create projects and custom forms, deploy the forms to users, and manage data.  It can import SHP &amp; CSV files for data maintenance workflows.  It can export data to the standard formats (CSV, KML, SHP), but aslo provides feeds and an API.  This allows users to add a WFS feed to ArcMap or QGIS to see the data live from the cloud, a network link to Google Earth, or create your own script to pull the data through API requests to integrate with other systems.  Collecting data is easy as well as quickly getting new or updated data back into a enterprise system of record.  Geospago is the only app I have seen so far that provides this.\nThe mobile app is used to collect, view, and edit data (point, line, and polygon).  It runs on both phones and tablets.  It handles connected and disconnected environments through the use of mbtiles.  It allows multiple photos to be attached to a single record.  It also has barcode scanning and signature capabilities.  Synchronization is set to user specified intervals or can be manually forced.  This prevents overlap and duplication if you have multiple people collecting data for the same projects in connected areas.\nGeospago is very affordable and available on a monthly, per-license pricing model that it can be frozen between projects or cancel-at-any-time basis so you can use it only when you need it.  Data is secure on Amazon cloud and can be download it at any time.\nThe Geospago website has more information and has a sign up link.  The website also has a link to the mobile app on the Google Play Store.\n\nFound an app called MapItFast that is easy to use.  A free version that lets you gather point, line, polygon features and even photos.  I&#39;ve used it for its basemaps and to calculate distance and area.  Unfortunately, the data stays on the device (no way to export or share..that I can find) without upgrading to the cloud services.  But that looks interesting since data can be exported to CSV, GPX, SHP and KMZ, it has built in synchronization to collaborate on mapping and location, full attribution, editing, and probably a bunch of other stuff I don&#39;t know about yet.  Might be useful to those folks doing group mapping on an Android and wanting a way to get it into Google Maps or ArcGIS.  I like the idea of a low cost Internet Map Server and tools.\nTheir website (http://www.mapitfast.com) has YouTube video.  I downloaded from Google Play.  Found the brochure online:\nhttp://www.mapitfast.com/Documents/MIF_Brochure_2013.pdf\n Even if the main aim is in the field of <span class=\"highlight\">surveying</span>, it contains tools that can be of great use also to OpenStreetMappers as well as tourists that want to keep a geo-diary. &hellip; The main aim of Geopaparazzi is to have a tool that:\n\nfits in any pocket and can be always at hand, when needed\ngives the possibility to take georeferenced and possibly orientated pictures during the <span class=\"highlight\">survey</span> &hellip; "
    },
    {
        "question": "How to select features containing specific text string using an expression in QGIS",
        "area": [
            "qgis",
            "features",
            "select",
            "expression"
        ],
        "text": "I need to style a survey parcel polygon shapefile, based on whether the polygon is a mineral claim or not. Unfortunately, the only information on whether a polygon is a mineral claim or not is contained in the &quot;TITLE&quot; field of the attribute table, which gives the full legal name of the surveyed parcel. \nFor instance, &#39;DISTRICT LOT 5639, BEING AWARD NO. 2 MINERAL CLAIM, KDYD&#39;.\nI need an expression that selects any feature containing the text &#39;MINERAL CLAIM&#39; in the &quot;TITLE&quot; field.\n I need to style a <span class=\"highlight\">survey</span> parcel polygon shapefile, based on whether the polygon is a mineral claim or not. &hellip; "
    },
    {
        "question": "When is a 3D Visualisation in GIS Useful?",
        "area": [
            "3d",
            "visualisation"
        ],
        "text": "I can currently only think of two cases:\n\nto visualise potential changes in a landscape, such as the effect of adding windfarms, or the addition of a new building to an urban area. However both these examples are often done using CAD packages.\n\nto impress an audience - which while no doubt effective to get an interest by stakeholders in a GIS, may not provide analytical benefits.\n\n\n\nWhilst 3D data is often critical (for floodplain analysis, river profiles, geological surveys etc.) does a 3D viewer add anything?\n I can currently only think of two cases:\n\nto visualise potential changes in a landscape, such as the effect of adding windfarms, or the addition of a new building to an urban area. However both these  &hellip; "
    },
    {
        "question": "Changing shapefiles from geographic (WGS84) to projected (EPSG:2263) coordinate system using QGIS",
        "area": [
            "qgis",
            "coordinate-system",
            "wgs84",
            "nad83"
        ],
        "text": "This answer has four sections:\n\nWhat you should do to solve the problem and what you should avoid\nAn example to better illustrate why assigning CRS and reprojecting are not the same\nAn analogy that should help to make this difference better understandable\nUsing batch process to transform several layers at once in QGIS\n\n1. What you should (not) do to solve the problem\nDo NOT &quot;change&quot; the CRS. When you , you simply assigning another CRS definition to your layer. You should never do that if you&#39;re not 100% sure about what you do.\nThis option is only for the case if the layer&#39;s CRS is somehow not correctly recognized - then you have to manually tell QGIS which CRS the layer was initially created in. You have to know the exact CRS, the definition the coordinates of the features are saved in.\nEach layer is saved with coordinates in a certain CRS (projection). So if you assign another CRS, the coordinates from one CRS (like EPSG:4326 / WGS84) are interpreted as being coordinate values belonging to another CRS, in your case NAD83/ New York Long Island EPSG:32118.\nTo make a comparison: it&#39;s somehow like if you had a length measurement in inches and you simply &quot;change&quot; it to meters by replacing &quot;inches&quot; with &quot;meters&quot;, but leaving the numbers as they are: .  This is what you did, simply &quot;assigning&quot; another CRS (=another definition how to interpret the numbers). This can&#39;t work - you must convert (1 inch = 0.0254 m): .\nWhat you should do is reprojecting the layer: right click on your layer /  or go to menu . There, you can define the CRS that your existing layer should be reprojected to. You will get a copy of your input layer in the new CRS.\nWhen saving, in the dialog window you have a CRS section with a drop down menu where you can select the CRS you want to reproject to. Or click on the right side the small symbol &quot;globe with grid&quot;. It will open an advanced CRS selection dialog with more information and the option to filter the CRS description by introducing some letters or numbers:\n\n\n2. Case study to illustrate assigning CRS vs. reprojection\nTo illustrate that: let&#39;s say you have coordinates in  (WGS84, GPS coordinates) 0&#176; E, 51.4777&#176; N: a point nearby the Greenwich observatory in London (today&#39;s IERS reference meridian passes a few dozen meters to the east of the observatory, but that is another story, however it shows how complex the topic is).\nIf you now change the EPSG, you assign another definition to the coordinate values of 0 and 51.4777. Let&#39;s say we tell QGIS that these values are in Web Mercator, . This defintion has it&#39;s point of origin at the intersection of the equator (red line) with the prime meridian (blue line), a point in the Atlantic west ob Gabon, south of Ghana: the red cross on the following map:\n\nThis point of origin is the same as when using . But  is a projected CRS, thus it measures it&#39;s coordinates not on a globe (spheroid) as  does that uses degrees as unit, but on a planar map projection and uses meters. Both start at the same point of origin in the Atlantic. So in /WebMercator, the latitude is measured in meters and our point will be 51.4777 meters to the north of this point, thus in the Atlantic very close to the point of origin. The longitude still has the &quot;right&quot; value because 0 remains zero, thus in this special case, nothing changes (to make things a bit easier here).\nYou see this on this screenshot: a point created in  with coordinates lon 0, lat 51.4777 creates a point that is a few dozen meters north of the equator (red line):\n\nTo get the &quot;right&quot; coordinates value for the point near the Greenwich observatory in , we must use a transformaton algorithm. QGIS normally handels this automatically when we reproject. But often there are several different algorithms for the transformation available. In such cases, QGIS alerts with a dialog window where we can choose one of the available transformations - see the following screenshot. The background: this has to do with different mathematical methods of transformation. Calculating the earths shape to different projections is not so trivial and is almost always not 100% exact, so you always get minor errors when reprojecting - see the info about the accuracy in the screenshot:\n\nWhen we reproject, we see that the latitude for our point near Greenwich observatory is 6706107.21 in  - that means: 6706.1 km to the north of the point of origin in the Atlantic. Be aware: this value is not a distance on earth&#39;s surface, but on the projected planar map canvas. Web Mercator heavily distorts lengths, so the values in meters are of use for coordinate values only, not for measuring distances.\nWe could now use another projected CRS, let&#39;s say ,  Ordnance Survey, British National Grid. After transformation, we see that the same point near Greenwich observatory has again other coordinates: lat: 177234.2, lon: 538989.7. These values are again in meters, but are completely different from the meters we had before when using Web Mercator. So you see: the values only make sense if they are interpreted in the correct CRS.\n\n3. An analogy that should help to make this difference better understandable\nAn analogy of the difference between set CRS and reproject, as this is a very common mistake a lot of users make: To better understand, you could imagine the different CRS as different &quot;languages&quot; (conventions about the meaning of symbols). If you have a text and try to translate it, you must first know in which language your text is to be able to look for the right dictionaries, hire the right interpreter or do the correct setting in the automatic translation tool.\nWhen you have a text in English and want to have a translation into Chinese, you can&#39;t just stick the label &quot;Chinese&quot; on the first page: this does not translate it. To the contrary, the text will make no sense: a native speaker of Chinese will still not be able to understand it (without knowing English) as the English words have no meaning in Chinese. Maybe some words happen to sound similar in both languages, but with completely different meaning: that&#39;s what happened to you: your layer was shown in QGIS, but in a wrong, meaningless place.\nSo that should help understand why you can&#39;t simply &quot;change&quot; the language. You must translate - the analogy of reprojecting in QGIS: every word/sentence must be taken from one language to the other one, according to certain rules (grammar). The same with reprojecting: every coordinate has to be recalculated respecting some transformation algorithms.\nIf you use an online translation tool as Google translate, the language of many texts you paste is automatically recognized. This is what QGIS also tries: when you load data, you normally should not have to set manually the CRS, as in almost all cases the CRS should be already stored in your data. So only if the CRS is not correctly recognized, you should manually assign the correct CRS.\n\n4. Using batch process to transform several layers at once in QGIS\nIf you have several files or layers, you run this as batch process. Just start the reproject dialog using the menu (as described above), than you find a button at the bottom left to start the tool as batch process, see:\n\n We could now use another projected CRS, let&#39;s say EPSG:27700,  Ordnance <span class=\"highlight\">Survey</span>, British National Grid. &hellip; "
    },
    {
        "question": "Seeking qml or sld file for QGIS + OpenStreetMap data?",
        "area": [
            "qgis",
            "openstreetmap",
            "sld",
            "qml"
        ],
        "text": "I&#39;m looking for a qml file (or equivalent e.g. sld) to allow me to use QGIS to take OpenStreetMap data and produce paper maps. I&#39;m re-asking this question (it was asked once or twice over a couple of years by other people) because I&#39;m really surprised not to easily find such a thing already (I looked hard). \n\nI have found Anita Graser&#39;s styles - which are good, but only style basic data like roads (and do so simply). I&#39;ve successfully followed the directions for getting OSM data to work with. I&#39;ve carried out some basic style editing successfully. I realise I could create my own styles for this purpose - but this seems like a very big job. I want a visually pleasing map taking into account most of the data available on OSM (i.e. not just streets, but tracks, paths, rivers, woods, lakes, buildings and so on). I&#39;d have thought that there would be other people out there already doing the same... It seems odd to have to re-invent the wheel when both OSM and QGIS are open source / open data projects. I feel like maybe I&#39;ve just missed the obvious repository of OSM qml files which resides out there on the internet somewhere if you know where to look.\n\nAdditional notes in response to query below...\n\nIdeally I&#39;m looking for a Mapnik style rendering of the OSM data, but any equivalent properly developed and complete style would be good.\n\nAt the moment the objective is to use this data to produce paper mapping, but simple use of the mapping as base data on which other geographic data can be displayed also requires a decent rendering. At work I use Ordnance Survey data completely styled to produce a full and very detailed UK map (the point being that I didn&#39;t have to design this styling, it came with the data). I realise that other tools exist for paper mapping, but the same issues tend to arise at one stage or another... I&#39;m more or less successful in making the tool work for me in really basic terms, but to get to something visually useful I end up back with me either needing to re-invent a complete rendering style from scratch (beyond my skill), or encountering such a complex set of requirements for database setups or whatever that the process crashes and burns before I get anywhere useful. With a few more years of GIS experience I&#39;ll maybe be a database, CartoCSS (or whatever else) wizz... but until then I&#39;m prevented from using the amazing resource that OSM provides by this one barrier.\n\nUpdate (July 2015): Please note that I&#39;m still looking for information on this, and given that I&#39;ve just been informed that the question has had 2500 views in the last year clearly others are too.\n At work I use Ordnance <span class=\"highlight\">Survey</span> data completely styled to produce a full and very detailed UK map (the point being that I didn&#39;t have to design this styling, it came with the data). &hellip; "
    },
    {
        "question": "Differences between triangulation and trilateration",
        "area": [
            "gps",
            "gis-principle",
            "trilateration",
            "triangulation-survey",
            "triangulation"
        ],
        "text": "It&#39;s already explained in the terms:\n\nTriangulation = working with angles\nTrilateration = working with distances.\n\nIn real world applications you often work with both, or combine them. For example, total station surveys measure both distances and angles. On the other hand, GPS receivers use trilateration concepts, where speed and time equals a distance, to determine your position.\n It&#39;s already explained in the terms:\n\nTriangulation = working with angles\nTrilateration = working with distances.\n\nIn real world applications you often work with both, or combine them. For example, to &hellip; "
    },
    {
        "question": "How to create an accurate Tissot Indicatrix?",
        "area": [
            "coordinate-system",
            "gis-principle"
        ],
        "text": "Any software that can project coordinates accurately can compute accurate Tissot indicatrices.\n\nA good source for the formulas is Snyder, John, Map Projections--A Working Manual, primarily at pp 20-26.  (I won&#39;t reproduce them here because this site doesn&#39;t have appropriate tools for communicating mathematical formulas.)  They require all four first derivatives of the projected coordinates (x,y) with respect to the spherical coordinates (lat, lon) = (phi, lambda):\n\n\n\nEverything else about the TI&#39;s is computed in terms of these (using some arithmetic and trigonometric functions: the cosine, principal inverse sine, and principal inverse tangent).  The computations require a description of the earth&#39;s shape.  For the greatest accuracy use an ellipsoidal datum with semimajor axis a and eccentricity e.  (These will be known to the software.)\n\nSnyder&#39;s book has instructions on how to compute everything except these derivatives.  Do it numerically.  I have had excellent results using first-order central finite difference estimates at a distance of h = 10^(-5.2) radians (typically around 50 meters): this is a good compromise between trying to get infinitesimally close and losing too much precision from floating point roundoff (assuming double precision), because the error made is proportional to (10^(-5.2))^2 = 10^(-10.4) and 10^(-5.2) equals 10^10.4 times the IEEE double precision accuracy of 10^(-15.6) and it&#39;s still a lot larger than typical precision in projections, which usually run from 10^(-10) to about 10^(-14).\n\nSo, how do you compute finite difference estimates?  This part is surprisingly easy.   To obtain dx/d(phi) at a point (phi, lambda), ask your GIS to project the points\n\n\n\nUse the estimates\n\n\n\nSimilarly, project the points\n\n\n\nand use the estimates\n\n\n\nThat takes four projections and a tiny bit of arithmetic.  (You can reduce it to three by using non-central differences, but the accuracy goes down a little.  It&#39;s wise aim for high accuracy, without letting h get too small, unless you are sure your GIS is using survey-grade (millimeter) accuracy in its projection formulas.)\n\nFrom these derivatives, along with Snyder&#39;s formulas (paying attention to the modifications described at 4-19 and 4-21), you can obtain the lengths of the axes of the Tissot Indicatrix at (phi, lambda) and its orientation.  On world-scale maps the TI will be so small as to be invisible, so the final thing to do is decide how much you want to rescale each TI.  I determine the scale factor by finding out how large the map will be, finding the sizes of typical TIs across the map, and scaling so that those TIs will be approximately 6% as wide as the map.  It&#39;s a good start, anyway; I let the user adjust the size of the TI from there.  Of course you will rescale all the TIs by the same amount, so they can be compared, and each will be rescaled around its own center (which is obtained by a fifth projection, (phi, lambda) --&gt; (x,y)).\n\nA nice addition to the elliptical portrayal of the TI is to show the directions of the local meridian and parallel: then, at a glance, you can assess the grid convergence.  I also show a standard circle (representing no distortion) concentric with each TI because it improves the reader&#39;s ability to gauge the amount of distortion represented by each ellipse.\n\n\n\nOf note in this Mollweide projection is the extreme TI near the south pole.  It is still a perfect ellipse and accurately describes the map distortion there.\n It&#39;s wise aim for high accuracy, without letting h get too small, unless you are sure your GIS is using <span class=\"highlight\">survey</span>-grade (millimeter) accuracy in its projection formulas.) &hellip; "
    },
    {
        "question": "Merging adjacent polygons in shapefile that has been split at tile boundaries?",
        "area": [
            "qgis",
            "shapefile",
            "vector",
            "dissolve",
            "ordnance-survey"
        ],
        "text": "I&#39;m currently using building data from the Ordnance Survey Vectormap District and I&#39;ve noticed that a lot of building polygons are split in 2 because of the way the OS split up the shapefile.\n\nThis is what I&#39;m seeing in QGIS \u2013&#160;I&#39;ve highlighted some of the buildings split at the tile boundary:\n\n\n\nI can&#39;t manually merge the buildings as there are way too many of them that have been split at the boundaries (this is just a zoomed in example). I&#39;m looking for an automated way to solve this.\n\nUnfortunately, each side of the split buildings has a different id so I can&#39;t easily dissolve them.\n\nHow would you suggest I can automatically merge the building tiles?\n\nEdit\n\nI&#39;m now using PostGIS to merge the polygons split at the tile boundaries. Here is the SQL statement that does this for me \u2013&#160;it&#39;s many, many times faster than doing it with QGIS:\n\n\n\n\n I&#39;m currently using building data from the Ordnance <span class=\"highlight\">Survey</span> Vectormap District and I&#39;ve noticed that a lot of building polygons are split in 2 because of the way the OS split up the shapefile. &hellip; "
    },
    {
        "question": "Why do valid polygons repeat the same start and end point?",
        "area": [
            "polygon",
            "polygon-creation",
            "storage"
        ],
        "text": "That convention goes back to the surveying industry; which has a point of beginning. So you start at a point in space, and the last point you reference is your closing point. This way you have a closed object. So to build a full COGO object you need to have a complete description of what is being described. Its more accurate than a assumed close.\n That convention goes back to the <span class=\"highlight\">surveying</span> industry; which has a point of beginning. So you start at a point in space, and the last point you reference is your closing point. &hellip; "
    },
    {
        "question": "Generally accepted root mean square (RMS) error for rectifying topographic maps",
        "area": [
            "georeferencing",
            "accuracy"
        ],
        "text": "No, there is no absolute value for RMS, because it depends on the quality of the map being georeferenced, the quality of the target (base) map, and the purpose of the georeferencing.  In particular, any advice that relates RMS to cellsize is misinformed, because cellsize reflects precision in the digital representation of an image whereas the RMS error reflects average accuracy (assuming the basemap is perfectly accurate).  Although distinguishing precision and accuracy may seem like aimless pedantry, confusing them is a basic mistake with practical consequences.\n\nAll this is rather vague, so let&#39;s look at a specific example.  Recently I received a series of screenshots of maps showing soil sample locations.  To obtain coordinates, I planned to georeference these screenshots to an orthophoto base map and then digitize the points with heads-up digitization.  Among the considerations were:\n\n\nThe orthophoto base map has 0.3 m cellsize.\nThe screenshots have approximately 2 m cellsize.\nThe soil sample locations were not surveyed; they were located &quot;by eye&quot; on the map when the sampler was in the field.  The client estimated the accuracy was about 3 m, but 10 m is more likely.\nThe screenshots have few sharp details: they are primarily contour lines, with occasional fencelines (which are not clearly visible in the orthophoto).  Thus establishing many good links would be time-consuming and error-prone.\nThere was likely some local distortion in the screenshots, meaning that high accuracy (low RMS) can be achieved only with complex transformations.\nIt was important to digitize the soil sample locations so that relative distances were fairly accurate for nearby points, but absolute accuracy was unnecessary, because one outcome of the study will be to obtain many more soil samples that refine and make more precise this preliminary survey.\n\n\nTo obtain an RMS of half the larger cellsize would require a high-order polynomial transformation or warping across a grid of points, calling for establishing a network of around 50 - 100 good links between the images: one to several hours of careful work, most likely, given the difficulty of even finding visible links.  To obtain an RMS of half the smaller cellsize would require an order of magnitude more effort: days of work.  However, for the purposes of the study an RMS of 5 m would be more than sufficient.  This was achieved with 7 links and an affine transformation, just a few minutes&#39; work.  Note that this RMS is several times greater than the larger of the two cellsizes in the images.\n\nThis example illustrates how blindly following bad rules of thumb can be costly.  Pay attention first to your data quality objectives; everything else follows from them.\n fairly accurate for nearby points, but absolute accuracy was unnecessary, because one outcome of the study will be to obtain many more soil samples that refine and make more precise this preliminary <span class=\"highlight\">survey</span> &hellip; "
    },
    {
        "question": "Removing small &quot;salt &amp; pepper&quot; polygons from layer in QGIS?",
        "area": [
            "qgis",
            "polygon",
            "point"
        ],
        "text": "It seems like you&#39;re working with Ordnance Survey Code-Point data, which is a dataset of the postal code areas in Great Britain and Northern Ireland.\n\nThe &quot;points&quot; you&#39;re referring to are small square polygons that represent so-called &quot;vertical streets&quot;: stacks of more than one post code, which can&#39;t be represented using &quot;conventional&quot; polygons (see Andy Harfoot&#39;s comment for more details). You might want to think twice about removing these polygons if you need the affected postal codes for your analysis.\n\n\n\nThat said, here&#39;s how you can remove these polygons:\n\n\nSelect all vertical street polygons by clicking &quot;Select Features Using an Expression&quot;  and entering . This will select all features that have a postal code starting with , which are the vertical streets.\n\n\nSimply deleting the features won&#39;t help, since the polygons will leave holes behind, as you have already noticed. Instead, you can merge the vertical streets with a neighbouring large polygon using &quot;Vector / Geoprocessing tools / Eliminate sliver polygons&quot;, saving the result to a new file.\n\n\nYou may get the warning message that some features could not be dissolved, together with a list of feature ID&#39;s. If you also want to get rid of these features, select the vertical streets in the new layer using the expression from before, and then do one of the following:\n\n\nIf you want an automatic solution, you can dissolve the vertical streets togehter with all neighbouring polygons. Save the selection to a new layer using &quot;Layer / Save selection as vector file&quot;, and then use &quot;Vector / Research Tools / Select by location&quot; to select features in the merged layer that intersect with the offending vertical streets, creating a new selection. Then dissolve this selection using &quot;Vector / Geoprocessing Tools / Dissolve&quot;, choosing  in the &quot;Dissolve field&quot;. Note that this approach can lead to the undesired dissolution of &quot;proper&quot; polygons if the offending vertical street is on the boundary of two other polygons, or if there are offending vertical streets within two neighbouring polygons.\nIf you want to avoid dissolving other polygons, you can manually select the vertical streets and one adjacent polygon, taking care not to select two neighbouring polygons, and then dissolving them as above.\n\n\n It seems like you&#39;re working with Ordnance <span class=\"highlight\">Survey</span> Code-Point data, which is a dataset of the postal code areas in Great Britain and Northern Ireland. &hellip; "
    },
    {
        "question": "Seeking introductory books or articles about Open Source GIS for students coming from Esri background",
        "area": [
            "open-source-gis",
            "references"
        ],
        "text": "I am preparing an intermediate GIS course for graduate and undergraduate students who have likely not been in touch with anything but Esri software. It is an existing course in the curriculum that I will be teaching for the first time. Currently, ArcGIS is the software of choice for the lab sections and practical assignments.\nI want to tweak the course a little to include an introduction to Open Source GIS alternatives. For now, this part of the course will only be two to four weeks (I&#39;m thinking a kind of extended epilogue) so I won&#39;t be able to dig too deep. I hope to branch this off into a full Open Source GIS course next year, but curriculum constraints prohibit me from doing that right away.\nHere&#39;s some reading I have been considering to support the Open Source GIS part of the course, to give you an idea of what I&#39;m (not) looking for:\n\nThe Geospatial Desktop is a book I&#39;d love to use for a full Open Source GIS course but is too much to cover in a few weeks. The chapter &#39;Survey Of Desktop Mapping Software&#39; looks like something I could use.\nThe Dekstop GIS book is of similar breadth but currently out of print.\nThe Grass Book seems too focused on GRASS. I think GRASS will put students with an ArcGIS mindset off. Also, I want them to learn about the breadth of the OS geospatial software spectrum.\n&#39;How to go from GIS novice to Pro without spending a Dime&#39; takes a good, practical approach to delving into OS GIS, and has good links for further reading.\nA white paper from OpenGeo talking about markets for geospatial software, and how that landscape is changing.\n\nCan you suggest other articles and / or books that would be useful to ease students coming from an Esri / ArcGIS background into becoming aware of and using Open Source alternatives?\n The chapter &#39;<span class=\"highlight\">Survey</span> Of Desktop Mapping Software&#39; looks like something I could use.\nThe Dekstop GIS book is of similar breadth but currently out of print.\nThe Grass Book seems too focused on GRASS. &hellip; "
    },
    {
        "question": "Using R to calculate the area of multiple polygons on a map that intersect with another overlaid polygon",
        "area": [
            "shapefile",
            "r"
        ],
        "text": "I have a shapefile downloaded from the Ordnance Survey that gives electoral ward (division) boundaries for a county of the United Kingdom. I have successfully used R to load the shapefile and plotted various maps using  as described in this question. It&#39;s all working rather well. \n\nNow I would like to create a new polygon of arbitrary shape, add it to the map, then calculate the population living in the area lying under the shape, which might cover or partially cover multiple divisions. I have the population for each electoral division and I can make the simplifying assumption that the population in each ward is uniformly distributed. That suggests the following steps.\n\n1) Overlay a new shape on the map that partially covers multiple electoral divisions. Let&#39;s say there are 3 divisions, for the sake of argument. It would look something like this. [Edit: except that in the image below the shape straddles 5 divisions rather than 3]\n\n\n\n2) Calculate the percentage of the area of each of these 3 divisions that intersects with the overlaid polygon.\n\n3) Estimate population by getting the percentage of the area of each division covered by the overlaid shape and multiplying this by the population of each division.\n\nI think I can probably work out how to create the polygon and overlay it on the map i.e. add it to the existing data frame using the useful answer to this and other questions. The bit that worries me is the task of working out the percentage of each division that is covered by the overlaid shape. The  and  columns in the data frame are those strange Ordnance Survey OpenData figures (Eastings and Northings or something). \n\nSo my first question is: How would I go about finding the area (or a subset of the area) of the polygons that define the borders of an electoral division using this data? Because even a meaningful subset of this data frame is large I have used  to create a 500k file (which can be copied and pasted or downloaded from here) rather than posting it in this question. The map that forms the base for the image above was created with the following:\n\n\n\nMy second question is: am I using the right tools? Currently I am using  from the  package to read the shapefile. I then use  to create a data frame of about 130k lines, suitable for use in . Maybe I should be using a different package if there is one with useful tools for such processes?\n I have a shapefile downloaded from the Ordnance <span class=\"highlight\">Survey</span> that gives electoral ward (division) boundaries for a county of the United Kingdom. &hellip; The lat and long columns in the data frame are those strange Ordnance <span class=\"highlight\">Survey</span> OpenData figures (Eastings and Northings or something). &hellip; "
    },
    {
        "question": "Is WGS84 a Coordinate system or projection system?",
        "area": [
            "coordinate-system",
            "wgs84",
            "geodesy"
        ],
        "text": "So there are two pieces to what someone might call a Coordinate System\n\nThe first is a Geographic Coordinate System or GCS, which is what WGS84 falls under. The definition given by ESRI states that a GCS uses a three-dimensional spherical surface to define locations on the earth. Basically, a GCS is used to define your real world points on a 3 dimensional digital surface. Examples of this include WGS84 (World Geodetic Survey 1984), NAD83 (North American Datum 1983), or NAD27 (used before NAD83. North American Datum 1927)\n\nThe other is a Projected Coordinate System or PCS. A PCS is used to take those points that you defined with your GCS and translate them to a 2-dimensional surface. This is what people commonly refer to as a &quot;projection&quot;. This can include things like Robinson, Albers Equal Area, and (one of my personal favorites) Waterman butterfly.\n\nThese are different parts and are made up of different pieces, but both of these together create a coordinate system. This is the very simple definition of both, but if you want to get into the math of everything, ESRI has good documentation in their resources section discussing map projections. Wikipedia&#39;s page on map projections also does a very good job of explaining the different types of PCSs, what distortions are caused, etc. Many projections also have their own pages explaining their history, math, etc.\n Examples of this include WGS84 (World Geodetic <span class=\"highlight\">Survey</span> 1984), NAD83 (North American Datum 1983), or NAD27 (used before NAD83. &hellip; "
    },
    {
        "question": "How to convert GeoTIFF to grayscale and add gaussian blur?",
        "area": [
            "geoprocessing",
            "gdal",
            "geotiff-tiff",
            "imagery",
            "aerial-photography"
        ],
        "text": "GDAL has a wonderful file format called VRT, which is an XML wrapper around one or more raster files.\nOne feature of VRTs is their ability to encode square convolution kernels for any given band. It does involve playing around with XML in a text editor (or programatically), but if you&#39;re already used to the GDAL tools, it shouldn&#39;t be too hard.\nExample&#39;s input\nTo illustrate, I took this image of some Ordnance Survey data from around the old OS building in Southampton:\n\nEmbed into .vrt\nAnd ran gdalbuildvrt to generate an initial VRT file:\n\nEdit metadata\nThen I replaced the  elements with  elements and add in the element  with a  and  (coefficients) for a 5x5 Gaussian convolution kernel:\n\nYou can get alternative values thanks to an online Gaussian Kernel Calculator.\nConvert back to .tiff\nThen ran gdal_translate to convert to a TIFF:\n\nWhich gives me this image:\n\nWith its georeferencing data intact, which you can check via :\n\nGrey scale\nFor the greyscale part, I suggest you use Quantum GIS and its good (if currently slightly quirky) Raster Calculator. Simply load up your blurred image, select  and use the following expression:\n\nLoading that image into QGIS, gives me:\n\nOther coefficients can be used for the greyscale conversion, but those are a good starting point.\nAlso, it shouldn&#39;t matter whether you blur first then reduce, or the other way round.\n Example&#39;s input\nTo illustrate, I took this image of some Ordnance <span class=\"highlight\">Survey</span> data from around the old OS building in Southampton:\n\nEmbed into .vrt\nAnd ran gdalbuildvrt to generate an initial VRT file:\ngdalbuildvrt &hellip; "
    },
    {
        "question": "Source for high-resolution satellite images free/low-cost?",
        "area": [
            "data",
            "remote-sensing",
            "google-earth",
            "google-earth-engine",
            "kenya"
        ],
        "text": "I am doing a household survey in Kenya, and I need to ensure that my survey team visits every house within a given area.  I&#39;ve been going to google maps and right-clicking on roofs to get coordinates via the &quot;what&#39;s here&quot; option.  This is really an inefficient use of time.\n\nI&#39;d prefer to have a high-resolution image that I could upload to google earth engine, and then perform a machine-learning algorithm to identify roofs.  I&#39;d want to get a text file of the lat/longs of all the houses, which I could then cluster by distance and give to my surveyors, both in map and in checklist format.\n\nBut the images in google maps satellite view are copyrighted and not available in earth engine.  So I need images at high-enough resolution to identify corrugated iron and straw thatch roofs, with roughly ~3km^2 spatial extent.\n\nWhat are some good sources for such data?  Ideally that will give it freely or cheaply to graduate students and/or nonprofits?\n I am doing a household <span class=\"highlight\">survey</span> in Kenya, and I need to ensure that my <span class=\"highlight\">survey</span> team visits every house within a given area. &hellip; "
    },
    {
        "question": "Spatial data? Geodata? Geographic Data? Geospatial data?",
        "area": [
            "data",
            "terminology"
        ],
        "text": "There is a good information about these terms on Basudeb Bhatta&#39;s Blog at this link, copied below. \n\n@Brad Nesom&#39;s definitions are good but I thought that geodata was an abbreviation of &quot;geographic data.&quot; However, Brad&#39;s definition of geodata is quite logical.\n\nBeside these in my opinion:\n\n\n\n...\n\n\n  Often my students ask about the difference(s) between spatial and\n  geospatial. These two words appear very frequently in remote sensing\n  and GIS literature.\n  \n  The word spatial originated from Latin &#39;spatium&#39;, which means space.\n  Spatial means &#39;pertaining to space&#39; or &#39;having to do with space,\n  relating to space and the position, size, shape, etc.&#39; (Oxford\n  Dictionary), which refers to features or phenomena distributed in\n  three-dimensional space (any space, not only the Earth&#39;s surface) and,\n  thus, having physical, measurable dimensions. In GIS, &#39;spatial&#39; is\n  also referred to as &#39;based on location on map&#39;.\n  \n  Geographic(al) means &#39;pertaining to geography (the study of the\n  surface of the earth)&#39; and &#39;referring to or characteristic of a\n  certain locality, especially in reference to its location in relation\n  to other places&#39; (Macquarie Dictionary). Spatial has broader meaning,\n  encompassing the term geographic. Geographic data can be defined as a\n  class of spatial data in which the frame is the surface and/or\n  near-surface of the Earth. &#39;Geographic&#39; is the right word for graphic\n  presentation (e.g., maps) of features and phenomena on or near the\n  Earth&#39;s surface. Geographic data uses different feature types (raster,\n  points, lines, or polygons) to uniquely identify the location and/or\n  the geographical boundaries of spatial (location based) entities that\n  exist on the earth surface. Geographic data are a significant subset\n  of spatial data, although the terms geographic, spatial, and\n  geospatial are often used interchangeably.\n  \n  Geospatial is another word, and might have originated in the industry\n  to make the things differentiate from geography. Though this word is\n  becoming popular, it has not been defined in any of the standard\n  dictionary yet. Since &#39;geo&#39; is from Greek &#39;gaya&#39; meaning Earth,\n  geospatial thus means earth-space. NASA says &#39;geospatial means the\n  distribution of something in a geographic sense; it refers to entities\n  that can be located by some co-ordinate system&#39;. Geospatial data is to\n  develop information about features, objects, and classes on Earth&#39;s\n  surface and/or near Earth&#39;s surface. Geospatial is that type of\n  spatial data which is related to the Earth, but the terms spatial and\n  geospatial are often used interchangeably. United States Geological\n  Survey (USGS) says &quot;the terms spatial and geospatial are equivalent&quot;.\n\n United States Geological\n  <span class=\"highlight\">Survey</span> (USGS) says &quot;the terms spatial and geospatial are equivalent&quot;. &hellip; "
    },
    {
        "question": "Resampling to highest or lowest resolution when dealing with rasters of varying resolutions",
        "area": [
            "resolution",
            "resampling"
        ],
        "text": "Actually it&#39;s not all that situation dependent and is all about statistical error.\n\nAny time you resample to a higher resolution, you are introducing false accuracy. Consider a set of data measured in feet at whole numbers only. Any given point may be +/- 0.5 feet from its actual location. If you resample to the nearest tenth, you are now saying any given number is no more than +/- 0.1 from its actual location. Yet you know your original measurements were not that accurate, and you are now operating within the margin of error. However if you go the other way and resample to the lower resolution, you know that any given point value is definitely accurate because it is contained within the larger sample&#39;s margin of error.\n\nOutside of statistical math, the first place that this comes to mind is in land surveying. Older surveys only specified bearings down to the nearest half-minute and distances to the tenth of a foot. Plotting a boundary traverse with these measurements can often result in a misclosure (the start point and end point should be the same but are not) measured in feet. Modern surveys go to at least the nearest second and hundreth of a foot. Derived values (such as the area of a lot) can be significantly affected by the difference in precision. The derived value itself can also be given as overly precise. \n\nIn your analysis case, if you resample to the higher resolution your results will imply a much greater accuracy than the data on which they are based. Consider your SRTM at 90m. By whatever method they measure the elevation (avg/max/mean return), the smallest unit (pixel) that can be differentiated from its neighbors is 90m. If you resample that to 30m, either:\n\n\nyou assume all nine of the resulting pixels are that same elevation when in\ntruth maybe only one - the center, or the top left - (or none!) is\nyou interpolate between pixels, creating derived values not present\nbefore\n\n\nThus in both cases you introduce false accuracy because your new subsamples were not actually measured.\n\nRelated question: What practices are available for modelling land suitability?\n Outside of statistical math, the first place that this comes to mind is in land <span class=\"highlight\">surveying</span>. Older surveys only specified bearings down to the nearest half-minute and distances to the tenth of a foot. &hellip; "
    },
    {
        "question": "Quality of free geodata compared to commercial sources",
        "area": [
            "google-maps",
            "spatial-database",
            "openstreetmap"
        ],
        "text": "See this paper (draft version):\n\n\n  Haklay, M. (2010), How good is volunteered geographical information? A\n  comparative study of OpenStreetMap and Ordnance Survey datasets.\n  Environment and Planning B: Planning and Design 37(4) 682 \u2013 703.\n\n\nfor more rigorous assessment (in UK context). \n\nThis one for assessment (in comparison wth Google Maps &amp; Bing Maps) in Ireland:\n\n\n  Ciep\u0142uch , B., Jacob, R.,Mooney, P., Winstanley, A. (2010) Comparison\n  of the accuracy of OpenStreetMap for Ireland with Google Maps and Bing\n  Maps. Proceedings of the Ninth International Symposium on Spatial\n  Accuracy Assessment in Natural Resuorces and Enviromental Sciences\n  20-23rd July 2010 . p. 337.\n\n\nAnd this for assessment in France (paywall):\n\n\n  Girres, J.-F. &amp; Touya, G. (2010) Quality Assessment of the French\n  OpenStreetMap Dataset. Transactions in GIS, 14, 435-459.\n\n\nGermany is covered in this paper:\n\n\n  Zielstra, D., Zipf, A. (2010) Quantitative Studies on the Data Quality of\n  OpenStreetMap in Germany. Paper presented at GIScience 2010.\n\n\nVery thorough comparison with TomTom data (in Germany as well) is covered here:\n\n\n  Helbich, M., Amelunxen, C., Neis, P. (2012): Comparative Spatial\n  Analysis of Positional Accuracy of OpenStreetMap and Proprietary\n  Geodata. Int. GI_Forum 2012. Salzburg. Austria.\n\n\nGerman street network is also discussed in detail here:\n\n\n  Neis, P.; Zielstra, D.; Zipf, A. (2012) The Street Network Evolution of\n  Crowdsourced Maps: OpenStreetMap in Germany 2007\u20132011. Future Internet\n  4, 1-21.\n\n\nThere also two Master&#39;s dissertations dealing with this topic: one from UCL:\n\n\n  Kounadi, O. (2009) Assessing the quality of OpenStreetMap data.\n\n\nand one presented at GI_Forum:\n\n\n  Stark, H-J. (2010) Quality assessment of crowdsourced geocoded\n  address-data within OpenAddresses\n\n\nAlso article from Cartographica (paywall) might be of interest:\n\n\n  Mondzech, J. &amp; Sester, M., (2011) Quality Analysis of OpenStreetMap\n  Data Based on Application Needs. Cartographica: The International\n  Journal for Geographic Information and Geovisualization, 46, 115-125.\n\n A\n  comparative study of OpenStreetMap and Ordnance <span class=\"highlight\">Survey</span> datasets.\n  Environment and Planning B: Planning and Design 37(4) 682 \u2013 703.\n\n\nfor more rigorous assessment (in UK context). &hellip; "
    },
    {
        "question": "Is PhD in GIS useful in non-educational career path?",
        "area": [
            "career"
        ],
        "text": "A bit of an open debate - I am curious for your opinions. I am considering commencing a PhD in GIS which may concern the application of surveys within the natural environments. Eventually, I wish to continue my career in professional consultancy and not to pursue academia beyond these studies.\n\nI wonder whether anybody has any experience or can just share their thoughts about how useful is to have a GIS PhD in a professional industry. My concern is that people have told me that for some professions (e.g. Law), having a PhD qualification can in fact reduce your employability.\n\nHow is it seen by industry employers to have a PhD in GIS? Also, are there any specific sites or tips anyone can suggest?\n A bit of an open debate - I am curious for your opinions. I am considering commencing a PhD in GIS which may concern the application of surveys within the natural environments. Eventually, I wish to c &hellip; "
    },
    {
        "question": "Seeking software for making digital elevation models from UAV aerial imagery",
        "area": [
            "python",
            "dem",
            "software-recommendations",
            "unmanned-aerial-vehicle"
        ],
        "text": "To solve the problem one needs to transform 2D images of 3D structures from different angles/perspectives into a solid model. This was earlier a manual job, but software allows for automated processes.\nRemember that processing software could provide both digital surface models (DSM) or digital elevation models (DEM)\nProducts from such processes can include Digital Elevation Models as well as Point Clouds, Digital Surface Models, Textured Digital Surface Models, Orthorectified Imagery and Classified Point Clouds. This is known as Structure from Motion analysis.\nProcessing can be done locally, through online services or a combination of the two. The software is basically the same, although one will find that local processing allows for more specialized settings.\nLocal processing\n\npix4D is an overall good tool providing exceptional ease of use for inexperienced to more experienced users. In addition to provide a desktop tool it also integrates with a cloud based service. A youtube video introduces the software in a good way. It is a bit in the high end with re to price.\nAgisoft Metashape (formerly known as PhotoScan) is available for Windows, OSX and Linux. Agisoft is flexible on the platform side. Having tried it out it produces good terrain models and ortophotos. A feature which lacks on Pix4D is the ability to set up batch jobs. You can also script the processing using a python API.\nDrone2Map from ESRI can create orthomosaics, 3D meshes and more. This is not an integrated ArcGIS desktop tool, but effectively a stand alone 64 bit application. On their webpage they state that: &quot;Drone2Map for ArcGIS is powered by Pix4D.&quot; Opposed to Pix4D the information provided to the user while calculating is poor. From what I understand this is Pix4D under the hood under a different licensing model.\nOpenDroneMap now provides a desktop version, WebODM, which runs fine on a desktop computer. It will let you create good ortophotos, digital elevation models as well as the rest of the products mentioned in the beginning of this answer. Set up correctly the tool can process projects of more than 4.000 images. It is important the computer has enough memory to do the processing. 32 GB or more is advised for projects over 2.000 pictures. You can also find code and more on github.\nERDAS Imagine have an UAV add-in module. Combined it&#39;s more expensive than Agisoft Photoscan, but if you&#39;re already an ERDAS user it integrates really well.\n3Dsurvey in addition to imagery analysis also offers what looks like good point cloud editing tools.\nOnline services\n\nProcessing of aerial imagery is resource demanding and will require some serious hardware. Online services are therefore pay-as-you-go or tied to a license.\nDronemapper is an online service where you can upload imagery and have it processed.\nDronedeploy was initially made as a planning and processing framework for DJI drones. It now supports creating maps and 3D models for any drone imagery. One can also do analysis based on the imagery. Produces good maps. Their app is also a marketplace where you can install apps for free.\nMicaSense MicaSense Atlas is a cloud-based data platform for processing, storage, management, presentation, and analytics of multispectral data captured with professional multispectral cameras like the MicaSense RedEdge and Parrot Sequoia.\nMaps Made Easy is another provider of online processing and data management.\n3Dsurvey Is also an option.\nCombined services\npix4D also provides an online processing service for users with a desktop license.\nApps\nApps seem to be more and more popular. They usually serve several purposes.\n\nHelp the user to plan surveys\nTake pictures according to the plan\nUpload survey plans to the drone\nProvide updated information from the drone during a survey\nHelp the user to adjust plans during a survey based on earlier flights\nFacilitate for upload of data so that data can be processed using an online service.\n\nDroneDeploy has an app which has an extraordinary update rate. The app is very flexible and also has an option to use plugins to focus the survey effort. Recent (July 2017) updates fixed issues with image spacing, but at the same time put limitations on the flight speed.\nPix4D Capture provides a stable work tool for collecting aerial images. It is probably the best available. On the downside the app has some shortcomings (unclear exposure settings, accurate control of speed, manual and not flexible way of controlling flight direction, lacking upload of survey areas (only android has this) and more) which should be fixed. It is rarely updated.\nDronelink and Litchi allow programmatically controlling your drone, including flying a structured mapping mission among others. Pricing can be more affordable compared to some of the above, especially for individuals. Dronelink in particular is usable for mapping with the DJI Mini, which otherwise does not allow enough automated control using some of the other apps.\nObsolete\nVisualSFM is a software package which in combination with CSVS might be a way to go. A youtube movie on the www.flightriot.com webpage gives a practical example of potential endpoint products. The resulting products are not referenced and as such not useful for GIS work. Visual SFM seems to be a project which lacks momentum. As far as I can see there has not been any development on the software for a couple of years.\n Help the user to plan surveys\nTake pictures according to the plan\nUpload <span class=\"highlight\">survey</span> plans to the drone\nProvide updated information from the drone during a <span class=\"highlight\">survey</span>\nHelp the user to adjust plans during a <span class=\"highlight\">survey</span> &hellip; The app is very flexible and also has an option to use plugins to focus the <span class=\"highlight\">survey</span> effort. &hellip; "
    },
    {
        "question": "What is the maximum Theoretical accuracy of GPS?",
        "area": [
            "gps",
            "accuracy"
        ],
        "text": "Ionospheric delay effects are the largest source of error in a single-frequency GPS receiver. WAAS and CORS are able to correct for this better than a receiver&#39;s almanac, so the best you can do with uncorrected GPS is typically about 15 meters. Survey-grade GPS using RTK is able to achieve centimeter accuracy.\n\n\nImage source: http://www.spatial-ed.com/gps/gps-basics/135-differential-correction-methods.html\n <span class=\"highlight\">Survey</span>-grade GPS using RTK is able to achieve centimeter accuracy.\n\n\nImage source: http://www.spatial-ed.com/gps/gps-basics/135-differential-correction-methods.html &hellip; "
    },
    {
        "question": "Linking Geoserver WMS layer to Google Earth?",
        "area": [
            "geoserver",
            "wms",
            "google-earth",
            "map-service"
        ],
        "text": "Instead of creating a KML file then using that to access Google Earth, you can instead add your GeoServer WMS directly as an overlay as below:\n\n\nFrom the menu select Add, \nselect Image Overlay, \n\n\ngive the overlay a name\n\nselect the Refresh tab\nselect WMS Parameters\nselect the Add button next to &#39;WMS Server:&#39; drop down\n\n\nAdd the URL to your service (without parameters) for example something like:\nhttp://ogc.bgs.ac.uk/cgi-bin/BGS_BGS-HPA_Radon_Potential/ows?\n(See attached image)\nClick OK \nSelect the layer you want to show on the map from the list of Transparent layers in the left hand side and add them to the list of Selected layers on the right hand side.\nClick OK\n\nNow in the &#39;New Image Overlay&#39; window you will see that the Link section has been filled out to give you something like the below string, which is the request that Google Earth will send to your GeoServer WMS server without the BoundingBox details:\n\n\nhttp://ogc.bgs.ac.uk/cgi-bin/BGS_BGS-HPA_Radon_Potential/ows?language=eng&amp;VERSION=1.1.1&amp;REQUEST=GetMap&amp;SRS=EPSG:4326&amp;WIDTH=512&amp;HEIGHT=512&amp;LAYERS=GBR_BGS-HPA_625K_RADON_POTENTIAL&amp;STYLES=default&amp;TRANSPARENT=TRUE&amp;FORMAT=image/gif\n\nTo get Google Earth to request a png instead of a gif change the FORMAT=image/gif parameter value to FORMAT=image/png\nClick OK\n\n\nThat&#39;s it\n\n\n\nThe above example use a MapServer WMS service but it&#39;s no different from a GeoServer WMS.\n\nLet&#39;s look at the GeoServer WMS service provided by the Delaware Geological Survey\n\nA GetCapabilities request has a URL like:\n\nhttp://maps.dgs.udel.edu:80/geoserver/DGS_Surficial_and_Contact_Geology/wms?SERVICE=WMS&amp;request=GetCapabilities&amp;\n\nSome example GetMap requests are:\n\nhttp://maps.dgs.udel.edu/geoserver/DGS_Surficial_and_Contact_Geology/wms?service=WMS&amp;TRANSPARENT=TRUE&amp;version=1.3.0&amp;request=GetMap&amp;EXCEPTIONS=INIMAGE&amp;FORMAT=image/png&amp;CRS=EPSG%3A4326&amp;BBOX=39.57931760121924,-75.79289049774037,39.784397224903465,-75.45691470533502&amp;WIDTH=1250&amp;HEIGHT=763&amp;LAYERS=US-DE_DGS_100k_Surficial_Geology&amp;STYLES=&amp;\n\nhttp://maps.dgs.udel.edu/geoserver/DGS_Surficial_and_Contact_Geology/wms?service=WMS&amp;TRANSPARENT=TRUE&amp;version=1.3.0&amp;request=GetMap&amp;EXCEPTIONS=INIMAGE&amp;FORMAT=image/png&amp;CRS=EPSG%3A4326&amp;BBOX=39.57931760121924,-75.79289049774037,39.784397224903465,-75.45691470533502&amp;WIDTH=1250&amp;HEIGHT=763&amp;SLD=http%3A%2F%2Fogc.bgs.ac.uk%2Fsld%2Fgeoserver-style-test-no-named-style1.sld&amp;layers=US-DE_DGS_100k_Surficial_Geology&amp;\n\nYou can click on these GetMap links and they will show you some maps in your browser. \n\nWhen we want to see the the Delaware maps in Google earth, using the above procedure, we just specify the part of the above URLS up to and including the question mark.  This part of the URL is known as the service end point.\n\nThat is, in this example:\n\nhttp://maps.dgs.udel.edu/geoserver/DGS_Surficial_and_Contact_Geology/wms?\n\nWhen we add this URL to the dialogue and then select the Geology layer we get the below map within Google Earth. \n\n\n Let&#39;s look at the GeoServer WMS service provided by the Delaware Geological <span class=\"highlight\">Survey</span>\n\nA GetCapabilities request has a URL like:\n\nhttp://maps.dgs.udel.edu:80/geoserver/DGS_Surficial_and_Contact_Geology/wms &hellip; "
    },
    {
        "question": "What causes the GPS offset/shift in China?",
        "area": [
            "gps",
            "wgs84",
            "china"
        ],
        "text": "The problem is poorly documented by authoritative sources for English speakers, despite affecting millions of people on an everyday basis. I&#39;ve spend the past two days trying to understand the situation and I&#39;ve created a Wikipedia article about the restrictions on mapping in China and about the China GPS shift problem. Below is the part of my research that answers the question.\n\nThe root of the problem is the severe restrictions that the Chinese State Council places on geographic data concerning China&#39;s air, land and waters. Mapping and surveying can only be done with authorization from the State Council, and foreigners must form a joint-venture in order to be granted authorization for surveys. There have been numerous examples of fines levied against individuals and companies breaking this (cough protectionist and isolationist cough) law.\n\nOnline map providers offering street maps of China must obtain an authorization from the State Council. These maps must use the GCJ-02 datum, instead of the WGS-84 that the most of the world uses. This causes WGS-84 coordinates, such as those coming from a regular GPS chip, to be plotted incorrectly on GCJ-02 maps. \n\n\n\nThe street maps displayed by both google.com/maps and google.cn/maps use GCJ-02 coordinates. This can be proved by getting the GPS (WGS-84) coordinates of a known landmark, such as the Monument to the People&#39;s Heroes in Shanghai, which is located at 31.24427 N, 121.48695 E:\n\n\nTerraserver satellite imagery - reference\nGoogle China street maps and satellite imagery for the same coordinates displays a location about 500 meters off to the north-west. To find the landmark, you must use the GCJ-02 location, 31.2423 N, 121.4914 E\nGoogle.com street maps in China also gets it wrong, and it also requires the GCJ-02 coordinates to zero in on the landmark correctly.\nGoogle.com Maps satellite imagery uses the WGS-84 coordinates, which causes a pretty terrible mismatch:\n\n\n\n\nI&#39;m still unclear as to whether GPS chips manufactured in China return GCJ-02 coordinates directly, or if they return WGS-84 coordinates, which approved map software can convert to GCJ-02.\n Mapping and <span class=\"highlight\">surveying</span> can only be done with authorization from the State Council, and foreigners must form a joint-venture in order to be granted authorization for surveys. &hellip; "
    },
    {
        "question": "How to load Ordnance Survey OpenSpace in QGIS?",
        "area": [
            "qgis",
            "ordnance-survey",
            "os-openspace-api"
        ],
        "text": "The version of gvSIG that I have on my Android tablet will load OS OpenSpace layers and I wonder whether or not it would be possible for QGIS desktop to do the same? And if so, how? I have my own OpenSpace API key.\n\nThis appears to be the (long) line in gvSIG&#39;s &#39;layers.txt&#39; file that does the job of fetching the layers:\n\n\n  101|Ordnance Survey (UK)\n  OpenSpace;6[&gt;],http://openspace.ordnancesurvey.co.uk/osmapapi/ts?FORMAT=image/png&amp;KEY=#KEY#&amp;URL=#URL#,image/png,11,0,200,0.0,0.0,0.0,0.0,1000000.0,1000000.0,EPSG:27700,2500.0:1000.0:500.0:200.0:100.0:50.0:25.0:10.0:5.0:4.0:2.0:1.0,\n  ,1.1.1,88013ECD7A8F379FE0405F0ACA607F60:8824326E25F94E17E0405F0AC86047BC,http://www.prodevelop.es/maps/map.htm|http://www.gvsigmini.org/maps/map.htm\n\n This appears to be the (long) line in gvSIG&#39;s &#39;layers.txt&#39; file that does the job of fetching the layers:\n\n\n  101|Ordnance <span class=\"highlight\">Survey</span> (UK)\n  OpenSpace;6[&gt;],http://openspace.ordnancesurvey.co.uk/osmapapi/ts &hellip; "
    },
    {
        "question": "Using R to calculate the area of multiple polygons on a map that intersect with another overlaid polygon",
        "area": [
            "shapefile",
            "r"
        ],
        "text": "Spacedman&#39;s answer and hints above were useful, but do not in themselves constitute a full answer. After some detective work on my part I have got closer to an answer although I have not yet managed to get  in the way I want (see original question above). Still, I have managed to get my new polygon into the SpatialPolygonsDataFrame.\n\nUPDATE 2012-11-11: I seem to have found a workable solution (see below). The key was to wrap the polygons in a  call when using  from the  package. The output looks like this:\n\n\n\nInserting the polygon was harder than I thought because, surprisingly, there doesn&#39;t seem to be an easy-to-follow example of inserting a new shape in an existing Ordnance Survey-derived shapefile. I have reproduced my steps here in the hope that it will be useful to somebody else. The result is a map like this.\n\n\n\nIf/when I solve the intersection issue I will edit this answer and add the final steps, unless, of course, somebody beats me to it and provides a full answer. In the meantime, comments/advice on my solution so far are all welcome.\n\nCode follows.\n\n\n 417503.7, intersect % = 22.4%&quot;\n\n\nInserting the polygon was harder than I thought because, surprisingly, there doesn&#39;t seem to be an easy-to-follow example of inserting a new shape in an existing Ordnance <span class=\"highlight\">Survey</span>-derived &hellip; objects\nrequire(mapdata) # includes good vector maps of world political boundaries.\nrequire(rgeos)\nrequire(rgdal)\nrequire(gpclib)\nrequire(ggplot2)\nrequire(scales)\ngpclibPermit()\n\n## Download the Ordnance <span class=\"highlight\">Survey</span> &hellip; "
    },
    {
        "question": "Converting XYZ files (with regularly spaced xy) to ESRI GRID format?",
        "area": [
            "arcgis-10.0",
            "dem",
            "convert",
            "lidar",
            "esri-grid-format"
        ],
        "text": "Normally consultants (LiDAR survey) provide me with data to my specifications; already in ESRI GRID or ASCII GRID format. This way LiDAR data can be easily used with ArcGIS. This time I only have xyz files (i.e., with regular spaced xy coordinates). \n\nPreviously, I would use a utility by Min-Lang Huang named GridBatch that would convert XYZ to ASCII GRID then to ESRI GRID files. Unfortunately, the utility is crashing since I upgraded my machine to W7 64bit and ArcGIS to version 10. \n\nIs there another way to batch convert LiDAR surface XYZ data to ESRI GRID files?\n\n(Convert to points -&gt; Interpolate is an option I would like to avoid considering there are 300+ tiles to convert).\n Normally consultants (LiDAR <span class=\"highlight\">survey</span>) provide me with data to my specifications; already in ESRI GRID or ASCII GRID format. This way LiDAR data can be easily used with ArcGIS. &hellip; "
    },
    {
        "question": "What algorithm should I use for wifi geolocation?",
        "area": [
            "geolocation",
            "mobile",
            "wifi"
        ],
        "text": "School Pickup Use Case (update)\n\nIt might be helpful to go into a more concrete use case instead of the original backyard example below.  Local law enforcement has started cracking down on use text messaging and cell phone use in school zones.  This presents a problem for parents picking up kids after  a middle school function.  Even for those who flaunt the law, the cell tower quickly becomes overloaded when hundreds of kids call their parents at once.  The campus is large, with wifi coverage.  It seems like it should be possible to write a mobile app that would allow a cell phone user to send a text message containing a list of wifi signal strengths to a webservice.  The web service would then create a location fix and push the message to the parent&#39;s on board navigation device.  The parent would then drive to the correct location on the campus.  \n\nBackyard Use Case (original)\nWhen I take my laptop into my backyard and choose &quot;view available networks&quot; I see a list of my 4 neighbors.  As I walk around, the relative signal strengths from my neighbors changes.\n\nI&#39;d like to stand with my laptop at known locations in my back yard, click on the map and collect points with 4 different signal strengths.\n\nAfter collecting a lot (but not too many) of these calibration points, I&#39;d like to then write a program that takes 4 wifi signal strength levels and estimates a location in the form of an error ellipse. The signals might be measured using a different device than the one used to collect the original calibration points.  \n\nWhat algorithm should I use?\n\nI do not want to disturb my neighbors by asking them if I can come in and survey the exact location of their router.\n\nI can assume, however, the location of my neighbors routers does not change.\n I do not want to disturb my neighbors by asking them if I can come in and <span class=\"highlight\">survey</span> the exact location of their router.\n\nI can assume, however, the location of my neighbors routers does not change. &hellip; "
    },
    {
        "question": "How To Understand Geological Directions?",
        "area": [
            "geolocation",
            "township-range-section"
        ],
        "text": "SW 1/ 4NE1/ 4sec. 29, T. 23 N., R. 8 W is not a direction, it&#39;s a location. Specifically, it is the southwest quarter of the NE quarter section of section 29, township 23 North, range 8 West. These terms are with respect to the public lands survey system (PLSS). \nUsing the  BLM Interactive map I navigated to this location and then eyeballed the SW quarter of the NE quarter section and get a lat/lon of 40.412643, -87.347025. This is roughly where Mud Pine Creek meets CR650.\n\nHere&#39;s what the map looks like with the cursor pointing to the approximate location.\n\n These terms are with respect to the public lands <span class=\"highlight\">survey</span> system (PLSS). &hellip; "
    },
    {
        "question": "ST_Union fails with TopologyException despite valid polygons and using ST_SnapToGrid",
        "area": [
            "postgis",
            "postgresql",
            "geos"
        ],
        "text": "This happens often with ST_Intersection, irrespective of whether you use ST_SnapToGrid (which is more useful for ensuring a certain precision than for fixing geometry errors) and ST_MakeValid. The problem is to do with the fact that when you intersect polygons, often they will meet at a single point or along a line, as well as producing a (Multi)Polygon intersection(s). That is, when you intersect any two polygons, they can have multiple intersections, not all of which will be polygonal. Consequently, the data type for that particular intersection will be a GeometryCollection. As you are then attempting to insert this into a MultiPolygon or Polygon field, you will see errors about non-noded intersection or self-intersections. The simplest way I have found to fix this issue is using ST_CollectionExtract which allows you to extract only Points, Linestrings or Polygon types from the GeometryCollection. In your case, using the parameter 3 (for polygons) and dropping ST_MakeValid ought to fix it:\n\n\n\nThe error you are seeing is consistent with your polygons all being valid in the first place, as you state. I generally think it is better to run ST_IsValid to check and in the case of errors,  ST_MakeValid, on geometries before doing any intersections -- as you have done. ST_MakeValid and ST_SnapToGrid have other uses, but are generally not the right tool for fixing geometry collection issues within a query.\n\nEDIT. After a lot of (unsuccessful) fiddling in an attempt to narrow down a specific subset of the polygons that cause this error, we had an insight from the comments. The input data, from the UK Ordnance Survey, originally in CRS 27700 had been reprojected to 4326. As the algorithm for this conversion is based on convergence, rather than being one step, it introduces arbitrary rounding errors into the reprojected geometries. From reading various GEOS mailing lists about the cause of the OP&#39;s error, relating to precision and rouding, we came to this realization. The OP has since re-run this job using the original 27700 data with no error. \n The input data, from the UK Ordnance <span class=\"highlight\">Survey</span>, originally in CRS 27700 had been reprojected to 4326. &hellip; "
    },
    {
        "question": "Is there a public shapefile with the London Underground stations and lines?",
        "area": [
            "shapefile",
            "data"
        ],
        "text": "Ordnance Survey&#39;s VectorMap District has a shapefile that contains Underground stations - it&#39;s within the &quot;RailwayStation&quot; file but you can filter on the &quot;CLASSIFICA&quot; field. The website is http://www.ordnancesurvey.co.uk/oswebsite/products/os-vectormap-district/index.html and the licence is based on the Open Government Licence http://www.ordnancesurvey.co.uk/oswebsite/opendata/licensing.html. The data is from March 2011 though so could be out of date! Unfortunately I can&#39;t see any line information in the OS open products.\n Ordnance Survey&#39;s VectorMap District has a shapefile that contains Underground stations - it&#39;s within the &quot;RailwayStation&quot; file but you can filter on the &quot;CLASSIFICA&quot; field. The website is http://www. &hellip; "
    },
    {
        "question": "Locating property corners using plat map description?",
        "area": [
            "gps",
            "latitude-longitude",
            "land-survey",
            "metes-and-bounds",
            "township-range-section"
        ],
        "text": "Disclaimer: Any method you use to do this, especially with a consumer GPS unit, is going to be an approximation at best. If you truly want to know where the boundaries are, you will need to locate property pins/corners which might require a metal detector. Your best, safest option is to hire a professional land surveyor.\n\nNo, those are not lat/longs in the description. Those are bearings and distances. What you have is a metes and bounds description which locates a point, gives bearing and distance to the next point, and so on all the way around and back to the point of beginning (known as a traverse). Such descriptions usually, and in the case of the example you give, refer to the Public Land Survey System (PLSS) in the US.\n\nTo locate a section corner you&#39;ll need to either estimate it from data or find a benchmark. For some states you can locate a GIS version of the PLSS grid - see PLSS shapefiles - alternative to geocommunicator.gov? But do note those aren&#39;t surveyed - some points are (control network) and the rest are calculated to fit. You could also check with the county to see if they make their survey control network available. This would have actual surveyed corners and locations of benchmark monuments, possibly with lat/long coordinates already provided. You&#39;d have to locate the nearest benchmark and work your way to it - the plat survey should have note on it somewhere of such a benchmark. If all you have is the description, you&#39;re on your own. And since you&#39;ll be starting at a quarter-quarter corner, you&#39;re unlikely to find a monument right there (they&#39;re usually sections or quarters at best).\n\nOnce you find that point, from your example the description starts immediately. In some cases there are commencement calls that get you to a true point of beginning, and then the shape starts. From there it&#39;s an orienteering exercise.\n\nTo get all this into GPS coordinates, you&#39;ll need to know at least one point&#39;s lat/long and work out the rest, or plot the description and unproject it to a geographic coordinate system. A related question, though for a different country, can be found at Outline a plot of land on a map. You don&#39;t mention what software you&#39;re using or have access to. If you specify something, more help could be given.\n\nHonestly, your best bet is to go to the county GIS website (per your descripton). Using their online map application, you can get a pretty good idea of where the parcel is and possibly turn imagery on to get some landmarks to use in locating it. Their section grid is on by default, zoom in far enough and you&#39;ll be able to see the labels to locate 03-25-2E per their labeling scheme. Looks like it&#39;s on the north end of the City of Bainbridge Island. Since I can&#39;t see the full description, nor do I know exactly where the quarter-quarter corners are, I&#39;m guessing it&#39;s one of the parcels in the vicinity of the one outlined in green below. The SE corner of the SW4 NW4 is somewhere around the bottom right corner of that parcel. I&#39;ve outlined the section in red, because the gray dashed line they use is kind of hard to see. If the documents you have include a parcel ID number or address, you can look that up directly in the system.\n\n\n\nYou can also use that page to identify the correct parcel, and then pull it up in Google Maps where if you right-click a point and choose What&#39;s Here? it will give you the lat/long coordinates of that point. So you could get a rough idea where the corners are and then get ballpark coordinates to use in your GPS. Which remember a consumer grade unit is only going to be accurate down to about 3m anyway.\n Such descriptions usually, and in the case of the example you give, refer to the Public Land <span class=\"highlight\">Survey</span> System (PLSS) in the US. &hellip; You could also check with the county to see if they make their <span class=\"highlight\">survey</span> control network available. &hellip; "
    },
    {
        "question": "Filter a GeoPandas dataframe for points within a specific country",
        "area": [
            "shapely",
            "filter",
            "geopandas"
        ],
        "text": "I have a dataframe of health survey data which is geotagged, called . I have converted the dataframe to a GeoPandas dataframe, and used the geotags as the geometry column within the dataframe, for example:\n\n\n\nI want to filter the dataframe so that only points in the UK are returned. I have the UK coordinates in a separate Geoseries, called uk_geom, which I simply took from the GeoPandas built-in world map:\n\n\n\nThis returns uk_geom as a GeoPandas GeoSeries:\n\n\n\nI simply want to filter  for all points within momdata.geometry that fall within uk_geom, returning a dataframe of only UK-based survey observations. This should be simple.\n\nI tried: \n\n\n\nbut this returns an empty dataframe, when I know that some of the survey observations for sure are in the UK. \n\nFor example:\n\n\n\nI tried this the other way round, checking which momdata points are contained within uk_geom:\n\n\n\nAlso when I test the &#39;within&#39; function on a point that I know is within , I get an error:\n\n\n\nI have assigned the correct co-ordinate reference system: \n\n\n\nI also tried a basic &#39;apply&#39; function using a predicate, but this returns an error:\n\n\n\nI also tried a spatial join, but then I get the error that one of the join columns is not a DataFrame, as of course it&#39;s trying to join on the geometry column:\n\n\n\nHow do I solve this? \n\nI can&#39;t seem to make it work.\n I have a dataframe of health <span class=\"highlight\">survey</span> data which is geotagged, called momdata. &hellip; I tried: \n\nuk_momdata = momdata[momdata.geometry.within(uk_geom)]\n\nbut this returns an empty dataframe, when I know that some of the <span class=\"highlight\">survey</span> observations for sure are in the UK. &hellip; "
    },
    {
        "question": "Difference between bounding box, envelope, extent, bounds?",
        "area": [
            "geometry",
            "extents",
            "gis-principle",
            "terminology",
            "bbox"
        ],
        "text": "I think you&#39;ll find there is a bit of overlap with these definitions. They&#39;re all very similar, in my opinion. However, ESRI has a glossary of GIS terms, so I just looked them up. The definitions are similar or identical to the wiki GIS glossary as well.\n\nBounding Box (Bounding Rectangle):\n\n\n  [map display] The rectangle, aligned with the coordinate axes and\n  placed on a map display, that encompasses a geographic feature or\n  group of features or an area of interest. It is defined by minimum and\n  maximum coordinates in the x and y directions and is used to\n  represent, in a general way, the location of a geographic area.\n\n\nExtent:\n\n\n  The minimum bounding rectangle (xmin, ymin and xmax, ymax) defined by\n  coordinate pairs of a data source. All coordinates for the data source\n  fall within this boundary.\n\n\nIt should be noted that in the arcpy documentation for extent (though you haven&#39;t said which software you&#39;re using), the definition is essentially the same:\n\n\n  An extent is a rectangle specified by providing the coordinate of the\n  lower left corner and the coordinate of the upper right corner in map\n  units.\n\n\nExtent Rectangle (you didn&#39;t ask for this one, but it was in the glossary so I threw it in):\n\n\n  [ESRI software] A rectangle that is displayed in one data frame,\n  showing the size and position of another data frame.\n\n\nThe glossary doesn&#39;t have a definition for bounds, but I think it would likely be similar or identical to extent.  It should be noted there is also a term called &quot;metes and bounds&quot;, which is not really what you&#39;re asking, but I thought I would include it anyway.\n\nMetes and Bounds:\n\n\n  A surveying method in which the limits of a parcel are identified as\n  relative distances and bearings from landmarks. Metes and bounds\n  surveying often resulted in irregularly shaped areas.\n\n\nFinally, there is a tool in ArcGIS called Minimum Bounding Geometry which:\n\n\n  Creates a feature class containing polygons which represent a\n  specified minimum bounding geometry enclosing each input feature or\n  each group of input features.\n\n\nDepending on which option you choose, the results will be different.  However, it&#39;s worth noting that the Envelope option is a polygon which appears to be to be identical to the extent.\n Metes and Bounds:\n\n\n  A <span class=\"highlight\">surveying</span> method in which the limits of a parcel are identified as\n  relative distances and bearings from landmarks. &hellip; Metes and bounds\n  <span class=\"highlight\">surveying</span> often resulted in irregularly shaped areas. &hellip; "
    },
    {
        "question": "Good resources on geocoding algorithms",
        "area": [
            "geocoding",
            "algorithm",
            "references",
            "gis-principle"
        ],
        "text": "From Text to Geographic Coordinates:\nThe Current State of Geocoding\n\nDaniel W. Goldberg, John P. Wilson, and Craig A. Knoblock\nAbstract: This article presents a survey of the state of the art in geocoding practices through a cross-disciplinary historical review\nof existing literature. We explore the evolving concept of geocoding and the fundamental components of the process. Frequently\nencountered sources of error and uncertainty are discussed as well as existing measures used to quantify them. An examination\nof common pitfalls and persistent challenges in the geocoding process is presented, and the traditional methods for overcoming\nthem are described.\n\n10.1.1.119.714.pdf\n\nPDF (page 34 onwards)\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.714&amp;rep=rep1&amp;type=pdf\n Knoblock\nAbstract: This article presents a <span class=\"highlight\">survey</span> of the state of the art in geocoding practices through a cross-disciplinary historical review\nof existing literature. &hellip; "
    },
    {
        "question": "Calculating visible sky percentage?",
        "area": [
            "spherical-geometry",
            "viewshed",
            "gis-principle",
            "visibility"
        ],
        "text": "Can anyone explain, as simply as possible, how to calculate the visible sky percentage?\n\nI have done a satellite survey and have worked out the height of buildings and the distance between them.  \n\nHow do I use that data to calculate the visible sky percentage according to where I was standing?\n I have done a satellite <span class=\"highlight\">survey</span> and have worked out the height of buildings and the distance between them. &hellip; "
    },
    {
        "question": "What is the difference between spatialreference.org catalogs: EPSG, ESRI, and User-defined?",
        "area": [
            "qgis",
            "coordinate-system",
            "epsg"
        ],
        "text": "Short Answer:\nQGIS handles SRS much the same as ESRI.  Dive into QGIS and you&#39;ll find all your favorite SRS waiting for you.\n\nLong Answer:\nEPSG is the European Petroleum Survey Group.  It provides &#39;official&#39; spatial reference systems and spheroids and its codes are ubiquitous.  ESRI \ntakes most of its SRS from the EPSG dataset.  So you are already using the EPSG SRS, except ESRI just doesn&#39;t tell you the catalog number in an obvious way.  ESRI has a few &#39;interesting&#39; SRS that are not available in the EPSG catalog (e.g. the Dymaxion and a cube projection) but they are not in common use.  \n\nQGIS uses the EPSG naming convention but provides common names too so you should not get lost if you are familiar with ESRI.  Coming from ESRI, the EPSG codes can seem a bit alien at first, but you quickly get used to it as you realise that you&#39;ve been using it all along.  \n\nLastly we have the user-defined SRS group.  These have no official status.  It is possible to define your own projection system (as you can in ArcGIS) but the need to do so is rare as there are so many tried and tested SRS out there and correctly defining an SRS is (IMO) a non-trivial task if you want to have something reliable and then have to convince all your co-workers that it is both credible and necessary.  Personally, I would be a bit suspicious of any of the User-defined SRS as I do not know their provenance or accuracy and would have to spend time researching their composition. I&#39;d rather use an EPSG SRS that has good documentation and is well supported.\n\nWhile we&#39;re on the subject, ESRI also borrows parts of GDAL so you are also using some of QGIS&#39; raster handling capabilities (particularly for converting between ratser data types)... you may not be aware of that either, but it should give you a bit of additional comfort moving to QGIS.\n Long Answer:\nEPSG is the European Petroleum <span class=\"highlight\">Survey</span> Group.  It provides &#39;official&#39; spatial reference systems and spheroids and its codes are ubiquitous. &hellip; "
    },
    {
        "question": "What is the difference between geocoding and georeferencing?",
        "area": [
            "geocoding",
            "georeferencing",
            "oracle-spatial"
        ],
        "text": "I see them as separate activities.\n\nGeocoding is the process of taking coded location information (such as addresses or grids) and turning it into explicit location information (X and Y coordinates, usually). Reverse geocoding is the opposite, taking XY data and locating the nearest address, grid, etc.\n\nGeoreferencing is the process of taking a raster image or vector coverage, assigning it a coordinate system and coordinates, and translating, transforming, and warping/rubbersheeting it into position relative to some other spatial data, such as survey locations, street intersections, etc.\n\nThis can be sometimes also be called rectification or georectification interchangeably, while in some contexts, georeferencing is considered to only include the assigning of a spatial reference and coordinates to the image, and rectification is the transformation and resampling of the image to remove distortion (as in orthorectification).\n\nIn ArcGIS, georeferencing is transitory (on-the-fly transformation of the source image) while rectification is permanent (creating a new resampled image given a georeferenced raster layer).\n raster image or vector coverage, assigning it a coordinate system and coordinates, and translating, transforming, and warping/rubbersheeting it into position relative to some other spatial data, such as <span class=\"highlight\">survey</span> &hellip; "
    },
    {
        "question": "How to build a geographic database of GPS logs?",
        "area": [
            "gps",
            "convert",
            "ogr",
            "spatialite",
            "gpx"
        ],
        "text": "On our aerial wildlife surveys we typically generate dozens of GPX files, and usually convert most of them into shapefiles for display in a GIS application. GPX files are a terrific way of keeping all (or almost all) of your GPS data in one place \u2013&#160;they are xml files that store tracklog, waypoint &amp; route information in one convenient format. They store multiple tracks, even old saved tracks from a Garmin. \n\nI&#39;d like to store all this track data in a spatialite database, in parallel with other tables that have point observational data from the same survey.\n\nogr2ogr will let me convert the track to a spatialite database:\n\n\n\nHowever, this imports each saved track as a line \u2013 losing the time / location information for each track point!\n\nAnyone know of any clever ways of building a tracklog database that will preserve that information?\n\nEDIT:\n\nTracklogs are not just a line - they are collections of sequential points, each with an elevation and time attribute. Each point belongs to a track segment, which in turn belong to a given track, and points within each track segment were taken without interruption and may be assumed to be linked. For example:\n\n\n\nThus, to save a tracklog you need to save this collection of points with their associated data.\n\nOne solution might be to load these tracks as points, with additional columns for track name, segment, elevation and time; I don&#39;t think ogr will convert the tracks as points, though.\n\nSolution\n\nThanks to @scruss who pointed out gpx2spatialite, which I installed (OS X 10.9) with . This set of tools is designed for the &#39;drawinglife&#39; project (and thus has some &#39;city&#39; information that is probably unnecessary for most of us); the main gpx2spatialite page doesn&#39;t explain much, but the drawinglife wiki is better. Still, lots of undocumented features - like removing duplicates!\n\nCreate a spatialite database for GPX files which will hold track segments, tracks, trackpoints and waypoints. It also has &#39;users&#39; set up (which seems odd, since sqlite is not a user-access system, but was meant for drawinglife) designed to label the various tracks:\n\n\n\nLoad a whole folder of GPX files, including all subfolders, checking and removing duplicates along the way:\n\n\n\nOptions:\n\n\n= don&#39;t check if the trackpoints are in the city database (speeds it up a LOT)\n = database to use;\n = add the user SL25 (just a label I used for the set of tracks collected);\n = the folder (with subfolders) that has the tracks I&#39;m interested in.\n\n\nBugs:\n\n\nIf you have saved tracks on an older Garmin that discards time stamp info, it&#39;ll crash the import (remove those saved tracks using a utility like GPSU). If you have gpsbabel, filter the file first with something like:\n\ngpsbabel -w -r -t -i gpx -f [INPUT.gpx] -x track,start=20000101 -o gpx -F [OUTPUT.gpx]\n\n I&#39;d like to store all this track data in a spatialite database, in parallel with other tables that have point observational data from the same <span class=\"highlight\">survey</span>. &hellip; "
    },
    {
        "question": "What is the SRID for EPSG 102743?",
        "area": [
            "postgis",
            "epsg",
            "srid"
        ],
        "text": "There is no EPSG SRID 102743. Note that EPSG is the authority, and 102743 is the SRID. If you look up SRID 102743 on spatialreference.org, the listing is for ESRI:102743, meaning that ESRI (the publishers of ArcGIS) is the authority, not EPSG (European Petroleum Survey Group, now absorbed by the International Association of Oil &amp; Gas Producers). The PostGIS database does not by default populate  with non-EPSG reference systems, so if you are using an ESRI one you have two choices:\nAdd it manually\nThis is fairly easy. Each SRID page on spatialreference.org has a link for a PostGIS  statement to add the code to . The statement for this SRID is:\n\nUse a &quot;close enough&quot; SRID\nThe PostGIS database includes a number of suitable SRIDs. As you have found, EPSG:3566 is a close match. In fact, 3566 (NAD83), 3569 (NAD83(HARN)), and 3677 (NAD83(NSRS2007)) are all extremely close matches. The only difference between 3566 and 102743 is the false easting and false northing parameters.\n\n3566\n\n\n\n\n\n102743\n\n\n\n\n\n\nSo using the &quot;wrong&quot; one might lead to a misalignment of 3/100,000th of a foot.\n If you look up SRID 102743 on spatialreference.org, the listing is for ESRI:102743, meaning that ESRI (the publishers of ArcGIS) is the authority, not EPSG (European Petroleum <span class=\"highlight\">Survey</span> Group, now absorbed &hellip; "
    },
    {
        "question": "What&#39;s up with the GeoJSON spec and CRS as a IRM?",
        "area": [
            "coordinate-system",
            "geojson",
            "ogc",
            "specification"
        ],
        "text": "I&#39;m writing a web API to our GIS data, currently revamping our geocoding service. I&#39;m creating the option for folks to specify the output type as GeoJSON so I&#39;m trying to follow the spec. Our data is stored in nad83 datum UTM zone 12 north projection. The GeoJSON spec says to add a CRS. The wkid is 26912 but what is the OGC CRS URN? \n\nI can understand that the OGC CRS URN is broken down into a few parts.\n\nurn:ogc:def:crs:OGC:1.3:CRS84\n\nurn is the identifier, ogc is the organization, def is another static deal, crs is the type (coordinate reference system), OGC is the authority, 1.3 is the version and CRS84 is the projection.\n\nWhy is the authority of utm 26912 the European Petroleum Survey Group? \n\nDo any mapping frameworks even use this CRS name? \n\nI want to follow the spec but it seems that more mapping frameworks are using the wkid.\n\nhttp://spatialreference.org/ref/epsg/26912/\n\nseems like the best place to get the info but they don&#39;t even list the urn. Is the GeoJSON spec just silly or what?\n Why is the authority of utm 26912 the European Petroleum <span class=\"highlight\">Survey</span> Group? \n\nDo any mapping frameworks even use this CRS name? &hellip; "
    },
    {
        "question": "What&#39;s the meaning of numbers before an EPSG code, e.g. the 6.9 in EPSG:6.9:4326?",
        "area": [
            "epsg"
        ],
        "text": "A WFS server I was using offered boundaries data in the following EPSG codes:\n\n\nEPSG:6.9:27700\nEPSG:6.9:4326\n\n\n...defined in the XML  spec like this:\n\n\n\nAs I understand it, EPSG 4326 is the &quot;standard&quot; latitude and longitude ellipsoid used by GPS systems, and EPSG:27700 is the older British system behind the Ordnance Survey National Grid. \n\nBut what&#39;s the  mean?\n\nI tried inputting it into ogr2ogr and it just got confused:\n\n\n  {&quot;errors&quot;:[&quot;ERROR 6: EPSG PCS/GCS code 6 not found in EPSG support files.  Is this a valid&quot;,&quot;EPSG coordinate system?&quot;,&quot;Failed to process SRS definition: EPSG:6.9:4326&quot;,&quot;&quot;]}\n\n\n...and I can&#39;t find any reference to what the component parts of an EPSG code mean, only lists of &#39;standard&#39; EPSG codes that don&#39;t have these initial numbers.\n def:crs:EPSG:6.9:4326&lt;/OtherSRS&gt;\n\n\nAs I understand it, EPSG 4326 is the &quot;standard&quot; latitude and longitude ellipsoid used by GPS systems, and EPSG:27700 is the older British system behind the Ordnance <span class=\"highlight\">Survey</span> &hellip; "
    },
    {
        "question": "QField connected to Cloud",
        "area": [
            "qgis",
            "qfield",
            "cloud-gis"
        ],
        "text": "qfield.cloud is exactly what you&#39;re looking for. It is natively supported in QField and allows you to synchronise your field survey directly to the cloud (and to your team) as soon as you have connectivity. This way you can work with no issues wherever you need to.\nOnce synchronised, you can use your data with QGIS, or any other tools you wish. Later we&#39;ll also add the possibility to directly publish your data on a web map from the QFieldCloud web panel.\nWe are currently in beta and are opening up spots every day to new preregistered users. If you preregister on qfield.cloud you&#39;ll get an information mail very soon, and if you reach out directly to us at opengis.ch you might even get an immediate invitation ;)\nyou can also checkout my [1h] talk about it on QGIS&#39;s youtube channel\nDisclaimer: I&#39;m one of the developers of QField/QFieldCloud\n It is natively supported in QField and allows you to synchronise your field <span class=\"highlight\">survey</span> directly to the cloud (and to your team) as soon as you have connectivity. &hellip; "
    },
    {
        "question": "How to convert Distance, Azimuth, Dip to XYZ?",
        "area": [
            "arcgis-10.0",
            "convert",
            "spherical-geometry",
            "vb",
            "borehole"
        ],
        "text": "I have an excel spreadsheet with header and survey drill data. Header data contains hole ID, and location coordinates, and the survey data contains related downhole survey with Distance, Azimuth and Dip values. \n\nSince I know the hole location and surface elevation, I would like to be able to convert the survey table to XYZ coordinates as well.  Does anyone has a function / procedure / example?  (VB &amp; ArcObjects)\n\nHeader Data:\n\n\n\nSurvey Data:\n\n\n I have an excel spreadsheet with header and <span class=\"highlight\">survey</span> drill data. &hellip; (VB &amp; ArcObjects)\n\nHeader Data:\n\n\n\n<span class=\"highlight\">Survey</span> Data: &hellip; "
    },
    {
        "question": "Why does one part of GML -&gt; KML conversion not work on Google Maps?",
        "area": [
            "google-maps",
            "kml",
            "gml",
            "google-fusion-tables"
        ],
        "text": "I have a client who wants to visualise cancer incidence and mortality rates by local/unitary authority across Great Britain. I&#39;ve used Ordnance Survey data to get the boundaries of the authorities in GML format and saved all of them as one large GML file. I used QGIS to convert the data to KML format. I have the data in Fusion Tables now and it all looks great except for one blatant gap in the coverage.\n\nWhen I look at the KML data for the missing local authority, it hasn&#39;t imported at all (ie the cell is empty). I&#39;ve tried re-uploading the geometry (and re-downloading and re-converting) and Fusion Tables is definitely rejecting it as KML. I&#39;ve read somewhere that Fusion Tables can mess around with your geometry somewhat, so I uploaded the KML file and pointed Google Maps directly at it and that didn&#39;t work either (I don&#39;t know how good a test that is).\n\nI don&#39;t know that I originally created a valid GML file (I don&#39;t know the standard) but they seemed to import ok to QGIS and the final result looks great apart from this one place. The area is visible in QGIS when I load the GML file, so I don&#39;t know if QGIS is producing invalid KML, or mayble Google Maps/Fusion Tables have limitations?\n\n\n\nI&#39;ve downloaded the OS Open data pointed to by @nhopton, loaded the appropriate layer into QGIS (Layer -&gt; Add vector layer), saved it as KML (Layer -&gt; Save as) and uploaded it to Fusion Tables. (Note that I didn&#39;t explicitly do anything with the CRS). Generally it&#39;s worked well (and importantly the particular area that had failed with my first method worked with this, so I have the missing geometry!). However, there&#39;s a number of missing areas again. And in this case, there&#39;s much less that I&#39;ve done to the data myself, so it&#39;s not so easy to assume I&#39;ve just messed up the data. Any ideas why my final results look like this?\n I&#39;ve used Ordnance <span class=\"highlight\">Survey</span> data to get the boundaries of the authorities in GML format and saved all of them as one large GML file. I used QGIS to convert the data to KML format. &hellip; "
    },
    {
        "question": "Derive WGS84 Longitude &amp; Latitude from British Northings &amp; Eastings",
        "area": [
            "qgis",
            "coordinate-system",
            "data"
        ],
        "text": "I&#39;m looking for a fairly simple way to append columns with  WGS84 longitude and latitude to a table containing northings and eastings.  The source data is Ordnance Survey&#39;s CodePoint Open, which I is I think OSBGB36.  I want to use this with OpenStreetMap.  I have the CodePoint data in a csv file and loaded into an MS Access database, from which I can load it into QGIS.  From there I&#39;ve tried exporting it with a transform operation into various file formats but this doesn&#39;t seem to do the trick.  I do have access to PostGIS and SQL Server 08R2 but little experience of using sql spatial.\n I&#39;m looking for a fairly simple way to append columns with  WGS84 longitude and latitude to a table containing northings and eastings.  The source data is Ordnance Survey&#39;s CodePoint Open, which I is  &hellip; "
    },
    {
        "question": "Partitioning Line into Segments using ArcGIS Desktop?",
        "area": [
            "arcgis-desktop",
            "arcgis-10.1",
            "arcmap",
            "line"
        ],
        "text": "The solution to the first part of your question is &quot;Splitting a line into an equal number of parts&quot;:\n\n\n  The Split command on the Editor toolbar allows you to split a line\n  into an equal number of new features. For example, you can use this\n  Split option to break a line into pieces that are the same length.\n  This functionality is similar to the Divide command available in\n  previous ArcGIS releases.\n\n\nFurther down on the same page is a section on &quot;Splitting lines proportionally&quot;.  This should help you with the second part of your question, although you will need at least a Standard (ArcEditor) license to do this.\n\n\n  The Proportion command Proportion on the COGO toolbar splits a\n  selected line feature into a number of segments, based on specified\n  distance values. If there is a difference between the feature length\n  and the entered values, this difference is proportioned between all\n  the new segments. Proportion is useful when you are working with exact\n  measurements, such as COGO or survey data.\n  \n  For example, you have line features that need to be split into\n  specific lengths. The example below shows a line feature that needs to\n  be split into four parts: 13.79 feet, 48 feet, 60 feet, and 60 feet.\n  The Proportion command is used to split this feature into the four new\n  features.\n\n\nAs stated above, in previous versions of ArcGIS, dividing lines into segments was accomplished using the Divide command.\n Proportion is useful when you are working with exact\n  measurements, such as COGO or <span class=\"highlight\">survey</span> data.\n  \n  For example, you have line features that need to be split into\n  specific lengths. &hellip; "
    },
    {
        "question": "Automating roof orientation detection from satellite imagery?",
        "area": [
            "python",
            "open-source-gis",
            "satellite"
        ],
        "text": "A while ago I did a neighbourhood roof orientation survey for solar panel deployment, by visually checking each roof and marking individually whether they were south or almost south-facing. \n\nAs this is very time-consuming, I would like to find a way to automate this, but don&#39;t know how this would be possible by merely analysing roof shadows. \n\nI can script a little but have never written any plug-ins. \n\nWhat other elements do I need to include? \n\nWe are on a very low budget, so seek any suggestions how to do this using open source tools.\n A while ago I did a neighbourhood roof orientation <span class=\"highlight\">survey</span> for solar panel deployment, by visually checking each roof and marking individually whether they were south or almost south-facing. &hellip; "
    },
    {
        "question": "Recommended Coordinate Reference System (CRS) for Germany",
        "area": [
            "coordinate-system",
            "germany"
        ],
        "text": "I have WGS84 latitude and longitude for data points near Munich and I&#39;d like to use a grid-type coordinate system, like the Ordnance Survey grids in Ireland or the UK.\nWhat similar coordinate system do you recommend for Germany?\n I have WGS84 latitude and longitude for data points near Munich and I&#39;d like to use a grid-type coordinate system, like the Ordnance <span class=\"highlight\">Survey</span> grids in Ireland or the UK. &hellip; "
    },
    {
        "question": "Ordnance Survey grids - download or generate?",
        "area": [
            "data",
            "ordnance-survey",
            "united-kingdom",
            "grids-graticules"
        ],
        "text": "Does anyone know a source from which to download vector UK Ordnance Survey grids at varying resolutions? Or failing that, a tool that can create an OS grid at a specified resolution? There are plenty of ways to generate a vector grid, but I&#39;ve found no way of populating the attributes with OS grid references.\n Does anyone know a source from which to download vector UK Ordnance <span class=\"highlight\">Survey</span> grids at varying resolutions? Or failing that, a tool that can create an OS grid at a specified resolution? &hellip; "
    },
    {
        "question": "Displaying azimuth of line in QGIS",
        "area": [
            "qgis",
            "qgis-2",
            "azimuth"
        ],
        "text": "I have drawn a series of straight lines on a map joining different locations. The lines have a single vertex at each end.  I am using the Ordnance Survey of Great Britain 1936 projection.\nI now want to know the compass bearings I will have to walk to move from one location to the next.\n\nIs there any easy way to get QGIS to calculate/display the azimuth of the lines I have drawn?\n\nBetter still is there any way to get QGIS to actively display the azimuth of the lines as I am drawing them?\n\n\nI am aware there is an azimuth function but the syntax appears to need the input of the coordinates of the vertices on either end of the line which would be very time-consuming.\n I am using the Ordnance <span class=\"highlight\">Survey</span> of Great Britain 1936 projection.\nI now want to know the compass bearings I will have to walk to move from one location to the next. &hellip; "
    },
    {
        "question": "What ratio scales do Google Maps zoom levels correspond to?",
        "area": [
            "google-maps",
            "scale",
            "zoom"
        ],
        "text": "Radius @ Equator 6,378,137 meters exact (WGS-84)\n\nCircumference at Equator = 40,075,017 meters (2\u03c0r)\n\nZoom level 24 uses 2 to the 32 power (4,294,967,296) pixels at circumference.\n\nEquatorial Circumference / 2 32 =  .009330692 meters per pixel\n\nUnit at Latitude =  (Cosine of Latitude) X (Unit at Equator)\n\nZoom level doubles each increment.\n\n1 foot (International) = 0.3048 meters\n\nEdit\n\nWell its not really a legitimate question to start with.  Scale ratios are relative to printed documents not computer screens.  What you need  for these images to be used with any accuracy is to know the dimension of each pixel then scale the image according to whatever your overlaying it with.\n\nSo back 15-20 year ago someone took WGS-84 as base data.  (note in a previous post someone used a value of 40,075,160  I&#39;ve seen this in Wikipedia a few places and it&#39;s incorrect.   The correct value is 40,075,017\n\nThey then took that and divided it by a full 32 bit integer.  This is a logical choice as it yields global accuracy to about one centimeter which is plenty for aerial imagery. 32 bit integers are also efficient to store and process.\n\nWhy this is level 24 was chosen I don&#39;t know however as someone else here worked out 0 gets you down to one 256 pixel tile for the earth.\n\nNow for an example of how to use the above data.  Lets say I have an image at zoom level 20 (as zoomed as they currently let you get)  Take 0.009330692 (Zoom 24 at equator) double it for zoom 23, again for zoom 22, again for zoom 21 and one last time for zoom 20.  You should now have 0.149231071.  \n\nNow lets say our image is at latitude 45.  Take the Cosine of that (0.707106781) and multiply it by our 0.149231071 and it will give you  0.105564729 meters.  That is the length and height of one pixel from an image at latitude 45 at zoom level 20.  If you screen capture a 1000 x 1000 pixel image of that area the dimension are 105.56 meters square.  If you want feet divide that 0.3048\n\nAs for sources I essencial reversed engineer about 5 years ago from various bit of info and documentation I found on the web including Google and MS mapping support sites.\n\nI have used this hundred of time and overlaying it with actually field survey data and its always been correct.  Check it against any to the tables posted here and the numbers will match.\n I have used this hundred of time and overlaying it with actually field <span class=\"highlight\">survey</span> data and its always been correct.  Check it against any to the tables posted here and the numbers will match. &hellip; "
    },
    {
        "question": "How is margin of error reported on a map?",
        "area": [
            "cartography",
            "statistics"
        ],
        "text": "A rencent journal article I came across discusses exactly what @Aksel in another answer (Sun and Wong, 2010) (It is available here for free online, but that link is void of pictures of the maps as far as I can tell). Essentially they suggest they prefer the overlay approach as opposed to the small multiple approach (i.e. making two maps, one showing the estimate and another showing uncertainty).\n\nValue by alpha maps as have been mentioned on this forum  are an alternative way to representing uncertainty than the overlay of the dash lines (which I find more intuitive).\n\nOther works that I have read that may be of interest (although they don&#39;t directly answer the question) are;\n\n\nMapping the Results of Geographically Weighted Regression (Mennis, 2006) PDF here\nAll maps of parameter estimates are misleading (Gelman, 1999) PDF here\nThe original article I cited is Incorporating Data Quality Information in Mapping American Community Survey Data (Sun and Wong, 2010)\n\n Regression (Mennis, 2006) PDF here\nAll maps of parameter estimates are misleading (Gelman, 1999) PDF here\nThe original article I cited is Incorporating Data Quality Information in Mapping American Community <span class=\"highlight\">Survey</span> &hellip; "
    },
    {
        "question": "How are you, as GIS professionals, spending most of your day at work?",
        "area": [
            "gis-professional"
        ],
        "text": "Im my &quot;GIS time&quot; (~ half of the working-day) I use\n\n60% day at computer scripting (70% developing software and &quot;GIS recipes&quot;, 30% leading with digital cartography); 20% at meetings (skype and presential); 20% learning/refreshing. \n\n\n\nSuggestion: review with more people here (and perhaps editing your question) the &quot;typical tasks&quot; list. The consensual list, and perhaps a survey (if here,  can you consolidate answers? else you can prepare a page like freeonlinesurveys?), can be used by many others.\n\nGIS professionals, typical day-by-day tasks\n\nPS: cartographers, geographers, programmers, etc. can be &quot;GIS professionals&quot;, since use/develop GIS as an usual task. \n\n\nCartography \u2013 creating new maps, or modifying others...\n\n\nMainly with layout (ex. editing CSS or mapfiles).\nMainly with databases (ex. building new layers with new SQL complex queries)\nMainly with raw data (ex. editing points, lines and polygons).\n\nResearch/develop - supposing  to producing new things,\n\n\non GIS software/architecture\non Geoprocessing methodologies/recipes\n\nInstalling and/or Testing GIS tools and methods - no new  thing; find, select, prepare and test.\nData editing/cleansing - editing or reviewing  already created data.\nSpatial Analysis - finding answers for spatial questions. \nMeetings\n\n\nWith &quot;GIS people&quot;\nWith &quot;non-GIS people&quot;\n\nLearning - reading books, journals, visiting GIS.stackexchange.com and another sites; using email, chat, telephone, presential talk, etc.\n\n The consensual list, and perhaps a <span class=\"highlight\">survey</span> (if here,  can you consolidate answers? else you can prepare a page like freeonlinesurveys?), can be used by many others. &hellip; "
    },
    {
        "question": "Does anyone know what a geoid10 and its numbers mean?",
        "area": [
            "census",
            "united-states"
        ],
        "text": "GEOID is the field used to join TIGER/Line geographic data to the demographic data in various American Community Survey products and in the Decennial Census. It is slightly confused by the fact that this field is called GEOID10 only in the TIGER/Line 2010 products (in fact, almost all of the field names in TIGER/Line 2010 end in 10), and by the fact that the actual code is different in the geographic and demographic products and has to be manipulated for the join to work.\n\nThis is discussed in several place, but most clearly in various ACS Technical Documents. See for example section 2.6 &quot;How to Join the ACS Summary File to the TIGER/Line Shapefiles&quot; of the 2006-2010 ACS 5-Year Summary File Technical Documentation.\n\nIn the ACS, GEOID begins as follows:\n\n\n3 digits for the summary level\n\n\n040 = state\n050 = county\netc...\n\n2 characters for the component\n\n\nThere are a large number of geographic components, but mostly what you need to know is 00 means the entire population, while anything else means only part of the population, e.g. the urban part, the rural part, etc.\n\nThe letters US\n\n\nAfter those 7 characters which are not present in the TIGER/Line products, the ACS GEOID and TIGER/Line GEOID[10] fields will match. The code will be a concatenation of the code of every geographic entity in the hierarchy of that record. For a tract, this may be two digits for the state FIPS, three digits for the county FIPS, and six digits for the tract code\u2014or it may not, because another version of the census tract (summary level 080) follows the hierarchy State-County-County Subdivision-Place/Remainder-Census Tract.\n GEOID is the field used to join TIGER/Line geographic data to the demographic data in various American Community <span class=\"highlight\">Survey</span> products and in the Decennial Census. &hellip; "
    },
    {
        "question": "Identifying coordinate system of San Francisco data?",
        "area": [
            "coordinate-system",
            "united-states"
        ],
        "text": "This was down a bit in the comments at the link you provided:\n\n\n  SF uses State Plane, NAD 83, Zone 3, US Survey Feet. This coordinate system is used vs lat/longs as they have greater accuracy for smaller areas. We are looking at ways to convert this to lat/long to make it easier for consumers to use.\n\n This was down a bit in the comments at the link you provided:\n\n\n  SF uses State Plane, NAD 83, Zone 3, US <span class=\"highlight\">Survey</span> Feet. &hellip; "
    },
    {
        "question": "Creating a line from two points in QGIS",
        "area": [
            "qgis"
        ],
        "text": "I&#39;m new to QGIS, and have what seems like basic requirements; however I&#39;m struggling to find a solution. I have GPS data in excel showing start and end points of a boat survey. In a row, it has start x, start y, end x, end y. \n\nI would like to plot these points on a map, and draw a line between each start and end point, but without drawing lines between points in different rows.\n\nI&#39;ve seen a few similar questions in the forums, but none of them seem to work when I try. Points to path seem to plot lines between rows, and only used one point per line, rather than the two required. I&#39;ve also seen WKT mentioned, but I don&#39;t know how this works.\n I have GPS data in excel showing start and end points of a boat <span class=\"highlight\">survey</span>. In a row, it has start x, start y, end x, end y. &hellip; "
    },
    {
        "question": "How do you display related records in QGIS?",
        "area": [
            "postgis",
            "qgis",
            "postgresql"
        ],
        "text": "Coming from an esri background I have always used relationship classes in a gdb to display records related to a feature. Eg. Relate 1 survey point to many documents, photos etc.\n\nDoes any one know how to do something similar in QGIS? \n\nAndo\n\nP.S I&#39;m using PostGreSQL 8.4.1 and PostGIS 1.4 and my clients are QGIS.\n Relate 1 <span class=\"highlight\">survey</span> point to many documents, photos etc.\n\nDoes any one know how to do something similar in QGIS? \n\nAndo\n\nP.S I&#39;m using PostGreSQL 8.4.1 and PostGIS 1.4 and my clients are QGIS. &hellip; "
    },
    {
        "question": "Understanding concept of Spatial Reference System?",
        "area": [
            "coordinate-system",
            "srid"
        ],
        "text": "Following on from the answer given by @atlefren, an SRID usually is made of two components, an &quot;authority&quot; and an identifier. The authority is just the name of the organization that catalogues the identifiers. The most common authority you&#39;ll see is , which sands for the &quot;European Petroleum Survey Group&quot;, and they have a comprehensive database of coordinate systems, datums, ellipsoids, projections, and so on, each with a code.\n\nThere are other authorities however, each with their own identifiers that may be different from, yet represent the same information, as an EPSG code. IGNF is one such authority supported by Quantum GIS for instance.\n The most common authority you&#39;ll see is EPSG, which sands for the &quot;European Petroleum <span class=\"highlight\">Survey</span> Group&quot;, and they have a comprehensive database of coordinate systems, datums, ellipsoids, projections, and so &hellip; "
    },
    {
        "question": "Using multiple XY fields for geometry definition in point layer in QGIS",
        "area": [
            "qgis",
            "point",
            "geometry",
            "visualisation",
            "point-creation"
        ],
        "text": "Use a Geometry Generator style for your point layer with an expression that creates a point based on x/y coordinate values for surveyed locations if it exists and else create a point based on x/y coordinate values for planned locations.\nThis expression does this based on field names of coordinate attributes called / and / respectively:\n\nScreenshot: red = surveyed, blue = planned holes (here with a slightly different expression, using  condition - it works the same):\n\nYou could also use two different symbol layers of Geometry Generator type (one for planning, one for surveyed locations) and apply a different style for each. Or use one symbol layer with the solution from above, but define a data-defined override for the color, something like:\n\n\nReferences:\n\nUse QGIS expressions to create geometries: difference between geometry generator and geometry by expression\n\n Use a Geometry Generator style for your point layer with an expression that creates a point based on x/y coordinate values for surveyed locations if it exists and else create a point based on x/y coor &hellip; "
    },
    {
        "question": "What&#39;s the convention for &quot;upside down&quot; labels?",
        "area": [
            "labeling",
            "cartography"
        ],
        "text": "I have line features that are to be used for labels. These lines are correctly oriented(rotated) and positioned such that text placed on them should give a good cartographic output.\n\nCompare the below two images and their labels. In particular the word &quot;Waverton&quot; and its orientation in relation to &quot;Avenue&quot;.\n\n\n\n\nThe left is what all labelling engines seem to produce by default. The right is what it &quot;should&quot; look like according to the Ordnance Survey.\n\nSo my main question is - Which one is correct and why? What is the cartographic convention here?\n\nI ask this because out of the 5 labelling engines split between: QGIS (has two), MapInfo and ArcGIS (has two), only Maplex has the option to allow the user to insist the label follow the orientation of the line. The others all assume that upside down text is undesirable and automatically &quot;correct&quot; it.\n\n(Maps: &#169; Crown Copyright and database right 2012. Ordnance Survey 100019520.)\n The right is what it &quot;should&quot; look like according to the Ordnance <span class=\"highlight\">Survey</span>.\n\nSo my main question is - Which one is correct and why? What is the cartographic convention here? &hellip; Ordnance <span class=\"highlight\">Survey</span> 100019520.) &hellip; "
    },
    {
        "question": "How can I use fortify() to create a filtered R data frame from a shapefile?",
        "area": [
            "shapefile",
            "r"
        ],
        "text": "I am in the process of building a  choropleth map of population in administrative areas in Wales. I have downloaded the Boundary-Line data from the Ordnance Survey and extracted what seems to be the right shapefile (community_ward_region.shp). Using R, I have got as far as reading in the shapefile.\n\n\n\nWhich gives me this promising output:\n\n\n\nNow if I do this:\n\n\n\nI get a nice data frame called  that looks pretty much as I expected:\n\n\n\nHowever, this is a large data frame and  runs out of puff when trying to display it. In reality I only want to look at one area at a time. It looks as if the  factor in the shape object is what I want as it mostly corresponds to counties and the major conurbations.\n\n\n\nQ. How can I select only a subset of the data from the  object I extract from the shapefile? For example, only the  parts? If I can somehow include the  in the data frame that is created with  then I could easily subset the  data frame but I don&#39;t know how to do that. Or is there a way to use  to extract only parts of the object?\n I have downloaded the Boundary-Line data from the Ordnance <span class=\"highlight\">Survey</span> and extracted what seems to be the right shapefile (community_ward_region.shp). &hellip; "
    },
    {
        "question": "Hiding specific points in shapefile layer",
        "area": [
            "qgis",
            "shapefile",
            "point"
        ],
        "text": "I am using QGIS 2.18.2 on a Macbook Pro running OS X 10.10.5.\n\nI created a layer of only 8 points from a wildlife survey. A few points have become less relevant, so I want to hide them from the display. But I would rather not delete them from the shapefile.\n\nIs there a way to do this? Or do I have to create a new, separate layer of the relevant points?\n I created a layer of only 8 points from a wildlife <span class=\"highlight\">survey</span>. A few points have become less relevant, so I want to hide them from the display. But I would rather not delete them from the shapefile. &hellip; "
    },
    {
        "question": "One-to-many joins in QGIS",
        "area": [
            "qgis",
            "attribute-joins",
            "one-to-many"
        ],
        "text": "I am looking for a possibility to make a one-to-many table-join in QGIS.\nI have a shapefile with postal codes and would like to join them with survey results (more than one). In other words, there is a specific postal code (shapefile) on one side and there are many survey participants on the other side.\n\nIf I do a normal join (right click on ) , I just get the first entry of the table with the postal codes.\nI found out a way to do it ArcGIS with the tool , but I&#180;m looking for a possibility to do it in QGIS.\n In other words, there is a specific postal code (shapefile) on one side and there are many <span class=\"highlight\">survey</span> participants on the other side.\npostal **code1** ----- <span class=\"highlight\">survey</span> participant **1**\npostal **code1** ----- &hellip; <span class=\"highlight\">survey</span> participant **2**\npostal **code1** ----- <span class=\"highlight\">survey</span> participant **3**\npostal **code2** ----- <span class=\"highlight\">survey</span> participant **1**\npostal **code2** ----- <span class=\"highlight\">survey</span> participant **2**\nand so on ... &hellip; "
    },
    {
        "question": "How can I see the coordinate transformation parameters in QGIS?",
        "area": [
            "qgis",
            "coordinate-system",
            "parameters"
        ],
        "text": "You can see the proj string used by QGIS to transform from and to WGS84 when you look at \n\n, CRS tab, and search for the EPSG code or name of a CRS. All CRS are referenced by their EPSG code, or user defined CRS.\n\nUusally, all EPSG-codes are bundled with one certain transformation to WGS84 which was decided to be most appropriate. American NAD27 CRS are the only ones which use a ntv2 grid by default instead of three- or seven-parameter Helmert transformation.\n\nIf you are unhappy with the accuracy of a defined transformation, you can define a custom CRS with different +towgs84 parameters.\n\n\n\nEDIT\n\nFor your Lisbon datum example, which is a projection of EPSG:4207, the EPSG database offers several transformation parameters which can be found in http://svn.osgeo.org/gdal/trunk/gdal/data/datum_shift.csv:\n\n\n  214,1656,4207,4326,&quot;Parameter values from Lisbon to ETRS89 (1) (code\n  1655). Assumes ETRS89 and WGS 84 can be considered the same to within\n  the accuracy of the transformation. Replaced by Lisbon to WGS 84 (4)\n  (code 1988).&quot;,For applications to an accuracy of 3\n  metres.,1294,36.96,42.15,-9.55,-6.19,1,0,9606,\n  -280.9,-89.8,130.2,-1.721,0.355,-0.371,-5.92,0\n  \n  215,1944,4207,4326,&quot;Parameter values from Lisbon to ETRS89 (2) (code\n  1790). Assumes ETRS89 and WGS 84 can be considered the same to within\n  the accuracy of the transformation.&quot;,For applications to an accuracy\n  of 2 metres.,1294,36.96,42.15,-9.55,-6.19,1,1,9606,\n  -282.1,-72.2,120,-1.592,0.145,-0.89,-4.46,0\n  \n  216,1984,4207,4326,,For low resolution\n  applications.,1294,36.96,42.15,-9.55,-6.19,1,0,9603,\n  -304.046,-60.576,103.64,,,,,1\n  \n  217,1988,4207,4326,,For medium resolution\n  applications.,1294,36.96,42.15,-9.55,-6.19,1,0,9607,\n  -288.885,-91.744,126.244,1.691,-0.41,0.211,-4.598,0\n\n\nSo you see, that the low resolution transformation with three parameters is used in your example.\nIt is stored in http://svn.osgeo.org/gdal/trunk/gdal/data/gcs.csv under code 4207 and used by Qgis and other GIS software depending on proj.4.\n\nhttp://www.epsg-registry.org/ gives an accuracy of 5 metres for EPSG:1984 (note that transformations have their own code numbers). These values were first published by NIMA when WGS84 was introduced.\nBut its not what the local surveying authority recommends. You can also have a look at http://www.fc.up.pt/pessoas/jagoncal/coordenadas/index_en.htm\n\nIf you want it more accurate, try the ntv2 grid from http://www.igeo.pt/produtos/geodesia/Grelhas_NTv2.htm\n But its not what the local <span class=\"highlight\">surveying</span> authority recommends. &hellip; "
    },
    {
        "question": "Are North Arrows Pointless?",
        "area": [
            "cartography",
            "printing",
            "maps"
        ],
        "text": "I remember being taught that a north arrow must be present always except in few specific cases, which actually cover 99% of maps.\n\nYou typically do not need a north arrow when:\n\n\nthere is a geographic grid present\nthe map presents a well known area to the map user, e.g. the map of the world, Europe, or your whole country on one sheet\nthe map is part of a larger map set or atlas with given standardised orientation; typically this applies to maps produced by national survey offices etc.\n\n the map of the world, Europe, or your whole country on one sheet\nthe map is part of a larger map set or atlas with given standardised orientation; typically this applies to maps produced by national <span class=\"highlight\">survey</span> &hellip; "
    },
    {
        "question": "Converting .kml to different projection in QGIS",
        "area": [
            "qgis",
            "coordinate-system",
            "epsg",
            "ordnance-survey"
        ],
        "text": "KML files are always WGS 84/lon lat (http://www.opengis.net/def/crs/OGC/0/LonLat84). Save the KML file as an EPSG:27700 shapefile instead.\nAlternatively, you could download the Ordnance Survey OpenData Boundary-Line dataset, which is already in EPSG:27700. See:\nhttps://www.ordnancesurvey.co.uk/opendatadownload/products.html\n Alternatively, you could download the Ordnance <span class=\"highlight\">Survey</span> OpenData Boundary-Line dataset, which is already in EPSG:27700. See:\nhttps://www.ordnancesurvey.co.uk/opendatadownload/products.html &hellip; "
    },
    {
        "question": "Creating different diameter circles round points using QGIS",
        "area": [
            "qgis",
            "point"
        ],
        "text": "I want to map a tree survey. I am thinking that I will plot positional points of the trees and then add other data like tree type etc. to the attribute table later.\nIs there a way I can have an attribute that describes a radius or diameter, whichever is easier, of a circle round the point?\nIn fact I need two circles, one to describe the canopy radius/diameter and another to do the same for the root protection area.\nI am using QGIS 1.8.0\n I want to map a tree <span class=\"highlight\">survey</span>. I am thinking that I will plot positional points of the trees and then add other data like tree type etc. to the attribute table later. &hellip; "
    },
    {
        "question": "What is the highest obtainable resolution of FREE elevation data in the UK?",
        "area": [
            "dem",
            "elevation",
            "united-kingdom",
            "data"
        ],
        "text": "OS Terrain 50 contours (10m contours) for Great Britain (England, Scotland and Wales)\n\n\n  It is supplied both as a set of 50m gridded digital terrain model (OS\n  Terrain 50 grid) and 10m contours and spot heights (OS Terrain 50\n  contours).\n\n\nNotice: OS Terrain 50 contours and OS Terrain 50 grid are now available as of 8th July 2013.\n\nTip: Opt for the OS Terrain 50 - ESRI SHAPE (CONTOURS) - GB\n\nhttp://www.ordnancesurvey.co.uk/business-and-government/products/terrain-50.html\n\nUpdate: 27th October 2015.\nWith a lot of processing it is possible to get even more detailed elevation data (for England currently) from Environmental Agency Opendata LiDAR example http://environment.data.gov.uk/ds/survey#/download?grid=TL45 has 1m res LiDAR which heights of features (including the ground) can be extracted.\n\nA Example of the contours created from LiDAR are here http://relief.raggedred.net/#18/53.76828/-0.36981 (Layers button &#39;contours&#39;) and zoom in.\n With a lot of processing it is possible to get even more detailed elevation data (for England currently) from Environmental Agency Opendata LiDAR example http://environment.data.gov.uk/ds/<span class=\"highlight\">survey</span>#/download &hellip; "
    },
    {
        "question": "Seeking GIS career advice?",
        "area": [
            "career"
        ],
        "text": "\n  This question has been converted to Community Wiki and wiki locked\n  because it is an example of a question that seeks a list of answers\n  and appears to be popular enough to protect it from closure.  It\n  should be treated as a special case and should not be viewed as the\n  type of question that is encouraged on this, or any Stack Exchange\n  site, but if you wish to contribute more content to it then feel free\n  to do so by editing this answer.\n\n\nCareer advice is best provided individually and, since the aim of the Main site of GIS SE is to maximize re-use of its answers, it should not be sought here.  However, once you have attained a reputation of 20 you are free to seek career advice in our GIS Chat Room.\n\n\n\nA good way to get your hands dirty is to contribute to one of the many FOSS projects out there. For instance, there are over 600 bugs in the QGIS database. It also has a good plugin architecture, so if you can think of something that hasn&#39;t been covered, then write and contribute your own plugin. I&#39;m on the developer mailing list, and they&#39;re a good bunch of people always on the lookout for people willing to contribute.\n\nHave a look at the OSGEO website which has a number of open source projects under its auspices that you could contribute to, which gives you a chance to find an area you&#39;re interested in. In fact, as you&#39;re educated to degree level, it would be a good idea to start thinking about concentrating on a few areas of expertise - do you want to deal with database programming, cartography, or like me combining my degree in archaeology with my love of all things maps and programming to advance the use of GIS in archaeology.\n\nA possibility might be to see if your national mapping agency is hiring. I worked for the Ordnance Survey in the UK as a GIS programmer with no prior GIS experience apart from a love of maps.\n\nAs for colleges, it depends on which country you&#39;re in and whether you&#39;re willing to move. In the UK, Leeds, Edinburgh, and Sheffield, to name just a few, have GIS courses, but they tend to be part of a more general geography degree.\n\n\n\n&#39;Making sure that you understand geodesy..to me..the kind of ideas underpinning GIS is paramount.  I have taken trigonometry and an assorted list of math curriculum.  Please correct me if I am wrong, I think Trigonometry is important in GIS programming for figuring out route and relationships between GIS data..for example, if the user picks a point and then wants to create the nearest point on all lines in a line dataset in relation to that point...programmatically...\n\n\n\nIn Canada, Fleming College, Centre of Geographic Sciences (COGS) and BC Institute of Technology (BCIT) are good choices. All I would recommend beyond the scope of what you&#39;ll absorb in a post-grad is that you familiarize yourself with a greater range of open-source software. Mostly you&#39;ll learn using the ESRI suite, which is licensed to colleges free I believe, but many in the industry will opt to avoid the licensing fees or they like to juggle different software. Job postings frequently mention FME, PostGIS, Geoserver, etc.\n\nOne more thing. Even with a programming focus, you would do well to create a portfolio with some stellar maps. The industry cites map-production skills frequently. \n\nThe demand for fresh, skilled GIS workers does not seem great anymore though.\n I worked for the Ordnance <span class=\"highlight\">Survey</span> in the UK as a GIS programmer with no prior GIS experience apart from a love of maps. &hellip; "
    },
    {
        "question": "Help using the US American Community Survey Data",
        "area": [
            "data",
            "census"
        ],
        "text": "You want to assemble a nationwide set in one file? For how many variables?\n\nThere are a few hoops to get over to actually connect the STFIDs in your shapefile with the data. I couldn&#39;t read if your primary problem is decoding the naming schemes of the files and figuring out what is in each, or if it was about relating the primary keys of the shape file and data files. At any rate, here is one way. I must say that I refer to the ACS 2005-2009 sample, but it seems the structure is analogous:\n\n\nGet the data file. Sounds like you downloaded the entire nationwide dataset? The one you refer to is from ACS 2009, Alaska, segment 0001 (because there are so many fields in the ACS summary file, the bureau segments them into more than 100 separate files for the estimates and 100 additional files containing margins of errors. These files have an &quot;m&quot;-prefix (for each state).\nYou will need the table headers, too. For ACS they are stored in xls files.\nSTFID is one way to uniquely refer to a block group. Another is LOGRECNO, which is the field actually found in the data files. You need to relate that using one of the geo files (also xls). For instance, the california one is here. STFID is a shorter version of column C (the last 15 or so characters; don&#39;t remember the exact number for block groups, but it identifies a two digit code for state, a three digit code for county, a six digit code for tract, and a (I think) four one digit code for block group). For example, a block group in San Francisco would be 060750101001  or so.\nIf you are only interested in a handful of variables it is a lot easier just to fetch those tables from American Factfinder. I think most ACS surveys are now on factfinder2.\nlastly, when I was dealing with this, I found this document useful, albeit for the five year sample. This one is available for the 1-year sample.\n\n You want to assemble a nationwide set in one file? For how many variables?\n\nThere are a few hoops to get over to actually connect the STFIDs in your shapefile with the data. I couldn&#39;t read if your pr &hellip; "
    },
    {
        "question": "maximum circle inside an irregular polygon from a random point",
        "area": [
            "polygon",
            "circle"
        ],
        "text": "I am trying to work out an algorithm for creating the maximum radius circle within an irregular polygon (a census tract) based on a given center of the circle.\n\nThe motivation for this is to obscure the location of an individual who has answered a survey. Their actual location is known, however it needs to be obscured in the analysis, in order to release the data to the public, for further analysis.\n\nWe want to have a donut shaped polygon for each survey respondent that has some inside radius (easy), bounded by an outside radius that is constrained by the census tract that the individual is in. Their final location will be randomly placed within the donut polygon.\n\nI have seen many answers to similar questions here, but not this specific one, which in this case starts with a SPECIFIC location.\n\nOnce we have the donut established, we can randomize the location of the individual response within the polygon. That&#39;s relatively easy... \n\nThanks for your ideas, mine so far have seemed pretty brute force, and computationally &quot;expensive&quot; or inefficient... \n The motivation for this is to obscure the location of an individual who has answered a <span class=\"highlight\">survey</span>. &hellip; We want to have a donut shaped polygon for each <span class=\"highlight\">survey</span> respondent that has some inside radius (easy), bounded by an outside radius that is constrained by the census tract that the individual is in. &hellip; "
    },
    {
        "question": "How do you treat partial 3d features in PostGIS?",
        "area": [
            "postgis",
            "data",
            "3d",
            "model"
        ],
        "text": "We have features from survey data that contain partial 3d information. \n\nThe most common example would be a 2D LineString representing a road, that contains elevation information in certain points where it was surveyed. Other examples include roof shapes - A MultiLineString where some key points have an assigned elevation from the building plan, but not all.\n\nUsing PostGIS, which data model would you recommend to store this kind of information, to keep it as accessible as possible, without losing or generating interpolated information? \n We have features from <span class=\"highlight\">survey</span> data that contain partial 3d information. &hellip; "
    },
    {
        "question": "Creating polygon using coordinates",
        "area": [
            "qgis",
            "latitude-longitude",
            "polygon-creation"
        ],
        "text": "To give an example according to @geom recommendation. You must use the syntax to define polygons in WKT format,  here an example in CSV:\n\n\n\nFinally use add delimited text data source:\n\n\n\nWith the following result:\n\n\n\nTo edit the question to provide an example of where I need to create a polygon via distances. \n\nI need to create a polygon to represent a survey area. The survey area required is 3.58km x 3.0km. I have used the  and the  tool. Which I select a certain point to buffer Around to create the survey area. However I cant find any input within these tools where I can enter such distances. Do you know how to fix this?\n I need to create a polygon to represent a <span class=\"highlight\">survey</span> area. The <span class=\"highlight\">survey</span> area required is 3.58km x 3.0km. I have used the v.buffer GRASS tool and the Buffer tool. &hellip; Which I select a certain point to buffer Around to create the <span class=\"highlight\">survey</span> area. However I cant find any input within these tools where I can enter such distances. Do you know how to fix this? &hellip; "
    },
    {
        "question": "Naming clipped layer according to the attributes of the mask layer in QGIS",
        "area": [
            "qgis",
            "clip",
            "modis"
        ],
        "text": "I have calculated the dnbr for a fire season across a whole region, and I&#39;ve clipped it using a mask.\nThe mask is a layer of ground survey plot locations because I want to find out the dnbr for each plot. Each plot has a number under the field &#39;ID&#39;. I have clipped the dnbr to each plot location but has returned (over 100 of) these new clipped files as &#39;new_clip&#39;and a number irrelevant to the plot number. So I can&#39;t see which dnbr matches to which plot. I would like the new clipped files to look something like &#39;ID_247_clip&#39;.\nI&#39;ve done this via : input is Whole Region dNBR, overlay is plot locations. Then I&#39;ve clicked the  button. It gives me exactly what I need, just with the wrong title for the clipped layers.\nIs there a way to program the clip to name each layer according to the plot numbers in the ID field?\nI&#39;ve tried executing in batch mode but this doesn&#39;t work, as I only have one input and one overlay layer, whereas bulk seems to work for multiple input layers.\nAlso, a lot of the plot locations overlap, so I can&#39;t do anything like join by location.\n\n The mask is a layer of ground <span class=\"highlight\">survey</span> plot locations because I want to find out the dnbr for each plot. Each plot has a number under the field &#39;ID&#39;. &hellip; "
    },
    {
        "question": "What file format has 18n, 18g and 18o file extensions?",
        "area": [
            "qgis",
            "convert",
            "gps",
            "format",
            "files"
        ],
        "text": "Those files are Receiver Independent Exchange Format (RINEX). Which is an open source standard for raw satellite navigation system data. For more information about the file format standards refer to this document. That document is quite thorough but a (very) brief description of the files:\n\n\n18 in the file extension refers to two digit year the data was collected in.\n*o is an observation file. The meat of the data this contains the raw observable(s) collected in the field (C/A code, P or Y code, L1 and L2 or time, phase and range).\n*n is a navigation file.\n*g is a GLONASS navigation file.\n*m is a meteorological data file.\nRINEX files are ASCII based files so you can open them with any text editor, although there is not much you can do without processing the files further.\n\n\nWithout knowing what your task is it is difficult to say how you should work with this data but one common way would be to upload your observation file (18o) to the National Geodetic Survey (NGS) Online Positioning User Service (OPUS) to solve for the solution of the observables in the file. Even though your data is from Ireland according to this article from GPS World OPUS can still process data collected outside the US if it meets certain requirements.\n Without knowing what your task is it is difficult to say how you should work with this data but one common way would be to upload your observation file (18o) to the National Geodetic <span class=\"highlight\">Survey</span> (NGS) Online &hellip; "
    },
    {
        "question": "Cleaning large Shapefile using v.clean in order to dissolve features?",
        "area": [
            "qgis",
            "shapefile",
            "dissolve",
            "simplify",
            "file-size"
        ],
        "text": "I&#39;m having real problems cleaning up and reducing the size of a Shapefile which is published by the UK&#39;s Environment Agency. \n\nIt shows the extents of the LiDAR open data they publish: each polygon is a survey flight, and there are fields for the resolution, the date of the flight and so on.\n\nEventually I&#39;d like to end up with a dissolved (merging all features) and simplified Shapefile which is much smaller in size. At the moment:\n\n\nThe .shp is 360.6MB\nThe .dbp is 26.9MB\nThere are 121,753 polygons\n\n\nI think one of the reasons the file is so large is that there are many small &#39;specks&#39; of data (which aren&#39;t important for my purposes):\n\n\n\nWhat I&#39;ve tried so far:\n\n\nDissolving with QGIS: this seemed to make no progress on such a big file so I cancelled it after a while\nDissolving with OGR (): after a few hours I would get an error like this:  \u2013 I guess this will just be the first of many errors\nCleaning the Shapefile, first with QGIS&#39;s Check Geometry Validity, then with GRASS&#39;s v.clean (I tried bpol), but the cleaned file still fails dissolve (I also tried adding a zero buffer)\nConverting the multipart polygons to singleparts, adding a geometry column and removing features smaller than a certain area. This took about 100MB off the filesize, but didn&#39;t affect the &#39;holes&#39; within polygons \u2013 to get rid of those I tried to make a difference layer, but the difference operation consistently fails (if I check ignore invalid geometry, it creates lots of features which are visible in the attribute table, but doesn&#39;t display them).\n\n\nI will simplify the file in the end, but don&#39;t want to do this before dissolving in case I introduce slivers.\n\nShould I use a different tool within v.clean? \n\nI have not yet tried to split the file into regions and dissolve those, then dissolve the regions. \n It shows the extents of the LiDAR open data they publish: each polygon is a <span class=\"highlight\">survey</span> flight, and there are fields for the resolution, the date of the flight and so on. &hellip; "
    },
    {
        "question": "Teaching Python to Land Surveyors",
        "area": [
            "python",
            "arcpy",
            "education",
            "land-survey",
            "teaching"
        ],
        "text": "Does anyone have any good examples of using Python to automate or simplify common surveying tasks? \n\nI&#39;m teaching a Python/ArcPy lab this week for a GIS class.  There are a number of surveying students in the class that think GIS is largely a waste of their time, and are only taking the course because it&#39;s required.  I want to give them something to be excited about.  \n\nA little context: Most of the students will probably be working for forestry or title companies when they graduate, and we are in Arkansas, so almost everything around here is based on PLSS.  So far, my thoughts are showing them the angular math functions and mentioning the couple of free Python-based CAD programs.  I&#39;ve also learned there is a project to write a plugin for AutoCAD that provides a Python interface.  \n\n\n\nI&#39;ve already taught the class, and as expected, the surveyors weren&#39;t too thrilled.  I&#39;d still love to hear any good examples of using Python to facilitate surveying.\n Does anyone have any good examples of using Python to automate or simplify common <span class=\"highlight\">surveying</span> tasks? \n\nI&#39;m teaching a Python/ArcPy lab this week for a GIS class. &hellip; I&#39;d still love to hear any good examples of using Python to facilitate <span class=\"highlight\">surveying</span>. &hellip; "
    },
    {
        "question": "What is the best technique for interpolating soil depth from sample points",
        "area": [
            "interpolation"
        ],
        "text": "This is my first post here.\n\nI have some points from a soil depth survey and I need to interpolate the depth for a whole area.  What is the most appropriate technique for this and is there anything I need to take into account when using the technique?  A pointer to a tutorial would be brilliant!\n\nThanks\n I have some points from a soil depth <span class=\"highlight\">survey</span> and I need to interpolate the depth for a whole area. &hellip; "
    },
    {
        "question": "How should I manage PostGIS Raster data with different projections?",
        "area": [
            "postgis",
            "raster"
        ],
        "text": "I have a requirement to store and manage archaeological geophysics data that is collected as a rectangular array of samples -- a raster image.\n\n\nEach raster will usually 20x20 or 30x30 floating-point samples, typically sampled at 1m intervals.\nA survey will consist of one or more of these images in a given location.\nIt is possible that two different surveys may take place in different countries, or areas that use different projections, but each survey will use one and only one projection. \nThey&#39;re never likely to be viewed together, each survey will usually sit by itself.\nThe data will only be accessed by a custom front-end, so there will be no users getting direct control of it through  or similar.\nEach sample needs to be stored as it was collected, so I can&#39;t reproject it into a common CRS such as Web Mercator because one sample could end up covering more or less area than in the original projection, and analysis will need to be performed on the data.\n\n\nHow should I best store the data in a PostGIS Raster database? The options I have come up with are:\n\n\nIgnore SRID constraints and store all the data in one table, writing my front-end code to deal with manipulating the data in a consistent manner.\nStore all the data in one table, and rewrite the SRID constraint as a compound of SRID and survey ID.\nThrough table inheritance, create a new table for each new SRID.\nThrough table inheritance, create a new table for each survey.\n\n\n1 and 2 break some of the nice automated parts of PostGIS, but will be otherwise hidden in front-end code. But queries will probably take slightly longer.\n\n3 and 4 could end up with an explosion of tables that would make it harder to manage FK constraints and so on.\n\nPractically, the number of rasters per survey is anywhere from 1 to 100 or more, and the number of surveys is likely to run into the hundreds. But the number of distinct projections is likely to remain very low, which favours 3.\n A <span class=\"highlight\">survey</span> will consist of one or more of these images in a given location. &hellip; They&#39;re never likely to be viewed together, each <span class=\"highlight\">survey</span> will usually sit by itself. &hellip; "
    },
    {
        "question": "Create a Raster file out of a ASCII grid file?",
        "area": [
            "qgis",
            "raster",
            "geotiff-tiff",
            "esri-ascii-raster"
        ],
        "text": "I&#39;m using a special system to do geomagnetic surveys. The software let&#39;s me output the information as image files, ASCII grid or in its own proprietary file format.\n\nNow I want to get its information in my GIS (using QGIS). I can of course import the exported image files but I would love to import the raw data to play around with the visualisation a bit more, not depending on the original software.\n\nThe files look like this:\n\n\n\nand so on..... (looooong file ;) )\n\nEvery 0.05 cm movement on X and Y contains a data value, positive and negative.\n\nI want to convert this data into a raster file, a pixel for every data value.\nMy goal is to tune the visualisation comparable to a DEM TIFF file in my QGIS project, without having the problem to export this through the original software every time.\n\nWhat would be the best way to do this?\n\nI think GDAL is the program to use I need some help. Perhaps there is even a way to do this in QGIS?\n\nUpdate:\n\nSo I finally imported a fraction of my data, sorting everything to Y.\nSaving everything as TIFF wasn&#39;t a problem as well. Now my next step is to get this spatially correct data (in terms of length) into my project. The coordinates in the file are just a local project oriented coordinate system.\n\nGeoreferencing the created TIFF wasn&#39;t a big problem but it results in a little annoying problem. after georeferencing my perfect square gets rotated a bit, resulting in big nodata areas. \n\nMy data also contains positive as well as negative data and even zero is important.\n\nI couldn\u2019t find a way to get this nodata area to disappear, QGIS  georeferencing gives it a value that is contained in the data areas as well.\nif I set this to transparency my raster files gets some annoying holes.\n I&#39;m using a special system to do geomagnetic surveys. The software let&#39;s me output the information as image files, ASCII grid or in its own proprietary file format.\n\nNow I want to get its information  &hellip; "
    },
    {
        "question": "Creating flow maps in QGIS",
        "area": [
            "qgis",
            "flow-map"
        ],
        "text": "I have several records from a survey and would like to show flow map from places mentioned in the survey. I have all places mentioned georeferenced and some records mentioned no places and others mentioned up to 16 places.\nI made a graphic so I can make myself clearer.\n\n I have several records from a <span class=\"highlight\">survey</span> and would like to show flow map from places mentioned in the <span class=\"highlight\">survey</span>. &hellip; "
    },
    {
        "question": "What does M-value represent?",
        "area": [
            "gis-principle",
            "terminology",
            "m-values"
        ],
        "text": "It is a measured distance along a route. A mile marker along a highway that is nominally 10.1 miles from some start (such as where the route crosses into a county) may not be exactly 10.1 miles. Someone surveys where certain landmarks, mile markers, or buildings are along the route exactly. These route events get an M value representing their measured location. A route feature has both its line and its measured locations, and other events, along it. A measured distance along a line has many uses, such as route planning.\nMeasured distance points can also be used to improve linear referencing. Some points that have been located exactly can be given higher weight, so that they have more influence on where new geocoded points are placed along a line. This is very important on long lonesome stretches of highway where there is not much to geocode from.\n It is a measured distance along a route. A mile marker along a highway that is nominally 10.1 miles from some start (such as where the route crosses into a county) may not be exactly 10.1 miles. Someo &hellip; "
    },
    {
        "question": "Viewshed Analysis - use DSM or DTM?",
        "area": [
            "viewshed",
            "visibility",
            "dem"
        ],
        "text": "Your choice of DSM vs DTM will depend on whether there is best-practice guidance or regulations governing the planning process for which you are performing the calculation.  \n\nFor instance, Viewshed Analysis for planning in the UK, especially for windfarms, requires that you use DTM data (and specifically Ordnance Survey data).  Analysis with DSM may be used as a supplementary presentation to demonstrate the screening effect of buildings and trees but a &#39;bald Earth&#39; calculation is the standard requirement.  The reason for this is that screening is rarely total and, in deciduous woodland areas, is also seasonal. On top of that trees can be cut down and buildings demolished.\n\nThis is why the phrases &#39;Zones of Theoretical Visibility&#39; (ZTV) or &#39;Zones of Visual Influence&#39; (ZVI) are used in many countries&#39; planning systems to describe the output of &#39;bald Earth&#39; (DTM) viewshed analysis, as it is the worst-case potential impact that is being measured.\n\nYou can only answer your question by reading the planning regulations that pertain to your country, state or province.   While we are on the subject, the relevant planning regulations will almost certainly also specify the resolution of data required.  If you are in doubt, my advice is to use a 10m resolution and present both a worst-case (DTM) and current-reality (DSM) viewsheds with a radius of 15km (for structures up to 50m).  Then describe/show the differences in a narrative or 3rd map.\n\nAs it is unlikely you are going to use a 0.5m resolution DTM over a radius of 10km plus, a further problem with trying to calculate &#39;true viewsheds&#39; is that small/thin features such as walls and hedges may well either not be represented at all in the DSM or be over-stated in some areas.  Any clever planner/lawyer can instantly nullify the validity of your entire DSM-based calculation by an argument based on this fact and suggest that you are claiming a false level of accuracy.  This is another reason why a worst-case analysis is often required because the analysis gives a definite baseline for theoretical visibility within which some screening may be achieved by small structures, eye-height differences etc.  In individual contentious locations you are well advised to preform a line of sight calculation based on site-surveyed data of tree and building heights and present that as profile drawings.\n\nGiven the resolution of your height data and common radii over which the viewshed analysis must normally be run, it therefore only really makes sense to consider large areas/structures such as entire Woodland blocks and towns or villages in a DSM-based calculation.  A common approach for the second part f your question is to perform the calculation normally with a Bald Earth DTM supplemented with DSM data or a simple addition of +15m in woodland areas and +5m for building footprints and then mask these areas in the output (clearly stating that you have done so in notes on the map). The figures of 15m and 5m are deliberately conservative to counter any arguments that your analysis is intentionally disingenuous in its suggestion of screening.  These are just commonly used values.  Whatever value you use will need to be justified.\n\nFinally, 1.5m is a common value for eye height, but then so is 2m.  You can argue the 2m represents a VERY tall person but the logic is again, worst-case scenario with some compensation for terrain inaccuracy.  Again, read your planning guidance because there may be a specific height prescribed which you MUST use.\n For instance, Viewshed Analysis for planning in the UK, especially for windfarms, requires that you use DTM data (and specifically Ordnance <span class=\"highlight\">Survey</span> data). &hellip; "
    },
    {
        "question": "Where can I get ArcView 1.0?",
        "area": [
            "installation",
            "windows-7"
        ],
        "text": "From the The Surveying, Mapping &amp; GIS blog post blast from the past. (direct download link). You&#39;ll need Windows 3.1 or Windows for Workgroups, though I wouldn&#39;t be surprised if FreeDOS or Wine would work as well (or better!).\n From the The <span class=\"highlight\">Surveying</span>, Mapping &amp; GIS blog post blast from the past. (direct download link). &hellip; "
    },
    {
        "question": "Is a master&#39;s degree needed for a GIS career?",
        "area": [
            "education",
            "career",
            "belarus"
        ],
        "text": "Pursuing a MS is dependent upon your goals.  If you are interested in conducting scientific research, a MS (or PhD) is for you.  Having a MS opens doors in academia that would not normally exist with a BS.  For example, these are the education requirements for a mid-level research position in academia:  \n\n\n  Master\u2019s degree (or higher) in remote sensing, GIS, oceanography, or\n  related degree including a strong background in statistics,\n  mathematics, computer science, and/or engineering, and 2 years of\n  experience. \n  \n  OR \n  \n  Bachelor\u2019s degree in remote sensing, GIS, or related\n  science degree including a strong background in statistics,\n  mathematics, computer science, and/or engineering, and 5 years of\n  experience.\n\n\nLooking at the government sector, a MS is virtually required these days unless you have significant experience already.  The following are typical qualifications for a mid-level GIS job with the feds:\n\n\n  FOR THE GS-09 LEVEL, in addition to the educational requirements\n  listed above, applicants must have at least one year or twelve (12)\n  months of specialized experience equivalent to grade level GS-07 that\n  demonstrates:  work performing duties such as providing geographic\n  information systems (GIS) training and support with guidance for\n  resource conservation planning and the integration of GIS and planning\n  tools into daily operations; this would include business tools for a\n  variety of disciplines such as engineering, ecological, etc., and\n  other software applications as assigned; provide support with\n  assistance to state, field, and soil survey offices regarding ArcGIS,\n  soil data viewer, and other GIS software;  OR  applicants must have\n  two (2) years of progressively higher level graduate education leading\n  to a master&#39;s degree or master&#39;s or equivalent graduate degree\n  directly related to cartography.   Equivalent combinations of\n  education and experience are qualifying for this grade level.\n\n\nFor a mid-level private sector job (ESRI Support Analyst), the following requirements are nearly industry-wide:\n\n\n  Requirements:\n  \n  \n  Bachelor\u2019s in GIS, a related field, or equivalent work experience    while using GIS as a primary tool\n  \n  \n  Recommended Qualifications:\n  \n  \n  Master\u2019s in GIS, environmental science, geography, or other relevant    field\n  \n\n\nThe bottom line is a MS will jump start your career, provide increased opportunities and almost certainly yield a higher salary.\n include business tools for a\n  variety of disciplines such as engineering, ecological, etc., and\n  other software applications as assigned; provide support with\n  assistance to state, field, and soil <span class=\"highlight\">survey</span> &hellip; "
    },
    {
        "question": "Transformation parameters for Everest datum to WGS84",
        "area": [
            "coordinate-system",
            "parameters"
        ],
        "text": "You can put the WKT text into a text file, and run gdalsrsinfo on it:\n\n\n\nThe ellipsoid parameters look very much like , EPSG 4145:\n\n\n\nWhich gives you a 3-parameter transformation to WGS84. But according to the EPSG database the transformation is valid for Pakistan onshore, not India. For India, they suggest EPSG 4146:\n\n\n\nThe ellipsoid is slightly smaller, but the calculated offset is just about 4 centimeters, while the datum shift is given an accuracy of 10 to 25m.\n\nThe official NIMA TR8350.2 on the WGS84 Datum lists the following datums on page B.3-2:\n\n\n\nThe flattening is equal for all. Just to confuse, there are other Datums called &quot;Indian&quot; for Thailand, Cambodia and Vietnam, and Malaysia and Sri Lanka use the Everest ellipsoid as well.\n\nEverest 1956 is defined on page A.1-1 with , just the value you have for Everest 1962. The source notes that the 1956 datum was an adoption of a new yard to meter conversion factor.\n\nSee also this article on the conversion of the Everest 1956 datum: http://www.gisdevelopment.net/technology/ip/ma03037pf.htm\n\nThe article compares surveyed Everest 1956 coordinates with satellite-measured WGS84 coordinates of 11 major airports, and states offsets between measured and calculated WGS84 coordinates by up to 1 arc second (about 30m). The distortion is arbitrary across the country, so a 7-parameter datum shift will not give better values.\n\nThere might have been efforts to get more accurate datum conversions, but the surveying authority is keeping it secret. It might be considered as a case of national security.\n\nSee also http://lists.maptools.org/pipermail/proj/2012-November/006472.html and https://github.com/klokantech/epsg.io/issues/49\n There might have been efforts to get more accurate datum conversions, but the <span class=\"highlight\">surveying</span> authority is keeping it secret. It might be considered as a case of national security. &hellip; "
    },
    {
        "question": "Floating point: understanding their inaccuracy",
        "area": [
            "floating-point"
        ],
        "text": "The difference between float4 (32-bit float) and float8 (64-bit float, or double precision) depends on the context of what it is storing and how it is to be used. For many applications, float4 is sufficient, but GIS has particular demands on extra storage precision.\n\nConsider storing UTM coordinates to millimeter precision. You might have a Northing of  measured using fancy survey equipment. Stored as float4, the number truncates to , loosing the millimetres. Stored as float8, the extra digits are preserved (down to the picometre scale). The reason why storing UTM coordinates is challenging, requiring double precision storage, is that they are typically on the order of hundreds of thousands to millions in scale.\n You might have a Northing of 4833438.204 measured using fancy <span class=\"highlight\">survey</span> equipment. Stored as float4, the number truncates to 4833438, loosing the millimetres. &hellip; "
    },
    {
        "question": "Why do some maps show Sandy Island?",
        "area": [
            "google-maps",
            "web-mapping",
            "google-earth"
        ],
        "text": "There are 3 possible reasons what could have happened:\n\n\nThere was actually an island at that location, and is not longer present. The possibility of this is remote.\nThis could have been a Copyright Easter egg. This is mis-information that is put in a map, so that when someone copies it, you can use it as a red flag to indicate that copying took place. See this page for more examples. http://wiki.openstreetmap.org/wiki/Copyright_Easter_Eggs\nIt was an error. This could have been due to various reasons, as sinister as an unscrupulous survey company, who didn&#39;t actually survey the area, to something as simple, as it was copied from an old map that had a printing error.\n\n\nThis situation is an illustrative example of just how important metadata is, and how it should be maintained and saved when merging data from various sources.\n This could have been due to various reasons, as sinister as an unscrupulous <span class=\"highlight\">survey</span> company, who didn&#39;t actually <span class=\"highlight\">survey</span> the area, to something as simple, as it was copied from an old map that had a printing &hellip; "
    },
    {
        "question": "What to consider when hiring aerial LiDAR survey?",
        "area": [
            "data",
            "lidar",
            "canada",
            "business",
            "land-survey"
        ],
        "text": "My organization is considering hiring a company to capture new LiDAR data to help with current stormwater issues that we are currently experiencing. I am a GIS analyst that has been assigned with this task.\n\nOur current quote is for roughly 70 square km and the project deliverables will include:\n\n\n1m resolution orthophoto TIFF imagery. \n50cm resolution orthophoto TIFF imagery. \nTiled 11cm resolution orthophoto TIFF imagery - each image\ndelivered in ATS sections.\nLiDAR data collected with approximate 7 points per sq meter.\nRaster bare earth DEM produced from the LiDAR data. Two files will be delivered:\n\n\n1 - 50cm grid spacing. \n1 - 1m grid spacing.\n\n6 new survey checkpoints.\n\n\nWe have been quoted roughly $30000 CAD (canadian dollars). \n\n\nIs cost of new LiDAR data reasonable for deliverables provided?\nWhat else should be considered when hiring aerial LiDAR survey?\n\n\nAny feedback would be great. I have never had the luxury of being included in data purchases so this is all new to me.\n Two files will be delivered:\n\n\n1 - 50cm grid spacing. \n1 - 1m grid spacing.\n\n6 new <span class=\"highlight\">survey</span> checkpoints.\n\n\nWe have been quoted roughly $30000 CAD (canadian dollars). &hellip; What else should be considered when hiring aerial LiDAR <span class=\"highlight\">survey</span>?\n\n\nAny feedback would be great. I have never had the luxury of being included in data purchases so this is all new to me. &hellip; "
    },
    {
        "question": "Capturing accurate GPS points using mobile devices",
        "area": [
            "gps",
            "android",
            "mobile",
            "ios"
        ],
        "text": "I&#39;m  currently working in Vietnam as a climbing guide, but am putting my GIS skills to use by doing a side project for the company involving the mapping of climbing routes. Along with another employee who is an app developer, our goal is produce a digital guidebook for the area.\n\nFor this project to work for me, I need to be able to take fairly accurate GPS points, as there are features just a few meters apart from each other that need to be distinguishable, but obviously survey grade equipment is not and option for me here. I&#39;ve been using the app GPS Averaging to take several hundred points for each location.\n\nDespite taking these averages, I&#39;m having very little luck achieving accuracy in my output points, and I suspect my precision is low as well because the in app reported error gets very low (0.8m) after about 20 collected points, then goes up to about 3m after 200-300 collected points. However when I import these points, the actual errors appear to be well beyond 3 meters.\n\nWhat can I do to improve GPS point accuracy from a mobile device?\n\nI&#39;ve currently only worked on this with android devices, but have access to ios devices too if they provide superior GPS chips.\n For this project to work for me, I need to be able to take fairly accurate GPS points, as there are features just a few meters apart from each other that need to be distinguishable, but obviously <span class=\"highlight\">survey</span> &hellip; "
    },
    {
        "question": "Label placement on rotated map in QGIS",
        "area": [
            "qgis",
            "labeling"
        ],
        "text": "I&#39;m a newbie to GIS and QGIS (please be nice to me).  I&#39;m working on a map for a garden/arboretum catalogue using QGIS 2.6.1.  The arboretum has been surveyed using GPS, and the specimen trees and plants become a point layer labelled with a reference number, which points to a description in the main catalogue.\n\nBecause of the site layout and orientation, the map needs to be rotated to fit comfortably on a rectangular canvas (paper, screen).  Fine, I can do that in print composer.  But that rotates the labels too, and for maximum legibility I want them to stay horizontal.\n\nI&#39;ve been experimenting with label placement. &quot;Around point&quot; gives significantly better results than &quot;Offset from point&quot;.  Using this method, the only way I&#39;ve found to apply a compensating rotation to the labels (so that when the map is rotated they end up back horizontal) is to add a &quot;rotation&quot; column to the attribute table and use data defined rotation.  But this to some extent messes up the label placement.  So my first question is:  is it possible to get the placement engine to run (again?) after the labels have been rotated?\n\nIf not, I would like to be able to reposition a few of the labels manually, but leave most of them automatically placed.  But if I add coordinate x and y columns to the attribute table and try to use data defined coordinates, then label rotation stops working if there is a NULL value in either or both of the x and y coordinate columns.  I can&#39;t leave most of the points to be automatically placed and just fix a few - effectively I have to do manual placement for all of them if I want to do it for any of them.  Since there are approx. 200 of the things, that&#39;s a major chore.  Have I missed something?\n\nSome of this might be easier if the &quot;Move label&quot; button would work.  But however I&#39;ve fiddled - with editing on/off, data defined placement on/off and so on - I&#39;ve never seen the thing not greyed out.  What do I need to do to get this working?\n\nThe best I&#39;ve been able to do is have a data defined distance override for some points.  This is rather hit and miss, because there&#39;s not much control over where the label will actually go, and it has unpredictable knock-on, domino effects on other labels some of which may end up worse than they were before.  But it doesn&#39;t affect label rotation.\n I&#39;m a newbie to GIS and QGIS (please be nice to me).  I&#39;m working on a map for a garden/arboretum catalogue using QGIS 2.6.1.  The arboretum has been surveyed using GPS, and the specimen trees and pla &hellip; "
    },
    {
        "question": "Raster incorrectly reprojected to OSGB(27700) using QGIS",
        "area": [
            "qgis",
            "coordinate-system"
        ],
        "text": "There was a lot of discussion on that lately:\nOSGB36 to WGS84 reprojection &#39;error&#39;\nhttp://osgeo-org.1560.n6.nabble.com/OSGB-coordinates-to-WGS84-lat-lon-problem-td4965339.html\nhttps://stackoverflow.com/questions/1426941/proj-4-library-and-osgb36\nIf you want it very exact, use the +nadgrids and .gsb file mentioned. Here I gave some command line examples: How to reproject a raster file in QGIS with datum transformation?\nIf you want your data to fit to each other, always use the same +towgs84 instead of +datum.\nIn your case, update the GDAL to 1.9.2.\nFor clarification: the ellipsoids airy and WGS84 do not match exactly. Therefore the +towgs84  parameters were invented. But these even change across the country. The +nadgrids takes this into account.\n\nJust to explain a bit deeper:\nEPSG:27700 is originally only a definition for the projection and ellipsoid used. Datum shift transformations from one ellipsoid to another are listed seperately by EPSG, with their own EPSG codes. There are several transformations available from OSB1936 to WGS84, depending on the region or wanted accuracy. These are:\n\nthe official grid datum can be obtained here: http://www.ordnancesurvey.co.uk/business-and-government/help-and-support/navigation-technology/os-net/ostn02-ntv2-format.html\nThe three-parameter-transformations were published by NIMA in the last century calculated from measuring of a handfull of satellite stations, while the seven parameters are published by Ordnance Survey more recently.\nSo depending on the GDAL version a raster is georeferenced with, you might get an offset, or might not.\n\nrelief is on the way:\nhttp://trac.osgeo.org/gdal/changeset/25589\nSo there is a good chance that the seven-parameter transformation will be back in the next QGIS version.\n format.html\nThe three-parameter-transformations were published by NIMA in the last century calculated from measuring of a handfull of satellite stations, while the seven parameters are published by Ordnance <span class=\"highlight\">Survey</span> &hellip; "
    },
    {
        "question": "Creating grid in QGIS &#39;anchored&#39; to specific point",
        "area": [
            "qgis",
            "coordinates",
            "vector-grid",
            "grids-graticules"
        ],
        "text": "I need to create grids using QGIS with specific intervals &#39;anchored&#39; to, or beginning at, a specific UTM coordinate. This is for a survey sampling procedure. For example: a point was determined - UTM 0561111, 6111111, as the starting point and I must create a grid with 92m spacing extending north and east for the extent of the polygon. The intersection of those gridlines will be unbiased sample points.\nI can&#39;t seem to &#39;anchor&#39; the grid to the starting point using &quot;Create Grid&quot; or MMQGIS &quot;Create Grid Layer&quot;. I&#39;d like to be able to do this with QGIS 3.4. Here&#39;s a sketch of what is needed.\n This is for a <span class=\"highlight\">survey</span> sampling procedure. &hellip; "
    }
]